# Background

I have long thought that LLMs are a useful component of intelligent systems but not the whole thing; they seem to function rather as the human subconscious does, for instance, when writing this the next word appears from somewhere, I don't have to ploddingly think through each one. In contrast, if trying to do an integration by parts I would have to look up how to do it and then follow the steps with a slow, clumsy conscious process. 

Recently I was wondering about the "maze of twisty passages all alike" and asked chatgpt about it, it replied that that was from the early text adventure "Colossal Cave" and offered to act as the game engine for me. We had a nice game.

Then I saw Sabine Hossenfelder's video in which she mentioned that early LLMs had displayed the emergent property of being able to do simple arithmetic, but that this ability had not progressed far since then. This seemed very weird to me when LLMs are now vastly more capable than any one human in dozens of areas at once.

So I tried asking chatgpt to devise a script for doing digit-by-digit arbitrary length multiplication; it did so, and once we had ironed out a small imprecision in the spec of the script it was able to follow it reliably and perform long multiplications; quite quickly even.

# The Idea (if it even rises to that level, it seems so obvious)

It struck me that we are expecting LLMs to display human-like abilities and derive emergent properties in a very inefficient way, when all we really need to do is "tell them how". Right now LLM engineers mostly use a giant hammer of training data to force LLMs to learn. Even when people ask LLMs to do things "step-by-step" -- an early prompt engineering technique, we're still being rather inscrutable -- why not just give the LLM the procedure to follow? Hence, my early thought on NeuroScript -- a very simple, slightly standard way of providing instructions.

Naturally, once we have a standard way of instructing LLMs we want to be able to provide whole libraries of such "skills"; and then to have the LLMs themselves write additional scripts so we don't have to -- they seem quite able to write them even if they don't know to follow them without being told. Hence the idea of having LLMs write scripts and also of having them in a repo and being able to look them up in real time via an LLM-friendly index.

We would like to allow continuous addition of abilities to LLMs -- right now you kinda have to wait for the next version and you really have to rely on OpenAI et al to add stuff. Fine tuning and (extant) prompt engineering only get you so far.

Next, of course, is the idea of LLMs being able to update and improve the scripts.

Also, share skills among many LLMs

Also, it seems sensible to have the ability to execute purely mechanical scripts in golang at GIPS rather than LLM at dozens of tokens/sec.

Also, the ability for scripts to spawn LLM subprocesses for LLMy-type tasks such as evaluating natural language would be good.

Also, the ability to manage and conserve context since this is limited resource when calling LLMs

# What does this add

Adds human-style conscious "discrete logic" reasoning abilities to LLMs, which only kind-of have them
Permits reliable, repeatable performance of somewhat defined tasks
Permits sharing skills among LLMs easily
Probably allows lesser LLMs to perform at the level of more capable LLMs. I think that most modern models are vastly more capable than they really need to be. We already see many vendors using a mixture of models for tasks to save resources. I think NeuroScript simply makes it easier to share this process.
Allows any LLM use to add ability to their LLM continuously in (near) real time

# Is it new?

Not really, but I haven't seen this formulated in this way yet.

# What are the pieces of a useful system?

1. A git repo of NeuroScripts (enables version control etc, recharging vector db index etc.)
2. A vector database index of them
3. A golang ns interpreter that:
  - starts up the LLM query
  - does context housekeeping
  - manages spawned sub-tasks and golang to LLM calls
  - enables LLM to golang calls
  - does vector db queries for nss
  - manages interaction with the git repo and keeps the vector index up to date
  - executes ns than it can do by itself


In the future, please give the full file if there is more than one copy/paste to do to vscode for it, otherwise (only one), give just the changed lines ta.

./gonsi/gonsi gonsi/skills HandleSkillRequest "Create a NeuroScript skill that reverses a given input string"